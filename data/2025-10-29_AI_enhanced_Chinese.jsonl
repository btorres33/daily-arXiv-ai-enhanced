{"id": "2510.24567", "categories": ["physics.acc-ph", "physics.plasm-ph"], "pdf": "https://arxiv.org/pdf/2510.24567", "abs": "https://arxiv.org/abs/2510.24567", "authors": ["Pablo J. Bilbao", "Thales Silva", "Luis O. Silva"], "title": "Phase-Space Shaping in Wakefield Accelerators due to Betatron Cooling", "comment": "13 pages, 7 Figures", "summary": "Plasma-based accelerators are beginning to employ relativistic beams with\nunprecedented charge and ultrashort durations. These dense driver beams can\ndrive wakes even in high-density plasmas ($\\gtrsim10^{19}$ cm$^{-3}$), where\nbetatron radiation becomes increasingly important and begins to affect the\ndynamics of the accelerated beam. In this Letter, we show that betatron cooling\nleads to a strong, structuring of the phase space of the beam. This gives rise\nto bunched, ring-like structures with positive radial position and momentum\ngradients, \\emph{i.e.}, population inversion of the amplitude of oscillation.\nWe derive the characteristic timescales for this process analytically and\nconfirm our predictions with multi-dimensional Particle-in-Cell simulations.\nThe radiation-dominated regime of beam dynamics fundamentally alters the\nacceleration process and produces self-structured beams capable of triggering\ncoherent betatron emission in ion channels.", "AI": {"tldr": "\u7b49\u79bb\u5b50\u4f53\u52a0\u901f\u5668\u4e2d\uff0c\u9ad8\u5bc6\u5ea6\u7b49\u79bb\u5b50\u4f53\u4e2d\u7684\u76f8\u5bf9\u8bba\u6027\u675f\u6d41\u901a\u8fc7\u62cd\u9891\u8f90\u5c04\u6548\u5e94\uff0c\u5bfc\u81f4\u675f\u76f8\u7a7a\u95f4\u7ed3\u6784\u5316\uff0c\u5f62\u6210\u5177\u6709\u6b63\u5f84\u5411\u4f4d\u7f6e\u548c\u52a8\u91cf\u68af\u5ea6\u7684\u73af\u72b6\u7ed3\u6784\uff0c\u5b9e\u73b0\u7c92\u5b50\u5e03\u5c45\u53cd\u8f6c\uff0c\u6b64\u8fc7\u7a0b\u53ef\u901a\u8fc7\u89e3\u6790\u548cPIC\u6a21\u62df\u5f97\u5230\u8bc1\u5b9e\uff0c\u5e76\u53ef\u80fd\u5f15\u53d1\u76f8\u5e72\u62cd\u9891\u8f90\u5c04\u3002", "motivation": "\u968f\u7740\u7b49\u79bb\u5b50\u4f53\u52a0\u901f\u5668\u4e2d\u4f7f\u7528\u7684\u76f8\u5bf9\u8bba\u6027\u675f\u6d41\u7684\u7535\u8377\u91cf\u548c\u6301\u7eed\u65f6\u95f4\u8fbe\u5230\u524d\u6240\u672a\u6709\u7684\u6c34\u5e73\uff0c\u5728\u4f20\u7edf\u4e0a\u96be\u4ee5\u5904\u7406\u7684\u9ad8\u5bc6\u5ea6\u7b49\u79bb\u5b50\u4f53\uff08\u5bc6\u5ea6\u5927\u4e8e10^19 cm^-3\uff09\u4e2d\uff0c\u62cd\u9891\u8f90\u5c04\u6548\u5e94\u65e5\u76ca\u663e\u8457\uff0c\u5e76\u5f00\u59cb\u5f71\u54cd\u88ab\u52a0\u901f\u675f\u6d41\u7684\u52a8\u529b\u5b66\u884c\u4e3a\u3002\u7406\u89e3\u5e76\u5229\u7528\u8fd9\u79cd\u6548\u5e94\u5bf9\u4e8e\u4f18\u5316\u52a0\u901f\u8fc7\u7a0b\u548c\u5b9e\u73b0\u65b0\u578b\u8f90\u5c04\u6e90\u81f3\u5173\u91cd\u8981\u3002", "method": "\u901a\u8fc7\u591a\u7ef4\u7c92\u5b50\u675f\u6a21\u62df\uff08Particle-in-Cell simulations\uff09\u548c\u89e3\u6790\u63a8\u5bfc\uff0c\u7814\u7a76\u4e86\u62cd\u9891\u8f90\u5c04\u5bf9\u675f\u6d41\u76f8\u7a7a\u95f4\u52a8\u529b\u5b66\u7684\u5f71\u54cd\u3002\u5177\u4f53\u5730\uff0c\u5206\u6790\u4e86\u62cd\u9891\u8f90\u5c04\u5bfc\u81f4\u7684\u675f\u6d41\u7ed3\u6784\u5316\uff0c\u5e76\u63a8\u5bfc\u4e86\u8be5\u8fc7\u7a0b\u7684\u7279\u5f81\u65f6\u95f4\u5c3a\u5ea6\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u62cd\u9891\u51b7\u5374\u6548\u5e94\u5728\u675f\u6d41\u76f8\u7a7a\u95f4\u4e2d\u4ea7\u751f\u4e86\u5f3a\u70c8\u7684\u7ed3\u6784\u5316\uff0c\u5f62\u6210\u4e86\u5177\u6709\u6b63\u5f84\u5411\u4f4d\u7f6e\u548c\u52a8\u91cf\u68af\u5ea6\u7684\u73af\u72b6\u7ed3\u6784\uff0c\u8fd9\u76f8\u5f53\u4e8e\u5b9e\u73b0\u4e86\u632f\u8361\u5e45\u5ea6\u7684\u5e03\u5c45\u53cd\u8f6c\u3002\u901a\u8fc7\u89e3\u6790\u548c\u6a21\u62df\uff0c\u9a8c\u8bc1\u4e86\u8be5\u7ed3\u6784\u5316\u7684\u5f62\u6210\u8fc7\u7a0b\u53ca\u5176\u65f6\u95f4\u5c3a\u5ea6\u3002", "conclusion": "\u5728\u8f90\u5c04\u4e3b\u5bfc\u7684\u52a8\u529b\u5b66\u673a\u5236\u4e0b\uff0c\u675f\u6d41\u7684\u52a0\u901f\u8fc7\u7a0b\u53d1\u751f\u4e86\u6839\u672c\u6027\u6539\u53d8\uff0c\u4ea7\u751f\u4e86\u80fd\u591f\u89e6\u53d1\u79bb\u5b50\u901a\u9053\u4e2d\u76f8\u5e72\u62cd\u9891\u8f90\u5c04\u7684\u81ea\u7ed3\u6784\u5316\u675f\u6d41\u3002\u8fd9\u4e00\u53d1\u73b0\u4e3a\u5229\u7528\u7b49\u79bb\u5b50\u4f53\u52a0\u901f\u5668\u4ea7\u751f\u9ad8\u4eae\u5ea6\u76f8\u5e72\u8f90\u5c04\u5f00\u8f9f\u4e86\u65b0\u7684\u9014\u5f84\u3002"}}
{"id": "2510.24618", "categories": ["physics.acc-ph"], "pdf": "https://arxiv.org/pdf/2510.24618", "abs": "https://arxiv.org/abs/2510.24618", "authors": ["Julien Dular", "Alexander Glock", "Arjan Verweij", "Mariusz Wozniak"], "title": "Distributed Inter-Strand Coupling Current Model for Finite Element Simulations of Rutherford Cables", "comment": "23 pages, 29 figures", "summary": "In this paper, we present the Distributed Inter-Strand Coupling Current\n(DISCC) model. It is a finite element (FE) model based on a homogenization\napproach enabling efficient and accurate simulation of the transient magnetic\nresponse of superconducting Rutherford cables without explicitly representing\nindividual strands. The DISCC model reproduces the inter-strand coupling\ncurrent dynamics via a novel mixed FE formulation, and can be combined with the\nReduced Order Hysteretic Magnetization (ROHM) and Flux (ROHF) models applied at\nthe strand level in order to reproduce the internal strand dynamics:\nhysteresis, eddy, and inter-filament coupling currents, as well as ohmic\neffects. We first analyze the performance of the DISCC model alone, as a linear\nproblem. We then extend the analysis to include the internal strand dynamics\nthat make the problem nonlinear. In all cases, the DISCC model offers a massive\nreduction of the computational time compared to conventional fully detailed FE\nmodels while still accounting for all types of loss, magnetization and\ninductance contributions. Rutherford cables homogenized with the DISCC model\ncan be directly included in FE models of magnet cross-sections for efficient\nelectro-magneto-thermal simulations of their transient response. We present two\npossible FE formulations for the implementation of the DISCC model, a first one\nbased on the h-phi-formulation, and a second one based on the\nh-phi-a-formulation, which is well suited for an efficient treatment of the\nferromagnetic regions in magnet cross-sections.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u5206\u5e03\u5f0f\u8de8\u5c42\u8026\u5408\u7535\u6d41\uff08DISCC\uff09\u7684\u6709\u9650\u5143\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u91c7\u7528\u5747\u8d28\u5316\u65b9\u6cd5\uff0c\u80fd\u591f\u9ad8\u6548\u51c6\u786e\u5730\u6a21\u62df\u8d85\u5bfc\u5362\u745f\u798f\u7535\u7f06\u7684\u77ac\u6001\u78c1\u54cd\u5e94\uff0c\u800c\u65e0\u9700\u663e\u5f0f\u8868\u793a\u5355\u4e2a\u5bfc\u4f53\u3002DISCC\u6a21\u578b\u901a\u8fc7\u4e00\u79cd\u65b0\u9896\u7684\u6df7\u5408\u6709\u9650\u5143\u516c\u5f0f\u518d\u73b0\u4e86\u8de8\u5c42\u8026\u5408\u7535\u6d41\u52a8\u529b\u5b66\uff0c\u5e76\u53ef\u4e0e\u57fa\u4e8e\u5bfc\u4f53\u5c42\u9762\u7684\u964d\u9636\u8fdf\u6ede\u78c1\u5316\uff08ROHM\uff09\u548c\u78c1\u901a\uff08ROHF\uff09\u6a21\u578b\u7ed3\u5408\uff0c\u4ee5\u91cd\u73b0\u5bfc\u4f53\u5185\u90e8\u7684\u8fdf\u6ede\u3001\u6da1\u6d41\u3001\u8de8\u4e1d\u8026\u5408\u7535\u6d41\u548c\u6b27\u59c6\u6548\u5e94\u7b49\u52a8\u529b\u5b66\u3002\u8be5\u6a21\u578b\u5728\u4fdd\u6301\u5bf9\u6240\u6709\u635f\u8017\u3001\u78c1\u5316\u548c\u7535\u611f\u8d21\u732e\u7684\u8003\u8651\u7684\u540c\u65f6\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u8ba1\u7b97\u65f6\u95f4\u3002", "motivation": "\u4f20\u7edf\u7684\u8d85\u5bfc\u5362\u745f\u798f\u7535\u7f06\u7684\u6709\u9650\u5143\u6a21\u578b\u5728\u6a21\u62df\u77ac\u6001\u78c1\u54cd\u5e94\u65f6\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\uff0c\u5c24\u5176\u662f\u5728\u9700\u8981\u8003\u8651\u5bfc\u4f53\u5185\u90e8\u590d\u6742\u52a8\u529b\u5b66\uff08\u5982\u8fdf\u6ede\u3001\u6da1\u6d41\u548c\u8026\u5408\u7535\u6d41\uff09\u65f6\u3002\u8fd9\u79cd\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\u9650\u5236\u4e86\u5728\u5927\u578b\u7535\u78c1\u7cfb\u7edf\uff08\u5982\u5f3a\u5b50\u5bf9\u649e\u673a\uff09\u4e2d\u8fdb\u884c\u8be6\u7ec6\u4eff\u771f\u548c\u8bbe\u8ba1\u4f18\u5316\u7684\u80fd\u529b\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u6a21\u578b\u6765\u51c6\u786e\u6355\u6349\u7535\u7f06\u7684\u7535\u78c1\u884c\u4e3a\uff0c\u4ee5\u652f\u6301\u66f4\u5feb\u7684\u4eff\u771f\u901f\u5ea6\u548c\u66f4\u5e7f\u6cdb\u7684\u5e94\u7528\u3002", "method": "\u672c\u6587\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u4e00\u79cd\u5206\u5e03\u5f0f\u8de8\u5c42\u8026\u5408\u7535\u6d41\uff08DISCC\uff09\u6709\u9650\u5143\u6a21\u578b\u3002\u8be5\u6a21\u578b\u57fa\u4e8e\u5747\u8d28\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e00\u79cd\u65b0\u9896\u7684\u6df7\u5408\u6709\u9650\u5143\u516c\u5f0f\u6765\u6a21\u62df\u8de8\u5c42\u8026\u5408\u7535\u6d41\u7684\u52a8\u529b\u5b66\uff0c\u800c\u65e0\u9700\u663e\u5f0f\u89e3\u6790\u6bcf\u6839\u5bfc\u4f53\u3002\u6b64\u5916\uff0cDISCC\u6a21\u578b\u53ef\u4ee5\u4e0e\u964d\u9636\u8fdf\u6ede\u78c1\u5316\uff08ROHM\uff09\u548c\u78c1\u901a\uff08ROHF\uff09\u6a21\u578b\u76f8\u7ed3\u5408\uff0c\u4ee5\u8003\u8651\u5bfc\u4f53\u5185\u90e8\u7684\u8fdf\u6ede\u3001\u6da1\u6d41\u3001\u8de8\u4e1d\u8026\u5408\u7535\u6d41\u4ee5\u53ca\u6b27\u59c6\u6548\u5e94\u3002\u6587\u7ae0\u5206\u6790\u4e86DISCC\u6a21\u578b\u5355\u72ec\u4f5c\u4e3a\u7ebf\u6027\u95ee\u9898\u65f6\u7684\u6027\u80fd\uff0c\u5e76\u8fdb\u4e00\u6b65\u5c06\u5176\u6269\u5c55\u5230\u5305\u542b\u5bfc\u4f53\u5185\u90e8\u52a8\u529b\u5b66\u7684\u975e\u7ebf\u6027\u95ee\u9898\u3002\u6587\u7ae0\u8fd8\u63d0\u51fa\u4e86\u4e24\u79cd\u5b9e\u73b0DISCC\u6a21\u578b\u7684\u6709\u9650\u5143\u65b9\u6cd5\uff1a\u4e00\u79cd\u57fa\u4e8eh-\u03c6\u516c\u5f0f\uff0c\u53e6\u4e00\u79cd\u57fa\u4e8eh-\u03c6-A\u516c\u5f0f\uff0c\u540e\u8005\u7279\u522b\u9002\u7528\u4e8e\u5904\u7406\u78c1\u4f53\u6a2a\u622a\u9762\u4e2d\u7684\u94c1\u78c1\u533a\u57df\u3002", "result": "\u4e0e\u4f20\u7edf\u7684\u5168\u89e3\u6790\u6709\u9650\u5143\u6a21\u578b\u76f8\u6bd4\uff0cDISCC\u6a21\u578b\u5728\u8ba1\u7b97\u6548\u7387\u4e0a\u5b9e\u73b0\u4e86\u6570\u91cf\u7ea7\u7684\u63d0\u5347\uff0c\u663e\u8457\u7f29\u77ed\u4e86\u8ba1\u7b97\u65f6\u95f4\u3002\u8be5\u6a21\u578b\u80fd\u591f\u51c6\u786e\u5730\u8003\u8651\u6240\u6709\u7c7b\u578b\u7684\u635f\u8017\u3001\u78c1\u5316\u548c\u7535\u611f\u8d21\u732e\u3002\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7DISCC\u6a21\u578b\u5747\u8d28\u5316\u540e\u7684\u5362\u745f\u798f\u7535\u7f06\u53ef\u4ee5\u76f4\u63a5\u96c6\u6210\u5230\u78c1\u4f53\u6a2a\u622a\u9762\u7684\u6709\u9650\u5143\u6a21\u578b\u4e2d\uff0c\u7528\u4e8e\u9ad8\u6548\u7684\u7535\u78c1-\u70ed\u77ac\u6001\u54cd\u5e94\u4eff\u771f\u3002", "conclusion": "DISCC\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u65b9\u6cd5\u6765\u6a21\u62df\u8d85\u5bfc\u5362\u745f\u798f\u7535\u7f06\u7684\u77ac\u6001\u78c1\u54cd\u5e94\uff0c\u540c\u65f6\u80fd\u591f\u8003\u8651\u5bfc\u4f53\u5185\u90e8\u590d\u6742\u7684\u7535\u78c1\u73b0\u8c61\u3002\u8be5\u6a21\u578b\u901a\u8fc7\u5747\u8d28\u5316\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u4f7f\u5f97\u5728\u5927\u578b\u7535\u78c1\u7cfb\u7edf\u4e2d\u8fdb\u884c\u8be6\u7ec6\u7684\u77ac\u6001\u4eff\u771f\u6210\u4e3a\u53ef\u80fd\u3002\u5176\u7075\u6d3b\u6027\u4f7f\u5176\u80fd\u591f\u4e0e\u73b0\u6709\u6a21\u578b\u7ed3\u5408\uff0c\u5e76\u9002\u7528\u4e8e\u5305\u542b\u94c1\u78c1\u6750\u6599\u7684\u590d\u6742\u51e0\u4f55\u7ed3\u6784\u3002\u672a\u6765\u5de5\u4f5c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63a2\u7d22\u8be5\u6a21\u578b\u5728\u4e0d\u540c\u5e94\u7528\u573a\u666f\u4e0b\u7684\u4f18\u5316\u548c\u9a8c\u8bc1\u3002"}}
{"id": "2509.19794", "categories": ["physics.acc-ph"], "pdf": "https://arxiv.org/pdf/2509.19794", "abs": "https://arxiv.org/abs/2509.19794", "authors": ["M. King", "A. D. Brynes", "F. Jackson", "J. K. Jones", "N. Ziyan", "M. A. Johnson", "K. Baker", "D. J. Scott", "E. Yang", "T. Kabana", "C. Garnier", "S. Chowdhury", "N. Neveu", "R. Roussel"], "title": "Controls Abstraction Towards Accelerator Physics: A Middle Layer Python Package for Particle Accelerator Control", "comment": null, "summary": "Control system middle layers act as a co-ordination and communication bridge\nbetween end users, including operators, system experts, scientists, and\nexperimental users, and the low-level control system interface. This article\ndescribes a Python package -- Controls Abstraction Towards Acclerator Physics\n(CATAP) -- which aims to build on previous experience and provide a modern\nPython-based middle layer with explicit abstraction, YAML-based configuration,\nand procedural code generation. CATAP provides a structured and coherent\ninterface to a control system, allowing researchers and operators to centralize\nhigher-level control logic and device information. This greatly reduces the\namount of code that a user must write to perform a task, and codifies system\nknowledge that is usually anecdotal. The CATAP design has been deployed at two\naccelerator facilities, and has been developed to produce a procedurally\ngenerated facility-specific middle layer package from configuration files to\nenable its wider dissemination across other machines.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3aCATAP\u7684Python\u5305\uff0c\u5b83\u4e3a\u52a0\u901f\u5668\u7269\u7406\u5b66\u63d0\u4f9b\u4e86\u4e00\u4e2a\u73b0\u4ee3\u5316\u7684\u63a7\u5236\u7cfb\u7edf\u4e2d\u95f4\u5c42\u3002CATAP\u901a\u8fc7\u663e\u5f0f\u62bd\u8c61\u3001YAML\u914d\u7f6e\u548c\u8fc7\u7a0b\u4ee3\u7801\u751f\u6210\uff0c\u7b80\u5316\u4e86\u7528\u6237\u7f16\u5199\u63a7\u5236\u903b\u8f91\u548c\u8bbe\u5907\u4fe1\u606f\u6240\u9700\u7684\u5de5\u4f5c\u91cf\uff0c\u5e76\u5c06\u7cfb\u7edf\u77e5\u8bc6\u7f16\u7801\u5316\u3002\u8be5\u5de5\u5177\u5df2\u5728\u4e24\u4e2a\u52a0\u901f\u5668\u8bbe\u65bd\u4e2d\u90e8\u7f72\uff0c\u5e76\u8bbe\u8ba1\u6210\u53ef\u751f\u6210\u7279\u5b9a\u4e8e\u8bbe\u65bd\u7684\u4e2d\u95f4\u5c42\u5305\uff0c\u4ee5\u4fbf\u63a8\u5e7f\u5230\u5176\u4ed6\u673a\u5668\u3002", "motivation": "\u73b0\u6709\u7684\u63a7\u5236\u7cfb\u7edf\u4e2d\u95f4\u5c42\u5728\u534f\u8c03\u7ec8\u7aef\u7528\u6237\uff08\u5982\u64cd\u4f5c\u5458\u3001\u4e13\u5bb6\u3001\u79d1\u5b66\u5bb6\u548c\u5b9e\u9a8c\u7528\u6237\uff09\u4e0e\u4f4e\u7ea7\u63a7\u5236\u7cfb\u7edf\u63a5\u53e3\u4e4b\u95f4\u5b58\u5728\u4e0d\u8db3\u3002\u9700\u8981\u4e00\u4e2a\u66f4\u73b0\u4ee3\u3001\u66f4\u6613\u4e8e\u4f7f\u7528\u7684\u89e3\u51b3\u65b9\u6848\u6765\u7b80\u5316\u7528\u6237\u7684\u5de5\u4f5c\uff0c\u5e76\u5bf9\u901a\u5e38\u4ee5\u8f76\u4e8b\u5f62\u5f0f\u5b58\u5728\u7684\u7cfb\u7edf\u77e5\u8bc6\u8fdb\u884c\u7f16\u7801\u3002", "method": "\u672c\u6587\u63cf\u8ff0\u4e86\u4e00\u4e2a\u540d\u4e3aCATAP\uff08Controls Abstraction Towards Acclerator Physics\uff09\u7684Python\u5305\u3002CATAP\u91c7\u7528\u663e\u5f0f\u62bd\u8c61\u3001\u57fa\u4e8eYAML\u7684\u914d\u7f6e\u548c\u8fc7\u7a0b\u4ee3\u7801\u751f\u6210\u3002\u5b83\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7ed3\u6784\u5316\u3001\u8fde\u8d2f\u7684\u63a5\u53e3\uff0c\u5141\u8bb8\u7814\u7a76\u4eba\u5458\u548c\u64cd\u4f5c\u5458\u96c6\u4e2d\u66f4\u9ad8\u5c42\u6b21\u7684\u63a7\u5236\u903b\u8f91\u548c\u8bbe\u5907\u4fe1\u606f\u3002CATAP\u7684\u8bbe\u8ba1\u5df2\u88ab\u90e8\u7f72\u5230\u4e24\u4e2a\u52a0\u901f\u5668\u8bbe\u65bd\uff0c\u5e76\u80fd\u591f\u4ece\u914d\u7f6e\u6587\u4ef6\u751f\u6210\u7279\u5b9a\u4e8e\u8bbe\u65bd\u7684\u4e2d\u95f4\u5c42\u5305\u3002", "result": "CATAP\u7684\u90e8\u7f72\u8868\u660e\uff0c\u5b83\u80fd\u591f\u663e\u8457\u51cf\u5c11\u7528\u6237\u7f16\u5199\u63a7\u5236\u4efb\u52a1\u6240\u9700\u7684\u4ee3\u7801\u91cf\uff0c\u5e76\u7cfb\u7edf\u5730\u8bb0\u5f55\u548c\u4f20\u64ad\u7cfb\u7edf\u77e5\u8bc6\u3002\u901a\u8fc7\u4ece\u914d\u7f6e\u6587\u4ef6\u751f\u6210\u7279\u5b9a\u4e8e\u8bbe\u65bd\u7684\u4e2d\u95f4\u5c42\u5305\uff0cCATAP\u80fd\u591f\u66f4\u5e7f\u6cdb\u5730\u4f20\u64ad\u5230\u5176\u4ed6\u673a\u5668\u3002", "conclusion": "CATAP\u4f5c\u4e3a\u4e00\u4e2a\u73b0\u4ee3\u5316\u7684Python\u63a7\u5236\u7cfb\u7edf\u4e2d\u95f4\u5c42\uff0c\u901a\u8fc7\u7b80\u5316\u7528\u6237\u4ea4\u4e92\u3001\u7f16\u7801\u7cfb\u7edf\u77e5\u8bc6\u548c\u4fc3\u8fdb\u8de8\u673a\u5668\u7684\u4f20\u64ad\uff0c\u5728\u52a0\u901f\u5668\u7269\u7406\u5b66\u9886\u57df\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\u3002\u8be5\u5de5\u5177\u7684\u6210\u529f\u90e8\u7f72\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\uff0c\u4e3a\u672a\u6765\u7684\u53d1\u5c55\u548c\u66f4\u5e7f\u6cdb\u7684\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2509.20995", "categories": ["physics.acc-ph"], "pdf": "https://arxiv.org/pdf/2509.20995", "abs": "https://arxiv.org/abs/2509.20995", "authors": ["Claire Hansel", "Agostino Marinelli", "Zhirong Huang", "Michael Litos"], "title": "Three Dimensional Theory of the Ion Channel Laser", "comment": null, "summary": "The ion channel laser (ICL) is a plasma-based alternative to the free\nelectron laser (FEL) that uses the electric field of a uniform-density ion\nchannel rather than the magnetic field of an undulator to induce transverse\noscillations of electrons in an ultrarelativistic bunch and thereby produce\ncoherent radiation via a collective electromagnetic instability. The powerful\nfocusing of the ion channel generally yields significantly higher gain\nparameters in the ICL as compared to the FEL. This permits lasing in extremely\nshort distances using electron bunches with an energy spread as large as a few\npercent; a value readily achievable with current plasma-based accelerators.\nICLs, however, impose stringent transverse phase space requirements on the\nelectron bunch beyond what is required in FELs. In this work, we present a\nnovel 3D theory of the planar off-axis configuration of the ICL that accounts\nfor a number of effects including diffraction, transverse radiation profile,\nfrequency and betatron phase detuning, and nonzero spread in energy and\nundulator parameter. We derive the ICL pendulum and field equations, which we\nuse to write down the 3D Maxwell-Klimontovich equations. After linearizing, we\nobtain an integro-differential equation describing the $z$-evolution of the\nradiation field. The 3D ICL dispersion relation is obtained using a Van Kampen\nnormal mode expansion. We numerically solve the $z$-evolution equation to\ncompute radiation power growth rates and transverse radiation profiles over a\nrange of different ICL parameters. We examine the gain reduction due to 3D\neffects, energy spread, and emittance. Electron bunch phase space and emittance\nrequirements for lasing are derived. Finally, we make general observations\nabout the performance and feasibility of the ICL and discuss future prospects.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u79bb\u5b50\u901a\u9053\u6fc0\u5149\u5668\uff08ICL\uff09\u7684 3D \u7406\u8bba\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u514b\u670d\u4e86\u81ea\u7531\u7535\u5b50\u6fc0\u5149\u5668\uff08FEL\uff09\u7684\u9650\u5236\uff0c\u5e76\u5728\u6781\u77ed\u8ddd\u79bb\u5185\u5b9e\u73b0\u9ad8\u589e\u76ca\u76f8\u5e72\u8f90\u5c04\uff0c\u5373\u4f7f\u7535\u5b50\u675f\u80fd\u91cf\u5c55\u5bbd\u8f83\u5927\u4e5f\u80fd\u5b9e\u73b0\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0cICL \u5177\u6709\u4f18\u4e8e FEL \u7684\u589e\u76ca\u53c2\u6570\uff0c\u4f46\u5bf9\u7535\u5b50\u675f\u7684\u6a2a\u5411\u76f8\u4f4d\u7a7a\u95f4\u8981\u6c42\u66f4\u9ad8\u3002\u8be5\u7406\u8bba\u6a21\u578b\u8003\u8651\u4e86\u884d\u5c04\u3001\u6a2a\u5411\u8f90\u5c04\u5206\u5e03\u3001\u9891\u7387\u548c betatron \u9636\u6bb5\u5931\u8c10\u4ee5\u53ca\u80fd\u91cf\u548c the undulator parameter \u5c55\u5bbd\u7b49\u591a\u79cd\u6548\u5e94\uff0c\u5e76\u63a8\u5bfc\u4e86 ICL \u7684\u674e\u8428\u5982\u56fe\u548c\u573a\u65b9\u7a0b\uff0c\u4ee5\u53ca 3D ICL \u8272\u6563\u5173\u7cfb\u3002\u6570\u503c\u6a21\u62df\u7ed3\u679c\u63ed\u793a\u4e86 3D \u6548\u5e94\u3001\u80fd\u91cf\u5c55\u5bbd\u548c\u53d1\u5c04\u7387\u5bf9\u589e\u76ca\u7684\u5f71\u54cd\uff0c\u5e76\u5f97\u51fa\u4e86 ICL \u5b9e\u73b0\u6fc0\u5149\u7684\u7535\u5b50\u675f\u76f8\u4f4d\u7a7a\u95f4\u548c\u53d1\u5c04\u7387\u8981\u6c42\u3002", "motivation": "\u81ea\u7531\u7535\u5b50\u6fc0\u5149\u5668\uff08FEL\uff09\u5728\u4ea7\u751f\u76f8\u5e72\u8f90\u5c04\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5176\u5bf9\u7535\u5b50\u675f\u7684\u8981\u6c42\u975e\u5e38\u82db\u523b\uff0c\u5c24\u5176\u662f\u5728\u80fd\u91cf\u5c55\u5bbd\u548c\u6a2a\u5411\u76f8\u4f4d\u7a7a\u95f4\u65b9\u9762\u3002\u79bb\u5b50\u901a\u9053\u6fc0\u5149\u5668\uff08ICL\uff09\u4f5c\u4e3a\u4e00\u79cd\u57fa\u4e8e\u7b49\u79bb\u5b50\u4f53\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u5229\u7528\u79bb\u5b50\u901a\u9053\u7684\u5f3a\u805a\u7126\u80fd\u529b\uff0c\u6709\u671b\u5728\u66f4\u77ed\u7684\u8ddd\u79bb\u5185\u5b9e\u73b0\u66f4\u9ad8\u7684\u589e\u76ca\uff0c\u5e76\u4e14\u5bf9\u7535\u5b50\u675f\u80fd\u91cf\u5c55\u5bbd\u7684\u5bb9\u5fcd\u5ea6\u66f4\u9ad8\uff0c\u8fd9\u4f7f\u5176\u5728\u4e0e\u7b49\u79bb\u5b50\u4f53\u52a0\u901f\u5668\u7ed3\u5408\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684 ICL \u7406\u8bba\u6a21\u578b\u672a\u80fd\u5145\u5206\u8003\u8651\u4e09\u7ef4\u6548\u5e94\uff0c\u9650\u5236\u4e86\u5176\u5728\u9ad8\u80fd\u91cf\u3001\u9ad8\u4eae\u5ea6\u5e94\u7528\u4e2d\u7684\u7cbe\u786e\u9884\u6d4b\u548c\u4f18\u5316\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u53d1\u5c55\u4e00\u4e2a\u66f4\u5168\u9762\u7684 3D ICL \u7406\u8bba\u6a21\u578b\uff0c\u4ee5\u51c6\u786e\u8bc4\u4f30\u5176\u6027\u80fd\uff0c\u5e76\u4e3a\u672a\u6765\u7684\u5b9e\u9a8c\u8bbe\u8ba1\u63d0\u4f9b\u6307\u5bfc\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u79bb\u5b50\u901a\u9053\u6fc0\u5149\u5668\uff08ICL\uff09\u7684 3D \u7406\u8bba\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u9488\u5bf9\u5e73\u9762\u79bb\u8f74\u914d\u7f6e\u8fdb\u884c\u4e86\u4f18\u5316\u3002\u7814\u7a76\u4eba\u5458\u9996\u5148\u63a8\u5bfc\u4e86 ICL \u7684\u674e\u8428\u5982\u56fe\u548c\u573a\u65b9\u7a0b\uff0c\u8fd9\u4e9b\u65b9\u7a0b\u8003\u8651\u4e86\u5305\u62ec\u884d\u5c04\u3001\u6a2a\u5411\u8f90\u5c04\u5206\u5e03\u3001\u9891\u7387\u548c betatron \u9636\u6bb5\u5931\u8c10\u4ee5\u53ca\u80fd\u91cf\u548c the undulator parameter \u5c55\u5bbd\u5728\u5185\u7684\u591a\u79cd\u6548\u5e94\u3002\u968f\u540e\uff0c\u5c06\u8fd9\u4e9b\u65b9\u7a0b\u4e0e 3D \u9ea6\u514b\u65af\u97e6-\u514b\u5229\u8499\u6258\u7ef4\u5947\u65b9\u7a0b\u76f8\u7ed3\u5408\uff0c\u5e76\u8fdb\u884c\u7ebf\u6027\u5316\u5904\u7406\uff0c\u5f97\u5230\u4e00\u4e2a\u63cf\u8ff0\u8f90\u5c04\u573a Z \u5411\u6f14\u5316\u7684\u8026\u5408\u5fae\u5206\u65b9\u7a0b\u3002\u5229\u7528 Van Kampen \u6b63\u5e38\u6a21\u5f0f\u5c55\u5f00\u65b9\u6cd5\uff0c\u63a8\u5bfc\u4e86 ICL \u7684 3D \u8272\u6563\u5173\u7cfb\u3002\u6700\u540e\uff0c\u901a\u8fc7\u6570\u503c\u6c42\u89e3 Z \u5411\u6f14\u5316\u65b9\u7a0b\uff0c\u8ba1\u7b97\u4e86\u5728\u4e0d\u540c ICL \u53c2\u6570\u4e0b\uff0c\u8f90\u5c04\u529f\u7387\u589e\u957f\u7387\u548c\u6a2a\u5411\u8f90\u5c04\u5206\u5e03\uff0c\u5e76\u5206\u6790\u4e86 3D \u6548\u5e94\u3001\u80fd\u91cf\u5c55\u5bbd\u548c\u53d1\u5c04\u7387\u5bf9\u589e\u76ca\u7684\u5f71\u54cd\uff0c\u4ece\u800c\u5f97\u51fa\u4e86 ICL \u5b9e\u73b0\u6fc0\u5149\u6240\u9700\u7684\u7535\u5b50\u675f\u76f8\u4f4d\u7a7a\u95f4\u548c\u53d1\u5c04\u7387\u8981\u6c42\u3002", "result": "\u901a\u8fc7\u6570\u503c\u6a21\u62df\uff0c\u7814\u7a76\u53d1\u73b0 ICL \u7684\u589e\u76ca\u53c2\u6570\u663e\u8457\u9ad8\u4e8e FEL\uff0c\u5e76\u4e14\u80fd\u591f\u5728\u6781\u77ed\u7684\u8ddd\u79bb\u5185\u5b9e\u73b0\u6fc0\u5149\u3002\u5373\u4f7f\u7535\u5b50\u675f\u7684\u80fd\u91cf\u5c55\u5bbd\u8fbe\u5230\u51e0\u4e2a\u767e\u5206\u6bd4\uff0cICL \u4ecd\u7136\u80fd\u591f\u4fdd\u6301\u8f83\u9ad8\u7684\u589e\u76ca\uff0c\u8fd9\u4e0e\u5f53\u524d\u7b49\u79bb\u5b50\u4f53\u52a0\u901f\u5668\u7684\u80fd\u529b\u76f8\u5339\u914d\u3002\u7136\u800c\uff0c\u7814\u7a76\u4e5f\u5f3a\u8c03\u4e86 ICL \u5bf9\u7535\u5b50\u675f\u6a2a\u5411\u76f8\u4f4d\u7a7a\u95f4\u63d0\u51fa\u4e86\u6bd4 FEL \u66f4\u4e3a\u4e25\u683c\u7684\u8981\u6c42\u30023D \u6548\u5e94\u3001\u80fd\u91cf\u5c55\u5bbd\u548c\u53d1\u5c04\u7387\u90fd\u4f1a\u5bfc\u81f4\u589e\u76ca\u964d\u4f4e\uff0c\u5177\u4f53\u964d\u4f4e\u5e45\u5ea6\u53d6\u51b3\u4e8e ICL \u7684\u53c2\u6570\u8bbe\u7f6e\u3002\u7814\u7a76\u7ed3\u679c\u8fd8\u91cf\u5316\u4e86\u5b9e\u73b0\u6fc0\u5149\u6240\u9700\u7684\u7535\u5b50\u675f\u53d1\u5c04\u7387\u548c\u76f8\u4f4d\u7a7a\u95f4\u9650\u5236\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684 3D ICL \u7406\u8bba\u6a21\u578b\u4e3a\u7406\u89e3\u548c\u4f18\u5316\u79bb\u5b50\u901a\u9053\u6fc0\u5149\u5668\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u5927\u7684\u5de5\u5177\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0cICL \u4f5c\u4e3a\u4e00\u79cd\u6709\u524d\u666f\u7684\u76f8\u5e72\u5149\u6e90\uff0c\u5728\u514b\u670d FEL \u7684\u4e00\u4e9b\u5c40\u9650\u6027\u65b9\u9762\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u5c24\u5176\u662f\u5728\u589e\u76ca\u548c\u5bf9\u80fd\u91cf\u5c55\u5bbd\u7684\u5bb9\u5fcd\u5ea6\u65b9\u9762\u3002\u7136\u800c\uff0c\u5176\u5bf9\u7535\u5b50\u675f\u6a2a\u5411\u76f8\u4f4d\u7a7a\u95f4\u7684\u9ad8\u8981\u6c42\u662f\u5b9e\u73b0\u9ad8\u6548 ICL \u7684\u5173\u952e\u6311\u6218\u3002\u672a\u6765\u7684\u5de5\u4f5c\u5e94\u96c6\u4e2d\u4e8e\u8fdb\u4e00\u6b65\u5b8c\u5584\u7406\u8bba\u6a21\u578b\uff0c\u5305\u62ec\u8003\u8651\u66f4\u590d\u6742\u7684\u79bb\u5b50\u901a\u9053\u6784\u578b\u548c\u66f4\u5e7f\u6cdb\u7684\u7b49\u79bb\u5b50\u4f53\u6548\u5e94\uff0c\u5e76\u7ed3\u5408\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u4ee5\u5145\u5206\u53d1\u6325 ICL \u7684\u6f5c\u529b\uff0c\u63a8\u52a8\u5176\u5728\u79d1\u5b66\u7814\u7a76\u548c\u5de5\u4e1a\u5e94\u7528\u4e2d\u7684\u53d1\u5c55\u3002"}}
{"id": "2510.23730", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.23730", "abs": "https://arxiv.org/abs/2510.23730", "authors": ["Alessandra Terranova", "Bj\u00f6rn Ross", "Alexandra Birch"], "title": "Evaluating Long-Term Memory for Long-Context Question Answering", "comment": "14 pages including appendix, 3 figures. Submitted to October ARR and\n  to Metacognition in Generative AI EurIPS workshop (under review for both)", "summary": "In order for large language models to achieve true conversational continuity\nand benefit from experiential learning, they need memory. While research has\nfocused on the development of complex memory systems, it remains unclear which\ntypes of memory are most effective for long-context conversational tasks. We\npresent a systematic evaluation of memory-augmented methods using LoCoMo, a\nbenchmark of synthetic long-context dialogues annotated for question-answering\ntasks that require diverse reasoning strategies. We analyse full-context\nprompting, semantic memory through retrieval-augmented generation and agentic\nmemory, episodic memory through in-context learning, and procedural memory\nthrough prompt optimization. Our findings show that memory-augmented approaches\nreduce token usage by over 90% while maintaining competitive accuracy. Memory\narchitecture complexity should scale with model capability, with small\nfoundation models benefitting most from RAG, and strong instruction-tuned\nreasoning model gaining from episodic learning through reflections and more\ncomplex agentic semantic memory. In particular, episodic memory can help LLMs\nrecognise the limits of their own knowledge.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u9700\u8981\u8bb0\u5fc6\u6765\u5b9e\u73b0\u5bf9\u8bdd\u7684\u8fde\u8d2f\u6027\u548c\u4f53\u9a8c\u5f0f\u5b66\u4e60\u3002\u672c\u7814\u7a76\u7cfb\u7edf\u8bc4\u4f30\u4e86\u4e0d\u540c\u8bb0\u5fc6\u589e\u5f3a\u65b9\u6cd5\u5728\u957f\u5bf9\u8bdd\u4efb\u52a1\u4e2d\u7684\u6548\u679c\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u8bb0\u5fc6\u589e\u5f3a\u65b9\u6cd5\u53ef\u5c06token\u4f7f\u7528\u91cf\u51cf\u5c1190%\u4ee5\u4e0a\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\u3002\u6a21\u578b\u80fd\u529b\u5e94\u4e0e\u8bb0\u5fc6\u67b6\u6784\u590d\u6742\u5ea6\u76f8\u5339\u914d\uff0c\u5c0f\u6a21\u578b\u66f4\u9002\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\uff0c\u800c\u5f3a\u5927\u7684\u6307\u4ee4\u5fae\u8c03\u6a21\u578b\u5219\u53d7\u76ca\u4e8e the episodic learning\uff08\u901a\u8fc7\u53cd\u601d\u548c\u66f4\u590d\u6742\u7684agentic semantic memory\uff09\u3002\u7279\u522b\u662f\uff0cepisodic memory\u80fd\u5e2e\u52a9LLM\u8ba4\u8bc6\u5230\u81ea\u8eab\u77e5\u8bc6\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u4e3a\u4e86\u4f7f\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u80fd\u591f\u5b9e\u73b0\u771f\u6b63\u7684\u5bf9\u8bdd\u8fde\u8d2f\u6027\u5e76\u4ece\u4f53\u9a8c\u5f0f\u5b66\u4e60\u4e2d\u53d7\u76ca\uff0c\u5b83\u4eec\u9700\u8981\u8bb0\u5fc6\u3002\u5c3d\u7ba1\u5df2\u6709\u7814\u7a76\u81f4\u529b\u4e8e\u5f00\u53d1\u590d\u6742\u7684\u8bb0\u5fc6\u7cfb\u7edf\uff0c\u4f46\u5bf9\u4e8e\u54ea\u79cd\u7c7b\u578b\u7684\u8bb0\u5fc6\u5bf9\u4e8e\u957f\u4e0a\u4e0b\u6587\u5bf9\u8bdd\u4efb\u52a1\u6700\u6709\u6548\uff0c\u76ee\u524d\u5c1a\u4e0d\u6e05\u695a\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u65e8\u5728\u7cfb\u7edf\u5730\u8bc4\u4f30\u4e0d\u540c\u7684\u8bb0\u5fc6\u589e\u5f3a\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3\u8fd9\u4e00\u5173\u952e\u95ee\u9898\uff0c\u5e76\u4e3aLLM\u5728\u957f\u5bf9\u8bdd\u573a\u666f\u4e0b\u7684\u8bb0\u5fc6\u673a\u5236\u63d0\u4f9b\u6307\u5bfc\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u5e76\u8bc4\u4f30\u4e86\u591a\u79cd\u8bb0\u5fc6\u589e\u5f3a\u65b9\u6cd5\uff0c\u5305\u62ec\uff1a1. \u5168\u4e0a\u4e0b\u6587\u63d0\u793a\uff08full-context prompting\uff09\uff1b2. \u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u5b9e\u73b0\u7684\u8bed\u4e49\u8bb0\u5fc6\uff08semantic memory\uff09\uff1b3. \u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08in-context learning\uff09\u5b9e\u73b0\u7684 the episodic memory\uff1b4. \u901a\u8fc7\u63d0\u793a\u4f18\u5316\uff08prompt optimization\uff09\u5b9e\u73b0\u7684\u7a0b\u5e8f\u5316\u8bb0\u5fc6\uff08procedural memory\uff09\u3002\u7814\u7a76\u4f7f\u7528LoCoMo\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u8be5\u6570\u636e\u96c6\u5305\u542b\u5408\u6210\u7684\u957f\u4e0a\u4e0b\u6587\u5bf9\u8bdd\uff0c\u5e76\u9488\u5bf9\u9700\u8981\u591a\u79cd\u63a8\u7406\u7b56\u7565\u7684\u95ee\u7b54\u4efb\u52a1\u8fdb\u884c\u4e86\u6807\u6ce8\u3002\u7814\u7a76\u4eba\u5458\u5206\u6790\u4e86\u8fd9\u4e9b\u65b9\u6cd5\u5728LoCoMo\u57fa\u51c6\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u4e0d\u4f7f\u7528\u8bb0\u5fc6\u589e\u5f3a\u7684\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8bb0\u5fc6\u589e\u5f3a\u7684\u65b9\u6cd5\u53ef\u4ee5\u5c06token\u4f7f\u7528\u91cf\u51cf\u5c1190%\u4ee5\u4e0a\uff0c\u540c\u65f6\u4fdd\u6301\u5177\u6709\u7ade\u4e89\u529b\u7684\u51c6\u786e\u6027\u3002\u6b64\u5916\uff0c\u7814\u7a76\u53d1\u73b0\u8bb0\u5fc6\u67b6\u6784\u7684\u590d\u6742\u6027\u5e94\u4e0e\u6a21\u578b\u7684\u6027\u80fd\u76f8\u5339\u914d\uff1a\u5c0f\u578b\u57fa\u7840\u6a21\u578b\u4eceRAG\u4e2d\u53d7\u76ca\u6700\u591a\uff1b\u800c\u5f3a\u5927\u7684\u6307\u4ee4\u5fae\u8c03\u6a21\u578b\u5219\u4ece the episodic learning\uff08\u901a\u8fc7\u53cd\u601d\u548c\u66f4\u590d\u6742\u7684agentic semantic memory\uff09\u4e2d\u83b7\u5f97\u66f4\u591a\u76ca\u5904\u3002\u5177\u4f53\u800c\u8a00\uff0cthe episodic memory\u6709\u52a9\u4e8eLLM\u8ba4\u8bc6\u5230\u5176\u81ea\u8eab\u77e5\u8bc6\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u7cfb\u7edf\u5730\u8bc4\u4f30\u4e86\u4e0d\u540c\u7684\u8bb0\u5fc6\u589e\u5f3a\u65b9\u6cd5\u5728\u957f\u4e0a\u4e0b\u6587\u5bf9\u8bdd\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\uff0c\u5e76\u63d0\u51fa\u4e86LoCoMo\u57fa\u51c6\u6570\u636e\u96c6\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u8bb0\u5fc6\u589e\u5f3a\u65b9\u6cd5\u5728\u663e\u8457\u51cf\u5c11token\u4f7f\u7528\u91cf\u7684\u540c\u65f6\uff0c\u80fd\u591f\u4fdd\u6301\u51c6\u786e\u6027\u3002\u6a21\u578b\u80fd\u529b\u4e0e\u8bb0\u5fc6\u67b6\u6784\u590d\u6742\u5ea6\u7684\u5339\u914d\u81f3\u5173\u91cd\u8981\uff0c\u5c0f\u578b\u6a21\u578b\u66f4\u9002\u5408RAG\uff0c\u800c\u5f3a\u5927\u6a21\u578b\u5219\u53d7\u76ca\u4e8e the episodic learning\u3002The episodic memory\u5c24\u5176\u6709\u52a9\u4e8eLLM\u8bc6\u522b\u81ea\u8eab\u77e5\u8bc6\u7684\u4e0d\u8db3\u3002\u8fd9\u9879\u5de5\u4f5c\u4e3a\u8bbe\u8ba1\u66f4\u6709\u6548\u7684\u957f\u5bf9\u8bddLLM\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u89c1\u89e3\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u7684\u65b9\u5411\uff0c\u4f8b\u5982\u8fdb\u4e00\u6b65\u63a2\u7d22\u4e0d\u540c\u8bb0\u5fc6\u673a\u5236\u7684\u7ec4\u5408\u4ee5\u53ca\u5176\u5728\u66f4\u5e7f\u6cdb\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2510.23690", "categories": ["physics.plasm-ph"], "pdf": "https://arxiv.org/pdf/2510.23690", "abs": "https://arxiv.org/abs/2510.23690", "authors": ["F. Alejandro Padilla-Gomez", "Sining Gong", "Michael S. Murillo", "F. R. Graziani", "Andrew J. Christlieb"], "title": "Quantum Kinetic Modeling of KEEN waves in a Warm-Dense Regime", "comment": null, "summary": "We report a fully kinetic, quantum study of Kinetic Electrostatic Electron\nNonlinear (KEEN) waves, showing that quantum diffraction systematically erodes\nthe classical trapping mechanism, narrow harmonic locking to the fundamental,\nand hasten post-drive decay. Electrons are evolved with a second-order\nStrang-split 1D1V Wigner-Poisson solver that couples conservative\nsemi-Lagrangian WENO advection to an analytic Fourier space update for the\nnon-local Wigner term, while ions remain classical. Short, frequency-tuned\nponderomotive pulses drive KEEN formation in a uniform Maxwellian plasma; as\nthe dimensionless quantum parameter H rises from the classical limit to values\nrelevant to warm-dense matter, doped semiconductors, and 2D electron systems,\nthe drive threshold increases, higher harmonics are damped, trapped electron\nvortices diffuse, and the subplasma electrostatic energy relaxes to a lower\nstationary level, as confirmed by continuous wavelet analysis. These\nmicroscopic changes carry macroscopic weight. Ignition-scale capsules now\ncompress matter to regimes where the electron de Broglie wavelength rivals the\nDebye length, making classical kinetic descriptions insufficient. By extending\nKEEN physics into this quantum domain, our results offer a potential diagnostic\nof nonequilibrium electron dynamics for next-generation inertial-confinement\ndesigns and high-energy-density platforms, indicating that predictive fusion\nmodeling may benefit from the integration of kinetic fidelity with quantum\neffects.", "AI": {"tldr": "\u672c\u7814\u7a76\u4f7f\u7528\u5168\u52a8\u529b\u5b66\u91cf\u5b50\u65b9\u6cd5\u7814\u7a76\u4e86\u52a8\u91cf\u9759\u7535\u7535\u5b50\u975e\u7ebf\u6027(KEEN)\u6ce2\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u91cf\u5b50\u6548\u5e94\u4f1a\u524a\u5f31\u7ecf\u5178\u6355\u83b7\u673a\u5236\uff0c\u9650\u5236\u8c10\u6ce2\u9501\u5b9a\uff0c\u5e76\u52a0\u901f\u9a71\u52a8\u540e\u7684\u8870\u51cf\u3002\u968f\u7740\u91cf\u5b50\u53c2\u6570H\u7684\u589e\u52a0\uff0c\u9a71\u52a8\u9608\u503c\u5347\u9ad8\uff0c\u9ad8\u6b21\u8c10\u6ce2\u88ab\u6291\u5236\uff0c\u88ab\u6355\u83b7\u7684\u7535\u5b50\u6da1\u65cb\u6269\u6563\uff0c\u9759\u7535\u80fd\u91cf\u964d\u4f4e\u3002\u8fd9\u4e9b\u5fae\u89c2\u53d8\u5316\u5bf9\u5b8f\u89c2\u73b0\u8c61\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u4f8b\u5982\u5728\u60ef\u6027\u7ea6\u675f\u805a\u53d8\u4e2d\uff0c\u7535\u5b50\u5fb7\u5e03\u7f57\u610f\u6ce2\u957f\u53ef\u80fd\u63a5\u8fd1\u5fb7\u62dc\u957f\u5ea6\uff0c\u6b64\u65f6\u7ecf\u5178\u63cf\u8ff0\u5df2\u4e0d\u9002\u7528\u3002\u672c\u7814\u7a76\u5c06KEEN\u7269\u7406\u6269\u5c55\u5230\u91cf\u5b50\u9886\u57df\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u60ef\u6027\u7ea6\u675f\u8bbe\u8ba1\u548c\u9ad8\u80fd\u5bc6\u5ea6\u5e73\u53f0\u63d0\u4f9b\u4e86\u8bca\u65ad\u975e\u5e73\u8861\u7535\u5b50\u52a8\u529b\u5b66\u7684\u65b0\u65b9\u6cd5\uff0c\u8868\u660e\u672a\u6765\u7684\u805a\u53d8\u6a21\u578b\u53ef\u80fd\u9700\u8981\u7ed3\u5408\u52a8\u529b\u5b66\u4fdd\u771f\u5ea6\u548c\u91cf\u5b50\u6548\u5e94\u3002", "motivation": "\u7ecf\u5178\u52a8\u91cf\u9759\u7535\u7535\u5b50\u975e\u7ebf\u6027(KEEN)\u6ce2\u7814\u7a76\u5728\u60ef\u6027\u7ea6\u675f\u805a\u53d8\u7b49\u9ad8\u80fd\u5bc6\u5ea6\u7269\u7406\u9886\u57df\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002\u7136\u800c\uff0c\u5728\u67d0\u4e9b\u6781\u7aef\u6761\u4ef6\u4e0b\uff0c\u4f8b\u5982\u7535\u5b50\u5fb7\u5e03\u7f57\u610f\u6ce2\u957f\u63a5\u8fd1\u5fb7\u62dc\u957f\u5ea6\u65f6\uff0c\u7ecf\u5178\u52a8\u529b\u5b66\u63cf\u8ff0\u53ef\u80fd\u4e0d\u518d\u51c6\u786e\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u7814\u7a76\u91cf\u5b50\u6548\u5e94\u5bf9KEEN\u6ce2\u7684\u5f71\u54cd\uff0c\u4ee5\u66f4\u51c6\u786e\u5730\u63cf\u8ff0\u548c\u9884\u6d4b\u8fd9\u4e9b\u6781\u7aef\u6761\u4ef6\u4e0b\u7684\u7b49\u79bb\u5b50\u4f53\u884c\u4e3a\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u5168\u52a8\u529b\u5b66\u91cf\u5b50\u65b9\u6cd5\uff0c\u4f7f\u7528\u4e8c\u9636Strang\u5206\u88c21D1V Wigner-\u6cca\u677e\u6c42\u89e3\u5668\u6765\u6a21\u62df\u7535\u5b50\u52a8\u529b\u5b66\u3002\u8be5\u6c42\u89e3\u5668\u8026\u5408\u4e86\u4fdd\u5b88\u7684\u534a\u62c9\u683c\u6717\u65e5WENO\u5e73\u6d41\u548c\u975e\u5c40\u57dfWigner\u9879\u7684\u89e3\u6790\u5085\u91cc\u53f6\u7a7a\u95f4\u66f4\u65b0\uff0c\u800c\u79bb\u5b50\u5219\u4fdd\u6301\u7ecf\u5178\u3002\u901a\u8fc7\u77ed\u7684\u3001\u9891\u7387\u8c03\u8c10\u7684\u8861\u52a8\u8109\u51b2\u6765\u9a71\u52a8KEEN\u6ce2\u7684\u5f62\u6210\u3002\u7814\u7a76\u4e86\u91cf\u5b50\u53c2\u6570H\u4ece\u7ecf\u5178\u6781\u9650\u5230\u4e0e\u6696\u5bc6\u7269\u8d28\u3001\u63ba\u6742\u534a\u5bfc\u4f53\u548c\u4e8c\u7ef4\u7535\u5b50\u7cfb\u7edf\u76f8\u5173\u7684\u6570\u503c\uff0c\u4ee5\u63a2\u7a76\u91cf\u5b50\u6548\u5e94\u5bf9KEEN\u6ce2\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u968f\u7740\u91cf\u5b50\u53c2\u6570H\u7684\u589e\u52a0\uff0c\u9a71\u52a8\u9608\u503c\u5347\u9ad8\uff0c\u9ad8\u6b21\u8c10\u6ce2\u88ab\u6291\u5236\uff0c\u88ab\u6355\u83b7\u7684\u7535\u5b50\u6da1\u65cb\u6269\u6563\uff0c\u5e76\u4e14\u9759\u7535\u80fd\u91cf\u964d\u4f4e\u5230\u8f83\u4f4e\u7684\u7a33\u6001\u6c34\u5e73\u3002\u8fde\u7eed\u5c0f\u6ce2\u5206\u6790\u8bc1\u5b9e\u4e86\u8fd9\u4e9b\u53d8\u5316\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u91cf\u5b50\u884d\u5c04\u7cfb\u7edf\u5730\u4fb5\u8680\u4e86\u7ecf\u5178\u7684\u6355\u83b7\u673a\u5236\uff0c\u7a84\u5316\u4e86\u8c10\u6ce2\u4e0e\u57fa\u9891\u7684\u9501\u5b9a\uff0c\u5e76\u52a0\u901f\u4e86\u9a71\u52a8\u540e\u7684\u8870\u51cf\u3002", "conclusion": "\u672c\u7814\u7a76\u5c06KEEN\u7269\u7406\u6269\u5c55\u5230\u4e86\u91cf\u5b50\u9886\u57df\uff0c\u63ed\u793a\u4e86\u91cf\u5b50\u6548\u5e94\u5bf9KEEN\u6ce2\u7684\u91cd\u8981\u5f71\u54cd\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5728\u60ef\u6027\u7ea6\u675f\u805a\u53d8\u7b49\u6781\u7aef\u6761\u4ef6\u4e0b\uff0c\u91cf\u5b50\u6548\u5e94\u4e0d\u53ef\u5ffd\u89c6\uff0c\u7ecf\u5178\u7684\u52a8\u529b\u5b66\u63cf\u8ff0\u5df2\u4e0d\u8db3\u4ee5\u51c6\u786e\u9884\u6d4b\u7b49\u79bb\u5b50\u4f53\u884c\u4e3a\u3002\u672c\u7814\u7a76\u63d0\u51fa\u7684\u65b9\u6cd5\u548c\u53d1\u73b0\u4e3a\u8bca\u65ad\u975e\u5e73\u8861\u7535\u5b50\u52a8\u529b\u5b66\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\uff0c\u5e76\u5f3a\u8c03\u4e86\u5728\u672a\u6765\u7684\u805a\u53d8\u6a21\u578b\u4e2d\u7ed3\u5408\u52a8\u529b\u5b66\u4fdd\u771f\u5ea6\u548c\u91cf\u5b50\u6548\u5e94\u7684\u91cd\u8981\u6027\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63a2\u7d22\u66f4\u5e7f\u6cdb\u7684\u91cf\u5b50\u53c2\u6570\u8303\u56f4\u548c\u66f4\u590d\u6742\u7684\u7b49\u79bb\u5b50\u4f53\u7cfb\u7edf\uff0c\u4ee5\u671f\u66f4\u5168\u9762\u5730\u7406\u89e3\u91cf\u5b50\u6548\u5e94\u5728\u9ad8\u80fd\u5bc6\u5ea6\u7269\u7406\u4e2d\u7684\u4f5c\u7528\u3002"}}
{"id": "2510.23766", "categories": ["cs.CL", "68T05", "I.2.6; I.2.7"], "pdf": "https://arxiv.org/pdf/2510.23766", "abs": "https://arxiv.org/abs/2510.23766", "authors": ["Ramshankar Bhuvaneswaran", "Handan Liu"], "title": "BitSkip: An Empirical Analysis of Quantization and Early Exit Composition", "comment": "Submitted to JMLR", "summary": "The pursuit of efficient Large Language Models (LLMs) has led to increasingly\ncomplex techniques like extreme quantization and dynamic routing. While\nindividual benefits of these methods are well-documented, their compositional\neffects remain poorly understood. This paper introduces BitSkip, a hybrid\narchitectural framework for systematically exploring these interactions.\nCounter-intuitively, our findings reveal that a simple 8-bit quantized model\nwithout Hadamard transform (BitSkip-V1) not only outperforms its more complex\n4-bit and Hadamard-enhanced counterparts but also competes the full-precision\nbaseline in quality (perplexity of 1.13 vs 1.19) . The introduction of Hadamard\ntransforms, even at 8-bit precision, catastrophically degraded performance by\nover 37,000%, tracing fundamental training instability. Our BitSkip-V1 recipe\ndemonstrates superior early-exit characteristics, with layer 18 providing\noptimal 32.5% speed gain for minimal 4% quality loss.", "AI": {"tldr": "BitSkip\u662f\u4e00\u4e2a\u6df7\u5408\u67b6\u6784\u6846\u67b6\uff0c\u7528\u4e8e\u63a2\u7d22LLM\u4e2d\u7684\u6781\u7aef\u91cf\u5316\u548c\u52a8\u6001\u8def\u7531\u7b49\u6280\u672f\u4e4b\u95f4\u7684\u7ec4\u5408\u6548\u5e94\u3002\u5b9e\u9a8c\u53d1\u73b0\uff0c\u7b80\u5355\u76848\u4f4d\u91cf\u5316\u6a21\u578b\uff08BitSkip-V1\uff09\u4f18\u4e8e\u66f4\u590d\u6742\u76844\u4f4d\u91cf\u5316\u548cHadamard\u53d8\u6362\u6a21\u578b\uff0c\u5e76\u4e14\u5728\u6027\u80fd\u4e0a\u53ef\u4e0e\u5168\u7cbe\u5ea6\u57fa\u7ebf\u76f8\u5ab2\u7f8e\u3002Hadamard\u53d8\u6362\u57288\u4f4d\u7cbe\u5ea6\u4e0b\u4f1a\u4e25\u91cd\u964d\u4f4e\u6027\u80fd\u3002BitSkip-V1\u5728\u65e9\u671f\u9000\u51fa\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u572818\u5c42\u5b9e\u73b032.5%\u7684\u901f\u5ea6\u63d0\u5347\uff0c\u4ec5\u635f\u59314%\u7684\u8d28\u91cf\u3002", "motivation": "\u5f53\u524dLLM\u7814\u7a76\u8fc7\u5ea6\u5173\u6ce8\u5982\u6781\u7aef\u91cf\u5316\u548c\u52a8\u6001\u8def\u7531\u7b49\u590d\u6742\u6280\u672f\uff0c\u4f46\u8fd9\u4e9b\u6280\u672f\u7684\u7ec4\u5408\u6548\u5e94\u7814\u7a76\u4e0d\u8db3\u3002\u672c\u7814\u7a76\u65e8\u5728\u7cfb\u7edf\u6027\u5730\u63a2\u7d22\u8fd9\u4e9b\u6280\u672f\u7ec4\u5408\u5bf9LLM\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u89e3\u51b3\u5f53\u524d\u7814\u7a76\u7684\u4e0d\u8db3\u3002", "method": "\u63d0\u51faBitSkip\u6df7\u5408\u67b6\u6784\u6846\u67b6\uff0c\u7528\u4e8e\u7cfb\u7edf\u5730\u63a2\u7d22LLM\u4e2d\u91cf\u5316\uff08\u59828\u4f4d\u548c4\u4f4d\uff09\u548cHadamard\u53d8\u6362\u7b49\u6280\u672f\u7684\u7ec4\u5408\u6548\u5e94\u3002\u5b9e\u9a8c\u901a\u8fc7\u6bd4\u8f83\u4e0d\u540c\u914d\u7f6e\uff08BitSkip-V1\uff1a8\u4f4d\u91cf\u5316\u65e0Hadamard\u53d8\u6362\uff1b4\u4f4d\u91cf\u5316\u6a21\u578b\uff1b8\u4f4d\u91cf\u5316\u52a0Hadamard\u53d8\u6362\uff09\u7684\u6027\u80fd\u6765\u8bc4\u4f30\u7ec4\u5408\u6548\u5e94\u3002", "result": "BitSkip-V1\uff088\u4f4d\u91cf\u5316\u65e0Hadamard\u53d8\u6362\uff09\u7684\u56f0\u60d1\u5ea6\u4e3a1.13\uff0c\u4f18\u4e8e4\u4f4d\u91cf\u5316\u6a21\u578b\u548c8\u4f4d\u91cf\u5316\u52a0Hadamard\u53d8\u6362\u6a21\u578b\u30028\u4f4d\u91cf\u5316\u52a0Hadamard\u53d8\u6362\u6a21\u578b\u6027\u80fd\u4e0b\u964d\u8d85\u8fc737000%\uff0c\u8868\u660e\u5b58\u5728\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u7684\u6839\u672c\u95ee\u9898\u3002BitSkip-V1\u5728\u7b2c18\u5c42\u5b9e\u73b032.5%\u7684\u901f\u5ea6\u589e\u76ca\uff0c\u4ec5\u635f\u59314%\u7684\u8d28\u91cf\uff0c\u663e\u793a\u51fa\u4f18\u8d8a\u7684\u65e9\u671f\u9000\u51fa\u7279\u6027\u3002", "conclusion": "BitSkip\u6846\u67b6\u4e3a\u63a2\u7d22LLM\u4e2d\u7684\u6280\u672f\u7ec4\u5408\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\u3002\u7814\u7a76\u8868\u660e\uff0c\u7b80\u5355\u6280\u672f\uff08\u59828\u4f4d\u91cf\u5316\uff09\u7684\u7ec4\u5408\u53ef\u80fd\u6bd4\u590d\u6742\u6280\u672f\u66f4\u6709\u6548\u3002BitSkip-V1\u5728\u901f\u5ea6\u548c\u8d28\u91cf\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u7684\u5e73\u8861\uff0c\u7279\u522b\u662f\u5728\u65e9\u671f\u9000\u51fa\u65b9\u9762\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u4f18\u5316BitSkip\u6846\u67b6\uff0c\u63a2\u7d22\u66f4\u591a\u6280\u672f\u7ec4\u5408\uff0c\u5e76\u89e3\u51b3Hadamard\u53d8\u6362\u5f15\u5165\u7684\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u6027\u95ee\u9898\u3002"}}
{"id": "2510.24121", "categories": ["physics.plasm-ph"], "pdf": "https://arxiv.org/pdf/2510.24121", "abs": "https://arxiv.org/abs/2510.24121", "authors": ["Y. Guo", "D. Wu", "J. Zhang"], "title": "Effect of flow-aligned external magnetic fields on mushroom instability", "comment": "Submitted to The Astrophysical Journal", "summary": "Mushroom instability (MI) is a shear instability considered responsible for\ngenerating and amplifying magnetic fields in relativistic jets. While\nastrophysical jets are usually considered to be magnetized, how MI acts in\nmagnetized jets remains poorly understood. In this paper, we investigate the\neffect of a flow-aligned external magnetic field on MI, with both theoretical\nanalyses and particle-in-cell (PIC) simulations. In the limit of a cold and\ncollisionless plasma, we derive a generalized dispersion relation for linear\ngrowth rates of the magnetized MIs. Numerical solutions of the dispersion\nrelation reveal that the external magnetic field always suppresses the growth\nof MI, though MIs are much more robust to the external magnetic field than\nelectron-scale Kelvin-Helmholtz instabilities (ESKHIs). Analyses are also\nextended to instabilities with an arbitrary wavevector in the shear interface\nplane. Two-dimensional PIC simulations of single-mode MIs reach a good\nagreement with our analytical predictions. In simulations with finite\ntemperatures, we observe the competition and cooperation between MIs and a\ndiffusion-induced DC magnetic field.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5916\u90e8\u78c1\u573a\u5bf9\u55b7\u6d41\u4e2d\u78c1\u573a\u4e0d\u7a33\u5b9a\u6027\uff08MI\uff09\u7684\u5f71\u54cd\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5916\u90e8\u78c1\u573a\u4f1a\u6291\u5236MI\u7684\u589e\u957f\uff0c\u4f46MI\u76f8\u6bd4\u4e8e\u7535\u5b50\u5c3a\u5ea6\u5f00\u5c14\u6587-\u4ea5\u59c6\u970d\u5179\u4e0d\u7a33\u5b9a\u6027\uff08ESKHI\uff09\u5bf9\u5916\u90e8\u78c1\u573a\u66f4\u5177\u9c81\u68d2\u6027\u3002\u7406\u8bba\u5206\u6790\u548c\u7c92\u5b50\u6a21\u62df\uff08PIC\uff09\u5747\u8bc1\u5b9e\u4e86\u8fd9\u4e00\u70b9\u3002\u5728\u6709\u6e29\u5ea6\u7684\u60c5\u51b5\u4e0b\uff0cMI\u4e0e\u6269\u6563\u5f15\u8d77\u7684\u76f4\u6d41\u78c1\u573a\u4e4b\u95f4\u5b58\u5728\u7ade\u4e89\u4e0e\u5408\u4f5c\u5173\u7cfb\u3002", "motivation": "\u7814\u7a76\u78c1\u5316\u55b7\u6d41\u4e2d\u78c1\u573a\u4e0d\u7a33\u5b9a\u6027\uff08MI\uff09\u7684\u884c\u4e3a\uff0c\u56e0\u4e3aMI\u88ab\u8ba4\u4e3a\u662f\u4ea7\u751f\u548c\u653e\u5927\u76f8\u5bf9\u8bba\u55b7\u6d41\u78c1\u573a\u7684\u539f\u56e0\uff0c\u800c\u78c1\u5316\u55b7\u6d41\u662f\u5929\u4f53\u7269\u7406\u5b66\u4e2d\u7684\u5e38\u89c1\u73b0\u8c61\uff0c\u4f46\u5bf9\u5176MI\u884c\u4e3a\u7684\u7406\u89e3\u5c1a\u4e0d\u5145\u5206\u3002", "method": "\u7ed3\u5408\u7406\u8bba\u5206\u6790\u548c\u7c92\u5b50 the cell (PIC) \u6a21\u62df\u3002\u7406\u8bba\u4e0a\uff0c\u63a8\u5bfc\u4e86\u78c1\u5316MI\u7ebf\u6027\u589e\u957f\u7387\u7684\u5e7f\u4e49\u8272\u6563\u5173\u7cfb\uff0c\u5e76\u6c42\u89e3\u4e86\u6570\u503c\u89e3\u3002\u5206\u6790\u4e86\u4efb\u610f\u6ce2\u77e2\u7684\u4e0d\u7a33\u5b9a\u6027\u3002\u5728\u6a21\u62df\u4e2d\uff0c\u4f7f\u7528\u4e86\u4e8c\u7ef4PIC\u6a21\u62df\u5355\u6a21MI\uff0c\u5e76\u4e0e\u7406\u8bba\u9884\u6d4b\u8fdb\u884c\u5bf9\u6bd4\u3002\u540c\u65f6\uff0c\u4e5f\u8fdb\u884c\u4e86\u6709\u9650\u6e29\u5ea6\u4e0b\u7684\u6a21\u62df\u3002", "result": "\u5916\u90e8\u78c1\u573a\u603b\u662f\u6291\u5236MI\u7684\u589e\u957f\uff0c\u4f46MI\u6bd4ESKHI\u66f4\u80fd\u62b5\u6297\u5916\u90e8\u78c1\u573a\u7684\u5f71\u54cd\u3002\u7406\u8bba\u9884\u6d4b\u4e0e\u4e8c\u7ef4PIC\u6a21\u62df\u7ed3\u679c\u543b\u5408\u826f\u597d\u3002\u5728\u6709\u9650\u6e29\u5ea6\u6a21\u62df\u4e2d\uff0c\u89c2\u5bdf\u5230MI\u4e0e\u6269\u6563\u5f15\u8d77\u7684\u76f4\u6d41\u78c1\u573a\u4e4b\u95f4\u5b58\u5728\u7ade\u4e89\u4e0e\u5408\u4f5c\u3002", "conclusion": "\u5916\u90e8\u78c1\u573a\u5bf9MI\u6709\u6291\u5236\u4f5c\u7528\uff0c\u4f46MI\u4ecd\u80fd\u6709\u6548\u589e\u957f\u3002MI\u5728\u78c1\u5316\u55b7\u6d41\u4e2d\u7684\u884c\u4e3a\u6bd4\u4e4b\u524d\u8ba4\u4e3a\u7684\u66f4\u590d\u6742\uff0c\u5b58\u5728\u4e0e\u6269\u6563\u78c1\u573a\u7684\u76f8\u4e92\u4f5c\u7528\u3002\u672a\u6765\u7684\u7814\u7a76\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63a2\u7d22\u8fd9\u4e9b\u76f8\u4e92\u4f5c\u7528\u4ee5\u53caMI\u5728\u4e0d\u540c\u55b7\u6d41\u73af\u5883\u4e0b\u7684\u884c\u4e3a\u3002"}}
{"id": "2510.23734", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23734", "abs": "https://arxiv.org/abs/2510.23734", "authors": ["Eamon Duede"], "title": "AI and the Decentering of Disciplinary Creativity", "comment": null, "summary": "This paper examines the role of artificial intelligence in scientific\nproblem-solving, with a focus on its implications for disciplinary creativity.\nDrawing on recent work in the philosophy of creativity, I distinguish between\ncreative approaches and creative products, and introduce the concept of\ndisciplinary creativity -the creative application of discipline-specific\nexpertise to a valued problem within that field. Through two cases in\nmathematics, I show that while computation can extend disciplinary creativity,\ncertain approaches involving AI can serve to displace it. This displacement has\nthe potential to alter (and, perhaps, diminish) the value of scientific\npursuit.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4eba\u5de5\u667a\u80fd\u5728\u79d1\u5b66\u95ee\u9898\u89e3\u51b3\u4e2d\u7684\u4f5c\u7528\uff0c\u7279\u522b\u662f\u5bf9\u5b66\u79d1\u521b\u9020\u529b\u7684\u5f71\u54cd\u3002\u7814\u7a76\u533a\u5206\u4e86\u521b\u9020\u6027\u65b9\u6cd5\u548c\u521b\u9020\u6027\u4ea7\u54c1\uff0c\u5e76\u5f15\u5165\u4e86\u201c\u5b66\u79d1\u521b\u9020\u529b\u201d\u7684\u6982\u5ff5\uff0c\u5373\u5728\u7279\u5b9a\u9886\u57df\u5185\u521b\u9020\u6027\u5730\u8fd0\u7528\u5b66\u79d1\u4e13\u4e1a\u77e5\u8bc6\u6765\u89e3\u51b3\u6709\u4ef7\u503c\u7684\u95ee\u9898\u3002\u901a\u8fc7\u4e24\u4e2a\u6570\u5b66\u6848\u4f8b\u7814\u7a76\uff0c\u672c\u6587\u8868\u660e\u8ba1\u7b97\u53ef\u4ee5\u6269\u5c55\u5b66\u79d1\u521b\u9020\u529b\uff0c\u4f46\u67d0\u4e9b\u6d89\u53ca\u4eba\u5de5\u667a\u80fd\u7684\u65b9\u6cd5\u53ef\u80fd\u4f1a\u53d6\u4ee3\u5b83\uff0c\u4ece\u800c\u53ef\u80fd\u6539\u53d8\u751a\u81f3\u964d\u4f4e\u79d1\u5b66\u8ffd\u6c42\u7684\u4ef7\u503c\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u63a2\u8ba8\u4eba\u5de5\u667a\u80fd\u5728\u79d1\u5b66\u95ee\u9898\u89e3\u51b3\u8fc7\u7a0b\u4e2d\u5bf9\u201c\u5b66\u79d1\u521b\u9020\u529b\u201d\u7684\u6f5c\u5728\u5f71\u54cd\u3002\u7814\u7a76\u8005\u5173\u6ce8\u4eba\u5de5\u667a\u80fd\u662f\u4f1a\u589e\u5f3a\u8fd8\u662f\u524a\u5f31\u79d1\u5b66\u5bb6\u8fd0\u7528\u5176\u4e13\u4e1a\u77e5\u8bc6\u89e3\u51b3\u9886\u57df\u5185\u96be\u9898\u7684\u80fd\u529b\uff0c\u5e76\u8ba4\u4e3a\u7406\u89e3\u8fd9\u4e00\u70b9\u5bf9\u4e8e\u8bc4\u4f30\u79d1\u5b66\u8ffd\u6c42\u7684\u672a\u6765\u4ef7\u503c\u81f3\u5173\u91cd\u8981\u3002", "method": "\u672c\u6587\u91c7\u7528\u4e86\u57fa\u4e8e\u54f2\u5b66\u7406\u8bba\u548c\u6848\u4f8b\u7814\u7a76\u7684\u65b9\u6cd5\u3002\u7814\u7a76\u8005\u9996\u5148\u533a\u5206\u4e86\u521b\u9020\u6027\u65b9\u6cd5\u548c\u521b\u9020\u6027\u4ea7\u54c1\uff0c\u5e76\u63d0\u51fa\u4e86\u201c\u5b66\u79d1\u521b\u9020\u529b\u201d\u7684\u6982\u5ff5\u3002\u968f\u540e\uff0c\u901a\u8fc7\u5bf9\u6570\u5b66\u9886\u57df\u4e24\u4e2a\u5177\u4f53\u6848\u4f8b\u7684\u5206\u6790\uff0c\u63a2\u8ba8\u4e86\u4eba\u5de5\u667a\u80fd\u5728\u8fd9\u4e9b\u6848\u4f8b\u4e2d\u7684\u4f5c\u7528\uff0c\u4ee5\u8bba\u8bc1\u5176\u5bf9\u5b66\u79d1\u521b\u9020\u529b\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u867d\u7136\u8ba1\u7b97\u65b9\u6cd5\u53ef\u4ee5\u6269\u5c55\u5b66\u79d1\u521b\u9020\u529b\uff0c\u4f46\u67d0\u4e9b\u6d89\u53ca\u4eba\u5de5\u667a\u80fd\u7684\u65b9\u6cd5\u53ef\u80fd\u5bfc\u81f4\u5b66\u79d1\u521b\u9020\u529b\u7684\u201c\u4f4d\u79fb\u201d\u3002\u8fd9\u79cd\u4f4d\u79fb\u53ef\u80fd\u4f1a\u5bf9\u79d1\u5b66\u8ffd\u6c42\u7684\u4ef7\u503c\u4ea7\u751f\u8d1f\u9762\u5f71\u54cd\uff0c\u751a\u81f3\u53ef\u80fd\u964d\u4f4e\u5176\u4ef7\u503c\u3002", "conclusion": "\u672c\u6587\u8ba4\u4e3a\uff0c\u4eba\u5de5\u667a\u80fd\u5728\u79d1\u5b66\u95ee\u9898\u89e3\u51b3\u4e2d\u7684\u5e94\u7528\u5177\u6709\u53cc\u91cd\u6027\u3002\u4e00\u65b9\u9762\uff0c\u5b83\u53ef\u4ee5\u4f5c\u4e3a\u5de5\u5177\u6269\u5c55\u4eba\u7c7b\u7684\u521b\u9020\u529b\uff1b\u53e6\u4e00\u65b9\u9762\uff0c\u67d0\u4e9b\u4eba\u5de5\u667a\u80fd\u65b9\u6cd5\u7684\u5e94\u7528\u53ef\u80fd\u4f1a\u53d6\u4ee3\u4eba\u7c7b\u7684\u521b\u9020\u6027\u52b3\u52a8\uff0c\u4ece\u800c\u5bf9\u79d1\u5b66\u7814\u7a76\u672c\u8eab\u7684\u4ef7\u503c\u548c\u610f\u4e49\u5e26\u6765\u6311\u6218\u3002\u672a\u6765\u7684\u7814\u7a76\u9700\u8981\u8fdb\u4e00\u6b65\u63a2\u7d22\u5982\u4f55\u5e73\u8861\u4eba\u5de5\u667a\u80fd\u4e0e\u4eba\u7c7b\u521b\u9020\u529b\u5728\u79d1\u5b66\u7814\u7a76\u4e2d\u7684\u5173\u7cfb\u3002"}}
{"id": "2510.23828", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.23828", "abs": "https://arxiv.org/abs/2510.23828", "authors": ["Mena Attia", "Aashiq Muhamed", "Mai Alkhamissi", "Thamar Solorio", "Mona Diab"], "title": "Beyond Understanding: Evaluating the Pragmatic Gap in LLMs' Cultural Processing of Figurative Language", "comment": null, "summary": "We present a comprehensive evaluation of the ability of large language models\n(LLMs) to process culturally grounded language, specifically to understand and\npragmatically use figurative expressions that encode local knowledge and\ncultural nuance. Using figurative language as a proxy for cultural nuance and\nlocal knowledge, we design evaluation tasks for contextual understanding,\npragmatic use, and connotation interpretation in Arabic and English. We\nevaluate 22 open- and closed-source LLMs on Egyptian Arabic idioms,\nmultidialectal Arabic proverbs, and English proverbs. Our results show a\nconsistent hierarchy: the average accuracy for Arabic proverbs is 4.29% lower\nthan for English proverbs, and performance for Egyptian idioms is 10.28% lower\nthan for Arabic proverbs. For the pragmatic use task, accuracy drops by 14.07%\nrelative to understanding, though providing contextual idiomatic sentences\nimproves accuracy by 10.66%. Models also struggle with connotative meaning,\nreaching at most 85.58% agreement with human annotators on idioms with 100%\ninter-annotator agreement. These findings demonstrate that figurative language\nserves as an effective diagnostic for cultural reasoning: while LLMs can often\ninterpret figurative meaning, they face challenges in using it appropriately.\nTo support future research, we release Kinayat, the first dataset of Egyptian\nArabic idioms designed for both figurative understanding and pragmatic use\nevaluation.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5168\u9762\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u7406\u89e3\u548c\u8fd0\u7528\u5305\u542b\u5730\u65b9\u77e5\u8bc6\u548c\u6587\u5316\u7ec6\u5fae\u5dee\u522b\u7684\u6bd4\u55bb\u6027\u8bed\u8a00\u65b9\u9762\u7684\u80fd\u529b\uff0c\u7279\u522b\u5173\u6ce8\u963f\u62c9\u4f2f\u8bed\u548c\u82f1\u8bed\u3002\u7814\u7a76\u53d1\u73b0\uff0cLLM\u5728\u5904\u7406\u963f\u62c9\u4f2f\u8bed\u4e60\u8bed\u548c\u8c1a\u8bed\u65b9\u9762\u8868\u73b0\u4e0d\u5982\u82f1\u8bed\uff0c\u5e76\u4e14\u5728\u5b9e\u9645\u8fd0\u7528\u6bd4\u55bb\u6027\u8bed\u8a00\u65f6\u9762\u4e34\u6311\u6218\u3002\u7814\u7a76\u8fd8\u53d1\u5e03\u4e86\u4e00\u4e2a\u65b0\u7684\u963f\u62c9\u4f2f\u8bed\u4e60\u8bed\u6570\u636e\u96c6 Kinayat\uff0c\u4ee5\u4fc3\u8fdb\u672a\u6765\u7684\u7814\u7a76\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u5404\u79cd\u8bed\u8a00\u4efb\u52a1\u4e2d\u8d8a\u6765\u8d8a\u5f3a\u5927\uff0c\u7406\u89e3\u5b83\u4eec\u5728\u5904\u7406\u6587\u5316\u7279\u5f02\u6027\u8bed\u8a00\u65b9\u9762\u7684\u80fd\u529b\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002\u6bd4\u55bb\u6027\u8bed\u8a00\uff0c\u5982\u4e60\u8bed\u548c\u8c1a\u8bed\uff0c\u56e0\u5176\u8574\u542b\u5730\u65b9\u77e5\u8bc6\u548c\u6587\u5316\u7ec6\u5fae\u5dee\u522b\u800c\u6210\u4e3a\u8861\u91cfLLM\u6587\u5316\u7406\u89e3\u80fd\u529b\u7684\u4e00\u4e2a\u6709\u6548\u6307\u6807\u3002\u7136\u800c\uff0c\u76ee\u524d\u5bf9\u4e8eLLM\u5728\u7406\u89e3\u548c\u6070\u5f53\u8fd0\u7528\u8fd9\u7c7b\u8bed\u8a00\u65b9\u9762\u7684\u8868\u73b0\u7f3a\u4e4f\u5168\u9762\u8bc4\u4f30\uff0c\u5c24\u5176\u662f\u5728\u975e\u82f1\u8bed\u8bed\u8a00\u4e2d\u3002\u672c\u7814\u7a76\u65e8\u5728\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\uff0c\u901a\u8fc7\u5bf9\u963f\u62c9\u4f2f\u8bed\u548c\u82f1\u8bed\u7684\u6bd4\u55bb\u6027\u8bed\u8a00\u8fdb\u884c\u6df1\u5165\u8bc4\u4f30\uff0c\u63ed\u793aLLM\u5728\u6587\u5316\u63a8\u7406\u65b9\u9762\u7684\u4f18\u52bf\u548c\u52a3\u52bf\u3002", "method": "\u8be5\u7814\u7a76\u8bbe\u8ba1\u4e86\u4e00\u7cfb\u5217\u8bc4\u4f30\u4efb\u52a1\uff0c\u7528\u4e8e\u6d4b\u8bd5LLM\u5728\u7406\u89e3\u3001\u5b9e\u9645\u8fd0\u7528\u548c\u5185\u6db5\u89e3\u91ca\u4e09\u4e2a\u65b9\u9762\u7684\u80fd\u529b\u3002\u7814\u7a76\u4eba\u5458\u4f7f\u7528\u4e86\u963f\u62c9\u4f2f\u8bed\uff08\u57c3\u53ca\u65b9\u8a00\u4e60\u8bed\u3001\u591a\u65b9\u8a00\u963f\u62c9\u4f2f\u8bed\u8c1a\u8bed\uff09\u548c\u82f1\u8bed\uff08\u82f1\u8bed\u8c1a\u8bed\uff09\u7684\u6bd4\u55bb\u6027\u8bed\u8a00\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u8bc4\u4f30\u4e8622\u4e2a\u5f00\u6e90\u548c\u95ed\u6e90LLM\u5728\u8fd9\u4e9b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002\u7814\u7a76\u4e2d\uff0c\u6a21\u578b\u9996\u5148\u88ab\u8981\u6c42\u7406\u89e3\u6bd4\u55bb\u6027\u8868\u8fbe\u7684\u542b\u4e49\uff0c\u7136\u540e\u662f\u5b9e\u9645\u8fd0\u7528\u8fd9\u4e9b\u8868\u8fbe\uff0c\u6700\u540e\u662f\u89e3\u91ca\u5176\u5185\u6db5\u3002\u4e3a\u4e86\u91cf\u5316\u6a21\u578b\u8868\u73b0\uff0c\u7814\u7a76\u4f7f\u7528\u4e86\u51c6\u786e\u7387\u4f5c\u4e3a\u4e3b\u8981\u8bc4\u4f30\u6307\u6807\uff0c\u5e76\u4e0e\u4eba\u7c7b\u6807\u6ce8\u8005\u8fdb\u884c\u6bd4\u8f83\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u53d1\u5e03\u4e86\u4e00\u4e2a\u540d\u4e3a Kinayat \u7684\u65b0\u6570\u636e\u96c6\uff0c\u5305\u542b\u57c3\u53ca\u963f\u62c9\u4f2f\u8bed\u4e60\u8bed\uff0c\u7528\u4e8e\u8bc4\u4f30\u6bd4\u55bb\u6027\u7406\u89e3\u548c\u5b9e\u9645\u8fd0\u7528\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0cLLM\u5728\u5904\u7406\u963f\u62c9\u4f2f\u8bed\u6bd4\u55bb\u6027\u8bed\u8a00\u65f6\u666e\u904d\u9762\u4e34\u66f4\u5927\u6311\u6218\u3002\u963f\u62c9\u4f2f\u8bed\u8c1a\u8bed\u7684\u5e73\u5747\u51c6\u786e\u7387\u6bd4\u82f1\u8bed\u8c1a\u8bed\u4f4e4.29%\uff0c\u57c3\u53ca\u963f\u62c9\u4f2f\u8bed\u4e60\u8bed\u7684\u51c6\u786e\u7387\u5219\u6bd4\u963f\u62c9\u4f2f\u8bed\u8c1a\u8bed\u4f4e10.28%\u3002\u5728\u5b9e\u9645\u8fd0\u7528\u4efb\u52a1\u4e2d\uff0c\u51c6\u786e\u7387\u6bd4\u7406\u89e3\u4efb\u52a1\u4e0b\u964d\u4e8614.07%\uff0c\u4f46\u63d0\u4f9b\u5305\u542b\u4e60\u8bed\u7684\u4e0a\u4e0b\u6587\u53e5\u5b50\u53ef\u4ee5\u5c06\u51c6\u786e\u7387\u63d0\u9ad810.66%\u3002\u5728\u89e3\u91ca\u5185\u6db5\u65b9\u9762\uff0c\u6a21\u578b\u8868\u73b0\u4e0d\u4f73\uff0c\u5728\u89e3\u91ca\u4e60\u8bed\u7684\u5185\u6db5\u65f6\uff0c\u4e0e\u4eba\u7c7b\u6807\u6ce8\u8005\u7684\u4e00\u81f4\u6027\u6700\u9ad8\u4ec5\u8fbe\u523085.58%\uff0c\u800c\u4eba\u7c7b\u6807\u6ce8\u8005\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\u4e3a100%\u3002\u8fd9\u8868\u660eLLM\u867d\u7136\u80fd\u591f\u90e8\u5206\u7406\u89e3\u6bd4\u55bb\u6027\u542b\u4e49\uff0c\u4f46\u5728\u6070\u5f53\u8fd0\u7528\u65b9\u9762\u5b58\u5728\u663e\u8457\u56f0\u96be\u3002", "conclusion": "\u672c\u7814\u7a76\u901a\u8fc7\u5bf9LLM\u5728\u7406\u89e3\u548c\u8fd0\u7528\u963f\u62c9\u4f2f\u8bed\u53ca\u82f1\u8bed\u6bd4\u55bb\u6027\u8bed\u8a00\u65b9\u9762\u7684\u80fd\u529b\u8fdb\u884c\u5168\u9762\u8bc4\u4f30\uff0c\u8bc1\u660e\u4e86\u6bd4\u55bb\u6027\u8bed\u8a00\u662f\u8bca\u65adLLM\u6587\u5316\u63a8\u7406\u80fd\u529b\u7684\u6709\u6548\u5de5\u5177\u3002\u7814\u7a76\u7ed3\u679c\u63ed\u793a\u4e86LLM\u5728\u5904\u7406\u6587\u5316\u7279\u5f02\u6027\u8bed\u8a00\uff0c\u7279\u522b\u662f\u963f\u62c9\u4f2f\u8bed\u65f6\u5b58\u5728\u7684\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u5b9e\u9645\u8fd0\u7528\u548c\u5185\u6db5\u89e3\u91ca\u65b9\u9762\u3002\u5c3d\u7ba1LLM\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u80fd\u591f\u7406\u89e3\u6bd4\u55bb\u6027\u542b\u4e49\uff0c\u4f46\u5b83\u4eec\u5728\u5c06\u5176\u6070\u5f53\u5730\u878d\u5165\u8bed\u5883\u4e2d\u4ecd\u9762\u4e34\u56f0\u96be\u3002\u4e3a\u4e86\u63a8\u52a8\u76f8\u5173\u9886\u57df\u7684\u7814\u7a76\uff0c\u7814\u7a76\u8005\u53d1\u5e03\u4e86 Kinayat \u6570\u636e\u96c6\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u96c6\u4e2d\u4e8e\u6539\u8fdbLLM\u7684\u6587\u5316\u7406\u89e3\u548c\u751f\u6210\u80fd\u529b\uff0c\u4ee5\u53ca\u6269\u5c55\u5bf9\u66f4\u591a\u8bed\u8a00\u548c\u6587\u5316\u80cc\u666f\u7684\u8bc4\u4f30\u3002"}}
{"id": "2510.24347", "categories": ["physics.plasm-ph"], "pdf": "https://arxiv.org/pdf/2510.24347", "abs": "https://arxiv.org/abs/2510.24347", "authors": ["Qianyun Dong", "Rongpeng Li", "Zongyu Yang", "Fan Xia", "Liang Liu", "Zhifeng Zhao", "Wulyu Zhong"], "title": "Physics-Informed Visual MARFE Prediction on the HL-3 Tokamak", "comment": "13 pages, 10 figures", "summary": "The Multifaceted Asymmetric Radiation From the Edge (MARFE) is a critical\nplasma instability that often precedes density-limit disruptions in tokamaks,\nposing a significant risk to machine integrity and operational efficiency.\nEarly and reliable alert of MARFE formation is therefore essential for\ndeveloping effective disruption mitigation strategies, particularly for\nnext-generation devices like ITER. This paper presents a novel,\nphysics-informed indicator for early MARFE prediction and disruption warning\ndeveloped for the HL-3 tokamak. Our framework integrates two core innovations:\n(1) a high-fidelity label refinement pipeline that employs a physics-scored,\nweighted Expectation-Maximization (EM) algorithm to systematically correct\nnoise and artifacts in raw visual data from cameras, and (2) a continuous-time,\nphysics-constrained Neural Ordinary Differential Equation (Neural ODE) model\nthat predicts the short-horizon ``worsening\" of a MARFE. By conditioning the\nmodel's dynamics on key plasma parameters such as normalized density ($f_G$,\nderived from core electron density) and core electron temperature ($T_e$), the\npredictor achieves superior performance in the low-false-alarm regime crucial\nfor control. On a large experimental dataset from HL-3, our model demonstrates\nhigh predictive accuracy, achieving an Area Under the Curve (AUC) of 0.969 for\n40ms-ahead prediction. The indicator has been successfully deployed for\nreal-time operation with updates every 1 ms. This work lays a very foundation\nfor future proactive MARFE mitigation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u7269\u7406\u4fe1\u606f\u548c\u6df1\u5ea6\u5b66\u4e60\u7684MARFE\uff08\u591a\u65b9\u9762\u4e0d\u5bf9\u79f0\u8f90\u5c04\uff09\u9884\u6d4b\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u63d0\u524d\u9884\u8b66\u6258\u5361\u9a6c\u514b\u88c5\u7f6e\u4e2d\u7684\u5bc6\u5ea6\u6781\u9650\u7834\u574f\u3002\u901a\u8fc7\u9ad8\u7cbe\u5ea6\u6807\u7b7e\u4fee\u6b63\u548c\u7ea6\u675f\u795e\u7ecfODE\u6a21\u578b\uff0c\u8be5\u65b9\u6cd5\u5728HL-3\u6258\u5361\u9a6c\u514b\u4e0a\u5b9e\u73b0\u4e860.969\u7684AUC\u9884\u6d4b\u7cbe\u5ea6\uff0c\u5e76\u5df2\u6210\u529f\u90e8\u7f72\u7528\u4e8e\u5b9e\u65f6\u64cd\u4f5c\uff0c\u4e3a\u672a\u6765\u7684\u4e3b\u52a8\u5f0fMARFE\u7f13\u89e3\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "motivation": "MARFE\uff08\u591a\u65b9\u9762\u4e0d\u5bf9\u79f0\u8f90\u5c04\uff09\u662f\u6258\u5361\u9a6c\u514b\u88c5\u7f6e\u4e2d\u4e00\u79cd\u53ef\u80fd\u5bfc\u81f4\u5bc6\u5ea6\u6781\u9650\u7834\u574f\u7684\u5173\u952e\u7b49\u79bb\u5b50\u4f53\u4e0d\u7a33\u5b9a\u6027\uff0c\u5bf9\u88c5\u7f6e\u7684\u5b89\u5168\u8fd0\u884c\u6784\u6210\u5a01\u80c1\u3002\u56e0\u6b64\uff0c\u5b9e\u73b0MARFE\u7684\u65e9\u671f\u53ef\u9760\u9884\u8b66\u5bf9\u4e8e\u5236\u5b9a\u6709\u6548\u7684\u7834\u574f\u7f13\u89e3\u7b56\u7565\uff0c\u7279\u522b\u662f\u5bf9\u4e8eITER\u7b49\u4e0b\u4e00\u4ee3\u88c5\u7f6e\u81f3\u5173\u91cd\u8981\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u3001\u57fa\u4e8e\u7269\u7406\u4fe1\u606f\u7684MARFE\u9884\u6d4b\u6307\u6807\u3002\u8be5\u6846\u67b6\u5305\u542b\u4e24\u9879\u6838\u5fc3\u521b\u65b0\uff1a1. \u4e00\u4e2a\u9ad8\u7cbe\u5ea6\u6807\u7b7e\u4fee\u6b63\u6d41\u7a0b\uff0c\u5229\u7528\u57fa\u4e8e\u7269\u7406\u8bc4\u5206\u7684\u52a0\u6743\u671f\u671b\u6700\u5927\u5316\uff08EM\uff09\u7b97\u6cd5\uff0c\u7cfb\u7edf\u5730\u6821\u6b63\u76f8\u673a\u539f\u59cb\u89c6\u89c9\u6570\u636e\u4e2d\u7684\u566a\u58f0\u548c\u4f2a\u5f71\uff1b2. \u4e00\u4e2a\u8fde\u7eed\u65f6\u95f4\u3001\u7269\u7406\u7ea6\u675f\u7684\u795e\u7ecf\u5e38\u5fae\u5206\u65b9\u7a0b\uff08Neural ODE\uff09\u6a21\u578b\uff0c\u7528\u4e8e\u9884\u6d4bMARFE\u7684\u77ed\u671f\u201c\u6076\u5316\u201d\u8d8b\u52bf\u3002\u8be5\u6a21\u578b\u901a\u8fc7\u5c06\u5173\u952e\u7b49\u79bb\u5b50\u4f53\u53c2\u6570\uff08\u5982\u5f52\u4e00\u5316\u5bc6\u5ea6 $f_G$ \u548c\u6838\u5fc3\u7535\u5b50\u6e29\u5ea6 $T_e$\uff09\u7eb3\u5165\u6a21\u578b\u52a8\u529b\u5b66\uff0c\u4ee5\u63d0\u9ad8\u9884\u6d4b\u6027\u80fd\u3002", "result": "\u5728HL-3\u6258\u5361\u9a6c\u514b\u7684\u6d77\u91cf\u5b9e\u9a8c\u6570\u636e\u4e0a\uff0c\u8be5\u6a21\u578b\u5c55\u793a\u4e86\u9ad8\u9884\u6d4b\u7cbe\u5ea6\uff0c\u5728\u63d0\u524d40\u6beb\u79d2\u8fdb\u884c\u9884\u6d4b\u65f6\uff0c\u8fbe\u5230\u4e860.969\u7684\u66f2\u7ebf\u4e0b\u9762\u79ef\uff08AUC\uff09\u3002\u8be5\u9884\u6d4b\u6307\u6807\u5df2\u6210\u529f\u90e8\u7f72\uff0c\u5b9e\u73b0\u6bcf1\u6beb\u79d2\u66f4\u65b0\u4e00\u6b21\u7684\u5b9e\u65f6\u64cd\u4f5c\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684MARFE\u9884\u6d4b\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u7269\u7406\u4fe1\u606f\u548c\u5148\u8fdb\u7684\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u65e9\u671f\u9884\u8b66\u80fd\u529b\u548c\u9884\u6d4b\u7cbe\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4f4e\u8bef\u62a5\u7387\u3002\u8be5\u65b9\u6cd5\u5df2\u6210\u529f\u5e94\u7528\u4e8eHL-3\u6258\u5361\u9a6c\u514b\u8fdb\u884c\u5b9e\u65f6\u64cd\u4f5c\uff0c\u4e3a\u89e3\u51b3\u6258\u5361\u9a6c\u514b\u8fd0\u884c\u4e2d\u7684\u5173\u952e\u5b89\u5168\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u4e3a\u672a\u6765\u7684\u4e3b\u52a8\u5f0fMARFE\u7f13\u89e3\u7b56\u7565\u5960\u5b9a\u4e86\u575a\u5b9e\u7684\u57fa\u7840\u3002"}}
{"id": "2510.24030", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2510.24030", "abs": "https://arxiv.org/abs/2510.24030", "authors": ["Ahmet Akkaya Melih", "Yamuna Singh", "Kunal L. Agarwal", "Priya Mukherjee", "Kiran Pattnaik", "Hanuman Bhatia"], "title": "Human Machine Social Hybrid Intelligence:A Collaborative Decision Making Framework for Large Model Agent Groups and Human Experts", "comment": null, "summary": "The rapid advancements in large foundation models and multi-agent systems\noffer unprecedented capabilities, yet current Human-in-the-Loop (HiTL)\nparadigms inadequately integrate human expertise, often leading to cognitive\noverload and decision-making bottlenecks in complex, high-stakes environments.\nWe propose the \"Human-Machine Social Hybrid Intelligence\" (HMS-HI) framework, a\nnovel architecture designed for deep, collaborative decision-making between\ngroups of human experts and LLM-powered AI agents. HMS-HI is built upon three\ncore pillars: (1) a \\textbf{Shared Cognitive Space (SCS)} for unified,\nmulti-modal situational awareness and structured world modeling; (2) a\n\\textbf{Dynamic Role and Task Allocation (DRTA)} module that adaptively assigns\ntasks to the most suitable agent (human or AI) based on capabilities and\nworkload; and (3) a \\textbf{Cross-Species Trust Calibration (CSTC)} protocol\nthat fosters transparency, accountability, and mutual adaptation through\nexplainable declarations and structured feedback. Validated in a high-fidelity\nurban emergency response simulation, HMS-HI significantly reduced civilian\ncasualties by 72\\% and cognitive load by 70\\% compared to traditional HiTL\napproaches, demonstrating superior decision quality, efficiency, and human-AI\ntrust. An ablation study confirms the critical contribution of each module,\nhighlighting that engineered trust and shared context are foundational for\nscalable, synergistic human-AI collaboration.", "AI": {"tldr": "\u5927\u578b\u57fa\u7840\u6a21\u578b\u548c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u8fdb\u6b65\u5e26\u6765\u4e86\u524d\u6240\u672a\u6709\u7684\u80fd\u529b\uff0c\u4f46\u73b0\u6709\u7684\u4eba\u673a\u534f\u4f5c\uff08HiTL\uff09\u8303\u5f0f\u672a\u80fd\u5145\u5206\u6574\u5408\u4eba\u7c7b\u4e13\u4e1a\u77e5\u8bc6\uff0c\u5bfc\u81f4\u5728\u9ad8\u98ce\u9669\u590d\u6742\u73af\u5883\u4e2d\u51fa\u73b0\u8ba4\u77e5\u8fc7\u8f7d\u548c\u51b3\u7b56\u74f6\u9888\u3002\u6211\u4eec\u63d0\u51fa\u4e86\u201c\u4eba\u673a\u793e\u4f1a\u6df7\u5408\u667a\u80fd\u201d\uff08HMS-HI\uff09\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u9896\u7684\u67b6\u6784\uff0c\u7528\u4e8e\u4eba\u7c7b\u4e13\u5bb6\u548c\u7531LLM\u9a71\u52a8\u7684AI\u667a\u80fd\u4f53\u7fa4\u4f53\u4e4b\u95f4\u7684\u6df1\u5ea6\u534f\u4f5c\u51b3\u7b56\u3002HMS-HI\u5efa\u7acb\u5728\u4e09\u4e2a\u6838\u5fc3\u652f\u67f1\u4e4b\u4e0a\uff1a\uff081\uff09\u7528\u4e8e\u7edf\u4e00\u3001\u591a\u6a21\u6001\u6001\u52bf\u611f\u77e5\u548c\u7ed3\u6784\u5316\u4e16\u754c\u5efa\u6a21\u7684\u5171\u4eab\u8ba4\u77e5\u7a7a\u95f4\uff08SCS\uff09\uff1b\uff082\uff09\u4e00\u4e2a\u52a8\u6001\u89d2\u8272\u548c\u4efb\u52a1\u5206\u914d\uff08DRTA\uff09\u6a21\u5757\uff0c\u6839\u636e\u80fd\u529b\u548c\u5de5\u4f5c\u8d1f\u8f7d\u81ea\u9002\u5e94\u5730\u5c06\u4efb\u52a1\u5206\u914d\u7ed9\u6700\u5408\u9002\u7684\u667a\u80fd\u4f53\uff08\u4eba\u7c7b\u6216AI\uff09\uff1b\uff083\uff09\u4e00\u4e2a\u8de8\u7269\u79cd\u4fe1\u4efb\u6821\u51c6\uff08CSTC\uff09\u534f\u8bae\uff0c\u901a\u8fc7\u53ef\u89e3\u91ca\u7684\u58f0\u660e\u548c\u7ed3\u6784\u5316\u53cd\u9988\u4fc3\u8fdb\u900f\u660e\u5ea6\u3001\u95ee\u8d23\u5236\u548c\u76f8\u4e92\u9002\u5e94\u3002\u5728\u9ad8\u5ea6\u4eff\u771f\u7684\u57ce\u5e02\u5e94\u6025\u54cd\u5e94\u6a21\u62df\u4e2d\uff0cHMS-HI\u4e0e\u4f20\u7edf\u7684HiTL\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5c06\u5e73\u6c11\u4f24\u4ea1\u51cf\u5c11\u4e8672%\uff0c\u8ba4\u77e5\u8d1f\u8377\u964d\u4f4e\u4e8670%\uff0c\u5e76\u5728\u51b3\u7b56\u8d28\u91cf\u3001\u6548\u7387\u548c\u4eba\u673a\u4fe1\u4efb\u65b9\u9762\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u3002\u5355\u72ec\u7814\u7a76\u8bc1\u5b9e\u4e86\u6bcf\u4e2a\u6a21\u5757\u7684\u5173\u952e\u8d21\u732e\uff0c\u5e76\u5f3a\u8c03\u5de5\u7a0b\u4fe1\u4efb\u548c\u5171\u4eab\u4e0a\u4e0b\u6587\u662f\u53ef\u6269\u5c55\u3001\u534f\u540c\u7684\u4eba\u673a\u534f\u4f5c\u7684\u57fa\u7840\u3002", "motivation": "\u5f53\u524d\u7684\u4eba\u673a\u534f\u4f5c\uff08HiTL\uff09\u8303\u5f0f\u5728\u6574\u5408\u4eba\u7c7b\u4e13\u4e1a\u77e5\u8bc6\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u5728\u9ad8\u98ce\u9669\u590d\u6742\u73af\u5883\u4e2d\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u8ba4\u77e5\u8fc7\u8f7d\u548c\u51b3\u7b56\u74f6\u9888\u3002\u968f\u7740\u5927\u578b\u57fa\u7840\u6a21\u578b\u548c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u6709\u5fc5\u8981\u63a2\u7d22\u66f4\u6df1\u5c42\u6b21\u7684\u4eba\u673a\u534f\u4f5c\u6a21\u5f0f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u4eba\u673a\u793e\u4f1a\u6df7\u5408\u667a\u80fd\u201d\uff08HMS-HI\uff09\u7684\u65b0\u9896\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a\uff081\uff09\u5171\u4eab\u8ba4\u77e5\u7a7a\u95f4\uff08SCS\uff09\uff0c\u7528\u4e8e\u7edf\u4e00\u7684\u591a\u6a21\u6001\u6001\u52bf\u611f\u77e5\u548c\u7ed3\u6784\u5316\u4e16\u754c\u5efa\u6a21\uff1b\uff082\uff09\u52a8\u6001\u89d2\u8272\u548c\u4efb\u52a1\u5206\u914d\uff08DRTA\uff09\u6a21\u5757\uff0c\u80fd\u591f\u6839\u636e\u80fd\u529b\u548c\u5de5\u4f5c\u8d1f\u8f7d\u81ea\u9002\u5e94\u5730\u5206\u914d\u4efb\u52a1\uff1b\uff083\uff09\u8de8\u7269\u79cd\u4fe1\u4efb\u6821\u51c6\uff08CSTC\uff09\u534f\u8bae\uff0c\u901a\u8fc7\u53ef\u89e3\u91ca\u7684\u58f0\u660e\u548c\u7ed3\u6784\u5316\u53cd\u9988\u6765\u589e\u5f3a\u900f\u660e\u5ea6\u3001\u95ee\u8d23\u5236\u548c\u76f8\u4e92\u9002\u5e94\u3002\u8be5\u6846\u67b6\u5728\u57ce\u5e02\u5e94\u6025\u54cd\u5e94\u6a21\u62df\u4e2d\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "result": "\u5728\u57ce\u5e02\u5e94\u6025\u54cd\u5e94\u6a21\u62df\u4e2d\uff0cHMS-HI\u6846\u67b6\u4e0e\u4f20\u7edf\u7684HiTL\u65b9\u6cd5\u76f8\u6bd4\uff0c\u663e\u8457\u51cf\u5c11\u4e8672%\u7684\u5e73\u6c11\u4f24\u4ea1\u548c70%\u7684\u8ba4\u77e5\u8d1f\u8377\u3002\u6b64\u5916\uff0c\u5728\u51b3\u7b56\u8d28\u91cf\u3001\u6548\u7387\u548c\u4eba\u673a\u4fe1\u4efb\u65b9\u9762\u4e5f\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u3002\u5355\u72ec\u7814\u7a76\u8bc1\u5b9e\u4e86SCS\u3001DRTA\u548cCSTC\u6a21\u5757\u5404\u81ea\u7684\u5173\u952e\u4f5c\u7528\uff0c\u5e76\u5f3a\u8c03\u4e86\u5de5\u7a0b\u4fe1\u4efb\u548c\u5171\u4eab\u4e0a\u4e0b\u6587\u5bf9\u4e8e\u53ef\u6269\u5c55\u3001\u534f\u540c\u7684\u4eba\u673a\u534f\u4f5c\u7684\u91cd\u8981\u6027\u3002", "conclusion": "HMS-HI\u6846\u67b6\u901a\u8fc7\u6574\u5408\u5171\u4eab\u8ba4\u77e5\u7a7a\u95f4\u3001\u52a8\u6001\u4efb\u52a1\u5206\u914d\u548c\u4fe1\u4efb\u6821\u51c6\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u4eba\u673a\u4e4b\u95f4\u66f4\u6df1\u5c42\u6b21\u7684\u534f\u4f5c\u51b3\u7b56\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5728\u9ad8\u98ce\u9669\u73af\u5883\u4e0b\u7684\u51b3\u7b56\u8d28\u91cf\u548c\u6548\u7387\uff0c\u5e76\u964d\u4f4e\u4e86\u8ba4\u77e5\u8d1f\u8377\u3002\u8be5\u7814\u7a76\u5f3a\u8c03\u4e86\u5728\u590d\u6742\u7684\u4eba\u673a\u534f\u4f5c\u4e2d\u5efa\u7acb\u4fe1\u4efb\u548c\u5171\u4eab\u4e0a\u4e0b\u6587\u7684\u57fa\u7840\u6027\u4f5c\u7528\uff0c\u4e3a\u672a\u6765\u4eba\u673a\u534f\u540c\u667a\u80fd\u7cfb\u7edf\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002"}}
{"id": "2510.23744", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23744", "abs": "https://arxiv.org/abs/2510.23744", "authors": ["Eline M. Bovy", "Caleb Probine", "Marnix Suilen", "Ufuk Topcu", "Nils Jansen"], "title": "Multi-Environment POMDPs: Discrete Model Uncertainty Under Partial Observability", "comment": "Accepted at NeurIPS 2025", "summary": "Multi-environment POMDPs (ME-POMDPs) extend standard POMDPs with discrete\nmodel uncertainty. ME-POMDPs represent a finite set of POMDPs that share the\nsame state, action, and observation spaces, but may arbitrarily vary in their\ntransition, observation, and reward models. Such models arise, for instance,\nwhen multiple domain experts disagree on how to model a problem. The goal is to\nfind a single policy that is robust against any choice of POMDP within the set,\ni.e., a policy that maximizes the worst-case reward across all POMDPs. We\ngeneralize and expand on existing work in the following way. First, we show\nthat ME-POMDPs can be generalized to POMDPs with sets of initial beliefs, which\nwe call adversarial-belief POMDPs (AB-POMDPs). Second, we show that any\narbitrary ME-POMDP can be reduced to a ME-POMDP that only varies in its\ntransition and reward functions or only in its observation and reward\nfunctions, while preserving (optimal) policies. We then devise exact and\napproximate (point-based) algorithms to compute robust policies for AB-POMDPs,\nand thus ME-POMDPs. We demonstrate that we can compute policies for standard\nPOMDP benchmarks extended to the multi-environment setting.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.23842", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.23842", "abs": "https://arxiv.org/abs/2510.23842", "authors": ["Saki Imai", "Lee Kezar", "Laurel Aichler", "Mert Inan", "Erin Walker", "Alicia Wooten", "Lorna Quandt", "Malihe Alikhani"], "title": "How Pragmatics Shape Articulation: A Computational Case Study in STEM ASL Discourse", "comment": null, "summary": "Most state-of-the-art sign language models are trained on interpreter or\nisolated vocabulary data, which overlooks the variability that characterizes\nnatural dialogue. However, human communication dynamically adapts to contexts\nand interlocutors through spatiotemporal changes and articulation style. This\nspecifically manifests itself in educational settings, where novel vocabularies\nare used by teachers, and students. To address this gap, we collect a motion\ncapture dataset of American Sign Language (ASL) STEM (Science, Technology,\nEngineering, and Mathematics) dialogue that enables quantitative comparison\nbetween dyadic interactive signing, solo signed lecture, and interpreted\narticles. Using continuous kinematic features, we disentangle dialogue-specific\nentrainment from individual effort reduction and show spatiotemporal changes\nacross repeated mentions of STEM terms. On average, dialogue signs are\n24.6%-44.6% shorter in duration than the isolated signs, and show significant\nreductions absent in monologue contexts. Finally, we evaluate sign embedding\nmodels on their ability to recognize STEM signs and approximate how entrained\nthe participants become over time. Our study bridges linguistic analysis and\ncomputational modeling to understand how pragmatics shape sign articulation and\nits representation in sign language technologies.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.24383", "categories": ["cs.AI", "cs.CY", "cs.MA", "I.2.11; I.2.1; I.2.4; K.4.1; K.4.3"], "pdf": "https://arxiv.org/pdf/2510.24383", "abs": "https://arxiv.org/abs/2510.24383", "authors": ["Juraj Mavra\u010di\u0107"], "title": "Policy Cards: Machine-Readable Runtime Governance for Autonomous AI Agents", "comment": "First published on 19/10/2025. Canonical archived record and DOI:\n  10.5281/zenodo.17391796", "summary": "Policy Cards are introduced as a machine-readable, deployment-layer standard\nfor expressing operational, regulatory, and ethical constraints for AI agents.\nThe Policy Card sits with the agent and enables it to follow required\nconstraints at runtime. It tells the agent what it must and must not do. As\nsuch, it becomes an integral part of the deployed agent. Policy Cards extend\nexisting transparency artifacts such as Model, Data, and System Cards by\ndefining a normative layer that encodes allow/deny rules, obligations,\nevidentiary requirements, and crosswalk mappings to assurance frameworks\nincluding NIST AI RMF, ISO/IEC 42001, and the EU AI Act. Each Policy Card can\nbe validated automatically, version-controlled, and linked to runtime\nenforcement or continuous-audit pipelines. The framework enables verifiable\ncompliance for autonomous agents, forming a foundation for distributed\nassurance in multi-agent ecosystems. Policy Cards provide a practical mechanism\nfor integrating high-level governance with hands-on engineering practice and\nenabling accountable autonomy at scale.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.23746", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23746", "abs": "https://arxiv.org/abs/2510.23746", "authors": ["Laura Mismetti", "Marvin Alberts", "Andreas Krause", "Mara Graziani"], "title": "Test-Time Tuned Language Models Enable End-to-end De Novo Molecular Structure Generation from MS/MS Spectra", "comment": null, "summary": "Tandem Mass Spectrometry enables the identification of unknown compounds in\ncrucial fields such as metabolomics, natural product discovery and\nenvironmental analysis. However, current methods rely on database matching from\npreviously observed molecules, or on multi-step pipelines that require\nintermediate fragment or fingerprint prediction. This makes finding the correct\nmolecule highly challenging, particularly for compounds absent from reference\ndatabases. We introduce a framework that, by leveraging test-time tuning,\nenhances the learning of a pre-trained transformer model to address this gap,\nenabling end-to-end de novo molecular structure generation directly from the\ntandem mass spectra and molecular formulae, bypassing manual annotations and\nintermediate steps. We surpass the de-facto state-of-the-art approach DiffMS on\ntwo popular benchmarks NPLIB1 and MassSpecGym by 100% and 20%, respectively.\nTest-time tuning on experimental spectra allows the model to dynamically adapt\nto novel spectra, and the relative performance gain over conventional\nfine-tuning is of 62% on MassSpecGym. When predictions deviate from the ground\ntruth, the generated molecular candidates remain structurally accurate,\nproviding valuable guidance for human interpretation and more reliable\nidentification.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.23845", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23845", "abs": "https://arxiv.org/abs/2510.23845", "authors": ["Grace Byun", "Rebecca Lipschutz", "Sean T. Minton", "Abigail Lott", "Jinho D. Choi"], "title": "CRADLE Bench: A Clinician-Annotated Benchmark for Multi-Faceted Mental Health Crisis and Safety Risk Detection", "comment": null, "summary": "Detecting mental health crisis situations such as suicide ideation, rape,\ndomestic violence, child abuse, and sexual harassment is a critical yet\nunderexplored challenge for language models. When such situations arise during\nuser--model interactions, models must reliably flag them, as failure to do so\ncan have serious consequences. In this work, we introduce CRADLE BENCH, a\nbenchmark for multi-faceted crisis detection. Unlike previous efforts that\nfocus on a limited set of crisis types, our benchmark covers seven types\ndefined in line with clinical standards and is the first to incorporate\ntemporal labels. Our benchmark provides 600 clinician-annotated evaluation\nexamples and 420 development examples, together with a training corpus of\naround 4K examples automatically labeled using a majority-vote ensemble of\nmultiple language models, which significantly outperforms single-model\nannotation. We further fine-tune six crisis detection models on subsets defined\nby consensus and unanimous ensemble agreement, providing complementary models\ntrained under different agreement criteria.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2506.18830", "categories": ["physics.plasm-ph", "76W05, 57R22"], "pdf": "https://arxiv.org/pdf/2506.18830", "abs": "https://arxiv.org/abs/2506.18830", "authors": ["Alejandro Mesa Dame", "Hong Qin", "Eric Palmerduca", "Yichen Fu"], "title": "Wave Topology in Hall MHD", "comment": "17 pages, 3 figures", "summary": "Hall Magnetohydrodynamics (HMHD) extends ideal MHD by incorporating the Hall\neffect via the induction equation, making it more accurate for describing\nplasma behavior at length scales below the ion skin depth. Despite its\nimportance, a comprehensive description of the eigenmodes in HMHD has been\nlacking. In this work, we derive the complete spectrum and eigenvectors of HMHD\nwaves and identify their underlying topological structure. We prove that the\nHMHD wave spectrum is homotopic to that of ideal MHD, consisting of three\ndistinct branches: the slow magnetosonic-Hall waves, the shear Alfv\\'en-Hall\nwaves, and the fast magnetosonic-Hall waves, which continuously reduce to their\nideal MHD counterparts in the limit of vanishing Hall parameter. Contrary to a\nrecent claim, we find that HMHD does not admit any additional wave branches\nbeyond those in ideal MHD. The key qualitative difference lies in the\ntopological nature of the HMHD wave structure: it exhibits nontrivial topology\ncharacterized by a Weyl point-an isolated eigenmode degeneracy point-and\nassociated nonzero Chern numbers of the eigenmode bundles over a 2-sphere in\nk-space surrounding the Weyl point.", "AI": {"tldr": "Hall Magnetohydrodynamics (HMHD) is an extension of ideal MHD that includes the Hall effect for more accurate plasma behavior at small scales. This paper comprehensively analyzes HMHD's eigenmodes, proving its wave spectrum is homotopic to ideal MHD's, consisting of slow, shear Alfv\u00e9n, and fast magnetosonic-Hall waves. It identifies a nontrivial topological structure with a Weyl point and nonzero Chern numbers, refuting claims of additional wave branches. The findings clarify HMHD's wave properties and topological characteristics.", "motivation": "Ideal Magnetohydrodynamics (MHD) is limited in describing plasma behavior at small length scales. Hall Magnetohydrodynamics (HMHD) extends ideal MHD by incorporating the Hall effect through the induction equation, offering greater accuracy for phenomena below the ion skin depth. However, a complete understanding and description of HMHD's eigenmodes and their topological structure were lacking, hindering a full grasp of its physical implications.", "method": "The researchers derived the complete spectrum and eigenvectors of Hall Magnetohydrodynamics (HMHD) waves. They analyzed these to identify the underlying topological structure of the wave spectrum. The study involved mathematical derivations and theoretical analysis of the HMHD equations and their solutions.", "result": "The study successfully derived the complete spectrum and eigenvectors of HMHD waves. It was proven that the HMHD wave spectrum is homotopic to that of ideal MHD, comprising three distinct branches: slow magnetosonic-Hall waves, shear Alfv\u00e9n-Hall waves, and fast magnetosonic-Hall waves. These branches continuously merge into their ideal MHD counterparts as the Hall parameter diminishes. Crucially, the research found that HMHD does not introduce new wave branches beyond those in ideal MHD. A key finding is the nontrivial topological nature of the HMHD wave structure, characterized by a Weyl point (an isolated eigenmode degeneracy point) and associated nonzero Chern numbers of the eigenmode bundles over a 2-sphere in k-space around the Weyl point.", "conclusion": "This work provides a comprehensive analysis of Hall Magnetohydrodynamics (HMHD) wave properties and their topological structure. The findings confirm that HMHD's spectrum is topologically similar to ideal MHD, comprising three main wave branches, and refutes the existence of additional branches. The identification of a Weyl point and associated topological invariants offers new insights into the fundamental physics of HMHD, with potential implications for understanding plasma phenomena at small scales and in topological contexts. Future work could explore the experimental verification of these topological features and their role in specific astrophysical or laboratory plasma scenarios."}}
{"id": "2510.24438", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.24438", "abs": "https://arxiv.org/abs/2510.24438", "authors": ["Abdullah Mushtaq", "Rafay Naeem", "Ezieddin Elmahjub", "Ibrahim Ghaznavi", "Shawqi Al-Maliki", "Mohamed Abdallah", "Ala Al-Fuqaha", "Junaid Qadir"], "title": "Can LLMs Write Faithfully? An Agent-Based Evaluation of LLM-generated Islamic Content", "comment": "Accepted at 39th Conference on Neural Information Processing Systems\n  (NeurIPS 2025) Workshop: 5th Muslims in Machine Learning (MusIML) Workshop", "summary": "Large language models are increasingly used for Islamic guidance, but risk\nmisquoting texts, misapplying jurisprudence, or producing culturally\ninconsistent responses. We pilot an evaluation of GPT-4o, Ansari AI, and Fanar\non prompts from authentic Islamic blogs. Our dual-agent framework uses a\nquantitative agent for citation verification and six-dimensional scoring (e.g.,\nStructure, Islamic Consistency, Citations) and a qualitative agent for\nfive-dimensional side-by-side comparison (e.g., Tone, Depth, Originality).\nGPT-4o scored highest in Islamic Accuracy (3.93) and Citation (3.38), Ansari AI\nfollowed (3.68, 3.32), and Fanar lagged (2.76, 1.82). Despite relatively strong\nperformance, models still fall short in reliably producing accurate Islamic\ncontent and citations -- a paramount requirement in faith-sensitive writing.\nGPT-4o had the highest mean quantitative score (3.90/5), while Ansari AI led\nqualitative pairwise wins (116/200). Fanar, though trailing, introduces\ninnovations for Islamic and Arabic contexts. This study underscores the need\nfor community-driven benchmarks centering Muslim perspectives, offering an\nearly step toward more reliable AI in Islamic knowledge and other high-stakes\ndomains such as medicine, law, and journalism.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4f0a\u65af\u5170\u6307\u5bfc\u65b9\u9762\u5b58\u5728\u8bef\u5f15\u3001\u66f2\u89e3\u6559\u6cd5\u548c\u6587\u5316\u4e0d\u4e00\u81f4\u7684\u98ce\u9669\u3002\u672c\u7814\u7a76\u8bc4\u4f30\u4e86 GPT-4o\u3001Ansari AI \u548c Fanar \u5728\u4f0a\u65af\u5170\u535a\u5ba2\u63d0\u793a\u4e0b\u7684\u8868\u73b0\u3002\u91c7\u7528\u5305\u542b\u5b9a\u91cf\uff08\u5f15\u7528\u9a8c\u8bc1\u3001\u516d\u7ef4\u5ea6\u8bc4\u5206\uff09\u548c\u5b9a\u6027\uff08\u4fa7\u8fb9\u6bd4\u8f83\u3001\u4e94\u7ef4\u5ea6\u8bc4\u5206\uff09\u7684\u6df7\u5408\u8bc4\u4f30\u6846\u67b6\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u4f0a\u65af\u5170\u6307\u5bfc\u9886\u57df\u7684\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u5b58\u5728\u5f15\u7528\u4e0d\u51c6\u786e\u3001\u6559\u6cd5\u5e94\u7528\u9519\u8bef\u4ee5\u53ca\u6587\u5316\u54cd\u5e94\u4e0d\u517c\u5bb9\u7b49\u98ce\u9669\uff0c\u8fd9\u5728\u5b97\u6559\u6307\u5bfc\u9886\u57df\u662f\u4e0d\u53ef\u63a5\u53d7\u7684\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u8bc4\u4f30\u73b0\u6709 LLM \u5728\u6b64\u654f\u611f\u9886\u57df\u7684\u8868\u73b0\uff0c\u5e76\u4e3a\u672a\u6765\u6539\u8fdb\u63d0\u4f9b\u65b9\u5411\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u4e86\u4e00\u4e2a\u53cc\u4e3b\u4f53\u6846\u67b6\u6765\u8bc4\u4f30 GPT-4o\u3001Ansari AI \u548c Fanar \u4e09\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002\u5b9a\u91cf\u4e3b\u4f53\u8d1f\u8d23\u8fdb\u884c\u5f15\u6587\u9a8c\u8bc1\uff0c\u5e76\u4ece\u7ed3\u6784\u3001\u4f0a\u65af\u5170\u4e00\u81f4\u6027\u3001\u5f15\u6587\u7b49\u516d\u4e2a\u7ef4\u5ea6\u8fdb\u884c\u8bc4\u5206\u3002\u5b9a\u6027\u4e3b\u4f53\u5219\u8fdb\u884c\u5e76\u5217\u6bd4\u8f83\uff0c\u4ece\u8bed\u8c03\u3001\u6df1\u5ea6\u3001\u539f\u521b\u6027\u7b49\u4e94\u4e2a\u7ef4\u5ea6\u8fdb\u884c\u8bc4\u4f30\u3002\u8bc4\u4f30\u7684\u63d0\u793a\u8bed\u6765\u81ea\u771f\u5b9e\u7684\u4f0a\u65af\u5170\u535a\u5ba2\u3002", "result": "\u5728\u4f0a\u65af\u5170\u51c6\u786e\u6027\u548c\u5f15\u6587\u65b9\u9762\uff0cGPT-4o \u7684\u5f97\u5206\u6700\u9ad8\uff08\u5206\u522b\u4e3a 3.93 \u548c 3.38\uff09\uff0c\u5176\u6b21\u662f Ansari AI\uff08\u5206\u522b\u4e3a 3.68 \u548c 3.32\uff09\uff0cFanar \u7684\u5f97\u5206\u6700\u4f4e\uff08\u5206\u522b\u4e3a 2.76 \u548c 1.82\uff09\u3002GPT-4o \u7684\u5e73\u5747\u5b9a\u91cf\u5f97\u5206\u4e3a 3.90/5\uff0c\u800c Ansari AI \u5728\u5b9a\u6027\u6bd4\u8f83\u4e2d\u83b7\u80dc\u6b21\u6570\u6700\u591a\uff08116/200\uff09\u3002\u5c3d\u7ba1 Fanar \u8868\u73b0\u843d\u540e\uff0c\u4f46\u5176\u5728\u4f0a\u65af\u5170\u548c\u963f\u62c9\u4f2f\u8bed\u5883\u65b9\u9762\u5177\u6709\u521b\u65b0\u6027\u3002", "conclusion": "\u5c3d\u7ba1 GPT-4o \u548c Ansari AI \u5728\u4f0a\u65af\u5170\u6307\u5bfc\u65b9\u9762\u8868\u73b0\u51fa\u76f8\u5bf9\u8f83\u5f3a\u7684\u80fd\u529b\uff0c\u4f46\u76ee\u524d\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u53ef\u9760\u751f\u6210\u51c6\u786e\u7684\u4f0a\u65af\u5170\u5185\u5bb9\u548c\u5f15\u7528\u65b9\u9762\u4ecd\u6709\u4e0d\u8db3\uff0c\u800c\u8fd9\u6070\u6070\u662f\u4fe1\u4ef0\u654f\u611f\u578b\u5199\u4f5c\u6240\u5fc5\u9700\u7684\u3002\u672c\u7814\u7a76\u5f3a\u8c03\u4e86\u5efa\u7acb\u4ee5\u7a46\u65af\u6797\u89c6\u89d2\u4e3a\u4e2d\u5fc3\u7684\u3001\u793e\u533a\u9a71\u52a8\u7684\u57fa\u51c6\u6d4b\u8bd5\u7684\u5fc5\u8981\u6027\uff0c\u5e76\u4e3a AI \u5728\u4f0a\u65af\u5170\u77e5\u8bc6\u53ca\u533b\u5b66\u3001\u6cd5\u5f8b\u3001\u65b0\u95fb\u7b49\u9ad8\u98ce\u9669\u9886\u57df\u7684\u5e94\u7528\u8fc8\u51fa\u4e86\u521d\u6b65\u63a2\u7d22\u3002"}}
{"id": "2510.23772", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23772", "abs": "https://arxiv.org/abs/2510.23772", "authors": ["Vivek Veeriah", "Federico Barbero", "Marcus Chiam", "Xidong Feng", "Michael Dennis", "Ryan Pachauri", "Thomas Tumiel", "Johan Obando-Ceron", "Jiaxin Shi", "Shaobo Hou", "Satinder Singh", "Nenad Toma\u0161ev", "Tom Zahavy"], "title": "Evaluating In Silico Creativity: An Expert Review of AI Chess Compositions", "comment": "Accepted at the Creative AI Track, NeurIPS 2025", "summary": "The rapid advancement of Generative AI has raised significant questions\nregarding its ability to produce creative and novel outputs. Our recent work\ninvestigates this question within the domain of chess puzzles and presents an\nAI system designed to generate puzzles characterized by aesthetic appeal,\nnovelty, counter-intuitive and unique solutions. We briefly discuss our method\nbelow and refer the reader to the technical paper for more details. To assess\nour system's creativity, we presented a curated booklet of AI-generated puzzles\nto three world-renowned experts: International Master for chess compositions\nAmatzia Avni, Grandmaster Jonathan Levitt, and Grandmaster Matthew Sadler. All\nthree are noted authors on chess aesthetics and the evolving role of computers\nin the game. They were asked to select their favorites and explain what made\nthem appealing, considering qualities such as their creativity, level of\nchallenge, or aesthetic design.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u751f\u6210\u5f0fAI\u5728\u56fd\u9645\u8c61\u68cb\u8c1c\u9898\u751f\u6210\u65b9\u9762\u7684\u521b\u9020\u529b\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u80fd\u591f\u751f\u6210\u5177\u6709\u7f8e\u5b66\u5438\u5f15\u529b\u3001\u65b0\u9896\u6027\u3001\u53cd\u76f4\u89c9\u548c\u72ec\u7279\u89e3\u6cd5\u7684AI\u7cfb\u7edf\u3002\u901a\u8fc7\u9080\u8bf7\u4e09\u4f4d\u56fd\u9645\u8c61\u68cb\u5927\u5e08\u5bf9AI\u751f\u6210\u7684\u8c1c\u9898\u8fdb\u884c\u8bc4\u4f30\uff0c\u65e8\u5728\u91cf\u5316AI\u7684\u521b\u9020\u529b\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u7684\u98de\u901f\u53d1\u5c55\uff0c\u5176\u751f\u6210\u521b\u610f\u548c\u65b0\u9896\u5185\u5bb9\u7684\u80fd\u529b\u5f15\u53d1\u4e86\u5e7f\u6cdb\u5173\u6ce8\u3002\u672c\u7814\u7a76\u805a\u7126\u4e8e\u56fd\u9645\u8c61\u68cb\u8c1c\u9898\u751f\u6210\u9886\u57df\uff0c\u65e8\u5728\u63a2\u7d22AI\u5728\u8fd9\u4e00\u5177\u6709\u9ad8\u5ea6\u521b\u9020\u6027\u8981\u6c42\u7684\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u8bc4\u4f30\u5176\u751f\u6210\u5177\u6709\u7f8e\u5b66\u4ef7\u503c\u548c\u65b0\u9896\u6027\u7684\u8c1c\u9898\u7684\u80fd\u529b\u3002", "method": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2aAI\u7cfb\u7edf\uff0c\u7528\u4e8e\u751f\u6210\u5177\u6709\u7279\u5b9a\u54c1\u8d28\uff08\u5982\u7f8e\u5b66\u5438\u5f15\u529b\u3001\u65b0\u9896\u6027\u3001\u53cd\u76f4\u89c9\u548c\u72ec\u7279\u89e3\u6cd5\uff09\u7684\u56fd\u9645\u8c61\u68cb\u8c1c\u9898\u3002\u7814\u7a76\u8005\u9080\u8bf7\u4e86\u4e09\u4f4d\u56fd\u9645\u8c61\u68cb\u9886\u57df\u7684\u4e13\u5bb6\uff08\u56fd\u9645\u5927\u5e08Amatzia Avni\u3001\u7279\u7ea7\u5927\u5e08 Jonathan Levitt \u548c\u7279\u7ea7\u5927\u5e08 Matthew Sadler\uff09\u8bc4\u4f30AI\u751f\u6210\u7684\u8c1c\u9898\u3002\u4e13\u5bb6\u4eec\u88ab\u8981\u6c42\u9009\u51fa\u4ed6\u4eec\u6700\u559c\u6b22\u7684\u8c1c\u9898\uff0c\u5e76\u9610\u8ff0\u5176\u5438\u5f15\u529b\u6240\u5728\uff0c\u8bc4\u4f30\u7ef4\u5ea6\u5305\u62ec\u521b\u9020\u529b\u3001\u6311\u6218\u6027\u548c\u7f8e\u5b66\u8bbe\u8ba1\u7b49\u65b9\u9762\u3002", "result": "\u4e09\u4f4d\u56fd\u9645\u8c61\u68cb\u4e13\u5bb6\u5bf9AI\u751f\u6210\u7684\u8c1c\u9898\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002\u867d\u7136\u5177\u4f53\u91cf\u5316\u6307\u6807\u672a\u5728\u6458\u8981\u4e2d\u8be6\u7ec6\u8bf4\u660e\uff0c\u4f46\u8bc4\u4f30\u7ed3\u679c\u8868\u660e\u4e13\u5bb6\u4eec\u80fd\u591f\u8bc6\u522b\u5e76\u6b23\u8d4fAI\u751f\u6210\u7684\u8c1c\u9898\u4e2d\u7684\u521b\u9020\u529b\u3001\u6311\u6218\u6027\u548c\u7f8e\u5b66\u8bbe\u8ba1\u3002\u4e13\u5bb6\u4eec\u7684\u53cd\u9988\u4e3a\u8861\u91cfAI\u5728\u56fd\u9645\u8c61\u68cb\u8c1c\u9898\u751f\u6210\u65b9\u9762\u7684\u521b\u9020\u529b\u63d0\u4f9b\u4e86\u5b9a\u6027\u4f9d\u636e\u3002", "conclusion": "\u672c\u7814\u7a76\u5c55\u793a\u4e86AI\u5728\u751f\u6210\u5177\u6709\u521b\u9020\u6027\u548c\u7f8e\u5b66\u5438\u5f15\u529b\u7684\u56fd\u9645\u8c61\u68cb\u8c1c\u9898\u65b9\u9762\u7684\u6f5c\u529b\u3002\u901a\u8fc7\u5f15\u5165\u4e13\u5bb6\u8bc4\u4f30\u673a\u5236\uff0c\u4e3a\u91cf\u5316AI\u7684\u521b\u9020\u529b\u63d0\u4f9b\u4e86\u4e00\u79cd\u9014\u5f84\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63a2\u7d22\u66f4\u590d\u6742\u7684\u8c1c\u9898\u751f\u6210\uff0c\u5e76\u5f00\u53d1\u66f4\u7cbe\u7ec6\u7684\u8bc4\u4f30\u6307\u6807\u6765\u5168\u9762\u8861\u91cfAI\u7684\u521b\u9020\u529b\u3002"}}
{"id": "2510.21239", "categories": ["physics.plasm-ph"], "pdf": "https://arxiv.org/pdf/2510.21239", "abs": "https://arxiv.org/abs/2510.21239", "authors": ["Shun-yi Yang", "Tao Tao", "Guang-yue Hu", "Chao Xiong", "Tian-yi Li", "Xue-cheng Li", "Hui-bo Tang", "Shuo-ting Shao", "Xiang Lv", "Chen Zhang", "Ming-yang Yu"], "title": "Laboratory formation of scaled astrophysical outflows", "comment": null, "summary": "Astrophysical systems exhibit a rich diversity of outflow morphologies, yet\ntheir mechanisms and existence conditions remain among the most persistent\npuzzles in the field. Here we present scaled laboratory experiments based on\nlaser-driven plasma outflow into magnetized ambient gas, which mimic five basic\nastrophysical outflows regulated by interstellar medium, namely collimated\njets, blocked jets, elliptical bubbles, as well as spherical winds and bubbles.\nTheir morphologies and existence conditions are found to be uniquely determined\nby the external Alfvenic and sonic Mach numbers Me-a and Me-s, i.e. the\nrelative strengths of the outflow ram pressure against the magnetic/thermal\npressures in the interstellar medium, with transitions occurring at Me-a ~ 2\nand 0.5, as well as Me-s ~ 1. These results are confirmed by\nmagnetohydrodynamics simulations and should also be verifiable from existing\nand future astronomical observations. Our findings provide a quantitative\nframework for understanding astrophysical outflows.", "AI": {"tldr": "\u901a\u8fc7\u6fc0\u5149\u7b49\u79bb\u5b50\u4f53\u5b9e\u9a8c\uff0c\u7814\u7a76\u4e86\u78c1\u5316\u80cc\u666f\u6c14\u4f53\u4e2d\u7684\u7b49\u79bb\u5b50\u4f53\u6d41\u51fa\u5f62\u6001\uff0c\u53d1\u73b0\u4e86\u5176\u5f62\u6001\uff08\u51c6\u76f4\u55b7\u6d41\u3001\u963b\u585e\u55b7\u6d41\u3001\u692d\u5706\u6ce1\u3001\u7403\u5f62\u98ce\u548c\u6ce1\uff09\u7531\u5916\u90e8\u963f\u5c14\u82ac\u9a6c\u8d6b\u6570 (Me-a) \u548c\u58f0\u6ce2\u9a6c\u8d6b\u6570 (Me-s) \u51b3\u5b9a\uff0c\u5e76\u7ed9\u51fa\u4e86\u5f62\u6001\u8f6c\u53d8\u7684\u4e34\u754c\u503c (Me-a ~ 2 \u548c 0.5\uff0cMe-s ~ 1)\uff0c\u4e3a\u7406\u89e3\u5929\u4f53\u7269\u7406\u6d41\u51fa\u63d0\u4f9b\u4e86\u5b9a\u91cf\u6846\u67b6\u3002", "motivation": "\u5929\u4f53\u7269\u7406\u7cfb\u7edf\u4e2d\u6d41\u51fa\u7684\u5f62\u6001\u591a\u6837\uff0c\u4f46\u5176\u5f62\u6210\u673a\u5236\u548c\u5b58\u5728\u6761\u4ef6\u4ecd\u662f\u8be5\u9886\u57df\u672a\u89e3\u4e4b\u8c1c\u3002\u7406\u89e3\u8fd9\u4e9b\u6d41\u51fa\u7684\u5f62\u6001\u548c\u5f62\u6210\u6761\u4ef6\u5bf9\u4e8e\u63ed\u793a\u5b87\u5b99\u6f14\u5316\u3001\u661f\u7cfb\u5f62\u6210\u4ee5\u53ca\u80fd\u91cf\u4f20\u8f93\u8fc7\u7a0b\u81f3\u5173\u91cd\u8981\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u57fa\u4e8e\u6fc0\u5149\u9a71\u52a8\u7684\u7b49\u79bb\u5b50\u4f53\u6d41\u51fa\u5b9e\u9a8c\uff0c\u5728\u78c1\u5316\u80cc\u666f\u6c14\u4f53\u4e2d\u6a21\u62df\u5929\u4f53\u7269\u7406\u6d41\u51fa\u3002\u901a\u8fc7\u6539\u53d8\u5b9e\u9a8c\u53c2\u6570\uff0c\u63a7\u5236\u7b49\u79bb\u5b50\u4f53\u6d41\u51fa\u7684\u52a8\u538b\u4e0e\u80cc\u666f\u4ecb\u8d28\u7684\u78c1\u538b\u548c\u70ed\u538b\u7684\u76f8\u5bf9\u5f3a\u5ea6\uff0c\u5373\u5916\u90e8\u963f\u5c14\u82ac\u9a6c\u8d6b\u6570 (Me-a) \u548c\u58f0\u6ce2\u9a6c\u8d6b\u6570 (Me-s)\uff0c\u6765\u7814\u7a76\u4e0d\u540c\u6d41\u51fa\u5f62\u6001\u7684\u5f62\u6210\u6761\u4ef6\u3002\u5b9e\u9a8c\u7ed3\u679c\u901a\u8fc7\u78c1\u6d41\u4f53\u529b\u5b66\u6a21\u62df\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6d41\u51fa\u7684\u5f62\u6001\uff08\u51c6\u76f4\u55b7\u6d41\u3001\u963b\u585e\u55b7\u6d41\u3001\u692d\u5706\u6ce1\u3001\u7403\u5f62\u98ce\u548c\u6ce1\uff09\u5b8c\u5168\u7531\u5916\u90e8\u963f\u5c14\u82ac\u9a6c\u8d6b\u6570 (Me-a) \u548c\u58f0\u6ce2\u9a6c\u8d6b\u6570 (Me-s) \u51b3\u5b9a\u3002\u7814\u7a76\u786e\u5b9a\u4e86\u5f62\u6001\u8f6c\u53d8\u7684\u4e34\u754c\u503c\uff1a\u5f53 Me-a \u7ea6\u7b49\u4e8e 2 \u548c 0.5\uff0c\u4ee5\u53ca Me-s \u7ea6\u7b49\u4e8e 1 \u65f6\uff0c\u6d41\u51fa\u5f62\u6001\u53d1\u751f\u8f6c\u53d8\u3002\u8fd9\u4e9b\u53d1\u73b0\u5f97\u5230\u4e86\u78c1\u6d41\u4f53\u529b\u5b66\u6a21\u62df\u7684\u8bc1\u5b9e\u3002", "conclusion": "\u672c\u7814\u7a76\u901a\u8fc7\u5b9e\u9a8c\u5ba4\u6a21\u62df\u5b9e\u9a8c\uff0c\u9996\u6b21\u63d0\u51fa\u4e86\u4e00\u4e2a\u5b9a\u91cf\u6846\u67b6\u6765\u7406\u89e3\u5929\u4f53\u7269\u7406\u6d41\u51fa\u7684\u5f62\u6001\u53ca\u5176\u5f62\u6210\u6761\u4ef6\uff0c\u8be5\u6846\u67b6\u7531\u5916\u90e8\u963f\u5c14\u82ac\u9a6c\u8d6b\u6570\u548c\u58f0\u6ce2\u9a6c\u8d6b\u6570\u51b3\u5b9a\u3002\u8fd9\u4e9b\u53d1\u73b0\u4e0d\u4ec5\u80fd\u89e3\u91ca\u5df2\u6709\u7684\u5929\u6587\u89c2\u6d4b\uff0c\u8fd8\u80fd\u6307\u5bfc\u672a\u6765\u7684\u89c2\u6d4b\u7814\u7a76\uff0c\u6709\u52a9\u4e8e\u6df1\u5165\u7406\u89e3\u5b87\u5b99\u4e2d\u7684\u80fd\u91cf\u4f20\u8f93\u548c\u7269\u8d28\u5206\u5e03\u3002\u7814\u7a76\u7684\u5c40\u9650\u6027\u53ef\u80fd\u5728\u4e8e\u5b9e\u9a8c\u5ba4\u6a21\u62df\u7684\u5c3a\u5ea6\u6548\u5e94\u548c\u7269\u7406\u6761\u4ef6\u7684\u7b80\u5316\uff0c\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u8003\u8651\u66f4\u590d\u6742\u7684\u7269\u7406\u8fc7\u7a0b\u548c\u66f4\u5927\u5c3a\u5ea6\u7684\u6a21\u62df\u3002"}}
{"id": "2510.23807", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.23807", "abs": "https://arxiv.org/abs/2510.23807", "authors": ["Hamid R. Tizhoosh"], "title": "Why Foundation Models in Pathology Are Failing", "comment": null, "summary": "In non-medical domains, foundation models (FMs) have revolutionized computer\nvision and language processing through large-scale self-supervised and\nmultimodal learning. Consequently, their rapid adoption in computational\npathology was expected to deliver comparable breakthroughs in cancer diagnosis,\nprognostication, and multimodal retrieval. However, recent systematic\nevaluations reveal fundamental weaknesses: low diagnostic accuracy, poor\nrobustness, geometric instability, heavy computational demands, and concerning\nsafety vulnerabilities. This short paper examines these shortcomings and argues\nthat they stem from deeper conceptual mismatches between the assumptions\nunderlying generic foundation modeling in mainstream AI and the intrinsic\ncomplexity of human tissue. Seven interrelated causes are identified:\nbiological complexity, ineffective self-supervision, overgeneralization,\nexcessive architectural complexity, lack of domain-specific innovation,\ninsufficient data, and a fundamental design flaw related to tissue patch size.\nThese findings suggest that current pathology foundation models remain\nconceptually misaligned with the nature of tissue morphology and call for a\nfundamental rethinking of the paradigm itself.", "AI": {"tldr": "\u867d\u7136\u5728\u975e\u533b\u7597\u9886\u57df\u53d6\u5f97\u4e86\u5de8\u5927\u6210\u529f\uff0c\u4f46\u76ee\u524d\u8ba1\u7b97\u75c5\u7406\u5b66\u9886\u57df\u7684\u57fa\u7840\u6a21\u578b\uff08FMs\uff09\u5728\u764c\u75c7\u8bca\u65ad\u3001\u9884\u540e\u548c\u591a\u6a21\u6001\u68c0\u7d22\u65b9\u9762\u5b58\u5728\u91cd\u5927\u7f3a\u9677\uff0c\u5305\u62ec\u8bca\u65ad\u51c6\u786e\u6027\u4f4e\u3001\u9c81\u68d2\u6027\u5dee\u3001\u51e0\u4f55\u4e0d\u7a33\u5b9a\u6027\u3001\u8ba1\u7b97\u9700\u6c42\u9ad8\u548c\u5b89\u5168\u6f0f\u6d1e\u3002\u672c\u6587\u6df1\u5165\u63a2\u8ba8\u4e86\u8fd9\u4e9b\u95ee\u9898\uff0c\u5e76\u8ba4\u4e3a\u5176\u6839\u6e90\u5728\u4e8e\u4e3b\u6d41AI\u4e2d\u7684\u901a\u7528FM\u5047\u8bbe\u4e0e\u4eba\u4f53\u7ec4\u7ec7\u5185\u5728\u590d\u6742\u6027\u4e4b\u95f4\u7684\u6982\u5ff5\u4e0d\u5339\u914d\u3002\u6587\u7ae0\u786e\u5b9a\u4e86\u4e03\u4e2a\u76f8\u4e92\u5173\u8054\u7684\u539f\u56e0\uff1a\u751f\u7269\u590d\u6742\u6027\u3001\u65e0\u6548\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u3001\u8fc7\u5ea6\u6cdb\u5316\u3001\u8fc7\u5ea6\u7684\u67b6\u6784\u590d\u6742\u6027\u3001\u7f3a\u4e4f\u9886\u57df\u7279\u5b9a\u521b\u65b0\u3001\u6570\u636e\u4e0d\u8db3\u4ee5\u53ca\u4e0e\u7ec4\u7ec7\u6591\u5757\u5c3a\u5bf8\u76f8\u5173\u7684\u57fa\u672c\u8bbe\u8ba1\u7f3a\u9677\u3002\u8fd9\u4e9b\u53d1\u73b0\u8868\u660e\uff0c\u5f53\u524d\u75c5\u7406\u5b66FM\u5728\u6982\u5ff5\u4e0a\u672a\u80fd\u4e0e\u7ec4\u7ec7\u5f62\u6001\u5b66\u7684\u672c\u8d28\u4fdd\u6301\u4e00\u81f4\uff0c\u9700\u8981\u5bf9\u8be5\u8303\u5f0f\u8fdb\u884c\u6839\u672c\u6027\u53cd\u601d\u3002", "motivation": "\u5728\u975e\u533b\u7597\u9886\u57df\uff0c\u57fa\u7840\u6a21\u578b\uff08FMs\uff09\u901a\u8fc7\u5927\u89c4\u6a21\u81ea\u76d1\u7763\u548c\u591a\u6a21\u6001\u5b66\u4e60\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u548c\u8bed\u8a00\u5904\u7406\u65b9\u9762\u53d6\u5f97\u4e86\u9769\u547d\u6027\u8fdb\u5c55\u3002\u56e0\u6b64\uff0c\u4eba\u4eec\u671f\u671b\u5b83\u4eec\u5728\u8ba1\u7b97\u75c5\u7406\u5b66\u4e2d\u7684\u5feb\u901f\u5e94\u7528\u80fd\u591f\u63a8\u52a8\u764c\u75c7\u8bca\u65ad\u3001\u9884\u540e\u548c\u591a\u6a21\u6001\u68c0\u7d22\u65b9\u9762\u7684\u7a81\u7834\u3002\u7136\u800c\uff0c\u5b9e\u9645\u5e94\u7528\u63ed\u793a\u4e86FMs\u5728\u8ba1\u7b97\u75c5\u7406\u5b66\u4e2d\u5b58\u5728\u663e\u8457\u7684\u5c40\u9650\u6027\uff0c\u8fd9\u963b\u788d\u4e86\u5176\u5728\u764c\u75c7\u8bca\u65ad\u7b49\u5173\u952e\u9886\u57df\u7684\u6709\u6548\u5e94\u7528\uff0c\u56e0\u6b64\uff0c\u7406\u89e3\u5e76\u89e3\u51b3\u8fd9\u4e9b\u5c40\u9650\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4ee5\u5145\u5206\u53d1\u6325AI\u5728\u75c5\u7406\u5b66\u4e2d\u7684\u6f5c\u529b\u3002", "method": "\u672c\u6587\u91c7\u7528\u7cfb\u7edf\u6027\u8bc4\u4f30\u548c\u6df1\u5165\u5206\u6790\u7684\u65b9\u6cd5\uff0c\u8003\u5bdf\u4e86\u8ba1\u7b97\u75c5\u7406\u5b66\u9886\u57df\u73b0\u6709\u57fa\u7840\u6a21\u578b\uff08FMs\uff09\u7684\u7f3a\u70b9\u3002\u901a\u8fc7\u8bc6\u522b\u6a21\u578b\u5728\u8bca\u65ad\u51c6\u786e\u6027\u3001\u9c81\u68d2\u6027\u3001\u51e0\u4f55\u7a33\u5b9a\u6027\u3001\u8ba1\u7b97\u9700\u6c42\u548c\u5b89\u5168\u6027\u65b9\u9762\u5b58\u5728\u7684\u6839\u672c\u6027\u5f31\u70b9\uff0c\u5e76\u8ffd\u6eaf\u8fd9\u4e9b\u95ee\u9898\u4e0e\u4e3b\u6d41AI\u901a\u7528FM\u5047\u8bbe\u4e0e\u4eba\u4f53\u7ec4\u7ec7\u590d\u6742\u6027\u4e4b\u95f4\u6982\u5ff5\u4e0d\u5339\u914d\u7684\u5173\u8054\u3002\u6587\u7ae0\u8fdb\u4e00\u6b65\u8be6\u7ec6\u9610\u8ff0\u4e86\u4e03\u4e2a\u5177\u4f53\u539f\u56e0\uff1a\u751f\u7269\u590d\u6742\u6027\u3001\u65e0\u6548\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u3001\u8fc7\u5ea6\u6cdb\u5316\u3001\u8fc7\u5ea6\u7684\u67b6\u6784\u590d\u6742\u6027\u3001\u7f3a\u4e4f\u9886\u57df\u7279\u5b9a\u521b\u65b0\u3001\u6570\u636e\u4e0d\u8db3\u4ee5\u53ca\u7ec4\u7ec7\u6591\u5757\u5c3a\u5bf8\u7684\u8bbe\u8ba1\u7f3a\u9677\u3002", "result": "\u7cfb\u7edf\u6027\u8bc4\u4f30\u63ed\u793a\u4e86\u5f53\u524d\u8ba1\u7b97\u75c5\u7406\u5b66\u9886\u57df\u57fa\u7840\u6a21\u578b\uff08FMs\uff09\u5b58\u5728\u4e00\u7cfb\u5217\u6839\u672c\u6027\u95ee\u9898\uff0c\u5305\u62ec\u8bca\u65ad\u51c6\u786e\u6027\u4f4e\u3001\u9c81\u68d2\u6027\u5dee\u3001\u51e0\u4f55\u4e0d\u7a33\u5b9a\u6027\u3001\u8ba1\u7b97\u9700\u6c42\u9ad8\u4ee5\u53ca\u5b89\u5168\u6f0f\u6d1e\u7b49\u3002\u8fd9\u4e9b\u95ee\u9898\u963b\u788d\u4e86FMs\u5728\u764c\u75c7\u8bca\u65ad\u3001\u9884\u540e\u548c\u591a\u6a21\u6001\u68c0\u7d22\u7b49\u65b9\u9762\u7684\u6709\u6548\u5e94\u7528\u3002", "conclusion": "\u672c\u6587\u7684\u7ed3\u8bba\u662f\uff0c\u5f53\u524d\u8ba1\u7b97\u75c5\u7406\u5b66\u9886\u57df\u7684\u57fa\u7840\u6a21\u578b\uff08FMs\uff09\u5728\u6982\u5ff5\u4e0a\u672a\u80fd\u4e0e\u7ec4\u7ec7\u5f62\u6001\u5b66\u7684\u5185\u5728\u590d\u6742\u6027\u76f8\u5339\u914d\uff0c\u5bfc\u81f4\u4e86\u6a21\u578b\u5728\u51c6\u786e\u6027\u3001\u9c81\u68d2\u6027\u548c\u5b89\u5168\u6027\u65b9\u9762\u5b58\u5728\u4e25\u91cd\u7f3a\u9677\u3002\u6587\u7ae0\u6307\u51fa\u7684\u4e03\u4e2a\u76f8\u4e92\u5173\u8054\u7684\u539f\u56e0\uff0c\u5305\u62ec\u751f\u7269\u590d\u6742\u6027\u3001\u65e0\u6548\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u3001\u8fc7\u5ea6\u6cdb\u5316\u3001\u67b6\u6784\u590d\u6742\u6027\u3001\u7f3a\u4e4f\u9886\u57df\u521b\u65b0\u3001\u6570\u636e\u4e0d\u8db3\u548c\u6591\u5757\u5c3a\u5bf8\u95ee\u9898\uff0c\u90fd\u5f3a\u8c03\u4e86\u5f53\u524d\u8303\u5f0f\u7684\u4e0d\u9002\u5e94\u6027\u3002\u56e0\u6b64\uff0c\u9700\u8981\u5bf9\u57fa\u7840\u6a21\u578b\u5728\u75c5\u7406\u5b66\u4e2d\u7684\u5e94\u7528\u8303\u5f0f\u8fdb\u884c\u6839\u672c\u6027\u7684\u53cd\u601d\u548c\u91cd\u65b0\u8bbe\u8ba1\uff0c\u4ee5\u5f00\u53d1\u51fa\u771f\u6b63\u9002\u7528\u4e8e\u8be5\u9886\u57df\u7684\u6709\u6548\u6a21\u578b\u3002"}}
{"id": "2510.23854", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23854", "abs": "https://arxiv.org/abs/2510.23854", "authors": ["Jyotika Singh", "Weiyi Sun", "Amit Agarwal", "Viji Krishnamurthy", "Yassine Benajiba", "Sujith Ravi", "Dan Roth"], "title": "Can LLMs Narrate Tabular Data? An Evaluation Framework for Natural Language Representations of Text-to-SQL System Outputs", "comment": "Accepted at EMNLP 2025", "summary": "In modern industry systems like multi-turn chat agents, Text-to-SQL\ntechnology bridges natural language (NL) questions and database (DB) querying.\nThe conversion of tabular DB results into NL representations (NLRs) enables the\nchat-based interaction. Currently, NLR generation is typically handled by large\nlanguage models (LLMs), but information loss or errors in presenting tabular\nresults in NL remains largely unexplored. This paper introduces a novel\nevaluation method - Combo-Eval - for judgment of LLM-generated NLRs that\ncombines the benefits of multiple existing methods, optimizing evaluation\nfidelity and achieving a significant reduction in LLM calls by 25-61%.\nAccompanying our method is NLR-BIRD, the first dedicated dataset for NLR\nbenchmarking. Through human evaluations, we demonstrate the superior alignment\nof Combo-Eval with human judgments, applicable across scenarios with and\nwithout ground truth references.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCombo-Eval\u7684\u65b0\u578b\u8bc4\u4f30\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u6587\u672c\u5230SQL\uff08Text-to-SQL\uff09\u6280\u672f\u4e2d\u4ece\u6570\u636e\u5e93\u7ed3\u679c\u751f\u6210\u81ea\u7136\u8bed\u8a00\u8868\u793a\uff08NLR\uff09\u7684\u8d28\u91cf\u3002\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u591a\u79cd\u73b0\u6709\u65b9\u6cd5\u7684\u4f18\u70b9\uff0c\u63d0\u9ad8\u4e86\u8bc4\u4f30\u7684\u51c6\u786e\u6027\uff0c\u5e76\u663e\u8457\u51cf\u5c11\u4e86\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u8c03\u7528\u6b21\u6570\uff0825-61%\uff09\u3002\u540c\u65f6\uff0c\u7814\u7a76\u4eba\u5458\u8fd8\u53d1\u5e03\u4e86NLR-BIRD\uff0c\u8fd9\u662f\u7b2c\u4e00\u4e2a\u4e13\u95e8\u7528\u4e8eNLR\u57fa\u51c6\u6d4b\u8bd5\u7684\u6570\u636e\u96c6\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cCombo-Eval\u4e0e\u4eba\u7c7b\u5224\u65ad\u9ad8\u5ea6\u4e00\u81f4\uff0c\u9002\u7528\u4e8e\u6709\u65e0\u771f\u5b9e\u53c2\u8003\u4e24\u79cd\u573a\u666f\u3002", "motivation": "\u5c3d\u7ba1Text-to-SQL\u6280\u672f\u5728\u73b0\u4ee3\u5de5\u4e1a\u7cfb\u7edf\uff08\u5982\u591a\u8f6e\u804a\u5929\u673a\u5668\u4eba\uff09\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u80fd\u591f\u5c06\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u8f6c\u5316\u4e3a\u6570\u636e\u5e93\u67e5\u8be2\uff0c\u4f46\u5c06\u67e5\u8be2\u7ed3\u679c\u4ece\u8868\u683c\u5f62\u5f0f\u8f6c\u6362\u4e3a\u81ea\u7136\u8bed\u8a00\u8868\u793a\uff08NLR\uff09\u7684\u8fc7\u7a0b\u4ecd\u9762\u4e34\u4fe1\u606f\u4e22\u5931\u6216\u9519\u8bef\u7684\u95ee\u9898\u3002\u76ee\u524d\u4e3b\u8981\u4f9d\u8d56\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5904\u7406NLR\u751f\u6210\uff0c\u4f46\u5bf9\u5176\u751f\u6210\u5185\u5bb9\u7684\u8bc4\u4f30\u65b9\u6cd5\u5c1a\u4e0d\u5b8c\u5584\uff0c\u4fe1\u606f\u635f\u5931\u548c\u9519\u8bef\u5448\u73b0\u7684\u95ee\u9898\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\uff0c\u8fd9\u963b\u788d\u4e86\u804a\u5929\u4ea4\u4e92\u7684\u8d28\u91cf\u548c\u53ef\u9760\u6027\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aCombo-Eval\u7684\u65b0\u578b\u8bc4\u4f30\u65b9\u6cd5\uff0c\u7528\u4e8e\u8861\u91cfLLM\u751f\u6210\u7684NLR\u7684\u8d28\u91cf\u3002Combo-Eval\u6574\u5408\u4e86\u591a\u79cd\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u7684\u4f18\u70b9\uff0c\u65e8\u5728\u4f18\u5316\u8bc4\u4f30\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002\u4e3a\u4e86\u652f\u6301NLR\u7684\u8bc4\u4f30\u548c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7814\u7a76\u4eba\u5458\u521b\u5efa\u4e86\u4e00\u4e2a\u540d\u4e3aNLR-BIRD\u7684\u65b0\u6570\u636e\u96c6\uff0c\u8fd9\u662f\u7b2c\u4e00\u4e2a\u4e13\u95e8\u4e3a\u6b64\u76ee\u7684\u8bbe\u8ba1\u7684\u6570\u636e\u96c6\u3002\u901a\u8fc7\u4e0e\u4eba\u7c7b\u5224\u65ad\u8fdb\u884c\u6bd4\u8f83\uff0c\u9a8c\u8bc1\u4e86Combo-Eval\u7684\u6709\u6548\u6027\uff0c\u8be5\u65b9\u6cd5\u5728\u6709\u65e0\u771f\u5b9e\u53c2\u8003\u7684\u60c5\u51b5\u4e0b\u5747\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\u3002", "result": "\u901a\u8fc7\u4e0e\u4eba\u7c7b\u5224\u65ad\u8fdb\u884c\u6bd4\u8f83\uff0cCombo-Eval\u5728\u8bc4\u4f30NLR\u7684\u51c6\u786e\u6027\u65b9\u9762\u663e\u793a\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\uff0c\u4e0e\u4eba\u7c7b\u7684\u5224\u65ad\u9ad8\u5ea6\u4e00\u81f4\u3002\u6b64\u5916\uff0cCombo-Eval\u80fd\u591f\u663e\u8457\u51cf\u5c11LLM\u7684\u8c03\u7528\u6b21\u6570\uff0c\u51cf\u5c11\u5e45\u5ea6\u572825%\u523061%\u4e4b\u95f4\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u8bc4\u4f30\u6548\u7387\u3002\u8be5\u65b9\u6cd5\u5728\u6709\u65e0\u771f\u5b9e\u53c2\u8003\u7684\u573a\u666f\u4e0b\u5747\u9002\u7528\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684Combo-Eval\u8bc4\u4f30\u65b9\u6cd5\u548cNLR-BIRD\u6570\u636e\u96c6\uff0c\u4e3aText-to-SQL\u6280\u672f\u4e2d\u7684NLR\u751f\u6210\u8bc4\u4f30\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u51c6\u786e\u3001\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002Combo-Eval\u901a\u8fc7\u7ed3\u5408\u591a\u79cd\u65b9\u6cd5\u7684\u4f18\u70b9\uff0c\u63d0\u9ad8\u4e86\u8bc4\u4f30\u7684\u51c6\u786e\u6027\uff0c\u5e76\u51cf\u5c11\u4e86\u5bf9LLM\u7684\u4f9d\u8d56\u3002NLR-BIRD\u6570\u636e\u96c6\u7684\u53d1\u5e03\u586b\u8865\u4e86NLR\u57fa\u51c6\u6d4b\u8bd5\u9886\u57df\u7684\u7a7a\u767d\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0cCombo-Eval\u4e0e\u4eba\u7c7b\u5224\u65ad\u9ad8\u5ea6\u4e00\u81f4\uff0c\u5e76\u4e14\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u5747\u8868\u73b0\u826f\u597d\uff0c\u9884\u793a\u7740\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u5de8\u5927\u6f5c\u529b\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63a2\u7d22Combo-Eval\u5728\u66f4\u5e7f\u6cdb\u7684NLP\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\uff0c\u4ee5\u53ca\u8fdb\u4e00\u6b65\u4f18\u5316\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u6307\u6807\u3002"}}
{"id": "2510.23822", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23822", "abs": "https://arxiv.org/abs/2510.23822", "authors": ["Zhenyu Zhang", "Tianyi Chen", "Weiran Xu", "Alex Pentland", "Jiaxin Pei"], "title": "ReCAP: Recursive Context-Aware Reasoning and Planning for Large Language Model Agents", "comment": null, "summary": "Long-horizon tasks requiring multi-step reasoning and dynamic re-planning\nremain challenging for large language models (LLMs). Sequential prompting\nmethods are prone to context drift, loss of goal information, and recurrent\nfailure cycles, while hierarchical prompting methods often weaken cross-level\ncontinuity or incur substantial runtime overhead. We introduce ReCAP (Recursive\nContext-Aware Reasoning and Planning), a hierarchical framework with shared\ncontext for reasoning and planning in LLMs. ReCAP combines three key\nmechanisms: (i) plan-ahead decomposition, in which the model generates a full\nsubtask list, executes the first item, and refines the remainder; (ii)\nstructured re-injection of parent plans, maintaining consistent multi-level\ncontext during recursive return; and (iii) memory-efficient execution, bounding\nthe active prompt so costs scale linearly with task depth. Together these\nmechanisms align high-level goals with low-level actions, reduce redundant\nprompting, and preserve coherent context updates across recursion. Experiments\ndemonstrate that ReCAP substantially improves subgoal alignment and success\nrates on various long-horizon reasoning benchmarks, achieving a 32% gain on\nsynchronous Robotouille and a 29% improvement on asynchronous Robotouille under\nthe strict pass@1 protocol.", "AI": {"tldr": "\u957f\u65f6\u4efb\u52a1\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6765\u8bf4\u662f\u4e00\u4e2a\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u4e0a\u4e0b\u6587\u6f02\u79fb\u548c\u4fe1\u606f\u4e22\u5931\u7b49\u95ee\u9898\u3002\u672c\u6587\u63d0\u51fa\u7684 ReCAP \u6846\u67b6\u901a\u8fc7\u9012\u5f52\u4e0a\u4e0b\u6587\u611f\u77e5\u63a8\u7406\u548c\u89c4\u5212\uff0c\u7ed3\u5408\u201c\u9884\u5148\u89c4\u5212\u5206\u89e3\u201d\u3001\u201c\u7ed3\u6784\u5316\u91cd\u6ce8\u5165\u7236\u8ba1\u5212\u201d\u548c\u201c\u5185\u5b58\u9ad8\u6548\u6267\u884c\u201d\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8fd9\u4e9b\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u578b\u5728\u957f\u65f6\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u957f\u65f6\u4efb\u52a1\u8981\u6c42\u591a\u6b65\u63a8\u7406\u548c\u52a8\u6001\u91cd\u89c4\u5212\uff0c\u8fd9\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6784\u6210\u4e86\u4e25\u5cfb\u6311\u6218\u3002\u73b0\u6709\u7684\u987a\u5e8f\u63d0\u793a\u65b9\u6cd5\u5bb9\u6613\u51fa\u73b0\u4e0a\u4e0b\u6587\u6f02\u79fb\u3001\u76ee\u6807\u4fe1\u606f\u4e22\u5931\u548c\u5faa\u73af\u5931\u8d25\u7b49\u95ee\u9898\u3002\u800c\u5206\u5c42\u63d0\u793a\u65b9\u6cd5\u867d\u7136\u53ef\u4ee5\u89e3\u51b3\u90e8\u5206\u95ee\u9898\uff0c\u4f46\u5e38\u5e38\u524a\u5f31\u8de8\u5c42\u7ea7\u8fde\u7eed\u6027\uff0c\u6216\u5bfc\u81f4\u663e\u8457\u7684\u8fd0\u884c\u65f6\u5f00\u9500\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u4e00\u79cd\u80fd\u591f\u6709\u6548\u5904\u7406\u957f\u65f6\u4efb\u52a1\uff0c\u540c\u65f6\u514b\u670d\u73b0\u6709\u65b9\u6cd5\u5c40\u9650\u6027\u7684\u65b0\u6846\u67b6\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u672c\u6587\u63d0\u51fa ReCAP\uff08Recursive Context-Aware Reasoning and Planning\uff09\u6846\u67b6\uff0c\u8fd9\u662f\u4e00\u79cd\u5206\u5c42\u6846\u67b6\uff0c\u5177\u6709\u5171\u4eab\u7684\u63a8\u7406\u548c\u89c4\u5212\u4e0a\u4e0b\u6587\u3002ReCAP \u7ed3\u5408\u4e86\u4e09\u4e2a\u5173\u952e\u673a\u5236\uff1a\uff081\uff09\u9884\u5148\u89c4\u5212\u5206\u89e3\uff1a\u6a21\u578b\u751f\u6210\u5b8c\u6574\u7684\u5b50\u4efb\u52a1\u5217\u8868\uff0c\u6267\u884c\u7b2c\u4e00\u9879\u4efb\u52a1\uff0c\u7136\u540e\u4f18\u5316\u5269\u4f59\u4efb\u52a1\u3002\uff082\uff09\u7ed3\u6784\u5316\u91cd\u6ce8\u5165\u7236\u8ba1\u5212\uff1a\u5728\u9012\u5f52\u8fd4\u56de\u8fc7\u7a0b\u4e2d\uff0c\u4fdd\u6301\u591a\u5c42\u7ea7\u4e0a\u4e0b\u6587\u7684\u4e00\u81f4\u6027\u3002\uff083\uff09\u5185\u5b58\u9ad8\u6548\u6267\u884c\uff1a\u9650\u5236\u6d3b\u52a8\u63d0\u793a\u7684\u957f\u5ea6\uff0c\u4f7f\u6210\u672c\u4e0e\u4efb\u52a1\u6df1\u5ea6\u5448\u7ebf\u6027\u5173\u7cfb\u3002\u8fd9\u4e9b\u673a\u5236\u5171\u540c\u4f5c\u7528\uff0c\u5c06\u9ad8\u5c42\u76ee\u6807\u4e0e\u4f4e\u5c42\u52a8\u4f5c\u5bf9\u9f50\uff0c\u51cf\u5c11\u5197\u4f59\u63d0\u793a\uff0c\u5e76\u4fdd\u6301\u9012\u5f52\u8fc7\u7a0b\u4e2d\u8fde\u8d2f\u7684\u4e0a\u4e0b\u6587\u66f4\u65b0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cReCAP \u5728\u5404\u79cd\u957f\u65f6\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86\u5b50\u76ee\u6807\u5bf9\u9f50\u548c\u6210\u529f\u7387\u3002\u5728\u4e25\u683c\u7684 pass@1 \u534f\u8bae\u4e0b\uff0cReCAP \u5728\u540c\u6b65 Robotouille \u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86 32% \u7684\u63d0\u5347\uff0c\u5728\u5f02\u6b65 Robotouille \u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86 29% \u7684\u6539\u8fdb\u3002", "conclusion": "ReCAP \u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u9884\u5148\u89c4\u5212\u5206\u89e3\u3001\u7ed3\u6784\u5316\u91cd\u6ce8\u5165\u7236\u8ba1\u5212\u548c\u5185\u5b58\u9ad8\u6548\u6267\u884c\u7b49\u673a\u5236\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u957f\u65f6\u4efb\u52a1\u65f6\u9762\u4e34\u7684\u4e0a\u4e0b\u6587\u6f02\u79fb\u3001\u4fe1\u606f\u4e22\u5931\u548c\u6548\u7387\u4f4e\u4e0b\u7b49\u95ee\u9898\u3002\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\u4e86 ReCAP \u5728\u63d0\u9ad8\u5b50\u76ee\u6807\u5bf9\u9f50\u548c\u4efb\u52a1\u6210\u529f\u7387\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u4e3a LLMs \u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63a2\u7d22 ReCAP \u5728\u66f4\u591a\u6837\u5316\u7684\u957f\u65f6\u4efb\u52a1\u548c\u66f4\u590d\u6742\u7684\u73af\u5883\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u4f18\u5316\u5176\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2510.23870", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23870", "abs": "https://arxiv.org/abs/2510.23870", "authors": ["Marianne Menglin Liu", "Sai Ashish Somayajula", "Syed Fahad Allam Shah", "Sujith Ravi", "Dan Roth"], "title": "OraPlan-SQL: A Planning-Centric Framework for Complex Bilingual NL2SQL Reasoning", "comment": null, "summary": "We present OraPlan-SQL, our system for the Archer NL2SQL Evaluation Challenge\n2025, a bilingual benchmark requiring complex reasoning such as arithmetic,\ncommonsense, and hypothetical inference. OraPlan-SQL ranked first, exceeding\nthe second-best system by more than 6% in execution accuracy (EX), with 55.0%\nin English and 56.7% in Chinese, while maintaining over 99% SQL validity (VA).\nOur system follows an agentic framework with two components: Planner agent that\ngenerates stepwise natural language plans, and SQL agent that converts these\nplans into executable SQL. Since SQL agent reliably adheres to the plan, our\nrefinements focus on the planner. Unlike prior methods that rely on multiple\nsub-agents for planning and suffer from orchestration overhead, we introduce a\nfeedback-guided meta-prompting strategy to refine a single planner. Failure\ncases from a held-out set are clustered with human input, and an LLM distills\nthem into corrective guidelines that are integrated into the planner's system\nprompt, improving generalization without added complexity. For the multilingual\nscenario, to address transliteration and entity mismatch issues, we incorporate\nentity-linking guidelines that generate alternative surface forms for entities\nand explicitly include them in the plan. Finally, we enhance reliability\nthrough plan diversification: multiple candidate plans are generated for each\nquery, with the SQL agent producing a query for each plan, and final output\nselected via majority voting over their executions.", "AI": {"tldr": "OraPlan-SQL \u5728 Archer NL2SQL \u8bc4\u4f30\u6311\u6218\u8d5b 2025 \u4e2d\u6392\u540d\u7b2c\u4e00\uff0c\u5728\u82f1\u8bed\u548c\u4e2d\u6587\u4e0a\u5206\u522b\u8fbe\u5230 55.0% \u548c 56.7% \u7684\u6267\u884c\u51c6\u786e\u7387 (EX)\uff0c\u540c\u65f6\u4fdd\u6301\u8d85\u8fc7 99% \u7684 SQL \u6709\u6548\u6027 (VA)\u3002\u8be5\u7cfb\u7edf\u91c7\u7528\u57fa\u4e8e\u667a\u80fd\u4f53 (agent) \u7684\u6846\u67b6\uff0c\u5305\u542b\u751f\u6210\u81ea\u7136\u8bed\u8a00\u8ba1\u5212\u7684 Planner agent \u548c\u5c06\u8ba1\u5212\u8f6c\u6362\u4e3a SQL \u7684 SQL agent\u3002\u901a\u8fc7\u53cd\u9988\u5f15\u5bfc\u7684\u5143\u63d0\u793a\u7b56\u7565\u4f18\u5316\u5355\u4e2a Planner agent\uff0c\u5e76\u901a\u8fc7\u5b9e\u4f53\u94fe\u63a5\u548c\u8ba1\u5212\u591a\u6837\u5316\u6765\u5904\u7406\u591a\u8bed\u8a00\u548c\u63d0\u9ad8\u53ef\u9760\u6027\u3002", "motivation": "\u5f53\u524d\u7684 NL2SQL \u7cfb\u7edf\u5728\u5904\u7406\u9700\u8981\u590d\u6742\u63a8\u7406\uff08\u5982\u7b97\u672f\u3001\u5e38\u8bc6\u548c\u5047\u8bbe\u63a8\u7406\uff09\u7684\u53cc\u8bed\u57fa\u51c6\u65f6\u9762\u4e34\u6311\u6218\u3002Archer NL2SQL \u8bc4\u4f30\u6311\u6218\u8d5b 2025 \u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u5bf9\u9700\u8981\u9ad8\u7ea7\u7406\u89e3\u548c\u63a8\u7406\u80fd\u529b\u7684\u7cfb\u7edf\u63d0\u51fa\u4e86\u66f4\u9ad8\u7684\u8981\u6c42\u3002", "method": "OraPlan-SQL \u91c7\u7528\u57fa\u4e8e\u667a\u80fd\u4f53\u7684\u6846\u67b6\uff0c\u7531 Planner agent \u548c SQL agent \u7ec4\u6210\u3002Planner agent \u8d1f\u8d23\u751f\u6210\u9010\u6b65\u7684\u81ea\u7136\u8bed\u8a00\u8ba1\u5212\uff0cSQL agent \u5219\u5c06\u8fd9\u4e9b\u8ba1\u5212\u8f6c\u6362\u4e3a\u53ef\u6267\u884c\u7684 SQL\u3002\u4e3a\u4e86\u4f18\u5316 Planner agent\uff0c\u5f15\u5165\u4e86\u4e00\u79cd\u53cd\u9988\u5f15\u5bfc\u7684\u5143\u63d0\u793a\u7b56\u7565\uff0c\u901a\u8fc7\u5206\u6790\u5931\u8d25\u6848\u4f8b\u5e76\u5c06\u5176\u63d0\u70bc\u6210\u7ea0\u6b63\u6027\u6307\u5357\u6765\u6539\u8fdb\u7cfb\u7edf\u63d0\u793a\u3002\u4e3a\u4e86\u5904\u7406\u591a\u8bed\u8a00\u573a\u666f\uff0c\u96c6\u6210\u4e86\u5b9e\u4f53\u94fe\u63a5\u6307\u5357\uff0c\u751f\u6210\u5b9e\u4f53\u7684\u4e0d\u540c\u8868\u9762\u5f62\u5f0f\u5e76\u5c06\u5176\u7eb3\u5165\u8ba1\u5212\u3002\u6700\u540e\uff0c\u901a\u8fc7\u8ba1\u5212\u591a\u6837\u5316\u6765\u589e\u5f3a\u53ef\u9760\u6027\uff0c\u5373\u4e3a\u6bcf\u4e2a\u67e5\u8be2\u751f\u6210\u591a\u4e2a\u5019\u9009\u8ba1\u5212\uff0c\u5e76\u4f7f\u7528\u591a\u6570\u6295\u7968\u9009\u62e9\u6700\u7ec8\u8f93\u51fa\u3002", "result": "OraPlan-SQL \u5728 Archer NL2SQL \u8bc4\u4f30\u6311\u6218\u8d5b 2025 \u4e2d\u53d6\u5f97\u4e86\u9886\u5148\u5730\u4f4d\uff0c\u5728\u82f1\u8bed\u4e0a\u5b9e\u73b0\u4e86 55.0% \u7684\u6267\u884c\u51c6\u786e\u7387 (EX)\uff0c\u5728\u4e2d\u6587\u4e0a\u5b9e\u73b0\u4e86 56.7% \u7684\u6267\u884c\u51c6\u786e\u7387 (EX)\uff0c\u5e73\u5747\u51c6\u786e\u7387\u8d85\u8fc7\u7b2c\u4e8c\u540d 6%\u3002\u540c\u65f6\uff0c\u7cfb\u7edf\u7684 SQL \u6709\u6548\u6027 (VA) \u4fdd\u6301\u5728 99% \u4ee5\u4e0a\u3002", "conclusion": "OraPlan-SQL \u901a\u8fc7\u521b\u65b0\u7684\u53cd\u9988\u5f15\u5bfc\u5143\u63d0\u793a\u7b56\u7565\u3001\u5b9e\u4f53\u94fe\u63a5\u65b9\u6cd5\u548c\u8ba1\u5212\u591a\u6837\u5316\u6280\u672f\uff0c\u5728\u590d\u6742\u7684\u53cc\u8bed NL2SQL \u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6210\u529f\u3002\u8be5\u7cfb\u7edf\u5728 Archer NL2SQL \u8bc4\u4f30\u6311\u6218\u8d5b 2025 \u4e2d\u540d\u5217\u524d\u8305\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u5904\u7406\u9700\u8981\u590d\u6742\u63a8\u7406\u548c\u591a\u8bed\u8a00\u80fd\u529b\u7684\u65b9\u9762\u7684\u6709\u6548\u6027\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63a2\u7d22\u5143\u63d0\u793a\u7b56\u7565\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4ee5\u53ca\u5728\u66f4\u5e7f\u6cdb\u7684\u591a\u8bed\u8a00\u548c\u9886\u57df\u7279\u5b9a\u573a\u666f\u4e0b\u7684\u5e94\u7528\u3002"}}
{"id": "2510.23824", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23824", "abs": "https://arxiv.org/abs/2510.23824", "authors": ["Murad Ismayilov", "Edwin Meriaux", "Shuo Wen", "Gregory Dudek"], "title": "Decentralized Multi-Agent Goal Assignment for Path Planning using Large Language Models", "comment": "Accepted at MIT URTC 2025", "summary": "Coordinating multiple autonomous agents in shared environments under\ndecentralized conditions is a long-standing challenge in robotics and\nartificial intelligence. This work addresses the problem of decentralized goal\nassignment for multi-agent path planning, where agents independently generate\nranked preferences over goals based on structured representations of the\nenvironment, including grid visualizations and scenario data. After this\nreasoning phase, agents exchange their goal rankings, and assignments are\ndetermined by a fixed, deterministic conflict-resolution rule (e.g., agent\nindex ordering), without negotiation or iterative coordination. We\nsystematically compare greedy heuristics, optimal assignment, and large\nlanguage model (LLM)-based agents in fully observable grid-world settings. Our\nresults show that LLM-based agents, when provided with well-designed prompts\nand relevant quantitative information, can achieve near-optimal makespans and\nconsistently outperform traditional heuristics. These findings underscore the\npotential of language models for decentralized goal assignment in multi-agent\npath planning and highlight the importance of information structure in such\nsystems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8fdb\u884c\u53bb\u4e2d\u5fc3\u5316\u591a\u667a\u80fd\u4f53\u8def\u5f84\u89c4\u5212\u4e2d\u76ee\u6807\u5206\u914d\u7684\u65b9\u6cd5\uff0c\u5e76\u4e0e\u4f20\u7edf\u542f\u53d1\u5f0f\u65b9\u6cd5\u548c\u6700\u4f18\u5206\u914d\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002\u7ed3\u679c\u8868\u660e\uff0cLLM \u5728\u8bbe\u8ba1\u826f\u597d\u7684\u63d0\u793a\u548c\u76f8\u5173\u5b9a\u91cf\u4fe1\u606f\u7684\u652f\u6301\u4e0b\uff0c\u53ef\u4ee5\u5b9e\u73b0\u63a5\u8fd1\u6700\u4f18\u7684\u5b8c\u6210\u65f6\u95f4\u548c\u6027\u80fd\u3002", "motivation": "\u5728\u5171\u4eab\u73af\u5883\u4e2d\u534f\u8c03\u591a\u4e2a\u81ea\u4e3b\u667a\u80fd\u4f53\uff0c\u7279\u522b\u662f\u5728\u53bb\u4e2d\u5fc3\u5316\u6761\u4ef6\u4e0b\uff0c\u662f\u673a\u5668\u4eba\u5b66\u548c\u4eba\u5de5\u667a\u80fd\u9886\u57df\u4e00\u4e2a\u957f\u671f\u5b58\u5728\u7684\u6311\u6218\u3002\u5177\u4f53\u800c\u8a00\uff0c\u5982\u4f55\u6709\u6548\u5730\u4e3a\u591a\u667a\u80fd\u4f53\u8def\u5f84\u89c4\u5212\u8fdb\u884c\u53bb\u4e2d\u5fc3\u5316\u76ee\u6807\u5206\u914d\u662f\u4e00\u4e2a\u5173\u952e\u95ee\u9898\uff0c\u56e0\u4e3a\u8fd9\u76f4\u63a5\u5f71\u54cd\u5230\u4efb\u52a1\u7684\u6574\u4f53\u6548\u7387\u548c\u5b8c\u6210\u65f6\u95f4\u3002", "method": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u53bb\u4e2d\u5fc3\u5316\u76ee\u6807\u5206\u914d\u65b9\u6cd5\u3002\u667a\u80fd\u4f53\u9996\u5148\u6839\u636e\u73af\u5883\u7684\u7ed3\u6784\u5316\u8868\u793a\uff08\u5305\u62ec\u7f51\u683c\u53ef\u89c6\u5316\u548c\u573a\u666f\u6570\u636e\uff09\u72ec\u7acb\u751f\u6210\u5bf9\u76ee\u6807\u7684\u6392\u5e8f\u504f\u597d\u3002\u7136\u540e\uff0c\u667a\u80fd\u4f53\u4ea4\u6362\u5176\u76ee\u6807\u6392\u540d\uff0c\u5e76\u6839\u636e\u56fa\u5b9a\u7684\u3001\u786e\u5b9a\u7684\u51b2\u7a81\u89e3\u51b3\u89c4\u5219\uff08\u4f8b\u5982\uff0c\u667a\u80fd\u4f53\u7d22\u5f15\u6392\u5e8f\uff09\u6765\u786e\u5b9a\u5206\u914d\uff0c\u65e0\u9700\u534f\u5546\u6216\u8fed\u4ee3\u534f\u8c03\u3002\u5728\u5b8c\u5168\u53ef\u89c2\u7684\u7f51\u683c\u4e16\u754c\u73af\u5883\u4e2d\uff0c\u7814\u7a76\u4eba\u5458\u7cfb\u7edf\u5730\u6bd4\u8f83\u4e86\u8d2a\u5a6a\u542f\u53d1\u5f0f\u7b97\u6cd5\u3001\u6700\u4f18\u5206\u914d\u548c\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u667a\u80fd\u4f53\u3002", "result": "\u5728\u5b8c\u5168\u53ef\u89c2\u7684\u7f51\u683c\u4e16\u754c\u8bbe\u7f6e\u4e2d\uff0cLLM \u9a71\u52a8\u7684\u667a\u80fd\u4f53\u5728\u7ecf\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63d0\u793a\u548c\u76f8\u5173\u5b9a\u91cf\u4fe1\u606f\u7684\u652f\u6301\u4e0b\uff0c\u53d6\u5f97\u4e86\u63a5\u8fd1\u6700\u4f18\u7684\u5b8c\u6210\u65f6\u95f4\uff0c\u5e76\u4e14\u5176\u8868\u73b0\u6301\u7eed\u4f18\u4e8e\u4f20\u7edf\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002\u8fd9\u9879\u6bd4\u8f83\u7814\u7a76\u4e86\u8d2a\u5a6a\u542f\u53d1\u5f0f\u3001\u6700\u4f18\u5206\u914d\u548c LLM \u667a\u80fd\u4f53\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u53bb\u4e2d\u5fc3\u5316\u591a\u667a\u80fd\u4f53\u8def\u5f84\u89c4\u5212\u7684\u76ee\u6807\u5206\u914d\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u5e76\u4e14\u4fe1\u606f\u7684\u7ed3\u6784\u5316\u5bf9\u4e8e\u6b64\u7c7b\u7cfb\u7edf\u7684\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002LLM \u667a\u80fd\u4f53\u5728\u63a5\u8fd1\u6700\u4f18\u7684\u5b8c\u6210\u65f6\u95f4\u548c\u4e00\u81f4\u6027\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002"}}
{"id": "2510.23884", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.23884", "abs": "https://arxiv.org/abs/2510.23884", "authors": ["Tananun Songdechakraiwut", "Michael Lutz"], "title": "Language Models for Longitudinal Clinical Prediction", "comment": null, "summary": "We explore a lightweight framework that adapts frozen large language models\nto analyze longitudinal clinical data. The approach integrates patient history\nand context within the language model space to generate accurate forecasts\nwithout model fine-tuning. Applied to neuropsychological assessments, it\nachieves accurate and reliable performance even with minimal training data,\nshowing promise for early-stage Alzheimer's monitoring.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u60a3\u8005\u75c5\u53f2\u548c\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u5728\u4e0d\u8fdb\u884c\u6a21\u578b\u5fae\u8c03\u7684\u60c5\u51b5\u4e0b\uff0c\u5229\u7528\u51bb\u7ed3\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5206\u6790\u7eb5\u5411\u4e34\u5e8a\u6570\u636e\uff0c\u5e76\u6210\u529f\u5e94\u7528\u4e8e\u795e\u7ecf\u5fc3\u7406\u5b66\u8bc4\u4f30\uff0c\u5728\u65e9\u671f\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u76d1\u6d4b\u65b9\u9762\u663e\u793a\u51fa\u5de8\u5927\u6f5c\u529b\u3002", "motivation": "\u4f20\u7edf\u7684\u4e34\u5e8a\u6570\u636e\u5206\u6790\u65b9\u6cd5\u5728\u5904\u7406\u7eb5\u5411\u6570\u636e\u65f6\u9762\u4e34\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u9700\u8981\u6574\u5408\u60a3\u8005\u5386\u53f2\u548c\u4e0a\u4e0b\u6587\u4fe1\u606f\u4ee5\u8fdb\u884c\u51c6\u786e\u9884\u6d4b\u7684\u60c5\u51b5\u4e0b\u3002\u6b64\u5916\uff0c\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u4ee5\u9002\u5e94\u7279\u5b9a\u4e34\u5e8a\u4efb\u52a1\u901a\u5e38\u9700\u8981\u5927\u91cf\u6807\u6ce8\u6570\u636e\u548c\u8ba1\u7b97\u8d44\u6e90\uff0c\u8fd9\u5728\u5927\u89c4\u6a21\u4e34\u5e8a\u5e94\u7528\u4e2d\u53ef\u80fd\u96be\u4ee5\u5b9e\u73b0\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u4e00\u79cd\u80fd\u591f\u6709\u6548\u5229\u7528\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u529b\uff0c\u540c\u65f6\u514b\u670d\u6570\u636e\u548c\u8ba1\u7b97\u8d44\u6e90\u9650\u5236\u7684\u8f7b\u91cf\u7ea7\u5206\u6790\u6846\u67b6\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u9002\u5e94\u5df2\u51bb\u7ed3\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u7528\u4e8e\u5206\u6790\u7eb5\u5411\u4e34\u5e8a\u6570\u636e\u3002\u8be5\u65b9\u6cd5\u7684\u6838\u5fc3\u5728\u4e8e\u5c06\u60a3\u8005\u7684\u5386\u53f2\u4fe1\u606f\u548c\u4e0a\u4e0b\u6587\u4fe1\u606f\u6574\u5408\u5230\u8bed\u8a00\u6a21\u578b\u7684\u5411\u91cf\u7a7a\u95f4\u4e2d\uff0c\u4ece\u800c\u65e0\u9700\u5bf9\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\u5373\u53ef\u751f\u6210\u51c6\u786e\u7684\u9884\u6d4b\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u5904\u7406\u975e\u7ed3\u6784\u5316\u7684\u4e34\u5e8a\u6587\u672c\u6570\u636e\uff0c\u63d0\u53d6\u5173\u952e\u7684\u60a3\u8005\u4fe1\u606f\uff0c\u5e76\u5c06\u5176\u7f16\u7801\u4e3a\u6a21\u578b\u80fd\u591f\u7406\u89e3\u7684\u8868\u793a\u5f62\u5f0f\u3002\u5728\u795e\u7ecf\u5fc3\u7406\u5b66\u8bc4\u4f30\u4efb\u52a1\u4e2d\uff0c\u8be5\u6846\u67b6\u88ab\u5e94\u7528\u4e8e\u5206\u6790\u7eb5\u5411\u6570\u636e\uff0c\u4ee5\u76d1\u6d4b\u75be\u75c5\u8fdb\u5c55\u548c\u9884\u6d4b\u672a\u6765\u8d8b\u52bf\u3002", "result": "\u5728\u795e\u7ecf\u5fc3\u7406\u5b66\u8bc4\u4f30\u4efb\u52a1\u7684\u5e94\u7528\u4e2d\uff0c\u8be5\u6846\u67b6\u53d6\u5f97\u4e86\u51c6\u786e\u4e14\u53ef\u9760\u7684\u6027\u80fd\u3002\u5373\u4f7f\u5728\u4ec5\u4f7f\u7528\u5c11\u91cf\u8bad\u7ec3\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u8be5\u65b9\u6cd5\u4e5f\u80fd\u591f\u6709\u6548\u5730\u8fdb\u884c\u9884\u6d4b\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u65e9\u671f\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u76d1\u6d4b\u65b9\u9762\u8868\u73b0\u51fa\u5de8\u5927\u7684\u6f5c\u529b\uff0c\u80fd\u591f\u51c6\u786e\u8bc6\u522b\u4e0e\u75be\u75c5\u76f8\u5173\u7684\u6a21\u5f0f\u548c\u8d8b\u52bf\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u8f7b\u91cf\u7ea7\u6846\u67b6\u4e3a\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5206\u6790\u7eb5\u5411\u4e34\u5e8a\u6570\u636e\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u4e14\u8d44\u6e90\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002\u901a\u8fc7\u5728\u4e0d\u8fdb\u884c\u6a21\u578b\u5fae\u8c03\u7684\u60c5\u51b5\u4e0b\u6574\u5408\u60a3\u8005\u5386\u53f2\u548c\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u8be5\u6846\u67b6\u5728\u795e\u7ecf\u5fc3\u7406\u5b66\u8bc4\u4f30\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u4f18\u5f02\u7684\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u65e9\u671f\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u76d1\u6d4b\u65b9\u9762\u3002\u8fd9\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u5b9e\u9645\u4e34\u5e8a\u5e94\u7528\u4e2d\u5177\u6709\u5e7f\u9614\u7684\u524d\u666f\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u63a2\u7d22\u8be5\u6846\u67b6\u5728\u5176\u4ed6\u4e34\u5e8a\u9886\u57df\u7684\u53ef\u6269\u5c55\u6027\uff0c\u5e76\u8fdb\u4e00\u6b65\u4f18\u5316\u5176\u5728\u5904\u7406\u4e0d\u540c\u7c7b\u578b\u4e34\u5e8a\u6570\u636e\u65f6\u7684\u6027\u80fd\u3002"}}
{"id": "2510.23896", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.23896", "abs": "https://arxiv.org/abs/2510.23896", "authors": ["Kosei Uemura", "Miaoran Zhang", "David Ifeoluwa Adelani"], "title": "AfriMTEB and AfriE5: Benchmarking and Adapting Text Embedding Models for African Languages", "comment": null, "summary": "Text embeddings are an essential building component of several NLP tasks such\nas retrieval-augmented generation which is crucial for preventing\nhallucinations in LLMs. Despite the recent release of massively multilingual\nMTEB (MMTEB), African languages remain underrepresented, with existing tasks\noften repurposed from translation benchmarks such as FLORES clustering or\nSIB-200. In this paper, we introduce AfriMTEB -- a regional expansion of MMTEB\ncovering 59 languages, 14 tasks, and 38 datasets, including six newly added\ndatasets. Unlike many MMTEB datasets that include fewer than five languages,\nthe new additions span 14 to 56 African languages and introduce entirely new\ntasks, such as hate speech detection, intent detection, and emotion\nclassification, which were not previously covered. Complementing this, we\npresent AfriE5, an adaptation of the instruction-tuned mE5 model to African\nlanguages through cross-lingual contrastive distillation. Our evaluation shows\nthat AfriE5 achieves state-of-the-art performance, outperforming strong\nbaselines such as Gemini-Embeddings and mE5.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.23881", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23881", "abs": "https://arxiv.org/abs/2510.23881", "authors": ["Xidong Feng", "Vivek Veeriah", "Marcus Chiam", "Michael Dennis", "Ryan Pachauri", "Thomas Tumiel", "Federico Barbero", "Johan Obando-Ceron", "Jiaxin Shi", "Satinder Singh", "Shaobo Hou", "Nenad Toma\u0161ev", "Tom Zahavy"], "title": "Generating Creative Chess Puzzles", "comment": null, "summary": "While Generative AI rapidly advances in various domains, generating truly\ncreative, aesthetic, and counter-intuitive outputs remains a challenge. This\npaper presents an approach to tackle these difficulties in the domain of chess\npuzzles. We start by benchmarking Generative AI architectures, and then\nintroduce an RL framework with novel rewards based on chess engine search\nstatistics to overcome some of those shortcomings. The rewards are designed to\nenhance a puzzle's uniqueness, counter-intuitiveness, diversity, and realism.\nOur RL approach dramatically increases counter-intuitive puzzle generation by\n10x, from 0.22\\% (supervised) to 2.5\\%, surpassing existing dataset rates\n(2.1\\%) and the best Lichess-trained model (0.4\\%). Our puzzles meet novelty\nand diversity benchmarks, retain aesthetic themes, and are rated by human\nexperts as more creative, enjoyable, and counter-intuitive than composed book\npuzzles, even approaching classic compositions. Our final outcome is a curated\nbooklet of these AI-generated puzzles, which is acknowledged for creativity by\nthree world-renowned experts.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.23921", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23921", "abs": "https://arxiv.org/abs/2510.23921", "authors": ["Kaveh Eskandari Miandoab", "Mahammed Kamruzzaman", "Arshia Gharooni", "Gene Louis Kim", "Vasanth Sarathy", "Ninareh Mehrabi"], "title": "Breaking the Benchmark: Revealing LLM Bias via Minimal Contextual Augmentation", "comment": "9 pages, 3 figures, 3 tables", "summary": "Large Language Models have been shown to demonstrate stereotypical biases in\ntheir representations and behavior due to the discriminative nature of the data\nthat they have been trained on. Despite significant progress in the development\nof methods and models that refrain from using stereotypical information in\ntheir decision-making, recent work has shown that approaches used for bias\nalignment are brittle. In this work, we introduce a novel and general\naugmentation framework that involves three plug-and-play steps and is\napplicable to a number of fairness evaluation benchmarks. Through application\nof augmentation to a fairness evaluation dataset (Bias Benchmark for Question\nAnswering (BBQ)), we find that Large Language Models (LLMs), including\nstate-of-the-art open and closed weight models, are susceptible to\nperturbations to their inputs, showcasing a higher likelihood to behave\nstereotypically. Furthermore, we find that such models are more likely to have\nbiased behavior in cases where the target demographic belongs to a community\nless studied by the literature, underlining the need to expand the fairness and\nsafety research to include more diverse communities.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.23882", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23882", "abs": "https://arxiv.org/abs/2510.23882", "authors": ["Adil Rasheed", "Oscar Ravik", "Omer San"], "title": "Hybrid Modeling, Sim-to-Real Reinforcement Learning, and Large Language Model Driven Control for Digital Twins", "comment": null, "summary": "This work investigates the use of digital twins for dynamical system modeling\nand control, integrating physics-based, data-driven, and hybrid approaches with\nboth traditional and AI-driven controllers. Using a miniature greenhouse as a\ntest platform, four predictive models Linear, Physics-Based Modeling (PBM),\nLong Short Term Memory (LSTM), and Hybrid Analysis and Modeling (HAM) are\ndeveloped and compared under interpolation and extrapolation scenarios. Three\ncontrol strategies Model Predictive Control (MPC), Reinforcement Learning (RL),\nand Large Language Model (LLM) based control are also implemented to assess\ntrade-offs in precision, adaptability, and implementation effort. Results show\nthat in modeling HAM provides the most balanced performance across accuracy,\ngeneralization, and computational efficiency, while LSTM achieves high\nprecision at greater resource cost. Among controllers, MPC delivers robust and\npredictable performance, RL demonstrates strong adaptability, and LLM-based\ncontrollers offer flexible human-AI interaction when coupled with predictive\ntools.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.23924", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23924", "abs": "https://arxiv.org/abs/2510.23924", "authors": ["Dina Pisarevskaya", "Arkaitz Zubiaga"], "title": "Agent-based Automated Claim Matching with Instruction-following LLMs", "comment": "Accepted for the International Joint Conference on Natural Language\n  Processing & Asia-Pacific Chapter of the Association for Computational\n  Linguistics (2025) Findings", "summary": "We present a novel agent-based approach for the automated claim matching task\nwith instruction-following LLMs. We propose a two-step pipeline that first\ngenerates prompts with LLMs, to then perform claim matching as a binary\nclassification task with LLMs. We demonstrate that LLM-generated prompts can\noutperform SOTA with human-generated prompts, and that smaller LLMs can do as\nwell as larger ones in the generation process, allowing to save computational\nresources. We also demonstrate the effectiveness of using different LLMs for\neach step of the pipeline, i.e. using an LLM for prompt generation, and another\nfor claim matching. Our investigation into the prompt generation process in\nturn reveals insights into the LLMs' understanding of claim matching.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.23883", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23883", "abs": "https://arxiv.org/abs/2510.23883", "authors": ["Shrestha Datta", "Shahriar Kabir Nahin", "Anshuman Chhabra", "Prasant Mohapatra"], "title": "Agentic AI Security: Threats, Defenses, Evaluation, and Open Challenges", "comment": null, "summary": "Agentic AI systems powered by large language models (LLMs) and endowed with\nplanning, tool use, memory, and autonomy, are emerging as powerful, flexible\nplatforms for automation. Their ability to autonomously execute tasks across\nweb, software, and physical environments creates new and amplified security\nrisks, distinct from both traditional AI safety and conventional software\nsecurity. This survey outlines a taxonomy of threats specific to agentic AI,\nreviews recent benchmarks and evaluation methodologies, and discusses defense\nstrategies from both technical and governance perspectives. We synthesize\ncurrent research and highlight open challenges, aiming to support the\ndevelopment of secure-by-design agent systems.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.23941", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23941", "abs": "https://arxiv.org/abs/2510.23941", "authors": ["Soham Satyadharma", "Fatemeh Sheikholeslami", "Swati Kaul", "Aziz Umit Batur", "Suleiman A. Khan"], "title": "Auto prompting without training labels: An LLM cascade for product quality assessment in e-commerce catalogs", "comment": null, "summary": "We introduce a novel, training free cascade for auto-prompting Large Language\nModels (LLMs) to assess product quality in e-commerce. Our system requires no\ntraining labels or model fine-tuning, instead automatically generating and\nrefining prompts for evaluating attribute quality across tens of thousands of\nproduct category-attribute pairs. Starting from a seed of human-crafted\nprompts, the cascade progressively optimizes instructions to meet\ncatalog-specific requirements. This approach bridges the gap between general\nlanguage understanding and domain-specific knowledge at scale in complex\nindustrial catalogs. Our extensive empirical evaluations shows the auto-prompt\ncascade improves precision and recall by $8-10\\%$ over traditional\nchain-of-thought prompting. Notably, it achieves these gains while reducing\ndomain expert effort from 5.1 hours to 3 minutes per attribute - a $99\\%$\nreduction. Additionally, the cascade generalizes effectively across five\nlanguages and multiple quality assessment tasks, consistently maintaining\nperformance gains.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.23925", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.23925", "abs": "https://arxiv.org/abs/2510.23925", "authors": ["Guohao Sun", "Hang Hua", "Jian Wang", "Jiebo Luo", "Sohail Dianat", "Majid Rabbani", "Raghuveer Rao", "Zhiqiang Tao"], "title": "Latent Chain-of-Thought for Visual Reasoning", "comment": "NeurIPS 2025", "summary": "Chain-of-thought (CoT) reasoning is critical for improving the\ninterpretability and reliability of Large Vision-Language Models (LVLMs).\nHowever, existing training algorithms such as SFT, PPO, and GRPO may not\ngeneralize well across unseen reasoning tasks and heavily rely on a biased\nreward model. To address this challenge, we reformulate reasoning in LVLMs as\nposterior inference and propose a scalable training algorithm based on\namortized variational inference. By leveraging diversity-seeking reinforcement\nlearning algorithms, we introduce a novel sparse reward function for\ntoken-level learning signals that encourage diverse, high-likelihood latent\nCoT, overcoming deterministic sampling limitations and avoiding reward hacking.\nAdditionally, we implement a Bayesian inference-scaling strategy that replaces\ncostly Best-of-N and Beam Search with a marginal likelihood to efficiently rank\noptimal rationales and answers. We empirically demonstrate that the proposed\nmethod enhances the state-of-the-art LVLMs on seven reasoning benchmarks, in\nterms of effectiveness, generalization, and interpretability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53d8\u5206\u63a8\u7406\u7684\u94fe\u5f0f\u601d\u8003\uff08CoT\uff09\u8bad\u7ec3\u7b97\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08LVLM\uff09\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u548c\u5956\u52b1\u6a21\u578b\u504f\u5dee\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u5c06\u63a8\u7406\u91cd\u6784\u4e3a\u540e\u9a8c\u63a8\u7406\uff0c\u5229\u7528\u591a\u6837\u6027\u5bfb\u6c42\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5f15\u5165\u7a00\u758f\u5956\u52b1\u51fd\u6570\uff0c\u9f13\u52b1\u751f\u6210\u591a\u6837\u5316\u7684\u9ad8\u4f3c\u7136\u5ea6\u6f5c CoT\uff0c\u514b\u670d\u4e86\u786e\u5b9a\u6027\u91c7\u6837\u548c\u5956\u52b1hacking\u7684\u9650\u5236\u3002\u6b64\u5916\uff0c\u8fd8\u91c7\u7528\u8d1d\u53f6\u65af\u63a8\u7406-\u7f29\u653e\u7b56\u7565\u66ff\u4ee3\u4e86\u8ba1\u7b97\u6210\u672c\u9ad8\u7684 Best-of-N \u548c Beam Search\uff0c\u4ee5\u9ad8\u6548\u5730\u8bc4\u4f30\u6700\u4f18\u63a8\u7406\u8def\u5f84\u548c\u7b54\u6848\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4e03\u4e2a\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u5347\u4e86 LVLM \u7684\u6709\u6548\u6027\u3001\u6cdb\u5316\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u94fe\u5f0f\u601d\u8003\uff08CoT\uff09\u8bad\u7ec3\u7b97\u6cd5\uff0c\u5982SFT\u3001PPO\u548cGRPO\uff0c\u5728\u5904\u7406\u672a\u77e5\u7684\u63a8\u7406\u4efb\u52a1\u65f6\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\uff0c\u5e76\u4e14\u4e25\u91cd\u4f9d\u8d56\u6709\u504f\u89c1\u7684\u5956\u52b1\u6a21\u578b\u3002\u8fd9\u9650\u5236\u4e86\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08LVLM\uff09\u5728\u63d0\u9ad8\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u9760\u6027\u65b9\u9762\u7684\u6f5c\u529b\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9c81\u68d2\u3001\u66f4\u901a\u7528\u7684\u8bad\u7ec3\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u672c\u6587\u5c06LVLM\u7684\u63a8\u7406\u8fc7\u7a0b\u91cd\u6784\u4e3a\u540e\u9a8c\u63a8\u7406\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u52a0\u901f\u53d8\u5206\u63a8\u7406\uff08amortized variational inference\uff09\u7684\u53ef\u6269\u5c55\u8bad\u7ec3\u7b97\u6cd5\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u5f15\u5165\u4e86\u591a\u6837\u6027\u5bfb\u6c42\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u7a00\u758f\u5956\u52b1\u51fd\u6570\uff0c\u7528\u4e8e\u63d0\u4f9btoken\u7ea7\u522b\u7684\u5b66\u4e60\u4fe1\u53f7\uff0c\u4ee5\u9f13\u52b1\u751f\u6210\u591a\u6837\u5316\u4e14\u9ad8\u4f3c\u7136\u5ea6\u7684\u6f5c\u5728CoT\uff0c\u4ece\u800c\u514b\u670d\u786e\u5b9a\u6027\u91c7\u6837\u548c\u5956\u52b1hacking\u7684\u5c40\u9650\u6027\u3002\u540c\u65f6\uff0c\u91c7\u7528\u8d1d\u53f6\u65af\u63a8\u7406-\u7f29\u653e\u7b56\u7565\uff0c\u7528\u8fb9\u9645\u4f3c\u7136\uff08marginal likelihood\uff09\u66ff\u4ee3\u4e86\u8ba1\u7b97\u6210\u672c\u9ad8\u7684Best-of-N\u548cBeam Search\u65b9\u6cd5\uff0c\u4ee5\u9ad8\u6548\u5730\u5bf9\u6700\u4f18\u63a8\u7406\u8def\u5f84\u548c\u7b54\u6848\u8fdb\u884c\u6392\u5e8f\u3002", "result": "\u5728\u4e03\u4e2a\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u6709\u6548\u6027\u3001\u6cdb\u5316\u6027\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684LVLM\u3002\u5177\u4f53\u6027\u80fd\u63d0\u5347\u548c\u4e0e\u73b0\u6709\u65b9\u6cd5\u7684\u5bf9\u6bd4\u6570\u636e\u5c06\u5728\u8bba\u6587\u7684\u5b9e\u9a8c\u90e8\u5206\u8be6\u7ec6\u5448\u73b0\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u57fa\u4e8e\u53d8\u5206\u63a8\u7406\u7684CoT\u8bad\u7ec3\u65b0\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709LVLM\u8bad\u7ec3\u7b97\u6cd5\u7684\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u548c\u5956\u52b1\u6a21\u578b\u504f\u5dee\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u5404\u9879\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u65b0\u9896\u7684\u5956\u52b1\u51fd\u6570\u548c\u63a8\u7406\u7b56\u7565\uff0c\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u6709\u6548\u6027\u3001\u6cdb\u5316\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4e3a\u672a\u6765LVLM\u7684\u7814\u7a76\u548c\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002\u672a\u6765\u5de5\u4f5c\u53ef\u4ee5\u63a2\u7d22\u8be5\u65b9\u6cd5\u5728\u66f4\u5e7f\u6cdb\u4efb\u52a1\u4e0a\u7684\u5e94\u7528\uff0c\u4ee5\u53ca\u8fdb\u4e00\u6b65\u4f18\u5316\u6a21\u578b\u7ed3\u6784\u548c\u8bad\u7ec3\u8fc7\u7a0b\u3002"}}
{"id": "2510.23946", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.23946", "abs": "https://arxiv.org/abs/2510.23946", "authors": ["Tananun Songdechakraiwut"], "title": "Leveraging LLMs for Early Alzheimer's Prediction", "comment": null, "summary": "We present a connectome-informed LLM framework that encodes dynamic fMRI\nconnectivity as temporal sequences, applies robust normalization, and maps\nthese data into a representation suitable for a frozen pre-trained LLM for\nclinical prediction. Applied to early Alzheimer's detection, our method\nachieves sensitive prediction with error rates well below clinically recognized\nmargins, with implications for timely Alzheimer's intervention.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u8fde\u63a5\u7ec4\u5b66\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u901a\u8fc7\u52a8\u6001\u529f\u80fd\u78c1\u5171\u632f\u6210\u50cf\uff08fMRI\uff09\u8fde\u63a5\u6570\u636e\u8fdb\u884c\u65e9\u671f\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u68c0\u6d4b\u3002", "motivation": "\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\uff08AD\uff09\u7684\u65e9\u671f\u68c0\u6d4b\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u654f\u611f\u6027\u548c\u4e34\u5e8a\u5e94\u7528\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\u3002\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u6709\u6548\u5206\u6790\u590d\u6742\u795e\u7ecf\u5f71\u50cf\u6570\u636e\u5e76\u8fdb\u884c\u7cbe\u51c6\u9884\u6d4b\u7684\u65b0\u65b9\u6cd5\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u8be5\u65b9\u6cd5\u5c06\u52a8\u6001fMRI\u8fde\u63a5\u6570\u636e\u7f16\u7801\u4e3a\u65f6\u95f4\u5e8f\u5217\uff0c\u8fdb\u884c\u7a33\u5065\u7684\u5f52\u4e00\u5316\u5904\u7406\uff0c\u5e76\u5c06\u5176\u6620\u5c04\u4e3a\u9002\u5408\u51bb\u7ed3\u7684\u9884\u8bad\u7ec3LLM\u7684\u8868\u793a\u3002\u7136\u540e\uff0c\u5229\u7528\u8be5LLM\u8fdb\u884c\u4e34\u5e8a\u9884\u6d4b\u3002", "result": "\u5728\u65e9\u671f\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u68c0\u6d4b\u4efb\u52a1\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u8fdc\u4f4e\u4e8e\u4e34\u5e8a\u516c\u8ba4\u9608\u503c\u7684\u9519\u8bef\u7387\uff0c\u663e\u793a\u51fa\u9ad8\u5ea6\u7684\u9884\u6d4b\u654f\u611f\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684\u8fde\u63a5\u7ec4\u5b66\u4fe1\u606fLLM\u6846\u67b6\u4e3a\u65e9\u671f\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u68c0\u6d4b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u524d\u666f\u7684\u65b0\u65b9\u6cd5\uff0c\u5176\u9ad8\u9884\u6d4b\u7cbe\u5ea6\u9884\u793a\u7740\u5728\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u65e9\u671f\u5e72\u9884\u65b9\u9762\u5177\u6709\u91cd\u8981\u6f5c\u529b\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63a2\u7d22\u8be5\u6846\u67b6\u5728\u5176\u4ed6\u795e\u7ecf\u9000\u884c\u6027\u75be\u75c5\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u4f18\u5316\u6a21\u578b\u4ee5\u63d0\u9ad8\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2510.23942", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23942", "abs": "https://arxiv.org/abs/2510.23942", "authors": ["Sridhar Mahadevan"], "title": "Decentralized Causal Discovery using Judo Calculus", "comment": "54 pages", "summary": "We describe a theory and implementation of an intuitionistic decentralized\nframework for causal discovery using judo calculus, which is formally defined\nas j-stable causal inference using j-do-calculus in a topos of sheaves. In\nreal-world applications -- from biology to medicine and social science --\ncausal effects depend on regime (age, country, dose, genotype, or lab\nprotocol). Our proposed judo calculus formalizes this context dependence\nformally as local truth: a causal claim is proven true on a cover of regimes,\nnot everywhere at once. The Lawvere-Tierney modal operator j chooses which\nregimes are relevant; j-stability means the claim holds constructively and\nconsistently across that family. We describe an algorithmic and implementation\nframework for judo calculus, combining it with standard score-based,\nconstraint-based, and gradient-based causal discovery methods. We describe\nexperimental results on a range of domains, from synthetic to real-world\ndatasets from biology and economics. Our experimental results show the\ncomputational efficiency gained by the decentralized nature of sheaf-theoretic\ncausal discovery, as well as improved performance over classical causal\ndiscovery methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8ejudo\u6f14\u7b97\u7684\u76f4\u89c9\u4e3b\u4e49\u53bb\u4e2d\u5fc3\u5316\u56e0\u679c\u53d1\u73b0\u6846\u67b6\uff0c\u5e76\u7ed9\u51fa\u4e86\u5176\u5728\u5e94\u7528\u4e2d\u7684\u8ba1\u7b97\u6548\u7387\u548c\u6027\u80fd\u63d0\u5347\u3002Judo\u6f14\u7b97\u5c06\u56e0\u679c\u6548\u5e94\u7684\u4f9d\u8d56\u6027\u5f62\u5f0f\u5316\u4e3a\u5c40\u90e8\u771f\u7406\uff0c\u5e76\u901a\u8fc7j-\u7a33\u5b9a\u6027\u5728\u76f8\u5173\u6a21\u578b\u4e0a\u4fdd\u6301\u4e00\u81f4\u6027\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u56e0\u679c\u6548\u5e94\u56e0\u5404\u79cd\u56e0\u7d20\uff08\u5982\u5e74\u9f84\u3001\u56fd\u5bb6\u3001\u5242\u91cf\u3001\u57fa\u56e0\u578b\u6216\u5b9e\u9a8c\u65b9\u6848\uff09\u800c\u5f02\u3002\u73b0\u6709\u7684\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\u672a\u80fd\u5145\u5206\u89e3\u51b3\u8fd9\u79cd\u60c5\u5883\u4f9d\u8d56\u6027\uff0c\u5bfc\u81f4\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u5e76\u5f62\u5f0f\u5316\u4e86judo\u6f14\u7b97\uff0c\u8be5\u6f14\u7b97\u5c06\u56e0\u679c\u53d1\u73b0\u4e2d\u7684\u60c5\u5883\u4f9d\u8d56\u6027\u8868\u8ff0\u4e3a\u5c40\u90e8\u771f\u7406\u3002\u5229\u7528Lawvere-Tierney\u6a21\u6001\u7b97\u5b50j\u9009\u62e9\u76f8\u5173\u6a21\u578b\uff0c\u5e76\u901a\u8fc7j-\u7a33\u5b9a\u6027\u786e\u4fdd\u56e0\u679c\u4e3b\u5f20\u5728\u6240\u9009\u6a21\u578b\u5bb6\u65cf\u4e2d\u5177\u6709\u5efa\u8bbe\u6027\u548c\u4e00\u81f4\u6027\u3002\u7ed3\u5408\u4e86\u57fa\u4e8e\u5206\u6570\u3001\u57fa\u4e8e\u7ea6\u675f\u548c\u57fa\u4e8e\u68af\u5ea6\u7b49\u6807\u51c6\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\uff0c\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u7b97\u6cd5\u548c\u5b9e\u73b0\u6846\u67b6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u57fa\u4e8esheaf\u7406\u8bba\u7684\u53bb\u4e2d\u5fc3\u5316\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\u5728\u8ba1\u7b97\u6548\u7387\u4e0a\u6709\u6240\u63d0\u5347\uff0c\u5e76\u4e14\u5728\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u7684\u6570\u636e\u96c6\uff08\u5305\u62ec\u751f\u7269\u5b66\u548c\u7ecf\u6d4e\u5b66\u9886\u57df\uff09\u4e0a\uff0c\u5176\u6027\u80fd\u4f18\u4e8e\u7ecf\u5178\u7684\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\u3002", "conclusion": "Judo\u6f14\u7b97\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f62\u5f0f\u5316\u56e0\u679c\u53d1\u73b0\u60c5\u5883\u4f9d\u8d56\u6027\u7684\u65b0\u6846\u67b6\uff0c\u5e76\u80fd\u901a\u8fc7\u53bb\u4e2d\u5fc3\u5316\u7684sheaf\u7406\u8bba\u5b9e\u73b0\u9ad8\u6548\u4e14\u9ad8\u6027\u80fd\u7684\u56e0\u679c\u53d1\u73b0\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63a2\u7d22\u8be5\u6846\u67b6\u5728\u66f4\u5e7f\u6cdb\u9886\u57df\u7684\u5e94\u7528\u4ee5\u53ca\u4e0e\u5176\u4ed6\u56e0\u679c\u63a8\u65ad\u65b9\u6cd5\u7684\u7ed3\u5408\u3002"}}
{"id": "2510.23949", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23949", "abs": "https://arxiv.org/abs/2510.23949", "authors": ["Kyomin Hwang", "Hyeonjin Kim", "Seungyeon Kim", "Sunghyun Wee", "Nojun Kwak"], "title": "Uncovering the Potential Risks in Unlearning: Danger of English-only Unlearning in Multilingual LLMs", "comment": null, "summary": "There have been a couple of studies showing that attempting to erase\nmultilingual knowledge using only English data is insufficient for multilingual\nLLMs. However, their analyses remain highly performance-oriented. In this\npaper, we switch the point of view to evaluation, and address an additional\nblind spot which reveals itself when the multilingual LLM is fully finetuned\nwith parallel multilingual dataset before unlearning. Here, language confusion\noccurs whereby a model responds in language different from that of the input\nprompt. Language confusion is a problematic phenomenon in unlearning, causing\nthe standard reference-based metrics to fail. We tackle this phenomenon in\nthree steps: (1) introduce N-gram-based Language-Mix (N-Mix) score to\nquantitatively show the language confusion is pervasive and consistent in\nmultilingual LLMs, (2) demonstrate that reference-based metrics result in false\nnegatives when N-Mix score is high, and(3) suggest the need of new type of\nunlearning evaluation that can directly assess the content of the generated\nsentences. We call this type of metrics as semantic-based metric.", "AI": {"tldr": "\u4ee5\u5f80\u7684\u7814\u7a76\u8868\u660e\uff0c\u4ec5\u4f7f\u7528\u82f1\u8bed\u6570\u636e\u6765\u64e6\u9664\u591a\u8bed\u8a00\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u591a\u8bed\u8a00\u77e5\u8bc6\u662f\u4e0d\u591f\u7684\u3002\u672c\u6587\u4ece\u8bc4\u4f30\u89d2\u5ea6\u5207\u5165\uff0c\u805a\u7126\u4e8e\u591a\u8bed\u8a00LLM\u5728\u5b8c\u5168\u4f7f\u7528\u5e76\u884c\u591a\u8bed\u8a00\u6570\u636e\u96c6\u8fdb\u884c\u5fae\u8c03\u540e\u8fdb\u884c\u201c\u9057\u5fd8\u201d\u65f6\u51fa\u73b0\u7684\u201c\u8bed\u8a00\u6df7\u6dc6\u201d\u95ee\u9898\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u8fd9\u79cd\u73b0\u8c61\u5bfc\u81f4\u6807\u51c6\u7684\u57fa\u4e8e\u53c2\u8003\u7684\u8bc4\u4f30\u6307\u6807\u5931\u6548\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u5173\u4e8e\u64e6\u9664\u591a\u8bed\u8a00LLM\u77e5\u8bc6\u7684\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u6027\u80fd\uff0c\u5ffd\u7565\u4e86\u5728\u5b8c\u5168\u5fae\u8c03\u540e\u7684\u9057\u5fd8\u8fc7\u7a0b\u4e2d\u53ef\u80fd\u51fa\u73b0\u7684\u201c\u8bed\u8a00\u6df7\u6dc6\u201d\u95ee\u9898\u3002\u8bed\u8a00\u6df7\u6dc6\u662f\u6307\u6a21\u578b\u56de\u5e94\u7684\u8bed\u8a00\u4e0e\u8f93\u5165\u63d0\u793a\u7684\u8bed\u8a00\u4e0d\u4e00\u81f4\uff0c\u8fd9\u4f7f\u5f97\u6807\u51c6\u7684\u57fa\u4e8e\u53c2\u8003\u7684\u8bc4\u4f30\u6307\u6807\uff08\u5982BLEU\u3001ROUGE\u7b49\uff09\u65e0\u6cd5\u51c6\u786e\u8861\u91cf\u9057\u5fd8\u6548\u679c\uff0c\u662f\u4e00\u4e2a\u4e9f\u5f85\u89e3\u51b3\u7684\u8bc4\u4f30\u76f2\u70b9\u3002", "method": "1. \u63d0\u51faN-gram-based Language-Mix (N-Mix)\u5f97\u5206\uff0c\u91cf\u5316\u8bc4\u4f30\u8bed\u8a00\u6df7\u6dc6\u7684\u666e\u904d\u6027\u548c\u4e00\u81f4\u6027\u30022. \u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5f53N-Mix\u5f97\u5206\u8f83\u9ad8\u65f6\uff0c\u57fa\u4e8e\u53c2\u8003\u7684\u8bc4\u4f30\u6307\u6807\u4f1a\u51fa\u73b0\u5047\u9634\u6027\u7ed3\u679c\u30023. \u8bba\u8bc1\u4e86\u9700\u8981\u4e00\u79cd\u65b0\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u53ef\u4ee5\u76f4\u63a5\u8bc4\u4f30\u751f\u6210\u53e5\u5b50\u7684\u8bed\u4e49\u5185\u5bb9\uff0c\u5373\u63d0\u51fa\u201c\u57fa\u4e8e\u8bed\u4e49\u7684\u6307\u6807\u201d\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u8bed\u8a00\u6df7\u6dc6\u5728\u591a\u8bed\u8a00LLM\u4e2d\u666e\u904d\u5b58\u5728\u4e14\u4e00\u81f4\u3002\u57fa\u4e8e\u53c2\u8003\u7684\u8bc4\u4f30\u6307\u6807\u5728\u8bed\u8a00\u6df7\u6dc6\u4e25\u91cd\u65f6\u4f1a\u4ea7\u751f\u8bef\u5bfc\u6027\u7684\u4f4e\u8bc4\u4f30\u7ed3\u679c\uff08\u5047\u9634\u6027\uff09\u3002N-Mix\u5f97\u5206\u80fd\u591f\u6709\u6548\u63ed\u793a\u8bed\u8a00\u6df7\u6dc6\u7684\u7a0b\u5ea6\u3002", "conclusion": "\u672c\u6587\u6307\u51fa\u4e86\u5f53\u524d\u591a\u8bed\u8a00LLM\u9057\u5fd8\u7814\u7a76\u4e2d\u8bc4\u4f30\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u8bed\u8a00\u6df7\u6dc6\u95ee\u9898\u5bf9\u6807\u51c6\u6307\u6807\u7684\u5e72\u6270\u3002\u7814\u7a76\u63d0\u51fa\u4e86\u91cf\u5316\u8bed\u8a00\u6df7\u6dc6\u7684\u65b0\u6307\u6807N-Mix\uff0c\u5e76\u5f3a\u8c03\u4e86\u5f00\u53d1\u76f4\u63a5\u8bc4\u4f30\u8bed\u4e49\u5185\u5bb9\u7684\u201c\u57fa\u4e8e\u8bed\u4e49\u7684\u6307\u6807\u201d\u7684\u5fc5\u8981\u6027\uff0c\u4e3a\u672a\u6765\u591a\u8bed\u8a00LLM\u7684\u9057\u5fd8\u8bc4\u4f30\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2510.23965", "categories": ["cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.23965", "abs": "https://arxiv.org/abs/2510.23965", "authors": ["Aymane El Gadarri", "Ali Aouad", "Vivek F. Farias"], "title": "The Sign Estimator: LLM Alignment in the Face of Choice Heterogeneity", "comment": null, "summary": "Traditional LLM alignment methods are vulnerable to heterogeneity in human\npreferences. Fitting a na\\\"ive probabilistic model to pairwise comparison data\n(say over prompt-completion pairs) yields an inconsistent estimate of the\npopulation-average utility -a canonical measure of social welfare. We propose a\nnew method, dubbed the sign estimator, that provides a simple, provably\nconsistent, and efficient estimator by replacing cross-entropy with binary\nclassification loss in the aggregation step. This simple modification recovers\nconsistent ordinal alignment under mild assumptions and achieves the first\npolynomial finite-sample error bounds in this setting. In realistic simulations\nof LLM alignment using digital twins, the sign estimator substantially reduces\npreference distortion over a panel of simulated personas, cutting (angular)\nestimation error by nearly 35% and decreasing disagreement with true population\npreferences from 12% to 8% compared to standard RLHF. Our method also compares\nfavorably to panel data heuristics that explicitly model user heterogeneity and\nrequire tracking individual-level preference data-all while maintaining the\nimplementation simplicity of existing LLM alignment pipelines.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u65b0\u65b9\u6cd5\u201c\u7b26\u53f7\u4f30\u8ba1\u5668\u201d\uff0c\u901a\u8fc7\u5728\u805a\u5408\u6b65\u9aa4\u4e2d\u7528\u4e8c\u5143\u5206\u7c7b\u635f\u5931\u66ff\u6362\u4ea4\u53c9\u71b5\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfLLM\u5bf9\u9f50\u65b9\u6cd5\u5728\u5904\u7406\u4eba\u7c7b\u504f\u597d\u5f02\u8d28\u6027\u65f6\u5b58\u5728\u7684\u4e0d\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u8be5\u65b9\u6cd5\u7b80\u5355\u3001\u4e00\u81f4\u4e14\u9ad8\u6548\uff0c\u5b9e\u73b0\u4e86\u9996\u4e2a\u591a\u9879\u5f0f\u6709\u9650\u6837\u672c\u8bef\u5dee\u754c\u9650\uff0c\u5e76\u5728\u6a21\u62df\u5b9e\u9a8c\u4e2d\u663e\u8457\u51cf\u5c11\u4e86\u504f\u597d\u5931\u771f\uff0c\u964d\u4f4e\u4e86\u4f30\u8ba1\u8bef\u5dee\u548c\u4e0e\u771f\u5b9e\u4eba\u53e3\u504f\u597d\u7684\u4e0d\u4e00\u81f4\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5bf9\u9f50\u65b9\u6cd5\u5728\u9762\u5bf9\u4eba\u7c7b\u504f\u597d\u5f02\u8d28\u6027\u65f6\u5bb9\u6613\u51fa\u73b0\u4e0d\u4e00\u81f4\u6027\u95ee\u9898\u3002\u76f4\u63a5\u62df\u5408\u6982\u7387\u6a21\u578b\u5230\u6210\u5bf9\u6bd4\u8f83\u6570\u636e\uff08\u5982\u63d0\u793a-\u5b8c\u6210\u5bf9\uff09\u4f1a\u5bfc\u81f4\u5bf9\u4eba\u53e3\u5e73\u5747\u6548\u7528\uff08\u793e\u4f1a\u798f\u5229\u7684\u5178\u578b\u8861\u91cf\u6807\u51c6\uff09\u7684\u4f30\u8ba1\u4e0d\u4e00\u81f4\uff0c\u8fd9\u9650\u5236\u4e86LLM\u5bf9\u9f50\u7684\u6709\u6548\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u7b26\u53f7\u4f30\u8ba1\u5668\u201d\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u805a\u5408\u6b65\u9aa4\u4e2d\u7528\u4e8c\u5143\u5206\u7c7b\u635f\u5931\u66ff\u6362\u4ea4\u53c9\u71b5\u6765\u5b9e\u73b0\u3002\u8fd9\u79cd\u65b9\u6cd5\u65e8\u5728\u63d0\u4f9b\u4e00\u4e2a\u7b80\u5355\u3001\u53ef\u8bc1\u660e\u4e00\u81f4\u4e14\u9ad8\u6548\u7684\u4f30\u8ba1\u5668\u3002\u5728\u6a21\u62dfLLM\u5bf9\u9f50\u7684\u5b9e\u9a8c\u4e2d\uff0c\u4f7f\u7528\u4e86\u6570\u5b57\u5b6a\u751f\u6765\u6a21\u62df\u4e0d\u540c\u4e2a\u4f53\u7684\u504f\u597d\u3002", "result": "\u7b26\u53f7\u4f30\u8ba1\u5668\u5728\u6a21\u62df\u5b9e\u9a8c\u4e2d\uff0c\u76f8\u6bd4\u6807\u51c6\u7684\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u4eba\u7c7b\u53cd\u9988\uff08RLHF\uff09\u65b9\u6cd5\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u6a21\u62df\u4eba\u7269\u9762\u677f\u7684\u504f\u597d\u5931\u771f\uff0c\u5c06\u89d2\u5ea6\u4f30\u8ba1\u8bef\u5dee\u964d\u4f4e\u4e86\u8fd135%\uff0c\u5e76\u5c06\u4e0e\u771f\u5b9e\u4eba\u53e3\u504f\u597d\u7684\u4e00\u81f4\u6027\u4ece12%\u964d\u4f4e\u52308%\u3002\u8be5\u65b9\u6cd5\u5728\u4e0e\u663e\u5f0f\u5efa\u6a21\u7528\u6237\u5f02\u8d28\u6027\u548c\u9700\u8981\u8ddf\u8e2a\u4e2a\u4f53\u5c42\u9762\u504f\u597d\u6570\u636e\u7684\u9762\u677f\u6570\u636e\u542f\u53d1\u5f0f\u65b9\u6cd5\u76f8\u6bd4\u65f6\uff0c\u4e5f\u8868\u73b0\u51fa\u4f18\u52bf\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u73b0\u6709LLM\u5bf9\u9f50\u6d41\u6c34\u7ebf\u7684\u5b9e\u73b0\u7b80\u5355\u6027\u3002", "conclusion": "\u7b26\u53f7\u4f30\u8ba1\u5668\u662f\u4e00\u79cd\u6709\u6548\u4e14\u7b80\u5355\u7684LLM\u5bf9\u9f50\u65b9\u6cd5\uff0c\u80fd\u591f\u89e3\u51b3\u4eba\u7c7b\u504f\u597d\u5f02\u8d28\u6027\u5e26\u6765\u7684\u6311\u6218\uff0c\u5e76\u5728\u6a21\u62df\u5b9e\u9a8c\u4e2d\u5c55\u73b0\u51fa\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u3002\u8be5\u65b9\u6cd5\u5728\u51cf\u5c11\u504f\u597d\u5931\u771f\u3001\u63d0\u9ad8\u4f30\u8ba1\u4e00\u81f4\u6027\u4ee5\u53ca\u7b80\u5316\u5b9e\u73b0\u65b9\u9762\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u4e3a\u672a\u6765LLM\u7684\u5bf9\u9f50\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2510.23995", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.23995", "abs": "https://arxiv.org/abs/2510.23995", "authors": ["Mengzhou Sun", "Sendong Zhao", "Jianyu Chen", "Haochun Wang", "Bin Qin"], "title": "M-Eval: A Heterogeneity-Based Framework for Multi-evidence Validation in Medical RAG Systems", "comment": null, "summary": "Retrieval-augmented Generation (RAG) has demonstrated potential in enhancing\nmedical question-answering systems through the integration of large language\nmodels (LLMs) with external medical literature. LLMs can retrieve relevant\nmedical articles to generate more professional responses efficiently. However,\ncurrent RAG applications still face problems. They generate incorrect\ninformation, such as hallucinations, and they fail to use external knowledge\ncorrectly. To solve these issues, we propose a new method named M-Eval. This\nmethod is inspired by the heterogeneity analysis approach used in\nEvidence-Based Medicine (EBM). Our approach can check for factual errors in RAG\nresponses using evidence from multiple sources. First, we extract additional\nmedical literature from external knowledge bases. Then, we retrieve the\nevidence documents generated by the RAG system. We use heterogeneity analysis\nto check whether the evidence supports different viewpoints in the response. In\naddition to verifying the accuracy of the response, we also assess the\nreliability of the evidence provided by the RAG system. Our method shows an\nimprovement of up to 23.31% accuracy across various LLMs. This work can help\ndetect errors in current RAG-based medical systems. It also makes the\napplications of LLMs more reliable and reduces diagnostic errors.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aM-Eval\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u501f\u9274\u5faa\u8bc1\u533b\u5b66\uff08EBM\uff09\u4e2d\u7684\u5f02\u8d28\u6027\u5206\u6790\uff0c\u5229\u7528\u591a\u6e90\u8bc1\u636e\u6765\u68c0\u67e5\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u5728\u533b\u5b66\u95ee\u7b54\u7cfb\u7edf\u4e2d\u751f\u6210\u54cd\u5e94\u7684\u4e8b\u5b9e\u51c6\u786e\u6027\u548c\u8bc1\u636e\u53ef\u9760\u6027\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\uff08\u6700\u9ad8\u63d0\u534723.31%\uff09\uff0c\u51cf\u5c11\u4e86\u9519\u8bef\u548c\u8bca\u65ad\u8bef\u5dee\u3002", "motivation": "\u5f53\u524d\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6280\u672f\u5728\u533b\u5b66\u95ee\u7b54\u7cfb\u7edf\u4e2d\u867d\u7136\u5229\u7528\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u5916\u90e8\u533b\u5b66\u6587\u732e\uff0c\u4f46\u4ecd\u5b58\u5728\u751f\u6210\u4e0d\u6b63\u786e\u4fe1\u606f\uff08\u5982\u5e7b\u89c9\uff09\u548c\u672a\u80fd\u6b63\u786e\u4f7f\u7528\u5916\u90e8\u77e5\u8bc6\u7684\u95ee\u9898\u3002\u8fd9\u4e25\u91cd\u5f71\u54cd\u4e86\u5176\u5728\u4e13\u4e1a\u9886\u57df\u7684\u5e94\u7528\u53ef\u9760\u6027\uff0c\u5e76\u53ef\u80fd\u5bfc\u81f4\u4e25\u91cd\u7684\u540e\u679c\u3002", "method": "\u63d0\u51faM-Eval\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u53d7\u5faa\u8bc1\u533b\u5b66\uff08EBM\uff09\u4e2d\u5f02\u8d28\u6027\u5206\u6790\u7684\u542f\u53d1\u3002\u5177\u4f53\u6b65\u9aa4\u5305\u62ec\uff1a1. \u4ece\u5916\u90e8\u77e5\u8bc6\u5e93\u63d0\u53d6\u989d\u5916\u7684\u533b\u5b66\u6587\u732e\u30022. \u68c0\u7d22RAG\u7cfb\u7edf\u751f\u6210\u7684\u8bc1\u636e\u6587\u6863\u30023. \u5229\u7528\u5f02\u8d28\u6027\u5206\u6790\u6280\u672f\uff0c\u68c0\u67e5\u63d0\u53d6\u7684\u8bc1\u636e\u662f\u5426\u652f\u6301\u54cd\u5e94\u4e2d\u5b58\u5728\u7684\u4e0d\u540c\u89c2\u70b9\u30024. \u8bc4\u4f30RAG\u7cfb\u7edf\u63d0\u4f9b\u8bc1\u636e\u7684\u53ef\u9760\u6027\uff0c\u4ee5\u9a8c\u8bc1\u54cd\u5e94\u7684\u51c6\u786e\u6027\u3002", "result": "M-Eval\u65b9\u6cd5\u5728\u591a\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e0a\u8fdb\u884c\u4e86\u6d4b\u8bd5\uff0c\u7ed3\u679c\u663e\u793a\u51c6\u786e\u6027\u63d0\u9ad8\u4e8623.31%\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u68c0\u6d4b\u5f53\u524d\u57fa\u4e8eRAG\u7684\u533b\u5b66\u7cfb\u7edf\u4e2d\u7684\u9519\u8bef\uff0c\u5e76\u63d0\u9ad8\u4e86LLM\u5e94\u7528\u7684\u53ef\u9760\u6027\u3002", "conclusion": "M-Eval\u901a\u8fc7\u5f15\u5165\u57fa\u4e8eEBM\u5f02\u8d28\u6027\u5206\u6790\u7684\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86RAG\u5728\u533b\u5b66\u95ee\u7b54\u4e2d\u5b58\u5728\u7684\u4e8b\u5b9e\u9519\u8bef\u548c\u77e5\u8bc6\u4f7f\u7528\u4e0d\u5f53\u7684\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u7cfb\u7edf\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\uff0c\u51cf\u5c11\u4e86\u6f5c\u5728\u7684\u8bca\u65ad\u8bef\u5dee\uff0c\u4e3aLLM\u5728\u533b\u7597\u9886\u57df\u7684\u5b89\u5168\u5e94\u7528\u5960\u5b9a\u4e86\u57fa\u7840\u3002\u672a\u6765\u5de5\u4f5c\u53ef\u8fdb\u4e00\u6b65\u63a2\u7d22\u5176\u5728\u66f4\u5e7f\u6cdb\u533b\u7597\u573a\u666f\u4e0b\u7684\u5e94\u7528\u548c\u4f18\u5316\u3002"}}
{"id": "2510.23989", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23989", "abs": "https://arxiv.org/abs/2510.23989", "authors": ["Shangde Gao", "Zelin Xu", "Zhe Jiang"], "title": "Learning Individual Movement Shifts After Urban Disruptions with Social Infrastructure Reliance", "comment": null, "summary": "Shifts in individual movement patterns following disruptive events can reveal\nchanging demands for community resources. However, predicting such shifts\nbefore disruptive events remains challenging for several reasons. First,\nmeasures are lacking for individuals' heterogeneous social infrastructure\nresilience (SIR), which directly influences their movement patterns, and\ncommonly used features are often limited or unavailable at scale, e.g.,\nsociodemographic characteristics. Second, the complex interactions between\nindividual movement patterns and spatial contexts have not been sufficiently\ncaptured. Third, individual-level movement may be spatially sparse and not\nwell-suited to traditional decision-making methods for movement predictions.\nThis study incorporates individuals' SIR into a conditioned deep learning model\nto capture the complex relationships between individual movement patterns and\nlocal spatial context using large-scale, sparse individual-level data. Our\nexperiments demonstrate that incorporating individuals' SIR and spatial context\ncan enhance the model's ability to predict post-event individual movement\npatterns. The conditioned model can capture the divergent shifts in movement\npatterns among individuals who exhibit similar pre-event patterns but differ in\nSIR.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4e2a\u4f53\u793e\u4f1a\u57fa\u7840\u8bbe\u65bd\u97e7\u6027\uff08SIR\uff09\u548c\u7a7a\u95f4\u4e0a\u4e0b\u6587\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u7528\u4e8e\u9884\u6d4b\u707e\u96be\u6027\u4e8b\u4ef6\u540e\u4e2a\u4f53\u79fb\u52a8\u6a21\u5f0f\u7684\u53d8\u5316\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u6a21\u578b\u80fd\u6709\u6548\u63d0\u9ad8\u9884\u6d4b\u7cbe\u5ea6\uff0c\u5e76\u80fd\u533a\u5206\u5177\u6709\u76f8\u4f3c\u4e8b\u524d\u79fb\u52a8\u6a21\u5f0f\u4f46SIR\u4e0d\u540c\u7684\u4e2a\u4f53\u3002", "motivation": "\u9884\u6d4b\u707e\u96be\u6027\u4e8b\u4ef6\u540e\u4e2a\u4f53\u79fb\u52a8\u6a21\u5f0f\u7684\u53d8\u5316\u5bf9\u4e8e\u4e86\u89e3\u793e\u533a\u8d44\u6e90\u9700\u6c42\u7684\u53d8\u5316\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u9762\u4e34\u6311\u6218\uff1a1. \u7f3a\u4e4f\u8861\u91cf\u4e2a\u4f53\u5f02\u8d28\u6027SIR\u7684\u6307\u6807\uff0c\u4e14\u5e38\u7528\u7279\u5f81\uff08\u5982\u793e\u4f1a\u4eba\u53e3\u7279\u5f81\uff09\u96be\u4ee5\u5927\u89c4\u6a21\u83b7\u53d6\u30022. \u672a\u5145\u5206\u6355\u6349\u4e2a\u4f53\u79fb\u52a8\u6a21\u5f0f\u4e0e\u7a7a\u95f4\u4e0a\u4e0b\u6587\u7684\u590d\u6742\u4ea4\u4e92\u30023. \u4e2a\u4f53\u79fb\u52a8\u6570\u636e\u7a00\u758f\uff0c\u4e0d\u9002\u5408\u4f20\u7edf\u9884\u6d4b\u65b9\u6cd5\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u4ee5\u63d0\u9ad8\u707e\u96be\u6027\u4e8b\u4ef6\u540e\u4e2a\u4f53\u79fb\u52a8\u6a21\u5f0f\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u6761\u4ef6\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u5c06\u4e2a\u4f53\u7684SIR\u7eb3\u5165\u8003\u91cf\uff0c\u4ee5\u6355\u6349\u4e2a\u4f53\u79fb\u52a8\u6a21\u5f0f\u4e0e\u5c40\u90e8\u7a7a\u95f4\u4e0a\u4e0b\u6587\u4e4b\u95f4\u7684\u590d\u6742\u5173\u7cfb\u3002\u8be5\u6a21\u578b\u80fd\u591f\u5904\u7406\u5927\u89c4\u6a21\u3001\u7a00\u758f\u7684\u4e2a\u4f53\u79fb\u52a8\u6570\u636e\u3002\u5b9e\u9a8c\u4e2d\uff0c\u901a\u8fc7\u5bf9\u6bd4\u5206\u6790\uff0c\u9a8c\u8bc1\u4e86\u5f15\u5165SIR\u548c\u7a7a\u95f4\u4e0a\u4e0b\u6587\u5bf9\u9884\u6d4b\u7cbe\u5ea6\u7684\u63d0\u5347\u6548\u679c\uff0c\u5e76\u5c55\u793a\u4e86\u6a21\u578b\u533a\u5206\u5177\u6709\u76f8\u4f3c\u4e8b\u524d\u79fb\u52a8\u6a21\u5f0f\u4f46SIR\u4e0d\u540c\u7684\u4e2a\u4f53\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5c06\u4e2a\u4f53SIR\u548c\u7a7a\u95f4\u4e0a\u4e0b\u6587\u4fe1\u606f\u878d\u5165\u6a21\u578b\u663e\u8457\u63d0\u9ad8\u4e86\u5bf9\u4e8b\u4ef6\u540e\u4e2a\u4f53\u79fb\u52a8\u6a21\u5f0f\u7684\u9884\u6d4b\u80fd\u529b\u3002\u8be5\u6761\u4ef6\u6a21\u578b\u80fd\u591f\u6355\u6349\u5230\u90a3\u4e9b\u4e8b\u524d\u79fb\u52a8\u6a21\u5f0f\u76f8\u4f3c\u4f46SIR\u4e0d\u540c\u7684\u4e2a\u4f53\u6240\u8868\u73b0\u51fa\u7684\u4e0d\u540c\u79fb\u52a8\u6a21\u5f0f\u53d8\u5316\u3002", "conclusion": "\u672c\u7814\u7a76\u6210\u529f\u5f00\u53d1\u5e76\u9a8c\u8bc1\u4e86\u4e00\u79cd\u7ed3\u5408SIR\u548c\u7a7a\u95f4\u4e0a\u4e0b\u6587\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u7528\u4e8e\u9884\u6d4b\u4e8b\u4ef6\u540e\u4e2a\u4f53\u79fb\u52a8\u6a21\u5f0f\u7684\u53d8\u5316\u3002\u7814\u7a76\u5f3a\u8c03\u4e86SIR\u5728\u4e2a\u4f53\u79fb\u52a8\u51b3\u7b56\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u5e76\u4e3a\u66f4\u7cbe\u51c6\u7684\u8d44\u6e90\u9700\u6c42\u9884\u6d4b\u548c\u5e94\u6025\u54cd\u5e94\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u6cd5\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63a2\u7d22\u66f4\u4e30\u5bcc\u7684SIR\u6307\u6807\u548c\u66f4\u590d\u6742\u7684\u6a21\u578b\u7ed3\u6784\uff0c\u4ee5\u5e94\u5bf9\u66f4\u5e7f\u6cdb\u7684\u573a\u666f\u548c\u6570\u636e\u3002"}}
{"id": "2510.23998", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.23998", "abs": "https://arxiv.org/abs/2510.23998", "authors": ["Mengzhou Sun", "Sendong Zhao", "Jianyu Chen", "Bin Qin"], "title": "PICOs-RAG: PICO-supported Query Rewriting for Retrieval-Augmented Generation in Evidence-Based Medicine", "comment": null, "summary": "Evidence-based medicine (EBM) research has always been of paramount\nimportance. It is important to find appropriate medical theoretical support for\nthe needs from physicians or patients to reduce the occurrence of medical\naccidents. This process is often carried out by human querying relevant\nliterature databases, which lacks objectivity and efficiency. Therefore,\nresearchers utilize retrieval-augmented generation (RAG) to search for evidence\nand generate responses automatically. However, current RAG methods struggle to\nhandle complex queries in real-world clinical scenarios. For example, when\nqueries lack certain information or use imprecise language, the model may\nretrieve irrelevant evidence and generate unhelpful answers. To address this\nissue, we present the PICOs-RAG to expand the user queries into a better\nformat. Our method can expand and normalize the queries into professional ones\nand use the PICO format, a search strategy tool present in EBM, to extract the\nmost important information used for retrieval. This approach significantly\nenhances retrieval efficiency and relevance, resulting in up to an 8.8\\%\nimprovement compared to the baseline evaluated by our method. Thereby the\nPICOs-RAG improves the performance of the large language models into a helpful\nand reliable medical assistant in EBM.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPICOs-RAG\u7684\u6539\u8fdb\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u5728\u5faa\u8bc1\u533b\u5b66\uff08EBM\uff09\u9886\u57df\u4e2d\u5904\u7406\u590d\u6742\u3001\u4e0d\u7cbe\u786e\u7684\u4e34\u5e8a\u67e5\u8be2\u7684\u6311\u6218\u3002\u901a\u8fc7\u5c06\u7528\u6237\u67e5\u8be2\u6269\u5c55\u5e76\u683c\u5f0f\u5316\u4e3aPICO\uff08Population, Intervention, Comparison, Outcome\uff09\u6807\u51c6\uff0cPICOs-RAG\u663e\u8457\u63d0\u9ad8\u4e86\u8bc1\u636e\u68c0\u7d22\u7684\u6548\u7387\u548c\u76f8\u5173\u6027\uff0c\u76f8\u8f83\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u6027\u80fd\u63d0\u5347\u9ad8\u8fbe8.8%\uff0c\u4f7f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u66f4\u597d\u5730\u4f5c\u4e3a\u533b\u5b66\u52a9\u624b\u3002", "motivation": "\u5faa\u8bc1\u533b\u5b66\uff08EBM\uff09\u7684\u7814\u7a76\u81f3\u5173\u91cd\u8981\uff0c\u65e8\u5728\u4e3a\u533b\u751f\u548c\u60a3\u8005\u63d0\u4f9b\u53ef\u9760\u7684\u533b\u7597\u7406\u8bba\u652f\u6301\uff0c\u4ee5\u51cf\u5c11\u533b\u7597\u4e8b\u6545\u3002\u4f20\u7edf\u7684\u4eba\u5de5\u6587\u732e\u68c0\u7d22\u65b9\u6cd5\u6548\u7387\u4f4e\u4e0b\u4e14\u7f3a\u4e4f\u5ba2\u89c2\u6027\u3002\u73b0\u6709\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u65b9\u6cd5\u5728\u5904\u7406\u73b0\u5b9e\u4e34\u5e8a\u573a\u666f\u4e2d\u590d\u6742\u3001\u4fe1\u606f\u4e0d\u5168\u6216\u8868\u8ff0\u4e0d\u7cbe\u786e\u7684\u67e5\u8be2\u65f6\u5b58\u5728\u56f0\u96be\uff0c\u5bfc\u81f4\u68c0\u7d22\u5230\u7684\u8bc1\u636e\u4e0d\u76f8\u5173\uff0c\u751f\u6210\u7684\u56de\u7b54\u65e0\u5e2e\u52a9\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u6539\u8fdbRAG\u65b9\u6cd5\u4ee5\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u7684PICOs-RAG\u65b9\u6cd5\uff0c\u901a\u8fc7\u67e5\u8be2\u6269\u5c55\u548c\u6807\u51c6\u5316\u6765\u4f18\u5316\u7528\u6237\u8f93\u5165\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u5b83\u5c06\u7528\u6237\u7684\u67e5\u8be2\u6269\u5c55\u6210\u66f4\u4e13\u4e1a\u7684\u683c\u5f0f\uff0c\u5e76\u5229\u7528PICO\uff08Population, Intervention, Comparison, Outcome\uff09\u683c\u5f0f\uff0c\u4e00\u79cd\u5faa\u8bc1\u533b\u5b66\u4e2d\u5e38\u7528\u7684\u641c\u7d22\u7b56\u7565\u5de5\u5177\uff0c\u6765\u63d0\u53d6\u7528\u4e8e\u68c0\u7d22\u7684\u6700\u5173\u952e\u4fe1\u606f\u3002\u8fd9\u79cd\u65b9\u6cd5\u65e8\u5728\u63d0\u9ad8\u68c0\u7d22\u7684\u6548\u7387\u548c\u76f8\u5173\u6027\u3002", "result": "PICOs-RAG\u65b9\u6cd5\u5728\u8bc4\u4f30\u4e2d\u5c55\u73b0\u51fa\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u4e0e\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0c\u68c0\u7d22\u6548\u7387\u548c\u76f8\u5173\u6027\u63d0\u9ad8\u4e86\u9ad8\u8fbe8.8%\u3002\u8fd9\u4e00\u7ed3\u679c\u8868\u660e\uff0cPICOs-RAG\u80fd\u591f\u6709\u6548\u5730\u5904\u7406\u590d\u6742\u548c\u4e0d\u7cbe\u786e\u7684\u4e34\u5e8a\u67e5\u8be2\uff0c\u63d0\u5347\u4e86\u8bc1\u636e\u68c0\u7d22\u7684\u51c6\u786e\u6027\u3002", "conclusion": "PICOs-RAG\u65b9\u6cd5\u7684\u63d0\u51fa\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709RAG\u65b9\u6cd5\u5728\u5904\u7406\u590d\u6742\u4e34\u5e8a\u67e5\u8be2\u65f6\u7684\u4e0d\u8db3\uff0c\u901a\u8fc7\u5f15\u5165PICO\u683c\u5f0f\u4f18\u5316\u4e86\u4fe1\u606f\u68c0\u7d22\u8fc7\u7a0b\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u63d0\u5347\u68c0\u7d22\u6548\u7387\u548c\u76f8\u5173\u6027\uff0c\u4f7f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5faa\u8bc1\u533b\u5b66\u9886\u57df\u6210\u4e3a\u66f4\u53ef\u9760\u3001\u66f4\u6709\u5e2e\u52a9\u7684\u533b\u5b66\u52a9\u624b\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63a2\u7d22\u8be5\u65b9\u6cd5\u5728\u66f4\u591a\u6837\u5316\u7684\u4e34\u5e8a\u573a\u666f\u548c\u66f4\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u7684\u5e94\u7528\u3002"}}
{"id": "2510.24003", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24003", "abs": "https://arxiv.org/abs/2510.24003", "authors": ["Mengzhou Sun", "Sendong Zhao", "Jianyu Chen", "Haochun Wang", "Bin Qin"], "title": "META-RAG: Meta-Analysis-Inspired Evidence-Re-Ranking Method for Retrieval-Augmented Generation in Evidence-Based Medicine", "comment": null, "summary": "Evidence-based medicine (EBM) holds a crucial role in clinical application.\nGiven suitable medical articles, doctors effectively reduce the incidence of\nmisdiagnoses. Researchers find it efficient to use large language models (LLMs)\ntechniques like RAG for EBM tasks. However, the EBM maintains stringent\nrequirements for evidence, and RAG applications in EBM struggle to efficiently\ndistinguish high-quality evidence. Therefore, inspired by the meta-analysis\nused in EBM, we provide a new method to re-rank and filter the medical\nevidence. This method presents multiple principles to filter the best evidence\nfor LLMs to diagnose. We employ a combination of several EBM methods to emulate\nthe meta-analysis, which includes reliability analysis, heterogeneity analysis,\nand extrapolation analysis. These processes allow the users to retrieve the\nbest medical evidence for the LLMs. Ultimately, we evaluate these high-quality\narticles and show an accuracy improvement of up to 11.4% in our experiments and\nresults. Our method successfully enables RAG to extract higher-quality and more\nreliable evidence from the PubMed dataset. This work can reduce the infusion of\nincorrect knowledge into responses and help users receive more effective\nreplies.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u5143\u5206\u6790\u601d\u60f3\u7684\u91cd\u6392\u548c\u8fc7\u6ee4\u533b\u5b66\u8bc1\u636e\u7684\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u5728\u5faa\u8bc1\u533b\u5b66\uff08EBM\uff09\u4efb\u52a1\u4e2d\u7684\u8bc1\u636e\u8d28\u91cf\uff0c\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u80fd\u663e\u8457\u63d0\u9ad8\u8bca\u65ad\u51c6\u786e\u7387\u3002", "motivation": "\u5faa\u8bc1\u533b\u5b66\uff08EBM\uff09\u5728\u4e34\u5e8a\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u80fd\u51cf\u5c11\u8bef\u8bca\u3002\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u5728EBM\u4efb\u52a1\u4e2d\u6548\u7387\u5f88\u9ad8\uff0c\u4f46EBM\u5bf9\u8bc1\u636e\u8d28\u91cf\u6709\u4e25\u683c\u8981\u6c42\uff0c\u800c\u73b0\u6709RAG\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u7b5b\u9009\u9ad8\u8d28\u91cf\u8bc1\u636e\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u501f\u9274EBM\u5143\u5206\u6790\u601d\u60f3\u7684\u65b0\u65b9\u6cd5\uff0c\u7ed3\u5408\u53ef\u9760\u6027\u5206\u6790\u3001\u5f02\u8d28\u6027\u5206\u6790\u548c\u5916\u63a8\u5206\u6790\uff0c\u5bf9\u533b\u5b66\u8bc1\u636e\u8fdb\u884c\u91cd\u6392\u548c\u8fc7\u6ee4\uff0c\u4e3aLLMs\u63d0\u4f9b\u6700\u4f73\u8bc1\u636e\u3002\u8be5\u65b9\u6cd5\u65e8\u5728\u6a21\u62df\u5143\u5206\u6790\u8fc7\u7a0b\uff0c\u4ee5\u68c0\u7d22\u6700\u4f18\u533b\u5b66\u8bc1\u636e\u3002", "result": "\u5728PubMed\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u63d0\u9ad8LLMs\u5728EBM\u4efb\u52a1\u4e2d\u7684\u51c6\u786e\u6027\uff0c\u6700\u9ad8\u53ef\u63d0\u534711.4%\u3002\u8be5\u65b9\u6cd5\u6210\u529f\u4f7fRAG\u80fd\u591f\u63d0\u53d6\u66f4\u9ad8\u8d28\u91cf\u3001\u66f4\u53ef\u9760\u7684\u8bc1\u636e\uff0c\u51cf\u5c11\u9519\u8bef\u77e5\u8bc6\u7684\u6ce8\u5165\uff0c\u4ece\u800c\u63d0\u4f9b\u66f4\u6709\u6548\u7684\u56de\u590d\u3002", "conclusion": "\u8be5\u7814\u7a76\u6210\u529f\u63d0\u51fa\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u63d0\u5347RAG\u5728EBM\u4efb\u52a1\u4e2d\u7684\u8bc1\u636e\u8d28\u91cf\uff0c\u901a\u8fc7\u6a21\u62df\u5143\u5206\u6790\u8fc7\u7a0b\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8bca\u65ad\u51c6\u786e\u7387\u3002\u672a\u6765\u5de5\u4f5c\u53ef\u8fdb\u4e00\u6b65\u63a2\u7d22\u8be5\u65b9\u6cd5\u7684\u6cdb\u5316\u80fd\u529b\u548c\u5728\u5176\u4ed6\u533b\u5b66\u9886\u57df\u7684\u5e94\u7528\u3002"}}
{"id": "2510.24028", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24028", "abs": "https://arxiv.org/abs/2510.24028", "authors": ["Tingyue Pan", "Mingyue Cheng", "Shilong Zhang", "Zhiding Liu", "Xiaoyu Tao", "Yucong Luo", "Jintao Zhang", "Qi Liu"], "title": "OneCast: Structured Decomposition and Modular Generation for Cross-Domain Time Series Forecasting", "comment": null, "summary": "Cross-domain time series forecasting is a valuable task in various web\napplications. Despite its rapid advancement, achieving effective generalization\nacross heterogeneous time series data remains a significant challenge. Existing\nmethods have made progress by extending single-domain models, yet often fall\nshort when facing domain-specific trend shifts and inconsistent periodic\npatterns. We argue that a key limitation lies in treating temporal series as\nundifferentiated sequence, without explicitly decoupling their inherent\nstructural components. To address this, we propose OneCast, a structured and\nmodular forecasting framework that decomposes time series into seasonal and\ntrend components, each modeled through tailored generative pathways.\nSpecifically, the seasonal component is captured by a lightweight projection\nmodule that reconstructs periodic patterns via interpretable basis functions.\nIn parallel, the trend component is encoded into discrete tokens at segment\nlevel via a semantic-aware tokenizer, and subsequently inferred through a\nmasked discrete diffusion mechanism. The outputs from both branches are\ncombined to produce a final forecast that captures seasonal patterns while\ntracking domain-specific trends. Extensive experiments across eight domains\ndemonstrate that OneCast mostly outperforms state-of-the-art baselines.", "AI": {"tldr": "OneCast\u662f\u4e00\u4e2a\u521b\u65b0\u7684\u8de8\u57df\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u65f6\u95f4\u5e8f\u5217\u5206\u89e3\u4e3a\u5b63\u8282\u6027\u548c\u8d8b\u52bf\u6027\u6210\u5206\uff0c\u5e76\u5206\u522b\u5efa\u6a21\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u9886\u57df\u7279\u5b9a\u8d8b\u52bf\u53d8\u5316\u548c\u4e0d\u4e00\u81f4\u5468\u671f\u6027\u6a21\u5f0f\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cOneCast\u5728\u591a\u4e2a\u9886\u57df\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u8de8\u57df\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\u5728\u5904\u7406\u5f02\u6784\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u65f6\uff0c\u5c24\u5176\u662f\u5728\u9762\u5bf9\u9886\u57df\u7279\u5b9a\u7684\u8d8b\u52bf\u53d8\u5316\u548c\u4e0d\u4e00\u81f4\u7684\u5468\u671f\u6027\u6a21\u5f0f\u65f6\uff0c\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u3002\u5176\u6839\u672c\u539f\u56e0\u5728\u4e8e\u5c06\u65f6\u95f4\u5e8f\u5217\u89c6\u4e3a\u672a\u533a\u5206\u7684\u5e8f\u5217\uff0c\u672a\u80fd\u663e\u5f0f\u5730\u5206\u79bb\u51fa\u5176\u5185\u5728\u7684\u7ed3\u6784\u6210\u5206\u3002", "method": "OneCast\u6846\u67b6\u5c06\u65f6\u95f4\u5e8f\u5217\u5206\u89e3\u4e3a\u5b63\u8282\u6027\u548c\u8d8b\u52bf\u6027\u6210\u5206\u3002\u5b63\u8282\u6027\u6210\u5206\u901a\u8fc7\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u6295\u5f71\u6a21\u5757\uff0c\u5229\u7528\u53ef\u89e3\u91ca\u7684\u57fa\u51fd\u6570\u6765\u91cd\u5efa\u5468\u671f\u6027\u6a21\u5f0f\u3002\u8d8b\u52bf\u6027\u6210\u5206\u5219\u901a\u8fc7\u4e00\u4e2a\u8bed\u4e49\u611f\u77e5\u7684\u5206\u8bcd\u5668\u5728\u5206\u6bb5\u5c42\u9762\u7f16\u7801\u4e3a\u79bb\u6563\u6807\u8bb0\uff0c\u968f\u540e\u901a\u8fc7\u63a9\u7801\u79bb\u6563\u6269\u6563\u673a\u5236\u8fdb\u884c\u63a8\u7406\u3002\u6700\u540e\uff0c\u5c06\u4e24\u4e2a\u5206\u652f\u7684\u8f93\u51fa\u7ed3\u5408\u8d77\u6765\uff0c\u751f\u6210\u5305\u542b\u5b63\u8282\u6027\u6a21\u5f0f\u5e76\u80fd\u8ddf\u8e2a\u9886\u57df\u7279\u5b9a\u8d8b\u52bf\u7684\u9884\u6d4b\u7ed3\u679c\u3002", "result": "\u5728\u516b\u4e2a\u9886\u57df\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cOneCast\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u90fd\u4f18\u4e8e\u73b0\u6709\u7684\u6700\u5148\u8fdb\u57fa\u7ebf\u6a21\u578b\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u8de8\u57df\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4efb\u52a1\u4e0a\u7684\u6709\u6548\u6027\u3002", "conclusion": "OneCast\u901a\u8fc7\u7ed3\u6784\u5316\u548c\u6a21\u5757\u5316\u7684\u65b9\u6cd5\uff0c\u6210\u529f\u5730\u5c06\u65f6\u95f4\u5e8f\u5217\u5206\u89e3\u4e3a\u5b63\u8282\u6027\u548c\u8d8b\u52bf\u6027\u6210\u5206\uff0c\u5e76\u91c7\u7528\u4e0d\u540c\u7684\u751f\u6210\u8def\u5f84\u8fdb\u884c\u5efa\u6a21\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8de8\u57df\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u6cdb\u5316\u96be\u9898\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u53d6\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u3002"}}
{"id": "2510.24020", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24020", "abs": "https://arxiv.org/abs/2510.24020", "authors": ["Hao An", "Yang Xu"], "title": "Teaching LLMs to Abstain via Fine-Grained Semantic Confidence Reward", "comment": "23pages, 4figures", "summary": "Mitigating hallucinations in Large Language Models (LLMs) is critical for\ntheir reliable deployment. Existing methods typically fine-tune LLMs to abstain\nfrom answering questions beyond their knowledge scope. However, these methods\noften rely on coarse-grained signals to guide LLMs to abstain, such as overall\nconfidence or uncertainty scores on multiple sampled answers, which may result\nin an imprecise awareness of the model's own knowledge boundaries. To this end,\nwe propose a novel reinforcement learning framework built on\n$\\textbf{\\underline{Fi}ne-grained \\underline{S}emantic \\underline{Co}nfidence\n\\underline{Re}ward (\\Ours)}$, which guides LLMs to abstain via sample-specific\nconfidence. Specifically, our method operates by sampling multiple candidate\nanswers and conducting semantic clustering, then training the LLM to retain\nanswers within high-confidence clusters and discard those within low-confidence\nones, thereby promoting accurate post-hoc abstention. Additionally, we propose\na new metric for evaluating the reliability of abstention fine-tuning tasks\nmore comprehensively. Our method significantly enhances reliability in both\nin-domain and out-of-distribution benchmarks.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u5e7b\u89c9\u95ee\u9898\u662f\u5176\u53ef\u9760\u90e8\u7f72\u7684\u5173\u952e\u3002\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u901a\u8fc7\u6574\u4f53\u7f6e\u4fe1\u5ea6\u6216\u4e0d\u786e\u5b9a\u6027\u5206\u6570\u6765\u6307\u5bfcLLMs\uff0c\u4f46\u8fd9\u53ef\u80fd\u5bfc\u81f4\u5bf9\u6a21\u578b\u77e5\u8bc6\u8fb9\u754c\u7684\u8ba4\u8bc6\u4e0d\u7cbe\u786e\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u2014\u2014\u7ec6\u7c92\u5ea6\u8bed\u4e49\u7f6e\u4fe1\u5956\u52b1\uff08Ours\uff09\uff0c\u901a\u8fc7\u6837\u672c\u7279\u5b9a\u7684\u7f6e\u4fe1\u5ea6\u6765\u6307\u5bfcLLMs\u8fdb\u884c\u63a8\u65ad\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u91c7\u6837\u591a\u4e2a\u5019\u9009\u7b54\u6848\u5e76\u8fdb\u884c\u8bed\u4e49\u805a\u7c7b\uff0c\u7136\u540e\u8bad\u7ec3LLM\u4fdd\u7559\u9ad8\u7f6e\u4fe1\u5ea6\u805a\u7c7b\u4e2d\u7684\u7b54\u6848\u5e76\u4e22\u5f03\u4f4e\u7f6e\u4fe1\u5ea6\u805a\u7c7b\u4e2d\u7684\u7b54\u6848\uff0c\u4ece\u800c\u5b9e\u73b0\u7cbe\u786e\u7684\u4e8b\u540e\u63a8\u65ad\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8bc4\u4f30\u6307\u6807\u6765\u66f4\u5168\u9762\u5730\u8bc4\u4f30\u63a8\u65ad\u5fae\u8c03\u4efb\u52a1\u7684\u53ef\u9760\u6027\u3002\u8be5\u65b9\u6cd5\u5728\u6a21\u578b\u5185\u548c\u6a21\u578b\u5916\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u90fd\u663e\u8457\u63d0\u9ad8\u4e86\u53ef\u9760\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u751f\u6210\u6587\u672c\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5bb9\u6613\u4ea7\u751f\u201c\u5e7b\u89c9\u201d\uff0c\u5373\u751f\u6210\u4e0d\u51c6\u786e\u6216\u634f\u9020\u7684\u4fe1\u606f\u3002\u8fd9\u963b\u788d\u4e86\u5b83\u4eec\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u53ef\u9760\u5e94\u7528\u3002\u76ee\u524d\u7684\u7f13\u89e3\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u4e8e\u7c97\u7c92\u5ea6\u7684\u4fe1\u53f7\uff0c\u5982\u6574\u4f53\u7f6e\u4fe1\u5ea6\u6216\u5bf9\u591a\u4e2a\u6837\u672c\u7b54\u6848\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u8fd9\u9650\u5236\u4e86\u6a21\u578b\u5bf9\u5176\u77e5\u8bc6\u8fb9\u754c\u7684\u7cbe\u786e\u611f\u77e5\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u7cbe\u7ec6\u7684\u65b9\u6cd5\u6765\u63d0\u9ad8LLMs\u5728\u4f55\u65f6\u5e94\u8be5\u56de\u7b54\u548c\u4f55\u65f6\u5e94\u8be5\u63a8\u65ad\u7684\u51c6\u786e\u6027\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u7ec6\u7c92\u5ea6\u8bed\u4e49\u7f6e\u4fe1\u5956\u52b1\uff08Ours\uff09\u201d\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u4ee5\u4e0b\u6b65\u9aa4\u6307\u5bfcLLMs\u8fdb\u884c\u63a8\u65ad\uff1a1. \u91c7\u6837\u591a\u4e2a\u5019\u9009\u7b54\u6848\u30022. \u5bf9\u8fd9\u4e9b\u5019\u9009\u7b54\u6848\u8fdb\u884c\u8bed\u4e49\u805a\u7c7b\u30023. \u8bad\u7ec3LLM\u4fdd\u7559\u9ad8\u7f6e\u4fe1\u5ea6\u805a\u7c7b\u4e2d\u7684\u7b54\u6848\uff0c\u5e76\u4e22\u5f03\u4f4e\u7f6e\u4fe1\u5ea6\u805a\u7c7b\u4e2d\u7684\u7b54\u6848\u3002\u8fd9\u79cd\u65b9\u6cd5\u80fd\u591f\u5b9e\u73b0\u66f4\u7cbe\u786e\u7684\u4e8b\u540e\u63a8\u65ad\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8005\u8fd8\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u7684\u8bc4\u4f30\u6307\u6807\uff0c\u7528\u4e8e\u66f4\u5168\u9762\u5730\u8861\u91cf\u63a8\u65ad\u5fae\u8c03\u4efb\u52a1\u7684\u53ef\u9760\u6027\u3002", "result": "\u901a\u8fc7\u7ec6\u7c92\u5ea6\u8bed\u4e49\u7f6e\u4fe1\u5956\u52b1\uff08Ours\uff09\u6846\u67b6\uff0c\u8be5\u7814\u7a76\u5728\u6a21\u578b\u5185\uff08in-domain\uff09\u548c\u6a21\u578b\u5916\uff08out-of-distribution\uff09\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5747\u663e\u8457\u63d0\u9ad8\u4e86LLMs\u7684\u53ef\u9760\u6027\u3002\u65b0\u7684\u8bc4\u4f30\u6307\u6807\u4e5f\u4e3a\u8bc4\u4f30\u63a8\u65ad\u5fae\u8c03\u4efb\u52a1\u7684\u6709\u6548\u6027\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u89c6\u89d2\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u7ec6\u7c92\u5ea6\u8bed\u4e49\u7f6e\u4fe1\u5956\u52b1\uff08Ours\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u6837\u672c\u7279\u5b9a\u7684\u7f6e\u4fe1\u5ea6\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u5176\u53ef\u9760\u6027\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u8bed\u4e49\u805a\u7c7b\u548c\u6837\u672c\u7279\u5b9a\u7684\u7f6e\u4fe1\u5ea6\u5956\u52b1\uff0c\u5b9e\u73b0\u4e86\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u7cbe\u786e\u7684\u63a8\u65ad\u3002\u65b0\u7684\u8bc4\u4f30\u6307\u6807\u4e5f\u4e3a\u8be5\u9886\u57df\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u5de5\u5177\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u63a2\u7d22\u8be5\u6846\u67b6\u5728\u66f4\u5e7f\u6cdb\u7684\u5e94\u7528\u573a\u666f\u4e2d\u7684\u6709\u6548\u6027\uff0c\u5e76\u8fdb\u4e00\u6b65\u4f18\u5316\u5176\u6027\u80fd\u3002"}}
{"id": "2510.24085", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24085", "abs": "https://arxiv.org/abs/2510.24085", "authors": ["Md. Shihab Uddin", "Md Nazmus Shakib", "Rahul Bhadani"], "title": "Modeling Electric Vehicle Car-Following Behavior: Classical vs Machine Learning Approach", "comment": null, "summary": "The increasing adoption of electric vehicles (EVs) necessitates an\nunderstanding of their driving behavior to enhance traffic safety and develop\nsmart driving systems. This study compares classical and machine learning\nmodels for EV car following behavior. Classical models include the Intelligent\nDriver Model (IDM), Optimum Velocity Model (OVM), Optimal Velocity Relative\nVelocity (OVRV), and a simplified CACC model, while the machine learning\napproach employs a Random Forest Regressor. Using a real world dataset of an EV\nfollowing an internal combustion engine (ICE) vehicle under varied driving\nconditions, we calibrated classical model parameters by minimizing the RMSE\nbetween predictions and real data. The Random Forest model predicts\nacceleration using spacing, speed, and gap type as inputs. Results demonstrate\nthe Random Forest's superior accuracy, achieving RMSEs of 0.0046 (medium gap),\n0.0016 (long gap), and 0.0025 (extra long gap). Among physics based models,\nCACC performed best, with an RMSE of 2.67 for long gaps. These findings\nhighlight the machine learning model's performance across all scenarios. Such\nmodels are valuable for simulating EV behavior and analyzing mixed autonomy\ntraffic dynamics in EV integrated environments.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86\u7ecf\u5178\u6a21\u578b\u548c\u968f\u673a\u68ee\u6797\u56de\u5f52\u6a21\u578b\u5728\u7535\u52a8\u6c7d\u8f66\uff08EV\uff09\u8ddf\u8f66\u884c\u4e3a\u6a21\u62df\u65b9\u9762\u7684\u6027\u80fd\u3002\u7ed3\u679c\u8868\u660e\uff0c\u968f\u673a\u68ee\u6797\u6a21\u578b\u5728\u6240\u6709\u573a\u666f\u4e0b\u5747\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u51c6\u786e\u6027\uff0c\u5176\u5747\u65b9\u6839\u8bef\u5dee\uff08RMSE\uff09\u663e\u8457\u4f4e\u4e8e\u7ecf\u5178\u6a21\u578b\uff0c\u7279\u522b\u662f\u5728\u4e2d\u3001\u957f\u3001\u8d85\u957f\u95f4\u9699\u6761\u4ef6\u4e0b\u3002", "motivation": "\u968f\u7740\u7535\u52a8\u6c7d\u8f66\uff08EV\uff09\u7684\u65e5\u76ca\u666e\u53ca\uff0c\u7406\u89e3\u5176\u9a7e\u9a76\u884c\u4e3a\u5bf9\u4e8e\u63d0\u5347\u4ea4\u901a\u5b89\u5168\u548c\u5f00\u53d1\u667a\u80fd\u9a7e\u9a76\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\u3002\u672c\u7814\u7a76\u65e8\u5728\u5bf9\u6bd4\u5206\u6790\u7ecf\u5178\u6a21\u578b\u548c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u6a21\u62dfEV\u8ddf\u8f66\u884c\u4e3a\u65b9\u9762\u7684\u8868\u73b0\uff0c\u4e3a\u76f8\u5173\u9886\u57df\u7684\u7814\u7a76\u63d0\u4f9b\u53c2\u8003\u3002", "method": "\u672c\u7814\u7a76\u5bf9\u6bd4\u4e86\u5305\u62ecIDM\u3001OVM\u3001OVRV\u548c\u7b80\u5316CACC\u6a21\u578b\u5728\u5185\u7684\u7ecf\u5178\u6a21\u578b\uff0c\u4ee5\u53ca\u91c7\u7528\u968f\u673a\u68ee\u6797\u56de\u5f52\uff08Random Forest Regressor\uff09\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3002\u7814\u7a76\u4f7f\u7528\u4e86\u771f\u5b9e\u4e16\u754c\u7684EV\u8ddf\u968f\u5185\u71c3\u673a\uff08ICE\uff09\u8f66\u8f86\u5728\u4e0d\u540c\u9a7e\u9a76\u6761\u4ef6\u4e0b\u7684\u6570\u636e\u96c6\u3002\u7ecf\u5178\u6a21\u578b\u7684\u53c2\u6570\u901a\u8fc7\u6700\u5c0f\u5316\u9884\u6d4b\u503c\u4e0e\u771f\u5b9e\u6570\u636e\u4e4b\u95f4\u7684\u5747\u65b9\u6839\u8bef\u5dee\uff08RMSE\uff09\u8fdb\u884c\u6821\u51c6\u3002\u968f\u673a\u68ee\u6797\u6a21\u578b\u4ee5\u95f4\u9699\u3001\u901f\u5ea6\u548c\u95f4\u9699\u7c7b\u578b\u4f5c\u4e3a\u8f93\u5165\uff0c\u9884\u6d4b\u52a0\u901f\u5ea6\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0c\u968f\u673a\u68ee\u6797\u6a21\u578b\u5728\u6a21\u62dfEV\u8ddf\u8f66\u884c\u4e3a\u65b9\u9762\u5177\u6709\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u3002\u5728\u4e0d\u540c\u95f4\u9699\u6761\u4ef6\u4e0b\uff0c\u5176RMSE\u503c\u5206\u522b\u4e3a\uff1a\u4e2d\u7b49\u95f4\u96990.0046\uff0c\u957f\u95f4\u96990.0016\uff0c\u8d85\u957f\u95f4\u96990.0025\u3002\u5728\u7ecf\u5178\u6a21\u578b\u4e2d\uff0cCACC\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0c\u5728\u957f\u95f4\u9699\u6761\u4ef6\u4e0b\u7684RMSE\u4e3a2.67\u3002\u603b\u4f53\u800c\u8a00\uff0c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u6240\u6709\u573a\u666f\u4e0b\u5747\u4f18\u4e8e\u7ecf\u5178\u6a21\u578b\u3002", "conclusion": "\u672c\u7814\u7a76\u8bc1\u5b9e\u4e86\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff08\u7279\u522b\u662f\u968f\u673a\u68ee\u6797\u56de\u5f52\uff09\u5728\u6a21\u62df\u7535\u52a8\u6c7d\u8f66\u8ddf\u8f66\u884c\u4e3a\u65b9\u9762\u7684\u4f18\u8d8a\u6027\u80fd\u3002\u8fd9\u4e9b\u6a21\u578b\u5728\u5404\u79cd\u9a7e\u9a76\u6761\u4ef6\u4e0b\u5747\u5c55\u73b0\u51fa\u66f4\u9ad8\u7684\u51c6\u786e\u6027\uff0c\u4e3aEV\u884c\u4e3a\u6a21\u62df\u548c\u672a\u6765\u5728\u96c6\u6210EV\u7684\u73af\u5883\u4e2d\u5206\u6790\u6df7\u5408\u4ea4\u901a\u6d41\u7684\u52a8\u6001\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u5de5\u5177\u3002\u672a\u6765\u7684\u7814\u7a76\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63a2\u7d22\u66f4\u590d\u6742\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u6216\u96c6\u6210\u5b66\u4e60\u65b9\u6cd5\uff0c\u4ee5\u5e94\u5bf9\u66f4\u5e7f\u6cdb\u7684\u4ea4\u901a\u573a\u666f\u548c\u66f4\u7cbe\u7ec6\u5316\u7684\u9a7e\u9a76\u884c\u4e3a\u5206\u6790\u3002"}}
{"id": "2510.24021", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24021", "abs": "https://arxiv.org/abs/2510.24021", "authors": ["Haiduo Huang", "Jiangcheng Song", "Yadong Zhang", "Pengju Ren"], "title": "SpecKD: Speculative Decoding for Effective Knowledge Distillation of LLMs", "comment": null, "summary": "Knowledge Distillation (KD) has become a cornerstone technique for\ncompressing Large Language Models (LLMs) into smaller, more efficient student\nmodels. However, conventional KD approaches typically apply the distillation\nloss uniformly across all tokens, regardless of the teacher's confidence. This\nindiscriminate mimicry can introduce noise, as the student is forced to learn\nfrom the teacher's uncertain or high-entropy predictions, which may ultimately\nharm student performance-especially when the teacher is much larger and more\npowerful. To address this, we propose Speculative Knowledge Distillation\n(SpecKD), a novel, plug-and-play framework that introduces a dynamic,\ntoken-level gating mechanism inspired by the \"propose-and-verify\" paradigm of\nspeculative decoding. At each step, the student's token proposal is verified\nagainst the teacher's distribution; the distillation loss is selectively\napplied only to \"accepted\" tokens, while \"rejected\" tokens are masked out.\nExtensive experiments on diverse text generation tasks show that SpecKD\nconsistently and significantly outperforms strong KD baselines, leading to more\nstable training and more capable student models, and achieving state-of-the-art\nresults.", "AI": {"tldr": "\u77e5\u8bc6\u84b8\u998f\uff08KD\uff09\u662f\u538b\u7f29\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5173\u952e\u6280\u672f\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u5bf9\u6240\u6709 token \u7edf\u4e00\u5e94\u7528\u84b8\u998f\u635f\u5931\uff0c\u53ef\u80fd\u5f15\u5165\u566a\u58f0\u5e76\u635f\u5bb3\u5b66\u751f\u6a21\u578b\u6027\u80fd\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u63a8\u6d4b\u6027\u77e5\u8bc6\u84b8\u998f\u201d\uff08SpecKD\uff09\u7684\u65b0\u578b\u5373\u63d2\u5373\u7528\u6846\u67b6\uff0c\u5f15\u5165\u4e86\u52a8\u6001\u7684\u3001 token \u7ea7\u522b\u7684\u95e8\u63a7\u673a\u5236\u3002\u8be5\u673a\u5236\u501f\u9274\u4e86\u63a8\u6d4b\u89e3\u7801\u7684\u201c\u63d0\u51fa-\u9a8c\u8bc1\u201d\u8303\u5f0f\uff0c\u4ec5\u5bf9\u201c\u63a5\u53d7\u201d\u7684 token \u5e94\u7528\u84b8\u998f\u635f\u5931\uff0c\u800c\u201c\u62d2\u7edd\u201d\u7684 token \u5219\u88ab\u5c4f\u853d\u3002\u5b9e\u9a8c\u8bc1\u660e SpecKD \u5728\u5404\u79cd\u6587\u672c\u751f\u6210\u4efb\u52a1\u4e0a\u5747\u663e\u8457\u4f18\u4e8e\u73b0\u6709 KD \u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e86\u8bad\u7ec3\u7a33\u5b9a\u6027\uff0c\u4f7f\u5b66\u751f\u6a21\u578b\u66f4\u5f3a\u5927\uff0c\u5e76\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u77e5\u8bc6\u84b8\u998f\uff08KD\uff09\u65b9\u6cd5\u5728\u538b\u7f29\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u65f6\uff0c\u901a\u5e38\u4f1a\u5bf9\u6240\u6709 token \u7edf\u4e00\u5e94\u7528\u84b8\u998f\u635f\u5931\uff0c\u800c\u4e0d\u8003\u8651\u6559\u5e08\u6a21\u578b\u5bf9\u4e0d\u540c token \u7684\u7f6e\u4fe1\u5ea6\u3002\u8fd9\u79cd\u505a\u6cd5\u53ef\u80fd\u5bfc\u81f4\u5b66\u751f\u6a21\u578b\u5b66\u4e60\u6559\u5e08\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\u6216\u9ad8\u71b5\u9884\u6d4b\uff0c\u5f15\u5165\u566a\u58f0\uff0c\u4ece\u800c\u635f\u5bb3\u5b66\u751f\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u6559\u5e08\u6a21\u578b\u8fdc\u5927\u4e8e\u5b66\u751f\u6a21\u578b\u65f6\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u667a\u80fd\u7684\u84b8\u998f\u65b9\u6cd5\uff0c\u80fd\u591f\u533a\u5206 token \u7684\u91cd\u8981\u6027\uff0c\u9009\u62e9\u6027\u5730\u5e94\u7528\u84b8\u998f\u635f\u5931\uff0c\u4ee5\u63d0\u9ad8\u84b8\u998f\u6548\u7387\u548c\u5b66\u751f\u6a21\u578b\u7684\u6027\u80fd\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u63a8\u6d4b\u6027\u77e5\u8bc6\u84b8\u998f\u201d\uff08SpecKD\uff09\u7684\u6846\u67b6\u3002\u8be5\u6846\u67b6\u662f\u4e00\u4e2a\u5373\u63d2\u5373\u7528\u7684\u6a21\u5757\uff0c\u5f15\u5165\u4e86\u4e00\u4e2a\u52a8\u6001\u7684\u3001 token \u7ea7\u522b\u7684\u95e8\u63a7\u673a\u5236\u3002\u8be5\u673a\u5236\u53d7\u5230\u63a8\u6d4b\u89e3\u7801\u4e2d\u201c\u63d0\u51fa-\u9a8c\u8bc1\u201d\u8303\u5f0f\u7684\u542f\u53d1\u3002\u5728\u6bcf\u4e2a\u6b65\u9aa4\u4e2d\uff0c\u5b66\u751f\u6a21\u578b\u63d0\u51fa\u7684 token \u4f1a\u4e0e\u6559\u5e08\u6a21\u578b\u7684\u5206\u5e03\u8fdb\u884c\u6bd4\u8f83\u548c\u9a8c\u8bc1\u3002\u53ea\u6709\u5f53\u6559\u5e08\u6a21\u578b\u7684\u9884\u6d4b\u88ab\u8ba4\u4e3a\u662f\u201c\u63a5\u53d7\u201d\u65f6\uff0c\u624d\u4f1a\u5bf9\u8be5 token \u5e94\u7528\u84b8\u998f\u635f\u5931\uff1b\u53cd\u4e4b\uff0c\u88ab\u201c\u62d2\u7edd\u201d\u7684 token \u5c06\u88ab\u5c4f\u853d\uff0c\u4e0d\u7528\u4e8e\u84b8\u998f\u3002\u8fd9\u79cd\u9009\u62e9\u6027\u84b8\u998f\u6709\u52a9\u4e8e\u5b66\u751f\u6a21\u578b\u4e13\u6ce8\u4e8e\u5b66\u4e60\u6559\u5e08\u6a21\u578b\u771f\u6b63\u786e\u4fe1\u7684\u90e8\u5206\u3002\u5b9e\u9a8c\u5728\u591a\u79cd\u6587\u672c\u751f\u6210\u4efb\u52a1\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u8bc4\u4f30\uff0c\u5e76\u4e0e\u5f3a\u57fa\u7ebf KD \u65b9\u6cd5\u8fdb\u884c\u4e86\u6bd4\u8f83\uff0c\u4ee5\u9a8c\u8bc1 SpecKD \u7684\u6709\u6548\u6027\u3002", "result": "\u5728\u591a\u79cd\u6587\u672c\u751f\u6210\u4efb\u52a1\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cSpecKD \u6301\u7eed\u4e14\u663e\u8457\u5730\u4f18\u4e8e\u5f3a\u5927\u7684\u77e5\u8bc6\u84b8\u998f\uff08KD\uff09\u57fa\u7ebf\u3002\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u5b66\u751f\u6a21\u578b\u7684\u6027\u80fd\uff0c\u8fd8\u5e26\u6765\u4e86\u66f4\u7a33\u5b9a\u7684\u8bad\u7ec3\u8fc7\u7a0b\u3002SpecKD \u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff0c\u8bc1\u660e\u4e86\u5176\u5728 LLM \u538b\u7f29\u548c\u5b66\u751f\u6a21\u578b\u80fd\u529b\u63d0\u5347\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u63a8\u6d4b\u6027\u77e5\u8bc6\u84b8\u998f\uff08SpecKD\uff09\u6846\u67b6\u901a\u8fc7\u5f15\u5165 token \u7ea7\u522b\u7684\u52a8\u6001\u95e8\u63a7\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf KD \u65b9\u6cd5\u4e2d\u4e0d\u533a\u5206 token \u7f6e\u4fe1\u5ea6\u7684\u95ee\u9898\u3002SpecKD \u5b9e\u73b0\u4e86\u9009\u62e9\u6027\u84b8\u998f\uff0c\u4ec5\u5728\u6559\u5e08\u6a21\u578b\u9ad8\u5ea6\u7f6e\u4fe1\u65f6\u624d\u5e94\u7528\u84b8\u998f\u635f\u5931\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u84b8\u998f\u6548\u7387\uff0c\u589e\u5f3a\u4e86\u5b66\u751f\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5e76\u4f18\u5316\u4e86\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cSpecKD \u5728\u5404\u9879\u6587\u672c\u751f\u6210\u4efb\u52a1\u4e0a\u5747\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6210\u679c\uff0c\u4e3a LLM \u7684\u9ad8\u6548\u538b\u7f29\u63d0\u4f9b\u4e86\u4e00\u79cd\u521b\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63a2\u7d22\u8be5\u673a\u5236\u5728\u4e0d\u540c\u6a21\u578b\u67b6\u6784\u548c\u4efb\u52a1\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4ee5\u53ca\u4f18\u5316\u95e8\u63a7\u673a\u5236\u7684\u53c2\u6570\u548c\u7b56\u7565\u3002"}}
{"id": "2510.24115", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24115", "abs": "https://arxiv.org/abs/2510.24115", "authors": ["Sandeep Vissapragada", "Vikrant Sahu", "Gagan Raj Gupta", "Vandita Singh"], "title": "HistoLens: An Interactive XAI Toolkit for Verifying and Mitigating Flaws in Vision-Language Models for Histopathology", "comment": null, "summary": "For doctors to truly trust artificial intelligence, it can't be a black box.\nThey need to understand its reasoning, almost as if they were consulting a\ncolleague. We created HistoLens1 to be that transparent, collaborative partner.\nIt allows a pathologist to simply ask a question in plain English about a\ntissue slide--just as they would ask a trainee. Our system intelligently\ntranslates this question into a precise query for its AI engine, which then\nprovides a clear, structured report. But it doesn't stop there. If a doctor\never asks, \"Why?\", HistoLens can instantly provide a 'visual proof' for any\nfinding--a heatmap that points to the exact cells and regions the AI used for\nits analysis. We've also ensured the AI focuses only on the patient's tissue,\njust like a trained pathologist would, by teaching it to ignore distracting\nbackground noise. The result is a workflow where the pathologist remains the\nexpert in charge, using a trustworthy AI assistant to verify their insights and\nmake faster, more confident diagnoses.", "AI": {"tldr": "HistoLens\u662f\u4e00\u4e2a\u900f\u660e\u7684\u3001\u53ef\u89e3\u91ca\u7684\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\uff0c\u5b83\u5141\u8bb8\u75c5\u7406\u5b66\u5bb6\u7528\u81ea\u7136\u8bed\u8a00\u63d0\u95ee\u5173\u4e8e\u7ec4\u7ec7\u5207\u7247\u7684\u95ee\u9898\uff0c\u5e76\u83b7\u5f97\u7ed3\u6784\u5316\u7684\u62a5\u544a\u548c\u53ef\u89c6\u5316\u7684\u8bc1\u636e\uff0c\u4ece\u800c\u589e\u5f3a\u4e86\u75c5\u7406\u5b66\u5bb6\u7684\u8bca\u65ad\u4fe1\u5fc3\u548c\u6548\u7387\u3002", "motivation": "\u76ee\u524d\u7684AI\u5728\u533b\u5b66\u8bca\u65ad\u9886\u57df\u88ab\u89c6\u4e3a\u201c\u9ed1\u7bb1\u201d\uff0c\u7f3a\u4e4f\u900f\u660e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u8fd9\u963b\u788d\u4e86\u533b\u751f\u5bf9\u5176\u7684\u4fe1\u4efb\u548c\u5e7f\u6cdb\u5e94\u7528\u3002\u75c5\u7406\u5b66\u5bb6\u9700\u8981\u4e00\u4e2a\u80fd\u591f\u50cf\u540c\u4e8b\u4e00\u6837\u89e3\u91ca\u5176\u63a8\u7406\u8fc7\u7a0b\u7684AI\u5de5\u5177\uff0c\u4ee5\u8f85\u52a9\u8bca\u65ad\u51b3\u7b56\u3002", "method": "HistoLens\u7cfb\u7edf\u5141\u8bb8\u75c5\u7406\u5b66\u5bb6\u7528\u81ea\u7136\u8bed\u8a00\u63d0\u95ee\uff0c\u7cfb\u7edf\u5c06\u5176\u8f6c\u5316\u4e3a\u5bf9AI\u5f15\u64ce\u7684\u7cbe\u786e\u67e5\u8be2\u3002AI\u5f15\u64ce\u751f\u6210\u7ed3\u6784\u5316\u62a5\u544a\uff0c\u5e76\u80fd\u63d0\u4f9b\u201c\u89c6\u89c9\u8bc1\u636e\u201d\uff08\u5982\u70ed\u56fe\uff09\u6765\u89e3\u91ca\u5176\u53d1\u73b0\u3002\u7cfb\u7edf\u8fd8\u88ab\u8bad\u7ec3\u4ee5\u5ffd\u7565\u80cc\u666f\u566a\u97f3\uff0c\u4e13\u6ce8\u4e8e\u60a3\u8005\u7ec4\u7ec7\u3002", "result": "HistoLens\u63d0\u4f9b\u4e86\u4e00\u4e2a\u589e\u5f3a\u75c5\u7406\u5b66\u5bb6\u80fd\u529b\u7684\u5de5\u4f5c\u6d41\u7a0b\uff0c\u4f7f\u4ed6\u4eec\u80fd\u591f\u83b7\u5f97\u53ef\u4fe1\u8d56\u7684AI\u52a9\u624b\uff0c\u4ee5\u9a8c\u8bc1\u89c1\u89e3\uff0c\u505a\u51fa\u66f4\u5feb\u3001\u66f4\u81ea\u4fe1\u7684\u8bca\u65ad\u3002", "conclusion": "HistoLens\u901a\u8fc7\u63d0\u4f9b\u900f\u660e\u5ea6\u3001\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u89c6\u5316\u8bc1\u636e\uff0c\u89e3\u51b3\u4e86AI\u5728\u533b\u5b66\u8bca\u65ad\u4e2d\u7684\u4fe1\u4efb\u95ee\u9898\uff0c\u4f7f\u75c5\u7406\u5b66\u5bb6\u80fd\u591f\u66f4\u6709\u6548\u5730\u5229\u7528AI\u8f85\u52a9\u8bca\u65ad\u3002"}}
{"id": "2510.24023", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24023", "abs": "https://arxiv.org/abs/2510.24023", "authors": ["Saujas Vaduguru", "Yilun Hua", "Yoav Artzi", "Daniel Fried"], "title": "Success and Cost Elicit Convention Formation for Efficient Communication", "comment": null, "summary": "Humans leverage shared conversational context to become increasingly\nsuccessful and efficient at communicating over time. One manifestation of this\nis the formation of ad hoc linguistic conventions, which allow people to\ncoordinate on short, less costly utterances that are understood using shared\nconversational context. We present a method to train large multimodal models to\nform conventions, enabling efficient communication. Our approach uses simulated\nreference games between models, and requires no additional human-produced data.\nIn repeated reference games involving photographs and tangram images, our\nmethod enables models to communicate efficiently with people: reducing the\nmessage length by up to 41% while increasing success by 15% over the course of\nthe interaction. Human listeners respond faster when interacting with our model\nthat forms conventions. We also show that training based on success or cost\nalone is insufficient - both are necessary to elicit convention formation.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.24145", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24145", "abs": "https://arxiv.org/abs/2510.24145", "authors": ["Yu Luo", "Jiamin Jiang", "Jingfei Feng", "Lei Tao", "Qingliang Zhang", "Xidao Wen", "Yongqian Sun", "Shenglin Zhang", "Jielong Huang", "Nan Qi", "Dan Pei"], "title": "From Observability Data to Diagnosis: An Evolving Multi-agent System for Incident Management in Cloud Systems", "comment": null, "summary": "Incident management (IM) is central to the reliability of large-scale cloud\nsystems. Yet manual IM, where on-call engineers examine metrics, logs, and\ntraces is labor-intensive and error-prone in the face of massive and\nheterogeneous observability data. Existing automated IM approaches often\nstruggle to generalize across systems, provide limited interpretability, and\nincur high deployment costs, which hinders adoption in practice. In this paper,\nwe present OpsAgent, a lightweight, self-evolving multi-agent system for IM\nthat employs a training-free data processor to convert heterogeneous\nobservability data into structured textual descriptions, along with a\nmulti-agent collaboration framework that makes diagnostic inference transparent\nand auditable. To support continual capability growth, OpsAgent also introduces\na dual self-evolution mechanism that integrates internal model updates with\nexternal experience accumulation, thereby closing the deployment loop.\nComprehensive experiments on the OPENRCA benchmark demonstrate state-of-the-art\nperformance and show that OpsAgent is generalizable, interpretable,\ncost-efficient, and self-evolving, making it a practically deployable and\nsustainable solution for long-term operation in real-world cloud systems.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.24051", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24051", "abs": "https://arxiv.org/abs/2510.24051", "authors": ["In Gim", "Zhiyao Ma", "Seung-seob Lee", "Lin Zhong"], "title": "Pie: A Programmable Serving System for Emerging LLM Applications", "comment": "SOSP 2025. Source code available at\n  https://github.com/pie-project/pie", "summary": "Emerging large language model (LLM) applications involve diverse reasoning\nstrategies and agentic workflows, straining the capabilities of existing\nserving systems built on a monolithic token generation loop. This paper\nintroduces Pie, a programmable LLM serving system designed for flexibility and\nefficiency. Pie decomposes the traditional generation loop into fine-grained\nservice handlers exposed via an API and delegates control of the generation\nprocess to user-provided programs, called inferlets. This enables applications\nto implement new KV cache strategies, bespoke generation logic, and seamlessly\nintegrate computation and I/O-entirely within the application, without\nrequiring modifications to the serving system. Pie executes inferlets using\nWebAssembly, benefiting from its lightweight sandboxing. Our evaluation shows\nPie matches state-of-the-art performance on standard tasks (3-12% latency\noverhead) while significantly improving latency and throughput (1.3x-3.4x\nhigher) on agentic workflows by enabling application-specific optimizations.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.24151", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24151", "abs": "https://arxiv.org/abs/2510.24151", "authors": ["Bingsen Qiu", "Zijian Liu", "Xiao Liu", "Haoshen Yang", "Zeren Gao", "Bingjie Wang", "Feier Zhang", "Yixuan Qin", "Chunyan Li"], "title": "BMGQ: A Bottom-up Method for Generating Complex Multi-hop Reasoning Questions from Semi-structured Data", "comment": null, "summary": "Building training-ready multi-hop question answering (QA) datasets that truly\nstress a model's retrieval and reasoning abilities remains highly challenging\nrecently. While there have been a few recent evaluation datasets that capture\nthe characteristics of hard-to-search but easy-to-verify problems -- requiring\nthe integration of ambiguous, indirect, and cross-domain cues -- these data\nresources remain scarce and are mostly designed for evaluation, making them\nunsuitable for supervised fine-tuning (SFT) or reinforcement learning (RL).\nMeanwhile, manually curating non-trivially retrievable questions -- where\nanswers cannot be found through a single direct query but instead require\nmulti-hop reasoning over oblique and loosely connected evidence -- incurs\nprohibitive human costs and fails to scale, creating a critical data bottleneck\nfor training high-capability retrieval-and-reasoning agents.\n  To address this, we present an automated framework for generating\nhigh-difficulty, training-ready multi-hop questions from semi-structured\nknowledge sources. The system (i) grows diverse, logically labeled evidence\nclusters through Natural Language Inference (NLI)-based relation typing and\ndiversity-aware expansion; (ii) applies reverse question construction to\ncompose oblique cues so that isolated signals are underinformative but their\ncombination uniquely identifies the target entity; and (iii) enforces quality\nwith a two-step evaluation pipeline that combines multi-model consensus\nfiltering with structured constraint decomposition and evidence-based matching.\nThe result is a scalable process that yields complex, retrieval-resistant yet\nverifiable questions suitable for SFT/RL training as well as challenging\nevaluation, substantially reducing human curation effort while preserving the\ndifficulty profile of strong evaluation benchmarks.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.24073", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24073", "abs": "https://arxiv.org/abs/2510.24073", "authors": ["Xinwei Wu", "Heng Liu", "Jiang Zhou", "Xiaohu Zhao", "Linlong Xu", "Longyue Wang", "Weihua Luo", "Kaifu Zhang"], "title": "Challenging Multilingual LLMs: A New Taxonomy and Benchmark for Unraveling Hallucination in Translation", "comment": null, "summary": "Large Language Models (LLMs) have advanced machine translation but remain\nvulnerable to hallucinations. Unfortunately, existing MT benchmarks are not\ncapable of exposing failures in multilingual LLMs. To disclose hallucination in\nmultilingual LLMs, we introduce a diagnostic framework with a taxonomy that\nseparates Instruction Detachment from Source Detachment. Guided by this\ntaxonomy, we create HalloMTBench, a multilingual, human-verified benchmark\nacross 11 English-to-X directions. We employed 4 frontier LLMs to generate\ncandidates and scrutinize these candidates with an ensemble of LLM judges, and\nexpert validation. In this way, we curate 5,435 high-quality instances. We have\nevaluated 17 LLMs on HalloMTBench. Results reveal distinct ``hallucination\ntriggers'' -- unique failure patterns reflecting model scale, source length\nsensitivity, linguistic biases, and Reinforcement-Learning (RL) amplified\nlanguage mixing. HalloMTBench offers a forward-looking testbed for diagnosing\nLLM translation failures. HalloMTBench is available in\nhttps://huggingface.co/collections/AIDC-AI/marco-mt.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.24161", "categories": ["cs.AI", "cs.MM", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.24161", "abs": "https://arxiv.org/abs/2510.24161", "authors": ["Wentao Tan", "Bowen Wang", "Heng Zhi", "Chenyu Liu", "Zhe Li", "Jian Liu", "Zengrong Lin", "Yukun Dai", "Yipeng Chen", "Wenjie Yang", "Enci Xie", "Hao Xue", "Baixu Ji", "Chen Xu", "Zhibin Wang", "Tianshi Wang", "Lei Zhu", "Heng Tao Shen"], "title": "BLM$_1$: A Boundless Large Model for Cross-Space, Cross-Task, and Cross-Embodiment Learning", "comment": null, "summary": "Multimodal large language models (MLLMs) have advanced vision-language\nreasoning and are increasingly deployed in embodied agents. However,\nsignificant limitations remain: MLLMs generalize poorly across digital-physical\nspaces and embodiments; vision-language-action models (VLAs) produce low-level\nactions yet lack robust high-level embodied reasoning; and most embodied large\nlanguage models (ELLMs) are constrained to digital-space with poor\ngeneralization to the physical world. Thus, unified models that operate\nseamlessly across digital and physical spaces while generalizing across\nembodiments and tasks remain absent. We introduce the \\textbf{Boundless Large\nModel (BLM$_1$)}, a multimodal spatial foundation model that preserves\ninstruction following and reasoning, incorporates embodied knowledge, and\nsupports robust cross-embodiment control. BLM$_1$ integrates three key\ncapabilities -- \\textit{cross-space transfer, cross-task learning, and\ncross-embodiment generalization} -- via a two-stage training paradigm. Stage I\ninjects embodied knowledge into the MLLM through curated digital corpora while\nmaintaining language competence. Stage II trains a policy module through an\nintent-bridging interface that extracts high-level semantics from the MLLM to\nguide control, without fine-tuning the MLLM backbone. This process is supported\nby a self-collected cross-embodiment demonstration suite spanning four robot\nembodiments and six progressively challenging tasks. Evaluations across digital\nand physical benchmarks show that a single BLM$_1$ instance outperforms four\nmodel families -- MLLMs, ELLMs, VLAs, and GMLMs -- achieving\n$\\sim\\!\\textbf{6%}$ gains in digital tasks and $\\sim\\!\\textbf{3%}$ in physical\ntasks.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.24081", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24081", "abs": "https://arxiv.org/abs/2510.24081", "authors": ["Tyler A. Chang", "Catherine Arnett", "Abdelrahman Eldesokey", "Abdelrahman Sadallah", "Abeer Kashar", "Abolade Daud", "Abosede Grace Olanihun", "Adamu Labaran Mohammed", "Adeyemi Praise", "Adhikarinayum Meerajita Sharma", "Aditi Gupta", "Afitab Iyigun", "Afonso Simpl\u00edcio", "Ahmed Essouaied", "Aicha Chorana", "Akhil Eppa", "Akintunde Oladipo", "Akshay Ramesh", "Aleksei Dorkin", "Alfred Malengo Kondoro", "Alham Fikri Aji", "Ali Eren \u00c7etinta\u015f", "Allan Hanbury", "Alou Dembele", "Alp Niksarli", "\u00c1lvaro Arroyo", "Amin Bajand", "Amol Khanna", "Ana Chkhaidze", "Ana Condez", "Andiswa Mkhonto", "Andrew Hoblitzell", "Andrew Tran", "Angelos Poulis", "Anirban Majumder", "Anna Vacalopoulou", "Annette Kuuipolani Kanahele Wong", "Annika Simonsen", "Anton Kovalev", "Ashvanth. S", "Ayodeji Joseph Lana", "Barkin Kinay", "Bashar Alhafni", "Benedict Cibalinda Busole", "Bernard Ghanem", "Bharti Nathani", "Biljana Stojanovska \u0110uri\u0107", "Bola Agbonile", "Bragi Bergsson", "Bruce Torres Fischer", "Burak Tutar", "Burcu Alaku\u015f \u00c7\u0131nar", "Cade J. Kanoniakapueo Kane", "Can Udomcharoenchaikit", "Catherine Arnett", "Chadi Helwe", "Chaithra Reddy Nerella", "Chen Cecilia Liu", "Chiamaka Glory Nwokolo", "Cristina Espa\u00f1a-Bonet", "Cynthia Amol", "DaeYeop Lee", "Dana Arad", "Daniil Dzenhaliou", "Daria Pugacheva", "Dasol Choi", "Daud Abolade", "David Liu", "David Semedo", "Deborah Popoola", "Deividas Mataciunas", "Delphine Nyaboke", "Dhyuthy Krishna Kumar", "Diogo Gl\u00f3ria-Silva", "Diogo Tavares", "Divyanshu Goyal", "DongGeon Lee", "Ebele Nwamaka Anajemba", "Egonu Ngozi Grace", "Elena Mickel", "Elena Tutubalina", "Elias Herranen", "Emile Anand", "Emmanuel Habumuremyi", "Emuobonuvie Maria Ajiboye", "Eryawan Presma Yulianrifat", "Esther Adenuga", "Ewa Rudnicka", "Faith Olabisi Itiola", "Faran Taimoor Butt", "Fathima Thekkekara", "Fatima Haouari", "Filbert Aurelian Tjiaranata", "Firas Laakom", "Francesca Grasso", "Francesco Orabona", "Francesco Periti", "Gbenga Kayode Solomon", "Gia Nghia Ngo", "Gloria Udhehdhe-oze", "Gon\u00e7alo Martins", "Gopi Naga Sai Ram Challagolla", "Guijin Son", "Gulnaz Abdykadyrova", "Hafsteinn Einarsson", "Hai Hu", "Hamidreza Saffari", "Hamza Zaidi", "Haopeng Zhang", "Harethah Abu Shairah", "Harry Vuong", "Hele-Andra Kuulmets", "Houda Bouamor", "Hwanjo Yu", "Iben Nyholm Debess", "\u0130brahim Ethem Deveci", "Ikhlasul Akmal Hanif", "Ikhyun Cho", "In\u00eas Calvo", "In\u00eas Vieira", "Isaac Manzi", "Ismail Daud", "Itay Itzhak", "Iuliia", "Alekseenko", "Ivan Belashkin", "Ivan Spada", "Ivan Zhelyazkov", "Jacob Brinton", "Jafar Isbarov", "Jaka \u010cibej", "Jan \u010cuhel", "Jan Koco\u0144", "Jauza Akbar Krito", "Jebish Purbey", "Jennifer Mickel", "Jennifer Za", "Jenny Kunz", "Jihae Jeong", "Jimena Tena D\u00e1valos", "Jinu Lee", "Jo\u00e3o Magalh\u00e3es", "John Yi", "Jongin Kim", "Joseph Chataignon", "Joseph Marvin Imperial", "Jubeerathan Thevakumar", "Judith Land", "Junchen Jiang", "Jungwhan Kim", "Kairit Sirts", "Kamesh R", "Kamesh V", "Kanda Patrick Tshinu", "K\u00e4triin Kukk", "Kaustubh Ponkshe", "Kavsar Huseynova", "Ke He", "Kelly Buchanan", "Kengatharaiyer Sarveswaran", "Kerem Zaman", "Khalil Mrini", "Kian Kyars", "Krister Kruusmaa", "Kusum Chouhan", "Lainitha Krishnakumar", "Laura Castro S\u00e1nchez", "Laura Porrino Moscoso", "Leshem Choshen", "Levent Sencan", "Lilja \u00d8vrelid", "Lisa Alazraki", "Lovina Ehimen-Ugbede", "Luheerathan Thevakumar", "Luxshan Thavarasa", "Mahnoor Malik", "Mamadou K. Keita", "Mansi Jangid", "Marco De Santis", "Marcos Garc\u00eda", "Marek Suppa", "Mariam D'Ciofalo", "Marii Ojastu", "Maryam Sikander", "Mausami Narayan", "Maximos Skandalis", "Mehak Mehak", "Mehmet \u0130lteri\u015f Bozkurt", "Melaku Bayu Workie", "Menan Velayuthan", "Michael Leventhal", "Micha\u0142 Marci\u0144czuk", "Mirna Poto\u010dnjak", "Mohammadamin Shafiei", "Mridul Sharma", "Mrityunjaya Indoria", "Muhammad Ravi Shulthan Habibi", "Murat Koli\u0107", "Nada Galant", "Naphat Permpredanun", "Narada Maugin", "Nicholas Kluge Corr\u00eaa", "Nikola Ljube\u0161i\u0107", "Nirmal Thomas", "Nisansa de Silva", "Nisheeth Joshi", "Nitish Ponkshe", "Nizar Habash", "Nneoma C. Udeze", "Noel Thomas", "No\u00e9mi Ligeti-Nagy", "Nouhoum Coulibaly", "Nsengiyumva Faustin", "Odunayo Kareemat Buliaminu", "Odunayo Ogundepo", "Oghojafor Godswill Fejiro", "Ogundipe Blessing Funmilola", "Okechukwu God'spraise", "Olanrewaju Samuel", "Olaoye Deborah Oluwaseun", "Olasoji Akindejoye", "Olga Popova", "Olga Snissarenko", "Onyinye Anulika Chiemezie", "Orkun Kinay", "Osman Tursun", "Owoeye Tobiloba Moses", "Oyelade Oluwafemi Joshua", "Oyesanmi Fiyinfoluwa", "Pablo Gamallo", "Pablo Rodr\u00edguez Fern\u00e1ndez", "Palak Arora", "Pedro Valente", "Peter Rupnik", "Philip Oghenesuowho Ekiugbo", "Pramit Sahoo", "Prokopis Prokopidis", "Pua Niau-Puhipau", "Quadri Yahya", "Rachele Mignone", "Raghav Singhal", "Ram Mohan Rao Kadiyala", "Raphael Merx", "Rapheal Afolayan", "Ratnavel Rajalakshmi", "Rishav Ghosh", "Romina Oji", "Ron Kekeha Solis", "Rui Guerra", "Rushikesh Zawar", "Sa'ad Nasir Bashir", "Saeed Alzaabi", "Sahil Sandeep", "Sai Pavan Batchu", "SaiSandeep Kantareddy", "Salsabila Zahirah Pranida", "Sam Buchanan", "Samuel Rutunda", "Sander Land", "Sarah Sulollari", "Sardar Ali", "Saroj Sapkota", "Saulius Tautvaisas", "Sayambhu Sen", "Sayantani Banerjee", "Sebastien Diarra", "SenthilNathan. M", "Sewoong Lee", "Shaan Shah", "Shankar Venkitachalam", "Sharifa Djurabaeva", "Sharon Ibejih", "Shivanya Shomir Dutta", "Siddhant Gupta", "Silvia Paniagua Su\u00e1rez", "Sina Ahmadi", "Sivasuthan Sukumar", "Siyuan Song", "Snegha A.", "Sokratis Sofianopoulos", "Sona Elza Simon", "Sonja Ben\u010dina", "Sophie Gvasalia", "Sphurti Kirit More", "Spyros Dragazis", "Stephan P. Kaufhold", "Suba. S", "Sultan AlRashed", "Surangika Ranathunga", "Taiga Someya", "Taja Kuzman Punger\u0161ek", "Tal Haklay", "Tasi'u Jibril", "Tatsuya Aoyama", "Tea Abashidze", "Terenz Jomar Dela Cruz", "Terra Blevins", "Themistoklis Nikas", "Theresa Dora Idoko", "Thu Mai Do", "Tilek Chubakov", "Tommaso Gargiani", "Uma Rathore", "Uni Johannesen", "Uwuma Doris Ugwu", "Vallerie Alexandra Putra", "Vanya Bannihatti Kumar", "Varsha Jeyarajalingam", "Varvara Arzt", "Vasudevan Nedumpozhimana", "Viktoria Ondrejova", "Viktoryia Horbik", "Vishnu Vardhan Reddy Kummitha", "Vuk Dini\u0107", "Walelign Tewabe Sewunetie", "Winston Wu", "Xiaojing Zhao", "Yacouba Diarra", "Yaniv Nikankin", "Yash Mathur", "Yixi Chen", "Yiyuan Li", "Yolanda Xavier", "Yonatan Belinkov", "Yusuf Ismail Abayomi", "Zaid Alyafeai", "Zhengyang Shan", "Zhi Rui Tam", "Zilu Tang", "Zuzana Nadova", "Baber Abbasi", "Stella Biderman", "David Stap", "Duygu Ataman", "Fabian Schmidt", "Hila Gonen", "Jiayi Wang", "David Ifeoluwa Adelani"], "title": "Global PIQA: Evaluating Physical Commonsense Reasoning Across 100+ Languages and Cultures", "comment": "Preprint", "summary": "To date, there exist almost no culturally-specific evaluation benchmarks for\nlarge language models (LLMs) that cover a large number of languages and\ncultures. In this paper, we present Global PIQA, a participatory commonsense\nreasoning benchmark for over 100 languages, constructed by hand by 335\nresearchers from 65 countries around the world. The 116 language varieties in\nGlobal PIQA cover five continents, 14 language families, and 23 writing\nsystems. In the non-parallel split of Global PIQA, over 50% of examples\nreference local foods, customs, traditions, or other culturally-specific\nelements. We find that state-of-the-art LLMs perform well on Global PIQA in\naggregate, but they exhibit weaker performance in lower-resource languages (up\nto a 37% accuracy gap, despite random chance at 50%). Open models generally\nperform worse than proprietary models. Global PIQA highlights that in many\nlanguages and cultures, everyday knowledge remains an area for improvement,\nalongside more widely-discussed capabilities such as complex reasoning and\nexpert knowledge. Beyond its uses for LLM evaluation, we hope that Global PIQA\nprovides a glimpse into the wide diversity of cultures in which human language\nis embedded.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.24166", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24166", "abs": "https://arxiv.org/abs/2510.24166", "authors": ["Xin Yang", "Yuhang Zhang", "Wei Li", "Xin Lin", "Wenbin Zou", "Chen Xu"], "title": "UniPlanner: A Unified Motion Planning Framework for Autonomous Vehicle Decision-Making Systems via Multi-Dataset Integration", "comment": null, "summary": "Motion planning is a critical component of autonomous vehicle decision-making\nsystems, directly determining trajectory safety and driving efficiency. While\ndeep learning approaches have advanced planning capabilities, existing methods\nremain confined to single-dataset training, limiting their robustness in\nplanning.\n  Through systematic analysis, we discover that vehicular trajectory\ndistributions and history-future correlations demonstrate remarkable\nconsistency across different datasets. Based on these findings, we propose\nUniPlanner, the first planning framework designed for multi-dataset integration\nin autonomous vehicle decision-making. UniPlanner achieves unified\ncross-dataset learning through three synergistic innovations.\n  First, the History-Future Trajectory Dictionary Network (HFTDN) aggregates\nhistory-future trajectory pairs from multiple datasets, using historical\ntrajectory similarity to retrieve relevant futures and generate cross-dataset\nplanning guidance.\n  Second, the Gradient-Free Trajectory Mapper (GFTM) learns robust\nhistory-future correlations from multiple datasets, transforming historical\ntrajectories into universal planning priors. Its gradient-free design ensures\nthe introduction of valuable priors while preventing shortcut learning, making\nthe planning knowledge safely transferable. Third, the Sparse-to-Dense (S2D)\nparadigm implements adaptive dropout to selectively suppress planning priors\nduring training for robust learning, while enabling full prior utilization\nduring inference to maximize planning performance.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.24096", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24096", "abs": "https://arxiv.org/abs/2510.24096", "authors": ["Md. Rezuwan Hassan", "Azmol Hossain", "Kanij Fatema", "Rubayet Sabbir Faruque", "Tanmoy Shome", "Ruwad Naswan", "Trina Chakraborty", "Md. Foriduzzaman Zihad", "Tawsif Tashwar Dipto", "Nazia Tasnim", "Nazmuddoha Ansary", "Md. Mehedi Hasan Shawon", "Ahmed Imtiaz Humayun", "Md. Golam Rabiul Alam", "Farig Sadeque", "Asif Sushmit"], "title": "RegSpeech12: A Regional Corpus of Bengali Spontaneous Speech Across Dialects", "comment": "26 pages", "summary": "The Bengali language, spoken extensively across South Asia and among\ndiasporic communities, exhibits considerable dialectal diversity shaped by\ngeography, culture, and history. Phonological and pronunciation-based\nclassifications broadly identify five principal dialect groups: Eastern\nBengali, Manbhumi, Rangpuri, Varendri, and Rarhi. Within Bangladesh, further\ndistinctions emerge through variation in vocabulary, syntax, and morphology, as\nobserved in regions such as Chittagong, Sylhet, Rangpur, Rajshahi, Noakhali,\nand Barishal. Despite this linguistic richness, systematic research on the\ncomputational processing of Bengali dialects remains limited. This study seeks\nto document and analyze the phonetic and morphological properties of these\ndialects while exploring the feasibility of building computational models\nparticularly Automatic Speech Recognition (ASR) systems tailored to regional\nvarieties. Such efforts hold potential for applications in virtual assistants\nand broader language technologies, contributing to both the preservation of\ndialectal diversity and the advancement of inclusive digital tools for\nBengali-speaking communities. The dataset created for this study is released\nfor public use.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.24168", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24168", "abs": "https://arxiv.org/abs/2510.24168", "authors": ["Weihua Cheng", "Ersheng Ni", "Wenlong Wang", "Yifei Sun", "Junming Liu", "Wangyu Shen", "Yirong Chen", "Botian Shi", "Ding Wang"], "title": "MGA: Memory-Driven GUI Agent for Observation-Centric Interaction", "comment": "Submitted to WWW2025", "summary": "The rapid progress of Large Language Models (LLMs) and their multimodal\nextensions (MLLMs) has enabled agentic systems capable of perceiving and acting\nacross diverse environments. A challenging yet impactful frontier is the\ndevelopment of GUI agents, which must navigate complex desktop and web\ninterfaces while maintaining robustness and generalization. Existing paradigms\ntypically model tasks as long-chain executions, concatenating historical\ntrajectories into the context. While approaches such as Mirage and GTA1 refine\nplanning or introduce multi-branch action selection, they remain constrained by\ntwo persistent issues: Dependence on historical trajectories, which amplifies\nerror propagation. And Local exploration bias, where \"decision-first,\nobservation-later\" mechanisms overlook critical interface cues. We introduce\nthe Memory-Driven GUI Agent (MGA), which reframes GUI interaction around the\nprinciple of observe first, then decide. MGA models each step as an\nindependent, context-rich environment state represented by a triad: current\nscreenshot, task-agnostic spatial information, and a dynamically updated\nstructured memory. Experiments on OSworld benchmarks, real desktop applications\n(Chrome, VSCode, VLC), and cross-task transfer demonstrate that MGA achieves\nsubstantial gains in robustness, generalization, and efficiency compared to\nstate-of-the-art baselines. The code is publicly available at:\n{https://anonymous.4open.science/r/MGA-3571}.", "AI": {"tldr": "LLM\u9a71\u52a8\u7684GUI\u667a\u80fd\u4f53MGA\uff0c\u901a\u8fc7\u201c\u5148\u89c2\u5bdf\u540e\u51b3\u7b56\u201d\u8303\u5f0f\u514b\u670d\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5728OSworld\u3001\u684c\u9762\u5e94\u7528\u548c\u8de8\u4efb\u52a1\u8fc1\u79fb\u4e2d\u7684\u9c81\u68d2\u6027\u3001\u6cdb\u5316\u6027\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709GUI\u667a\u80fd\u4f53\u5728\u5904\u7406\u590d\u6742\u754c\u9762\u548c\u4fdd\u6301\u6cdb\u5316\u6027\u65b9\u9762\u5b58\u5728\u6311\u6218\uff0c\u4e3b\u8981\u53d7\u5386\u53f2\u8f68\u8ff9\u4f9d\u8d56\uff08\u52a0\u5267\u8bef\u5dee\u4f20\u64ad\uff09\u548c\u5c40\u90e8\u63a2\u7d22\u504f\u5dee\uff08\u5ffd\u7565\u5173\u952e\u754c\u9762\u7ebf\u7d22\uff09\u7684\u9650\u5236\u3002", "method": "MGA\u5c06GUI\u4ea4\u4e92\u91cd\u65b0\u5b9a\u4e49\u4e3a\u201c\u5148\u89c2\u5bdf\u540e\u51b3\u7b56\u201d\u7684\u8303\u5f0f\u3002\u6bcf\u4e2a\u4ea4\u4e92\u6b65\u9aa4\u88ab\u5efa\u6a21\u4e3a\u4e00\u4e2a\u72ec\u7acb\u7684\u3001\u5bcc\u542b\u4e0a\u4e0b\u6587\u7684\u73af\u5883\u72b6\u6001\uff0c\u8be5\u72b6\u6001\u7531\u4e09\u4e2a\u90e8\u5206\u7ec4\u6210\uff1a\u5f53\u524d\u5c4f\u5e55\u622a\u56fe\u3001\u4efb\u52a1\u65e0\u5173\u7684\u7a7a\u95f4\u4fe1\u606f\u4ee5\u53ca\u52a8\u6001\u66f4\u65b0\u7684\u7ed3\u6784\u5316\u8bb0\u5fc6\u3002", "result": "\u5728OSworld\u57fa\u51c6\u3001Chrome\u3001VSCode\u3001VLC\u7b49\u771f\u5b9e\u684c\u9762\u5e94\u7528\u4ee5\u53ca\u8de8\u4efb\u52a1\u8fc1\u79fb\u5b9e\u9a8c\u4e2d\uff0cMGA\u76f8\u8f83\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u9c81\u68d2\u6027\u3001\u6cdb\u5316\u6027\u548c\u6548\u7387\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u7684\u63d0\u5347\u3002", "conclusion": "MGA\u901a\u8fc7\u5f15\u5165\u201c\u5148\u89c2\u5bdf\u540e\u51b3\u7b56\u201d\u7684\u65b0\u8303\u5f0f\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709GUI\u667a\u80fd\u4f53\u7684\u5173\u952e\u6311\u6218\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u548c\u771f\u5b9e\u5e94\u7528\u4e2d\u5c55\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u4e3a\u5f00\u53d1\u66f4\u5f3a\u5927\u7684GUI\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2510.24102", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24102", "abs": "https://arxiv.org/abs/2510.24102", "authors": ["Yihan Wang", "Peiyu Liu", "Runyu Chen", "Jiaxing Pu", "Wei Xu"], "title": "Squrve: A Unified and Modular Framework for Complex Real-World Text-to-SQL Tasks", "comment": null, "summary": "Text-to-SQL technology has evolved rapidly, with diverse academic methods\nachieving impressive results. However, deploying these techniques in real-world\nsystems remains challenging due to limited integration tools. Despite these\nadvances, we introduce Squrve, a unified, modular, and extensive Text-to-SQL\nframework designed to bring together research advances and real-world\napplications. Squrve first establishes a universal execution paradigm that\nstandardizes invocation interfaces, then proposes a multi-actor collaboration\nmechanism based on seven abstracted effective atomic actor components.\nExperiments on widely adopted benchmarks demonstrate that the collaborative\nworkflows consistently outperform the original individual methods, thereby\nopening up a new effective avenue for tackling complex real-world queries. The\ncodes are available at https://github.com/Satissss/Squrve.", "AI": {"tldr": "Squrve\u662f\u4e00\u4e2a\u7edf\u4e00\u3001\u6a21\u5757\u5316\u7684Text-to-SQL\u6846\u67b6\uff0c\u6574\u5408\u4e86\u5b66\u672f\u7814\u7a76\u548c\u5b9e\u9645\u5e94\u7528\uff0c\u901a\u8fc7\u901a\u7528\u7684\u6267\u884c\u8303\u5f0f\u548c\u591a\u4e3b\u4f53\u534f\u4f5c\u673a\u5236\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u90e8\u7f72\u6311\u6218\uff0c\u5e76\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u4f18\u4e8e\u5355\u72ec\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1Text-to-SQL\u6280\u672f\u53d1\u5c55\u8fc5\u901f\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u9762\u4e34\u96c6\u6210\u5de5\u5177\u4e0d\u8db3\u7684\u6311\u6218\u3002Squrve\u65e8\u5728\u5f25\u5408\u5b66\u672f\u7814\u7a76\u4e0e\u5b9e\u9645\u5e94\u7528\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u63d0\u4f9b\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u6846\u67b6\u3002", "method": "Squrve\u9996\u5148\u5efa\u7acb\u4e86\u4e00\u4e2a\u901a\u7528\u7684\u6267\u884c\u8303\u5f0f\uff0c\u6807\u51c6\u5316\u4e86\u8c03\u7528\u63a5\u53e3\u3002\u7136\u540e\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e03\u4e2a\u62bd\u8c61\u539f\u5b50\u884c\u4e3a\u7ec4\u4ef6\u7684\u591a\u4e3b\u4f53\u534f\u4f5c\u673a\u5236\u3002\u5b9e\u9a8c\u5728\u5e7f\u6cdb\u91c7\u7528\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8fdb\u884c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSqurve\u7684\u534f\u4f5c\u6d41\u7a0b\u5728\u6027\u80fd\u4e0a\u59cb\u7ec8\u4f18\u4e8e\u5355\u72ec\u4f7f\u7528\u7684\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "Squrve\u901a\u8fc7\u7edf\u4e00\u7684\u6846\u67b6\u548c\u521b\u65b0\u7684\u534f\u4f5c\u673a\u5236\uff0c\u4e3a\u89e3\u51b3\u590d\u6742\u7684\u771f\u5b9e\u4e16\u754cText-to-SQL\u67e5\u8be2\u5f00\u8f9f\u4e86\u65b0\u7684\u6709\u6548\u9014\u5f84\u3002\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2510.24126", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24126", "abs": "https://arxiv.org/abs/2510.24126", "authors": ["Vivek Kalyan", "Martin Andrews"], "title": "Reinforcement Learning for Long-Horizon Multi-Turn Search Agents", "comment": "4 pages plus references and appendices. Accepted into the First\n  Workshop on Multi-Turn Interactions in Large Language Models at NeurIPS 2025", "summary": "Large Language Model (LLM) agents can leverage multiple turns and tools to\nsolve complex tasks, with prompt-based approaches achieving strong performance.\nThis work demonstrates that Reinforcement Learning (RL) can push capabilities\nsignificantly further by learning from experience. Through experiments on a\nlegal document search benchmark, we show that our RL-trained 14 Billion\nparameter model outperforms frontier class models (85% vs 78% accuracy). In\naddition, we explore turn-restricted regimes, during training and at test-time,\nthat show these agents achieve better results if allowed to operate over longer\nmulti-turn horizons.", "AI": {"tldr": "Reinforcement Learning (RL) significantly enhances Large Language Model (LLM) agents for complex tasks, outperforming prompt-based methods and leading models on a legal document search benchmark by achieving 85% accuracy compared to 78%. Longer multi-turn interactions during training and testing further improve agent performance.", "motivation": "Current prompt-based LLM agents, while effective for complex tasks using tools and multi-turn interactions, have limitations. This research aims to explore whether Reinforcement Learning (RL), by enabling agents to learn from experience, can further advance LLM agent capabilities beyond existing prompt-based approaches and achieve superior performance.", "method": "The study employs Reinforcement Learning (RL) to train LLM agents. A 14 Billion parameter model is utilized. Experiments are conducted on a legal document search benchmark. The performance is evaluated under varying turn restrictions, both during the training phase and at test-time, to analyze the impact of multi-turn interaction length on the agent's effectiveness.", "result": "The RL-trained LLM agent demonstrated superior performance on the legal document search benchmark, achieving 85% accuracy, which surpasses frontier class models that attained 78% accuracy. The experiments also indicated that allowing agents to operate over longer multi-turn horizons, both in training and testing, leads to improved results.", "conclusion": "Reinforcement Learning (RL) offers a significant advancement for LLM agents, enabling them to learn from experience and achieve higher performance on complex tasks compared to traditional prompt-based methods. The research highlights the benefit of extended multi-turn interactions for agent effectiveness. Future work could explore more sophisticated RL techniques and their application to a wider range of complex tasks and domains."}}
{"id": "2510.24297", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24297", "abs": "https://arxiv.org/abs/2510.24297", "authors": ["Robin Schm\u00f6cker", "Alexander Dockhorn", "Bodo Rosenhahn"], "title": "Investigating Intra-Abstraction Policies For Non-exact Abstraction Algorithms", "comment": null, "summary": "One weakness of Monte Carlo Tree Search (MCTS) is its sample efficiency which\ncan be addressed by building and using state and/or action abstractions in\nparallel to the tree search such that information can be shared among nodes of\nthe same layer. The primary usage of abstractions for MCTS is to enhance the\nUpper Confidence Bound (UCB) value during the tree policy by aggregating visits\nand returns of an abstract node. However, this direct usage of abstractions\ndoes not take the case into account where multiple actions with the same parent\nmight be in the same abstract node, as these would then all have the same UCB\nvalue, thus requiring a tiebreak rule. In state-of-the-art abstraction\nalgorithms such as pruned On the Go Abstractions (pruned OGA), this case has\nnot been noticed, and a random tiebreak rule was implicitly chosen. In this\npaper, we propose and empirically evaluate several alternative\nintra-abstraction policies, several of which outperform the random policy\nacross a majority of environments and parameter settings.", "AI": {"tldr": "MCTS\u7684\u6837\u672c\u6548\u7387\u4f4e\u662f\u5176\u5f31\u70b9\uff0c\u53ef\u4ee5\u901a\u8fc7\u6784\u5efa\u548c\u4f7f\u7528\u72b6\u6001/\u52a8\u4f5c\u62bd\u8c61\u6765\u89e3\u51b3\uff0c\u4ee5\u5171\u4eab\u5c42\u5185\u8282\u70b9\u4fe1\u606f\u3002\u73b0\u6709\u62bd\u8c61\u7b97\u6cd5\uff08\u5982pruned OGA\uff09\u5728\u5904\u7406\u540c\u4e00\u62bd\u8c61\u8282\u70b9\u5185\u7684\u591a\u4e2a\u52a8\u4f5c\u65f6\uff0c\u4f1a\u9047\u5230\u540c\u8d28U C B\u503c\u95ee\u9898\uff0c\u5e76\u9690\u5f0f\u91c7\u7528\u968f\u673a\u7684tiebreak\u89c4\u5219\u3002\u672c\u6587\u63d0\u51fa\u4e86\u51e0\u79cd\u66ff\u4ee3\u7684\u62bd\u8c61\u5185\u7b56\u7565\uff0c\u5e76\u5728\u5927\u591a\u6570\u73af\u5883\u548c\u53c2\u6570\u8bbe\u7f6e\u4e0b\u4f18\u4e8e\u968f\u673a\u7b56\u7565\u3002", "motivation": "MCTS\u7684\u4e3b\u8981\u5f31\u70b9\u662f\u6837\u672c\u6548\u7387\u4f4e\u3002\u867d\u7136\u4f7f\u7528\u72b6\u6001\u548c/\u6216\u52a8\u4f5c\u62bd\u8c61\u53ef\u4ee5\u63d0\u9ad8\u4fe1\u606f\u5171\u4eab\u548cUCB\u503c\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u540c\u4e00\u62bd\u8c61\u8282\u70b9\u5185\u7684\u591a\u4e2a\u52a8\u4f5c\u65f6\u5b58\u5728\u95ee\u9898\uff0c\u5bfc\u81f4UCB\u503c\u76f8\u540c\uff0c\u9700\u8981tiebreak\u89c4\u5219\u3002pruned OGA\u7b49\u7b97\u6cd5\u672a\u6ce8\u610f\u5230\u6b64\u95ee\u9898\uff0c\u5e76\u9ed8\u8ba4\u91c7\u7528\u968f\u673atiebreak\uff0c\u8fd9\u53ef\u80fd\u4e0d\u662f\u6700\u4f18\u9009\u62e9\u3002", "method": "\u672c\u6587\u63d0\u51fa\u5e76\u5b9e\u8bc1\u8bc4\u4f30\u4e86\u51e0\u79cd\u4e0d\u540c\u7684\u62bd\u8c61\u5185\u7b56\u7565\uff0c\u7528\u4ee5\u66ff\u4ee3MCTS\u4e2d\u7531\u62bd\u8c61\u8282\u70b9\u5f15\u8d77\u7684\u968f\u673atiebreak\u89c4\u5219\u3002\u5177\u4f53\u65b9\u6cd5\u662f\u5728\u540c\u4e00\u62bd\u8c61\u8282\u70b9\u5185\u7684\u591a\u4e2a\u52a8\u4f5c\u4e4b\u95f4\u5f15\u5165\u66f4\u4f18\u5316\u7684\u7b56\u7565\uff0c\u4ee5\u6539\u8fdbUCB\u503c\u7684\u8ba1\u7b97\u548c\u9009\u62e9\u3002", "result": "\u4e0e\u968f\u673atiebreak\u7b56\u7565\u76f8\u6bd4\uff0c\u672c\u6587\u63d0\u51fa\u7684\u51e0\u79cd\u66ff\u4ee3\u62bd\u8c61\u5185\u7b56\u7565\u5728\u5927\u591a\u6570\u73af\u5883\u548c\u53c2\u6570\u8bbe\u7f6e\u4e0b\u5747\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u66ff\u4ee3\u62bd\u8c61\u5185\u7b56\u7565\u5728\u89e3\u51b3MCTS\u62bd\u8c61\u8282\u70b9\u5185\u7684\u591a\u52a8\u4f5c\u540c\u8d28UCB\u503c\u95ee\u9898\u4e0a\uff0c\u4f18\u4e8e\u73b0\u6709\u7684\u968f\u673atiebreak\u65b9\u6cd5\u3002\u8fd9\u4e3a\u63d0\u9ad8MCTS\u7684\u6837\u672c\u6548\u7387\u548c\u6027\u80fd\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\uff0c\u4f46\u4ecd\u9700\u5728\u66f4\u591a\u6837\u5316\u7684\u73af\u5883\u548c\u53c2\u6570\u8bbe\u7f6e\u4e0b\u8fdb\u884c\u9a8c\u8bc1\u3002"}}
{"id": "2510.24139", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24139", "abs": "https://arxiv.org/abs/2510.24139", "authors": ["Chanwoo Park", "Suyoung Park", "Yelim Ahn", "Jongmin Kim", "Jongyeon Park", "Jaejin Lee"], "title": "Beyond Line-Level Filtering for the Pretraining Corpora of LLMs", "comment": "submitted to ACL ARR Rolling Review", "summary": "While traditional line-level filtering techniques, such as line-level\ndeduplication and trailing-punctuation filters, are commonly used, these basic\nmethods can sometimes discard valuable content, negatively affecting downstream\nperformance. In this paper, we introduce two methods-pattern-aware line-level\ndeduplication (PLD) and pattern-aware trailing punctuation filtering (PTF)-by\nenhancing the conventional filtering techniques. Our approach not only\nconsiders line-level signals but also takes into account their sequential\ndistribution across documents, enabling us to retain structurally important\ncontent that might otherwise be removed. We evaluate these proposed methods by\ntraining small language models (1 B parameters) in both English and Korean. The\nresults demonstrate that our methods consistently improve performance on\nmultiple-choice benchmarks and significantly enhance generative\nquestion-answering accuracy on both SQuAD v1 and KorQuAD v1.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u6a21\u5f0f\u611f\u77e5\u7ebf\u7ea7\u53bb\u91cd\uff08PLD\uff09\u548c\u6a21\u5f0f\u611f\u77e5\u5c3e\u90e8\u6807\u70b9\u8fc7\u6ee4\uff08PTF\uff09\u4e24\u79cd\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u8003\u8651\u884c\u5185\u4fe1\u53f7\u53ca\u5176\u5728\u6587\u6863\u4e2d\u7684\u5e8f\u5217\u5206\u5e03\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u8fc7\u6ee4\u6389\u5b9d\u8d35\u5185\u5bb9\u7684\u95ee\u9898\uff0c\u5e76\u5728\u4e2d\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u591a\u9879\u9009\u62e9\u57fa\u51c6\u548c\u751f\u6210\u5f0f\u95ee\u7b54\u4efb\u52a1\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u7ebf\u7ea7\u8fc7\u6ee4\u6280\u672f\uff08\u5982\u53bb\u91cd\u548c\u5c3e\u90e8\u6807\u70b9\u8fc7\u6ee4\uff09\u867d\u7136\u5e38\u7528\uff0c\u4f46\u53ef\u80fd\u9519\u8bef\u5730\u5220\u9664\u6709\u4ef7\u503c\u7684\u5185\u5bb9\uff0c\u635f\u5bb3\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u667a\u80fd\u7684\u8fc7\u6ee4\u65b9\u6cd5\u6765\u4fdd\u7559\u7ed3\u6784\u6027\u5185\u5bb9\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e24\u79cd\u6a21\u5f0f\u611f\u77e5\u65b9\u6cd5\uff1a\u6a21\u5f0f\u611f\u77e5\u7ebf\u7ea7\u53bb\u91cd\uff08PLD\uff09\u548c\u6a21\u5f0f\u611f\u77e5\u5c3e\u90e8\u6807\u70b9\u8fc7\u6ee4\uff08PTF\uff09\u3002\u8fd9\u4e24\u79cd\u65b9\u6cd5\u4e0d\u4ec5\u8003\u8651\u7ebf\u7ea7\u4fe1\u53f7\uff0c\u8fd8\u7ed3\u5408\u4e86\u8fd9\u4e9b\u4fe1\u53f7\u5728\u6587\u6863\u4e2d\u7684\u5e8f\u5217\u5206\u5e03\u7279\u5f81\uff0c\u4ee5\u66f4\u7cbe\u786e\u5730\u8bc6\u522b\u548c\u4fdd\u7559\u6709\u4ef7\u503c\u7684\u5185\u5bb9\uff0c\u907f\u514d\u8bef\u5220\u3002", "result": "\u901a\u8fc7\u5728\u4e2d\u5c0f\u578b\uff0810\u4ebf\u53c2\u6570\uff09\u7684\u82f1\u8bed\u548c\u97e9\u8bed\u8bed\u8a00\u6a21\u578b\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684PLD\u548cPTF\u65b9\u6cd5\u80fd\u591f\u6301\u7eed\u63d0\u9ad8\u6a21\u578b\u5728\u591a\u9879\u9009\u62e9\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u6027\u80fd\uff0c\u5e76\u5728SQuAD v1\u548cKorQuAD v1\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u5347\u751f\u6210\u5f0f\u95ee\u7b54\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u6a21\u5f0f\u611f\u77e5\u7ebf\u7ea7\u53bb\u91cd\uff08PLD\uff09\u548c\u6a21\u5f0f\u611f\u77e5\u5c3e\u90e8\u6807\u70b9\u8fc7\u6ee4\uff08PTF\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u7ebf\u7ea7\u4fe1\u53f7\u548c\u5e8f\u5217\u5206\u5e03\u4fe1\u606f\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u8fc7\u6ee4\u6280\u672f\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u591a\u9879\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u95ee\u7b54\u4efb\u52a1\u4e0a\u3002\u8fd9\u8868\u660e\u5728\u6570\u636e\u9884\u5904\u7406\u9636\u6bb5\u91c7\u7528\u66f4\u590d\u6742\u7684\u6a21\u5f0f\u611f\u77e5\u65b9\u6cd5\u5bf9\u4e8e\u63d0\u5347\u6a21\u578b\u6548\u679c\u81f3\u5173\u91cd\u8981\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u63a2\u7d22\u66f4\u5e7f\u6cdb\u7684\u6a21\u578b\u89c4\u6a21\u548c\u66f4\u591a\u6837\u5316\u7684\u4e0b\u6e38\u4efb\u52a1\uff0c\u4ee5\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u8fd9\u4e9b\u65b9\u6cd5\u7684\u666e\u9002\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2510.24299", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24299", "abs": "https://arxiv.org/abs/2510.24299", "authors": ["Jiayu Liu", "Wei Dai", "Zhenya Huang", "Ning Miao", "Enhong Chen"], "title": "Verifying Large Language Models' Reasoning Paths via Correlation Matrix Rank", "comment": null, "summary": "Despite the strong reasoning ability of large language models~(LLMs), they\nare prone to errors and hallucinations. As a result, how to check their outputs\neffectively and efficiently has become a critical problem in their\napplications. Existing checking methods heavily rely on external resources,\nsuch as trained verifiers (e.g., process/outcome reward models) or elaborate\nprompts, which lead to high computational overhead and are only applicable to\nspecific domains. In this paper, we investigate whether the internal behaviors\nof LLMs have already implied the credibility of their reasoning paths.\nSpecifically, we find that the rank of the correlation matrix between the input\nproblem and the output reasoning path is a robust indicator of reasoning\ncorrectness. Different from other correctness indicators for LLMs, the\ncalculation of the correlation matrix only relies on the LLM itself, which\navoids the hassle of training a separate model or designing complicated\nprompts. Based on it, we design a simple, plug-and-play Self-Indicator method\nto reweight candidate reasoning paths, which achieves significant performance\nimprovements than other voting and verification methods with very few\ncomputational overhead. Our experiments across multiple LLMs of varying scales\nand model families have further shown the effectiveness of Self-Indicator. It\nachieves over 75% accuracy in distinguishing correct reasoning paths from\nincorrect ones, and, in turn, improves the accuracies on three reasoning\nbenchmarks by more than 8%.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u867d\u7136\u63a8\u7406\u80fd\u529b\u5f3a\u5927\uff0c\u4f46\u5bb9\u6613\u51fa\u9519\u548c\u4ea7\u751f\u5e7b\u89c9\u3002\u73b0\u6709\u68c0\u67e5\u65b9\u6cd5\u4f9d\u8d56\u5916\u90e8\u8d44\u6e90\uff0c\u8ba1\u7b97\u5f00\u9500\u5927\u4e14\u9002\u7528\u6027\u6709\u9650\u3002\u672c\u7814\u7a76\u63d0\u51fa\u4e00\u79cd\u201c\u81ea\u6307\u793a\u5668\u201d\uff08Self-Indicator\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u8f93\u5165\u95ee\u9898\u4e0e\u8f93\u51fa\u63a8\u7406\u8def\u5f84\u4e4b\u95f4\u76f8\u5173\u77e9\u9635\u7684\u79e9\u6765\u8bc4\u4f30LLM\u8f93\u51fa\u7684\u53ef\u4fe1\u5ea6\u3002\u8be5\u65b9\u6cd5\u4ec5\u4f9d\u8d56LLM\u81ea\u8eab\uff0c\u65e0\u9700\u989d\u5916\u6a21\u578b\u6216\u590d\u6742\u63d0\u793a\uff0c\u53ef\u63d2\u5165\u73b0\u6709\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u4e14\u8ba1\u7b97\u5f00\u9500\u6781\u5c0f\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u4ee5\u8d85\u8fc775%\u7684\u51c6\u786e\u7387\u533a\u5206\u6b63\u786e\u548c\u9519\u8bef\u7684\u63a8\u7406\u8def\u5f84\uff0c\u5e76\u5728\u4e09\u4e2a\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u63d0\u5347\u51c6\u786e\u7387\u8d85\u8fc78%\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u751f\u6210\u5185\u5bb9\u65f6\u867d\u7136\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5176\u8f93\u51fa\u7ed3\u679c\u5e38\u5e38\u5305\u542b\u9519\u8bef\u548c\u4e0d\u51c6\u786e\u7684\u4fe1\u606f\uff08\u5e7b\u89c9\uff09\u3002\u56e0\u6b64\uff0c\u5982\u4f55\u6709\u6548\u4e14\u9ad8\u6548\u5730\u9a8c\u8bc1LLM\u7684\u8f93\u51fa\u6210\u4e3a\u4e86\u4e00\u4e2a\u5173\u952e\u7684\u7814\u7a76\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5728\u5176\u5e7f\u6cdb\u5e94\u7528\u573a\u666f\u4e0b\u3002\u5f53\u524d\u5df2\u6709\u7684\u9a8c\u8bc1\u65b9\u6cd5\u5927\u591a\u4f9d\u8d56\u5916\u90e8\u8d44\u6e90\uff0c\u4f8b\u5982\u9700\u8981\u989d\u5916\u8bad\u7ec3\u7684\u9a8c\u8bc1\u6a21\u578b\uff08\u5982\u8fc7\u7a0b/\u7ed3\u679c\u5956\u52b1\u6a21\u578b\uff09\u6216\u8bbe\u8ba1\u590d\u6742\u7684\u63d0\u793a\u8bcd\u5de5\u7a0b\u3002\u8fd9\u4e9b\u65b9\u6cd5\u4e0d\u4ec5\u5e26\u6765\u4e86\u9ad8\u6602\u7684\u8ba1\u7b97\u6210\u672c\uff0c\u800c\u4e14\u5f80\u5f80\u53ea\u9002\u7528\u4e8e\u7279\u5b9a\u7684\u5e94\u7528\u9886\u57df\uff0c\u901a\u7528\u6027\u8f83\u5dee\u3002", "method": "\u672c\u7814\u7a76\u7684\u6838\u5fc3\u601d\u60f3\u662f\u63a2\u7d22LLM\u81ea\u8eab\u7684\u5185\u90e8\u884c\u4e3a\u662f\u5426\u80fd\u6307\u793a\u5176\u63a8\u7406\u8fc7\u7a0b\u7684\u53ef\u4fe1\u5ea6\u3002\u7814\u7a76\u8005\u53d1\u73b0\uff0c\u8f93\u5165\u95ee\u9898\u4e0e\u8f93\u51fa\u63a8\u7406\u8def\u5f84\u4e4b\u95f4\u76f8\u5173\u77e9\u9635\u7684\u79e9\uff08rank\uff09\u662f\u8861\u91cf\u63a8\u7406\u6b63\u786e\u6027\u7684\u4e00\u4e2a\u53ef\u9760\u6307\u6807\u3002\u57fa\u4e8e\u8fd9\u4e00\u53d1\u73b0\uff0c\u7814\u7a76\u8005\u8bbe\u8ba1\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u81ea\u6307\u793a\u5668\u201d\uff08Self-Indicator\uff09\u7684\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u662f\u4e00\u79cd\u5373\u63d2\u5373\u7528\u7684\uff08plug-and-play\uff09\u6280\u672f\uff0c\u5b83\u5229\u7528\u8ba1\u7b97\u76f8\u5173\u77e9\u9635\u7684\u65b9\u6cd5\u6765\u91cd\u65b0\u52a0\u6743\uff08reweight\uff09\u5019\u9009\u7684\u63a8\u7406\u8def\u5f84\u3002\u8fd9\u79cd\u65b9\u6cd5\u7684\u5173\u952e\u4f18\u52bf\u5728\u4e8e\uff0c\u5176\u8ba1\u7b97\u8fc7\u7a0b\u4ec5\u4f9d\u8d56\u4e8eLLM\u81ea\u8eab\uff0c\u907f\u514d\u4e86\u8bad\u7ec3\u989d\u5916\u6a21\u578b\u7684\u9ebb\u70e6\uff0c\u4e5f\u65e0\u9700\u8bbe\u8ba1\u590d\u6742\u7684\u63d0\u793a\u8bcd\u3002", "result": "\u901a\u8fc7\u5728\u591a\u79cd\u4e0d\u540c\u89c4\u6a21\u548c\u6a21\u578b\u7cfb\u5217\u7684LLM\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u201c\u81ea\u6307\u793a\u5668\u201d\u65b9\u6cd5\u5c55\u73b0\u4e86\u5176\u6709\u6548\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u533a\u5206\u6b63\u786e\u548c\u9519\u8bef\u7684\u63a8\u7406\u8def\u5f84\u65f6\uff0c\u51c6\u786e\u7387\u8d85\u8fc7\u4e8675%\u3002\u66f4\u91cd\u8981\u7684\u662f\uff0c\u5728\u4e09\u4e2a\u4e0d\u540c\u7684\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5e94\u7528\u201c\u81ea\u6307\u793a\u5668\u201d\u65b9\u6cd5\u540e\uff0cLLM\u7684\u6574\u4f53\u51c6\u786e\u7387\u5f97\u5230\u4e86\u8d85\u8fc78%\u7684\u63d0\u5347\u3002\u4e0e\u73b0\u6709\u7684\u5176\u4ed6\u6295\u7968\uff08voting\uff09\u548c\u9a8c\u8bc1\uff08verification\uff09\u65b9\u6cd5\u76f8\u6bd4\uff0c\u201c\u81ea\u6307\u793a\u5668\u201d\u5728\u53d6\u5f97\u663e\u8457\u6027\u80fd\u6539\u8fdb\u7684\u540c\u65f6\uff0c\u8ba1\u7b97\u5f00\u9500\u5374\u975e\u5e38\u5c0f\u3002", "conclusion": "\u672c\u7814\u7a76\u6210\u529f\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u201c\u81ea\u6307\u793a\u5668\u201d\u65b9\u6cd5\uff0c\u5b83\u5229\u7528LLM\u5185\u90e8\u884c\u4e3a\uff08\u76f8\u5173\u77e9\u9635\u7684\u79e9\uff09\u6765\u8bc4\u4f30\u63a8\u7406\u8def\u5f84\u7684\u53ef\u4fe1\u5ea6\u3002\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709LLM\u8f93\u51fa\u9a8c\u8bc1\u65b9\u6cd5\u8ba1\u7b97\u5f00\u9500\u5927\u3001\u9002\u7528\u6027\u53d7\u9650\u7684\u95ee\u9898\u3002\u901a\u8fc7\u4ec5\u4f9d\u8d56LLM\u81ea\u8eab\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u901a\u7528\u4e14\u5373\u63d2\u5373\u7528\u7684\u8f93\u51fa\u9a8c\u8bc1\uff0c\u5e76\u5728\u591a\u4e2a\u5b9e\u9a8c\u4e2d\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u5728\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u51c6\u786e\u7387\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63a2\u7d22\u8be5\u65b9\u6cd5\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4ee5\u53ca\u4e0e\u5176\u4ed6\u9a8c\u8bc1\u6280\u672f\u7684\u7ed3\u5408\u6f5c\u529b\u3002"}}
{"id": "2510.24150", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24150", "abs": "https://arxiv.org/abs/2510.24150", "authors": ["Chanwoo Park", "Suyoung Park", "JiA Kang", "Jongyeon Park", "Sangho Kim", "Hyunji M. Park", "Sumin Bae", "Mingyu Kang", "Jaejin Lee"], "title": "Ko-MuSR: A Multistep Soft Reasoning Benchmark for LLMs Capable of Understanding Korean", "comment": "submitted to ACL ARR Rolling Review", "summary": "We present Ko-MuSR, the first benchmark to comprehensively evaluate\nmultistep, soft reasoning in long Korean narratives while minimizing data\ncontamination. Built following MuSR, Ko-MuSR features fully Korean narratives,\nreasoning chains, and multiple-choice questions verified by human annotators\nfor logical consistency and answerability. Evaluations of four large language\nmodels -- two multilingual and two Korean-specialized -- show that multilingual\nmodels outperform Korean-focused ones even in Korean reasoning tasks,\nindicating cross-lingual generalization of reasoning ability. Carefully\ndesigned prompting strategies, which combine few-shot examples, reasoning\ntraces, and task-specific hints, further boost accuracy, approaching\nhuman-level performance. Ko-MuSR offers a solid foundation for advancing Korean\nNLP by enabling systematic evaluation of long-context reasoning and prompting\nstrategies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Ko-MuSR\uff0c\u4e00\u4e2a\u8bc4\u4f30\u97e9\u8bed\u957f\u7bc7\u53d9\u4e8b\u4e2d\u591a\u6b65\u3001\u8f6f\u63a8\u7406\u7684\u57fa\u51c6\uff0c\u5e76\u6700\u5927\u9650\u5ea6\u5730\u51cf\u5c11\u4e86\u6570\u636e\u6c61\u67d3\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u591a\u8bed\u8a00\u6a21\u578b\u5728\u97e9\u8bed\u63a8\u7406\u4efb\u52a1\u4e0a\u4f18\u4e8e\u97e9\u8bed\u4e13\u7528\u6a21\u578b\uff0c\u5e76\u4e14\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63d0\u793a\u7b56\u7565\u80fd\u663e\u8457\u63d0\u9ad8\u51c6\u786e\u6027\uff0c\u63a5\u8fd1\u4eba\u7c7b\u6c34\u5e73\u3002", "motivation": "\u73b0\u6709\u7684\u63a8\u7406\u57fa\u51c6\u5728\u8bc4\u4f30\u957f\u7bc7\u97e9\u8bed\u53d9\u4e8b\u4e2d\u7684\u591a\u6b65\u3001\u8f6f\u63a8\u7406\u80fd\u529b\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u5c24\u5176\u662f\u5728\u6570\u636e\u6c61\u67d3\u65b9\u9762\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u4e13\u95e8\u7684\u97e9\u8bed\u57fa\u51c6\u6765\u7cfb\u7edf\u5730\u8bc4\u4f30\u8fd9\u4e00\u80fd\u529b\uff0c\u5e76\u63a8\u52a8\u97e9\u8bed\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u7684\u53d1\u5c55\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u540d\u4e3aKo-MuSR\u7684\u57fa\u51c6\uff0c\u8be5\u57fa\u51c6\u5305\u542b\u5168\u97e9\u8bed\u53d9\u4e8b\u3001\u63a8\u7406\u94fe\u548c\u591a\u9879\u9009\u62e9\u9898\uff0c\u5e76\u7531\u4eba\u5de5\u6ce8\u91ca\u8005\u9a8c\u8bc1\u5176\u903b\u8f91\u4e00\u81f4\u6027\u548c\u53ef\u56de\u7b54\u6027\u3002\u8bc4\u4f30\u4e86\u56db\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u4e24\u79cd\u591a\u8bed\u8a00\uff0c\u4e24\u79cd\u97e9\u8bed\u4e13\u7528\uff09\uff0c\u5e76\u6d4b\u8bd5\u4e86\u7ed3\u5408\u5c11\u91cf\u6837\u672c\u3001\u63a8\u7406\u8f68\u8ff9\u548c\u4efb\u52a1\u7279\u5b9a\u63d0\u793a\u7684\u63d0\u793a\u7b56\u7565\u3002", "result": "\u5728Ko-MuSR\u57fa\u51c6\u4e0a\uff0c\u591a\u8bed\u8a00\u6a21\u578b\u5728\u97e9\u8bed\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u4f18\u4e8e\u97e9\u8bed\u4e13\u7528\u6a21\u578b\u3002\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u63d0\u793a\u7b56\u7565\uff08\u7ed3\u5408\u5c11\u91cf\u6837\u672c\u3001\u63a8\u7406\u8f68\u8ff9\u548c\u4efb\u52a1\u7279\u5b9a\u63d0\u793a\uff09\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u51c6\u786e\u6027\uff0c\u4f7f\u5176\u63a5\u8fd1\u4eba\u7c7b\u6c34\u5e73\u3002", "conclusion": "Ko-MuSR\u4e3a\u8bc4\u4f30\u97e9\u8bed\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u548c\u63d0\u793a\u7b56\u7565\u63d0\u4f9b\u4e86\u4e00\u4e2a\u575a\u5b9e\u7684\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u97e9\u8bedNLP\u7684\u53d1\u5c55\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u591a\u8bed\u8a00\u6a21\u578b\u5728\u8de8\u8bed\u8a00\u63a8\u7406\u65b9\u9762\u5177\u6709\u4f18\u52bf\uff0c\u5e76\u4e14\u63d0\u793a\u5de5\u7a0b\u662f\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u7684\u5173\u952e\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u6269\u5c55Ko-MuSR\u7684\u89c4\u6a21\u548c\u591a\u6837\u6027\uff0c\u5e76\u63a2\u7d22\u66f4\u5148\u8fdb\u7684\u63a8\u7406\u548c\u63d0\u793a\u6280\u672f\u3002"}}
{"id": "2510.24303", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24303", "abs": "https://arxiv.org/abs/2510.24303", "authors": ["Deniz Gorur", "Antoni Rago", "Francesca Toni"], "title": "Retrieval and Argumentation Enhanced Multi-Agent LLMs for Judgmental Forecasting", "comment": null, "summary": "Judgmental forecasting is the task of making predictions about future events\nbased on human judgment. This task can be seen as a form of claim verification,\nwhere the claim corresponds to a future event and the task is to assess the\nplausibility of that event. In this paper, we propose a novel multi-agent\nframework for claim verification, whereby different agents may disagree on\nclaim veracity and bring specific evidence for and against the claims,\nrepresented as quantitative bipolar argumentation frameworks (QBAFs). We then\ninstantiate the framework for supporting claim verification, with a variety of\nagents realised with Large Language Models (LLMs): (1) ArgLLM agents, an\nexisting approach for claim verification that generates and evaluates QBAFs;\n(2) RbAM agents, whereby LLM-empowered Relation-based Argument Mining (RbAM)\nfrom external sources is used to generate QBAFs; (3) RAG-ArgLLM agents,\nextending ArgLLM agents with a form of Retrieval-Augmented Generation (RAG) of\narguments from external sources. Finally, we conduct experiments with two\nstandard judgmental forecasting datasets, with instances of our framework with\ntwo or three agents, empowered by six different base LLMs. We observe that\ncombining evidence from agents can improve forecasting accuracy, especially in\nthe case of three agents, while providing an explainable combination of\nevidence for claim verification.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u6846\u67b6\u7684\u5224\u65ad\u5f0f\u9884\u6d4b\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5229\u7528\u91cf\u5316\u53cc\u6781\u8bba\u8bc1\u6846\u67b6\uff08QBAFs\uff09\u6765\u9a8c\u8bc1\u5173\u4e8e\u672a\u6765\u4e8b\u4ef6\u7684\u9884\u6d4b\u3002\u901a\u8fc7\u7ed3\u5408\u4e0d\u540c\u667a\u80fd\u4f53\uff08\u5305\u62ecArgLLM\u3001RbAM\u548cRAG-ArgLLM\uff09\u7684\u8bc1\u636e\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u63d0\u9ad8\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u5c24\u5176\u662f\u5728\u4f7f\u7528\u4e09\u4e2a\u667a\u80fd\u4f53\u65f6\uff0c\u5e76\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u8bc1\u636e\u7ec4\u5408\u3002", "motivation": "\u5224\u65ad\u5f0f\u9884\u6d4b\uff08Judgmental forecasting\uff09\u662f\u5c06\u5bf9\u4eba\u7c7b\u5224\u65ad\u7684\u672a\u6765\u4e8b\u4ef6\u7684\u9884\u6d4b\u4f5c\u4e3a\u4e00\u9879\u4efb\u52a1\u3002\u8fd9\u9879\u4efb\u52a1\u53ef\u4ee5\u88ab\u770b\u4f5c\u662f\u4e00\u79cd\u4e3b\u5f20\u9a8c\u8bc1\uff08claim verification\uff09\u7684\u5f62\u5f0f\uff0c\u5176\u4e2d\u4e3b\u5f20\u5bf9\u5e94\u4e8e\u4e00\u4e2a\u672a\u6765\u7684\u4e8b\u4ef6\uff0c\u800c\u4efb\u52a1\u662f\u8bc4\u4f30\u8be5\u4e8b\u4ef6\u7684\u53ef\u80fd\u6027\u3002\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u5982\u4f55\u66f4\u51c6\u786e\u3001\u66f4\u53ef\u4fe1\u5730\u8fdb\u884c\u5224\u65ad\u5f0f\u9884\u6d4b\u7684\u95ee\u9898\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8e\u4e3b\u5f20\u9a8c\u8bc1\u3002\u5728\u8be5\u6846\u67b6\u4e2d\uff0c\u4e0d\u540c\u7684\u667a\u80fd\u4f53\u53ef\u80fd\u5bf9\u4e3b\u5f20\u7684\u771f\u5b9e\u6027\u6709\u4e0d\u540c\u610f\u89c1\uff0c\u5e76\u63d0\u4f9b\u652f\u6301\u6216\u53cd\u5bf9\u4e3b\u5f20\u7684\u7279\u5b9a\u8bc1\u636e\u3002\u8fd9\u4e9b\u8bc1\u636e\u4ee5\u91cf\u5316\u53cc\u6781\u8bba\u8bc1\u6846\u67b6\uff08QBAFs\uff09\u7684\u5f62\u5f0f\u8868\u793a\u3002\u4e3a\u4e86\u652f\u6301\u4e3b\u5f20\u9a8c\u8bc1\uff0c\u8be5\u6846\u67b6\u88ab\u5b9e\u4f8b\u5316\uff0c\u5176\u4e2d\u5404\u79cd\u667a\u80fd\u4f53\u7531\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5b9e\u73b0\uff0c\u5305\u62ec\uff1a1\uff09ArgLLM\u667a\u80fd\u4f53\uff0c\u4e00\u79cd\u751f\u6210\u548c\u8bc4\u4f30QBAFs\u7684\u73b0\u6709\u65b9\u6cd5\uff1b2\uff09RbAM\u667a\u80fd\u4f53\uff0c\u5229\u7528LLM\u8d4b\u80fd\u7684\u5173\u7cfb\u578b\u8bba\u8bc1\u6316\u6398\uff08RbAM\uff09\u4ece\u5916\u90e8\u6765\u6e90\u751f\u6210QBAFs\uff1b3\uff09RAG-ArgLLM\u667a\u80fd\u4f53\uff0c\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u4ece\u5916\u90e8\u6765\u6e90\u83b7\u53d6\u8bba\u8bc1\u6765\u6269\u5c55ArgLLM\u667a\u80fd\u4f53\u3002\u6700\u540e\uff0c\u7814\u7a76\u4eba\u5458\u4f7f\u7528\u4e24\u4e2a\u6807\u51c6\u7684\u5224\u65ad\u5f0f\u9884\u6d4b\u6570\u636e\u96c6\uff0c\u5e76\u7ed3\u5408\u4e24\u4e2a\u6216\u4e09\u4e2a\u667a\u80fd\u4f53\uff08\u7531\u516d\u79cd\u4e0d\u540c\u7684\u57fa\u7840LLMs\u652f\u6301\uff09\u5bf9\u6846\u67b6\u8fdb\u884c\u4e86\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u7ed3\u5408\u6765\u81ea\u4e0d\u540c\u667a\u80fd\u4f53\u7684\u8bc1\u636e\u53ef\u4ee5\u63d0\u9ad8\u5224\u65ad\u5f0f\u9884\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u5c24\u5176\u662f\u5728\u4f7f\u7528\u4e09\u4e2a\u667a\u80fd\u4f53\u7684\u60c5\u51b5\u4e0b\u3002\u6b64\u5916\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u8bc1\u636e\u7ec4\u5408\uff0c\u7528\u4e8e\u4e3b\u5f20\u9a8c\u8bc1\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u4e0d\u540cLLM\u667a\u80fd\u4f53\u7684\u8bc1\u636e\uff0c\u6709\u6548\u5730\u63d0\u9ad8\u4e86\u5224\u65ad\u5f0f\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u589e\u52a0\u667a\u80fd\u4f53\u6570\u91cf\uff08\u4ece\u4e24\u4e2a\u5230\u4e09\u4e2a\uff09\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63d0\u5347\u9884\u6d4b\u6027\u80fd\u3002\u8be5\u6846\u67b6\u4e3a\u672a\u6765\u7684\u5224\u65ad\u5f0f\u9884\u6d4b\u548c\u4e3b\u5f20\u9a8c\u8bc1\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u524d\u666f\u7684\u65b9\u6cd5\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u63a2\u7d22\u66f4\u590d\u6742\u7684\u667a\u80fd\u4f53\u4ea4\u4e92\u673a\u5236\u548c\u8bba\u8bc1\u8868\u793a\u65b9\u5f0f\uff0c\u4ee5\u5e94\u5bf9\u66f4\u5e7f\u6cdb\u7684\u9884\u6d4b\u573a\u666f\u3002"}}
{"id": "2510.24178", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24178", "abs": "https://arxiv.org/abs/2510.24178", "authors": ["Aaron Scott", "Maike Z\u00fcfle", "Jan Niehues"], "title": "MuSaG: A Multimodal German Sarcasm Dataset with Full-Modal Annotations", "comment": null, "summary": "Sarcasm is a complex form of figurative language in which the intended\nmeaning contradicts the literal one. Its prevalence in social media and popular\nculture poses persistent challenges for natural language understanding,\nsentiment analysis, and content moderation. With the emergence of multimodal\nlarge language models, sarcasm detection extends beyond text and requires\nintegrating cues from audio and vision. We present MuSaG, the first German\nmultimodal sarcasm detection dataset, consisting of 33 minutes of manually\nselected and human-annotated statements from German television shows. Each\ninstance provides aligned text, audio, and video modalities, annotated\nseparately by humans, enabling evaluation in unimodal and multimodal settings.\nWe benchmark nine open-source and commercial models, spanning text, audio,\nvision, and multimodal architectures, and compare their performance to human\nannotations. Our results show that while humans rely heavily on audio in\nconversational settings, models perform best on text. This highlights a gap in\ncurrent multimodal models and motivates the use of MuSaG for developing models\nbetter suited to realistic scenarios. We release MuSaG publicly to support\nfuture research on multimodal sarcasm detection and human-model alignment.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86MuSaG\uff0c\u4e00\u4e2a\u5fb7\u8bed\u591a\u6a21\u6001\u8bbd\u523a\u68c0\u6d4b\u6570\u636e\u96c6\uff0c\u5e76\u8bc4\u4f30\u4e86\u4e5d\u4e2a\u6a21\u578b\u5728\u6587\u672c\u3001\u97f3\u9891\u3001\u89c6\u89c9\u548c\u591a\u6a21\u6001\u65b9\u9762\u7684\u8868\u73b0\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u4eba\u7c7b\u5728\u5bf9\u8bdd\u4e2d\u4e3b\u8981\u4f9d\u8d56\u97f3\u9891\uff0c\u800c\u6a21\u578b\u5728\u6587\u672c\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u8fd9\u8868\u660e\u5f53\u524d\u591a\u6a21\u6001\u6a21\u578b\u5728\u5904\u7406\u771f\u5b9e\u573a\u666f\u65f6\u5b58\u5728\u5dee\u8ddd\u3002MuSaG\u6570\u636e\u96c6\u7684\u53d1\u5e03\u65e8\u5728\u4fc3\u8fdb\u591a\u6a21\u6001\u8bbd\u523a\u68c0\u6d4b\u548c\u4eba\u673a\u5bf9\u9f50\u7684\u7814\u7a76\u3002", "motivation": "\u8bbd\u523a\u662f\u4e00\u79cd\u5e38\u89c1\u7684\u4fee\u8f9e\u624b\u6cd5\uff0c\u5176\u5b57\u9762\u610f\u601d\u4e0e\u5b9e\u9645\u542b\u4e49\u76f8\u53cd\uff0c\u5e7f\u6cdb\u5e94\u7528\u4e8e\u793e\u4ea4\u5a92\u4f53\u548c\u6d41\u884c\u6587\u5316\u4e2d\uff0c\u7ed9\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u3001\u60c5\u611f\u5206\u6790\u548c\u5185\u5bb9\u5ba1\u6838\u5e26\u6765\u4e86\u6311\u6218\u3002\u968f\u7740\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\uff0c\u8bbd\u523a\u68c0\u6d4b\u5df2\u4ece\u5355\u4e00\u7684\u6587\u672c\u5206\u6790\u6269\u5c55\u5230\u9700\u8981\u6574\u5408\u97f3\u9891\u548c\u89c6\u89c9\u7ebf\u7d22\u7684\u5c42\u9762\u3002\u56e0\u6b64\uff0c\u8feb\u5207\u9700\u8981\u4e00\u4e2a\u80fd\u591f\u652f\u6301\u591a\u6a21\u6001\u8bbd\u523a\u68c0\u6d4b\u7684\u7814\u7a76\u6570\u636e\u96c6\u3002", "method": "\u7814\u7a76\u8005\u521b\u5efa\u4e86MuSaG\u6570\u636e\u96c6\uff0c\u5176\u4e2d\u5305\u542b33\u5206\u949f\u4ece\u5fb7\u56fd\u7535\u89c6\u8282\u76ee\u4e2d\u624b\u52a8\u6311\u9009\u5e76\u7ecf\u8fc7\u4eba\u5de5\u6807\u6ce8\u7684\u8bed\u53e5\u3002\u6bcf\u4e2a\u6570\u636e\u6837\u672c\u90fd\u5bf9\u9f50\u4e86\u6587\u672c\u3001\u97f3\u9891\u548c\u89c6\u9891\u4e09\u79cd\u6a21\u6001\uff0c\u5e76\u7531\u4eba\u7c7b\u5206\u522b\u8fdb\u884c\u6807\u6ce8\uff0c\u4ee5\u4fbf\u5728\u5355\u6a21\u6001\u548c\u591a\u6a21\u6001\u8bbe\u7f6e\u4e0b\u8fdb\u884c\u8bc4\u4f30\u3002\u7814\u7a76\u8005\u4eec\u8fd8\u5bf9\u4e5d\u4e2a\u5f00\u6e90\u548c\u5546\u4e1a\u6a21\u578b\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8fd9\u4e9b\u6a21\u578b\u6db5\u76d6\u4e86\u6587\u672c\u3001\u97f3\u9891\u3001\u89c6\u89c9\u548c\u591a\u6a21\u6001\u67b6\u6784\uff0c\u5e76\u5c06\u5b83\u4eec\u7684\u6027\u80fd\u4e0e\u4eba\u7c7b\u6807\u6ce8\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0c\u5c3d\u7ba1\u4eba\u7c7b\u5728\u5bf9\u8bdd\u73af\u5883\u4e2d\u975e\u5e38\u4f9d\u8d56\u97f3\u9891\u4fe1\u606f\u6765\u8bc6\u522b\u8bbd\u523a\uff0c\u4f46\u76ee\u524d\u7684\u6a21\u578b\u5728\u6587\u672c\u6a21\u6001\u4e0a\u53d6\u5f97\u4e86\u6700\u4f73\u7684\u68c0\u6d4b\u6548\u679c\u3002\u8fd9\u63ed\u793a\u4e86\u5f53\u524d\u591a\u6a21\u6001\u6a21\u578b\u5728\u5904\u7406\u5305\u542b\u591a\u79cd\u611f\u5b98\u7ebf\u7d22\u7684\u771f\u5b9e\u573a\u666f\u65f6\u5b58\u5728\u6027\u80fd\u4e0a\u7684\u4e0d\u8db3\u3002", "conclusion": "MuSaG\u6570\u636e\u96c6\u7684\u521b\u5efa\u548c\u53d1\u5e03\u662f\u8be5\u7814\u7a76\u7684\u4e3b\u8981\u8d21\u732e\uff0c\u5b83\u4e3a\u591a\u6a21\u6001\u8bbd\u523a\u68c0\u6d4b\u548c\u4eba\u673a\u5bf9\u9f50\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9d\u8d35\u7684\u8d44\u6e90\u3002\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u73b0\u6709\u6a21\u578b\u5728\u6574\u5408\u591a\u6a21\u6001\u4fe1\u606f\u4ee5\u51c6\u786e\u8bc6\u522b\u8bbd\u523a\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u7684\u65b9\u5411\uff0c\u5373\u5f00\u53d1\u66f4\u9002\u5408\u771f\u5b9e\u4e16\u754c\u590d\u6742\u573a\u666f\u7684\u591a\u6a21\u6001\u6a21\u578b\u3002"}}
{"id": "2510.24337", "categories": ["cs.AI", "cs.SI"], "pdf": "https://arxiv.org/pdf/2510.24337", "abs": "https://arxiv.org/abs/2510.24337", "authors": ["Daria Kravets-Meinke", "Hannah Schmid-Petri", "Sonja Niemann", "Ute Schmid"], "title": "Generative Large Language Models (gLLMs) in Content Analysis: A Practical Guide for Communication Research", "comment": null, "summary": "Generative Large Language Models (gLLMs), such as ChatGPT, are increasingly\nbeing used in communication research for content analysis. Studies show that\ngLLMs can outperform both crowd workers and trained coders, such as research\nassistants, on various coding tasks relevant to communication science, often at\na fraction of the time and cost. Additionally, gLLMs can decode implicit\nmeanings and contextual information, be instructed using natural language,\ndeployed with only basic programming skills, and require little to no annotated\ndata beyond a validation dataset - constituting a paradigm shift in automated\ncontent analysis. Despite their potential, the integration of gLLMs into the\nmethodological toolkit of communication research remains underdeveloped. In\ngLLM-assisted quantitative content analysis, researchers must address at least\nseven critical challenges that impact result quality: (1) codebook development,\n(2) prompt engineering, (3) model selection, (4) parameter tuning, (5)\niterative refinement, (6) validation of the model's reliability, and\noptionally, (7) performance enhancement. This paper synthesizes emerging\nresearch on gLLM-assisted quantitative content analysis and proposes a\ncomprehensive best-practice guide to navigate these challenges. Our goal is to\nmake gLLM-based content analysis more accessible to a broader range of\ncommunication researchers and ensure adherence to established disciplinary\nquality standards of validity, reliability, reproducibility, and research\nethics.", "AI": {"tldr": "\u751f\u6210\u5f0f\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08gLLMs\uff09\u5728\u6c9f\u901a\u7814\u7a76\u7684\u5185\u5bb9\u5206\u6790\u65b9\u9762\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u80fd\u591f\u8d85\u8d8a\u4eba\u5de5\u7f16\u7801\u5458\uff0c\u5e76\u4ee5\u66f4\u4f4e\u7684\u6210\u672c\u548c\u65f6\u95f4\u5b9e\u73b0\u81ea\u52a8\u5316\u5185\u5bb9\u5206\u6790\u3002\u7136\u800c\uff0cgLLM\u5728\u6c9f\u901a\u7814\u7a76\u4e2d\u7684\u5e94\u7528\u4ecd\u5904\u4e8e\u65e9\u671f\u9636\u6bb5\uff0c\u7814\u7a76\u4eba\u5458\u5728\u4ee3\u7801\u7c3f\u5f00\u53d1\u3001\u63d0\u793a\u5de5\u7a0b\u3001\u6a21\u578b\u9009\u62e9\u3001\u53c2\u6570\u8c03\u4f18\u3001\u8fed\u4ee3\u4f18\u5316\u3001\u6a21\u578b\u53ef\u9760\u6027\u9a8c\u8bc1\u4ee5\u53ca\u6027\u80fd\u589e\u5f3a\u7b49\u65b9\u9762\u9762\u4e34\u4e25\u5cfb\u6311\u6218\u3002\u672c\u6587\u65e8\u5728\u6574\u5408gLLM\u8f85\u52a9\u5b9a\u91cf\u5185\u5bb9\u5206\u6790\u7684\u6700\u65b0\u7814\u7a76\uff0c\u5e76\u63d0\u51fa\u4e00\u5957\u5168\u9762\u7684\u6700\u4f73\u5b9e\u8df5\u6307\u5357\uff0c\u4ee5\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\uff0c\u4ece\u800c\u63d0\u9ad8gLLM\u5728\u6c9f\u901a\u7814\u7a76\u4e2d\u7684\u53ef\u53ca\u6027\u548c\u8d28\u91cf\u6807\u51c6\uff08\u6709\u6548\u6027\u3001\u53ef\u9760\u6027\u3001\u53ef\u590d\u73b0\u6027\u548c\u7814\u7a76\u4f26\u7406\uff09\u3002", "motivation": "\u6c9f\u901a\u7814\u7a76\u9886\u57df\u65e5\u76ca\u589e\u957f\u7684\u5185\u5bb9\u5206\u6790\u9700\u6c42\uff0c\u4ee5\u53ca\u73b0\u6709\u65b9\u6cd5\u5728\u6548\u7387\u3001\u6210\u672c\u548c\u6df1\u5ea6\u4e0a\u7684\u5c40\u9650\u6027\u3002\u751f\u6210\u5f0f\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08gLLMs\uff09\u5982ChatGPT\uff0c\u5728\u5185\u5bb9\u5206\u6790\u4efb\u52a1\u4e0a\u5c55\u73b0\u51fa\u8d85\u8d8a\u4eba\u7c7b\u7f16\u7801\u5458\u7684\u6f5c\u529b\uff0c\u80fd\u591f\u4ee5\u66f4\u5c11\u7684\u65f6\u95f4\u548c\u6210\u672c\u5b8c\u6210\u590d\u6742\u7f16\u7801\uff0c\u8fd8\u80fd\u7406\u89e3\u9690\u542b\u610f\u4e49\u548c\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002\u7136\u800c\uff0cgLLM\u5728\u6c9f\u901a\u7814\u7a76\u4e2d\u7684\u5e94\u7528\u65b9\u6cd5\u5c1a\u4e0d\u6210\u719f\uff0c\u7814\u7a76\u4eba\u5458\u5728\u5b9e\u9645\u64cd\u4f5c\u4e2d\u4f1a\u9047\u5230\u4e00\u7cfb\u5217\u6311\u6218\uff0c\u963b\u788d\u4e86\u5176\u5e7f\u6cdb\u5e94\u7528\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u6574\u5408\u73b0\u6709\u7814\u7a76\uff0c\u5e76\u63d0\u4f9b\u4e00\u5957\u660e\u786e\u7684\u5b9e\u8df5\u6307\u5357\uff0c\u4ee5\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\uff0c\u4ece\u800c\u63a8\u52a8gLLM\u5728\u6c9f\u901a\u7814\u7a76\u65b9\u6cd5\u5b66\u4e2d\u7684\u53d1\u5c55\uff0c\u5e76\u786e\u4fdd\u7814\u7a76\u8d28\u91cf\u3002", "method": "\u672c\u6587\u6574\u5408\u4e86\u5173\u4e8egLLM\u8f85\u52a9\u5b9a\u91cf\u5185\u5bb9\u5206\u6790\u7684\u6700\u65b0\u7814\u7a76\u8fdb\u5c55\uff0c\u5e76\u57fa\u4e8e\u8fd9\u4e9b\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u5957\u5168\u9762\u7684\u6700\u4f73\u5b9e\u8df5\u6307\u5357\u3002\u8be5\u6307\u5357\u65e8\u5728\u5e2e\u52a9\u6c9f\u901a\u7814\u7a76\u4eba\u5458\u6709\u6548\u5e94\u5bf9\u5728\u5e94\u7528gLLM\u8fdb\u884c\u5185\u5bb9\u5206\u6790\u65f6\u9047\u5230\u7684\u5173\u952e\u6311\u6218\uff0c\u5305\u62ec\u4ee3\u7801\u7c3f\u5f00\u53d1\u3001\u63d0\u793a\u5de5\u7a0b\u3001\u6a21\u578b\u9009\u62e9\u3001\u53c2\u6570\u8c03\u4f18\u3001\u8fed\u4ee3\u4f18\u5316\u3001\u6a21\u578b\u53ef\u9760\u6027\u9a8c\u8bc1\u4ee5\u53ca\u53ef\u9009\u7684\u6027\u80fd\u589e\u5f3a\u3002\u7814\u7a76\u65b9\u6cd5\u4fa7\u91cd\u4e8e\u6587\u732e\u7efc\u8ff0\u548c\u5b9e\u8df5\u7ecf\u9a8c\u7684\u603b\u7ed3\uff0c\u65e8\u5728\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e00\u4e2a\u6e05\u6670\u7684\u64cd\u4f5c\u6846\u67b6\u3002", "result": "\u5c3d\u7ba1\u672c\u6587\u4e3b\u8981\u63d0\u4f9b\u65b9\u6cd5\u8bba\u6307\u5bfc\u800c\u975e\u5b9e\u8bc1\u7ed3\u679c\uff0c\u4f46\u5176\u201c\u7ed3\u679c\u201d\u4f53\u73b0\u5728\u4e3agLLM\u8f85\u52a9\u5b9a\u91cf\u5185\u5bb9\u5206\u6790\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7ed3\u6784\u5316\u7684\u65b9\u6cd5\u548c\u4e00\u5957\u5e94\u5bf9\u6311\u6218\u7684\u6700\u4f73\u5b9e\u8df5\u3002\u901a\u8fc7\u9075\u5faa\u8fd9\u4e9b\u6307\u5357\uff0c\u7814\u7a76\u4eba\u5458\u53ef\u4ee5\u9884\u671f\u5728\u6709\u6548\u6027\u3001\u53ef\u9760\u6027\u3001\u53ef\u590d\u73b0\u6027\u548c\u7814\u7a76\u4f26\u7406\u65b9\u9762\u53d6\u5f97\u66f4\u9ad8\u8d28\u91cf\u7684\u7814\u7a76\u6210\u679c\u3002\u6587\u7ae0\u5f3a\u8c03\u4e86gLLM\u5728\u5904\u7406\u590d\u6742\u7f16\u7801\u4efb\u52a1\u3001\u7406\u89e3\u9690\u542b\u610f\u4e49\u548c\u4e0a\u4e0b\u6587\u4fe1\u606f\u65b9\u9762\u7684\u4f18\u52bf\uff0c\u4ee5\u53ca\u5176\u5728\u8282\u7701\u65f6\u95f4\u3001\u964d\u4f4e\u6210\u672c\u65b9\u9762\u7684\u6548\u7387\u63d0\u5347\uff0c\u8fd9\u4e9b\u90fd\u662fgLLM\u5728\u8be5\u9886\u57df\u5e94\u7528\u7684\u79ef\u6781\u201c\u7ed3\u679c\u201d\u3002", "conclusion": "\u672c\u6587\u6210\u529f\u5730\u6574\u5408\u4e86gLLM\u8f85\u52a9\u5b9a\u91cf\u5185\u5bb9\u5206\u6790\u7684\u73b0\u6709\u7814\u7a76\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u5957\u5168\u9762\u7684\u6700\u4f73\u5b9e\u8df5\u6307\u5357\uff0c\u4e3a\u6c9f\u901a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u5e94\u5bf9\u5173\u952e\u6311\u6218\u7684\u5b9e\u7528\u6846\u67b6\u3002\u8be5\u6307\u5357\u65e8\u5728\u964d\u4f4egLLM\u5728\u6c9f\u901a\u7814\u7a76\u4e2d\u5e94\u7528\u7684\u95e8\u69db\uff0c\u5e76\u786e\u4fdd\u7814\u7a76\u8d28\u91cf\u7b26\u5408\u5b66\u79d1\u6807\u51c6\u3002\u867d\u7136gLLM\u5728\u5185\u5bb9\u5206\u6790\u65b9\u9762\u6f5c\u529b\u5de8\u5927\uff0c\u4f46\u4ecd\u9700\u8fdb\u4e00\u6b65\u7684\u7814\u7a76\u6765\u5b8c\u5584\u5176\u5e94\u7528\uff0c\u7279\u522b\u662f\u5728\u6a21\u578b\u9009\u62e9\u3001\u63d0\u793a\u5de5\u7a0b\u7684\u7cbe\u7ec6\u5316\u4ee5\u53ca\u8de8\u6a21\u578b\u548c\u8de8\u4efb\u52a1\u7684\u53ef\u9760\u6027\u9a8c\u8bc1\u65b9\u9762\u3002\u672a\u6765\u7684\u5de5\u4f5c\u5e94\u7ee7\u7eed\u63a2\u7d22gLLM\u5728\u66f4\u5e7f\u6cdb\u7684\u6c9f\u901a\u7814\u7a76\u95ee\u9898\u4e0a\u7684\u5e94\u7528\uff0c\u5e76\u81f4\u529b\u4e8e\u5f00\u53d1\u66f4\u6807\u51c6\u5316\u7684\u8bc4\u4f30\u548c\u9a8c\u8bc1\u5de5\u5177\uff0c\u4ee5\u5145\u5206\u53d1\u6325gLLM\u5728\u8fd9\u4e00\u9886\u57df\u7684\u4f5c\u7528\u3002"}}
{"id": "2510.24179", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24179", "abs": "https://arxiv.org/abs/2510.24179", "authors": ["Iv\u00e1n Mart\u00ednez-Murillo", "Paloma Moreda", "Elena Lloret"], "title": "Exploring the Influence of Relevant Knowledge for Natural Language Generation Interpretability", "comment": null, "summary": "This paper explores the influence of external knowledge integration in\nNatural Language Generation (NLG), focusing on a commonsense generation task.\nWe extend the CommonGen dataset by creating KITGI, a benchmark that pairs input\nconcept sets with retrieved semantic relations from ConceptNet and includes\nmanually annotated outputs. Using the T5-Large model, we compare sentence\ngeneration under two conditions: with full external knowledge and with filtered\nknowledge where highly relevant relations were deliberately removed. Our\ninterpretability benchmark follows a three-stage method: (1) identifying and\nremoving key knowledge, (2) regenerating sentences, and (3) manually assessing\noutputs for commonsense plausibility and concept coverage. Results show that\nsentences generated with full knowledge achieved 91\\% correctness across both\ncriteria, while filtering reduced performance drastically to 6\\%. These\nfindings demonstrate that relevant external knowledge is critical for\nmaintaining both coherence and concept coverage in NLG. This work highlights\nthe importance of designing interpretable, knowledge-enhanced NLG systems and\ncalls for evaluation frameworks that capture the underlying reasoning beyond\nsurface-level metrics.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5728\u81ea\u7136\u8bed\u8a00\u751f\u6210\uff08NLG\uff09\u4efb\u52a1\u4e2d\u6574\u5408\u5916\u90e8\u77e5\u8bc6\u7684\u5f71\u54cd\uff0c\u7279\u522b\u5173\u6ce8\u5e38\u8bc6\u63a8\u7406\u751f\u6210\u3002\u7814\u7a76\u8005\u63d0\u51fa\u4e86KITGI\u57fa\u51c6\uff0c\u6269\u5c55\u4e86CommonGen\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5916\u90e8\u77e5\u8bc6\uff08\u6765\u81eaConceptNet\uff09\u5bf9\u53e5\u5b50\u751f\u6210\u7684\u91cd\u8981\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528\u5b8c\u6574\u7684\u5916\u90e8\u77e5\u8bc6\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u751f\u6210\u53e5\u5b50\u7684\u6b63\u786e\u6027\u548c\u6982\u5ff5\u8986\u76d6\u7387\uff08\u8fbe\u523091%\uff09\uff0c\u800c\u79fb\u9664\u5173\u952e\u77e5\u8bc6\u5219\u4f1a\u5bfc\u81f4\u6027\u80fd\u6025\u5267\u4e0b\u964d\u81f36%\u3002\u8fd9\u5f3a\u8c03\u4e86\u5916\u90e8\u77e5\u8bc6\u5bf9\u4e8e\u7ef4\u6301NLG\u8fde\u8d2f\u6027\u548c\u6982\u5ff5\u8986\u76d6\u7387\u7684\u5173\u952e\u4f5c\u7528\uff0c\u5e76\u547c\u5401\u8bbe\u8ba1\u53ef\u89e3\u91ca\u7684\u3001\u589e\u5f3a\u77e5\u8bc6\u7684NLG\u7cfb\u7edf\u3002", "motivation": "\u5f53\u524d\u81ea\u7136\u8bed\u8a00\u751f\u6210\uff08NLG\uff09\u7cfb\u7edf\u5728\u751f\u6210\u8fde\u8d2f\u4e14\u7b26\u5408\u5e38\u8bc6\u7684\u6587\u672c\u65b9\u9762\u4ecd\u9762\u4e34\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u9700\u8981\u6574\u5408\u5916\u90e8\u80cc\u666f\u77e5\u8bc6\u7684\u4efb\u52a1\u4e2d\u3002\u672c\u7814\u7a76\u65e8\u5728\u6df1\u5165\u7406\u89e3\u5916\u90e8\u77e5\u8bc6\uff0c\u7279\u522b\u662f\u5e38\u8bc6\u6027\u8bed\u4e49\u5173\u7cfb\uff0c\u5982\u4f55\u5f71\u54cdNLG\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u4ee5\u53ca\u5982\u4f55\u91cf\u5316\u8fd9\u79cd\u5f71\u54cd\u3002\u4e86\u89e3\u8fd9\u4e00\u70b9\u5bf9\u4e8e\u5f00\u53d1\u66f4\u667a\u80fd\u3001\u66f4\u53ef\u9760\u7684NLG\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\uff0c\u8fd9\u4e9b\u7cfb\u7edf\u80fd\u591f\u66f4\u597d\u5730\u7406\u89e3\u548c\u8fd0\u7528\u4e16\u754c\u77e5\u8bc6\u6765\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u6587\u672c\u3002", "method": "\u7814\u7a76\u8005\u9996\u5148\u6269\u5c55\u4e86CommonGen\u6570\u636e\u96c6\uff0c\u521b\u5efa\u4e86\u4e00\u4e2a\u540d\u4e3aKITGI\u7684\u65b0\u57fa\u51c6\u3002KITGI\u5c06\u8f93\u5165\u6982\u5ff5\u96c6\u4e0e\u4eceConceptNet\u68c0\u7d22\u5230\u7684\u8bed\u4e49\u5173\u7cfb\u914d\u5bf9\uff0c\u5e76\u8f85\u4ee5\u4eba\u5de5\u6807\u6ce8\u7684\u8f93\u51fa\u3002\u5b9e\u9a8c\u91c7\u7528T5-Large\u6a21\u578b\uff0c\u5728\u4e24\u79cd\u6761\u4ef6\u4e0b\u8fdb\u884c\u6bd4\u8f83\uff1a\u4e00\u79cd\u662f\u4f7f\u7528\u5168\u90e8\u5916\u90e8\u77e5\u8bc6\uff0c\u53e6\u4e00\u79cd\u662f\u4f7f\u7528\u7ecf\u8fc7\u8fc7\u6ee4\u7684\u77e5\u8bc6\uff08\u6545\u610f\u79fb\u9664\u9ad8\u5ea6\u76f8\u5173\u7684\u8bed\u4e49\u5173\u7cfb\uff09\u3002\u7814\u7a76\u91c7\u7528\u4e86\u4e00\u4e2a\u4e3a\u671f\u4e09\u9636\u6bb5\u7684\u53ef\u89e3\u91ca\u6027\u8bc4\u4f30\u65b9\u6cd5\uff1a1.\u8bc6\u522b\u5e76\u79fb\u9664\u5173\u952e\u7684\u5916\u90e8\u77e5\u8bc6\uff1b2.\u4f7f\u7528\u5269\u4f59\u77e5\u8bc6\u91cd\u65b0\u751f\u6210\u53e5\u5b50\uff1b3.\u7531\u4eba\u5de5\u8bc4\u4f30\u751f\u6210\u53e5\u5b50\u7684\u5e38\u8bc6\u5408\u7406\u6027\u548c\u6982\u5ff5\u8986\u76d6\u5ea6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728\u5b8c\u6574\u5916\u90e8\u77e5\u8bc6\u7684\u6761\u4ef6\u4e0b\uff0c\u6a21\u578b\u751f\u6210\u7684\u53e5\u5b50\u5728\u5e38\u8bc6\u5408\u7406\u6027\u548c\u6982\u5ff5\u8986\u76d6\u5ea6\u4e24\u9879\u6307\u6807\u4e0a\u5747\u8fbe\u5230\u4e8691%\u7684\u6b63\u786e\u7387\u3002\u7136\u800c\uff0c\u5f53\u8fc7\u6ee4\u6389\u5173\u952e\u7684\u5916\u90e8\u77e5\u8bc6\u540e\uff0c\u6027\u80fd\u6025\u5267\u4e0b\u964d\u81f36%\u3002\u8fd9\u4e00\u663e\u8457\u7684\u6027\u80fd\u5dee\u5f02\u6709\u529b\u5730\u8bc1\u660e\u4e86\u76f8\u5173\u5916\u90e8\u77e5\u8bc6\u5bf9\u4e8e\u7ef4\u6301NLG\u8f93\u51fa\u7684\u8d28\u91cf\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "\u672c\u7814\u7a76\u660e\u786e\u4e86\u5916\u90e8\u77e5\u8bc6\uff0c\u7279\u522b\u662f\u5e38\u8bc6\u6027\u8bed\u4e49\u5173\u7cfb\uff0c\u5bf9\u4e8e\u63d0\u9ad8\u81ea\u7136\u8bed\u8a00\u751f\u6210\uff08NLG\uff09\u8d28\u91cf\uff08\u5305\u62ec\u8fde\u8d2f\u6027\u548c\u6982\u5ff5\u8986\u76d6\u5ea6\uff09\u7684\u5173\u952e\u4f5c\u7528\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u79fb\u9664\u8fd9\u4e9b\u77e5\u8bc6\u4f1a\u4e25\u91cd\u635f\u5bb3\u6a21\u578b\u7684\u751f\u6210\u80fd\u529b\u3002\u8fd9\u9879\u5de5\u4f5c\u5f3a\u8c03\u4e86\u8bbe\u8ba1\u53ef\u89e3\u91ca\u7684\u3001\u77e5\u8bc6\u589e\u5f3a\u7684NLG\u7cfb\u7edf\u7684\u5fc5\u8981\u6027\uff0c\u5e76\u547c\u5401\u5f00\u53d1\u8d85\u8d8a\u8868\u9762\u6307\u6807\u3001\u80fd\u591f\u8bc4\u4f30\u5e95\u5c42\u63a8\u7406\u80fd\u529b\u7684\u8bc4\u4f30\u6846\u67b6\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u96c6\u4e2d\u4e8e\u5f00\u53d1\u66f4\u6709\u6548\u7684\u77e5\u8bc6\u6574\u5408\u7b56\u7565\u4ee5\u53ca\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002"}}
{"id": "2510.24339", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24339", "abs": "https://arxiv.org/abs/2510.24339", "authors": ["Yunxuan Jiang", "Silan Hu", "Xiaoning Wang", "Yuanyuan Zhang", "Xiangyu Chang"], "title": "VDSAgents: A PCS-Guided Multi-Agent System for Veridical Data Science Automation", "comment": "29 pages, 6 figures. Yunxuan Jiang and Silan Hu contributed equally.\n  Code available at https://github.com/fengzer/VDSAgents", "summary": "Large language models (LLMs) become increasingly integrated into data science\nworkflows for automated system design. However, these LLM-driven data science\nsystems rely solely on the internal reasoning of LLMs, lacking guidance from\nscientific and theoretical principles. This limits their trustworthiness and\nrobustness, especially when dealing with noisy and complex real-world datasets.\nThis paper provides VDSAgents, a multi-agent system grounded in the\nPredictability-Computability-Stability (PCS) principles proposed in the\nVeridical Data Science (VDS) framework. Guided by PCS principles, the system\nimplements a modular workflow for data cleaning, feature engineering, modeling,\nand evaluation. Each phase is handled by an elegant agent, incorporating\nperturbation analysis, unit testing, and model validation to ensure both\nfunctionality and scientific auditability. We evaluate VDSAgents on nine\ndatasets with diverse characteristics, comparing it with state-of-the-art\nend-to-end data science systems, such as AutoKaggle and DataInterpreter, using\nDeepSeek-V3 and GPT-4o as backends. VDSAgents consistently outperforms the\nresults of AutoKaggle and DataInterpreter, which validates the feasibility of\nembedding PCS principles into LLM-driven data science automation.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u6570\u636e\u79d1\u5b66\u5de5\u4f5c\u6d41\u4e2d\u65e5\u76ca\u666e\u53ca\uff0c\u4f46\u5b83\u4eec\u4ec5\u4f9d\u8d56\u5185\u90e8\u63a8\u7406\uff0c\u7f3a\u4e4f\u79d1\u5b66\u548c\u7406\u8bba\u6307\u5bfc\uff0c\u5bfc\u81f4\u5728\u5904\u7406\u771f\u5b9e\u4e16\u754c\u6570\u636e\u65f6\u53ef\u4fe1\u5ea6\u548c\u9c81\u68d2\u6027\u4e0d\u8db3\u3002\u672c\u6587\u63d0\u51fa\u4e86VDSAgents\uff0c\u4e00\u4e2a\u57fa\u4e8eVeridical Data Science\uff08VDS\uff09\u6846\u67b6\u7684Predictability-Computability-Stability\uff08PCS\uff09\u539f\u7406\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u3002\u8be5\u7cfb\u7edf\u901a\u8fc7\u6a21\u5757\u5316\u5de5\u4f5c\u6d41\uff08\u6570\u636e\u6e05\u6d17\u3001\u7279\u5f81\u5de5\u7a0b\u3001\u5efa\u6a21\u3001\u8bc4\u4f30\uff09\u548c\u667a\u80fd\u4f53\uff08\u5305\u542b\u6270\u52a8\u5206\u6790\u3001\u5355\u5143\u6d4b\u8bd5\u3001\u6a21\u578b\u9a8c\u8bc1\uff09\u6765\u786e\u4fdd\u529f\u80fd\u6027\u548c\u79d1\u5b66\u53ef\u5ba1\u8ba1\u6027\u3002\u5728\u4e5d\u4e2a\u591a\u6837\u5316\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cVDSAgents\u4f18\u4e8eAutoKaggle\u548cDataInterpreter\u7b49\u73b0\u6709\u7cfb\u7edf\uff0c\u8bc1\u660e\u4e86\u5c06PCS\u539f\u7406\u5d4c\u5165LLM\u9a71\u52a8\u7684\u6570\u636e\u79d1\u5b66\u81ea\u52a8\u5316\u7684\u53ef\u884c\u6027\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u6570\u636e\u79d1\u5b66\u7cfb\u7edf\u8bbe\u8ba1\u4e2d\u867d\u7136\u81ea\u52a8\u5316\u7a0b\u5ea6\u9ad8\uff0c\u4f46\u5176\u51b3\u7b56\u8fc7\u7a0b\u4ec5\u4f9d\u8d56\u5185\u90e8\u63a8\u7406\uff0c\u7f3a\u4e4f\u79d1\u5b66\u548c\u7406\u8bba\u539f\u5219\u7684\u6307\u5bfc\u3002\u8fd9\u5bfc\u81f4\u7cfb\u7edf\u5728\u9762\u5bf9\u590d\u6742\u548c\u5e26\u6709\u566a\u58f0\u7684\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u65f6\uff0c\u5176\u53ef\u4fe1\u5ea6\u548c\u9c81\u68d2\u6027\u53d7\u5230\u9650\u5236\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u7ed3\u5408LLM\u7684\u81ea\u52a8\u5316\u80fd\u529b\u548c\u79d1\u5b66\u7406\u8bba\u7684\u65b9\u6cd5\uff0c\u4ee5\u63d0\u9ad8\u6570\u636e\u79d1\u5b66\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aVDSAgents\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u4ee5Veridical Data Science\uff08VDS\uff09\u6846\u67b6\u4e2d\u7684Predictability-Computability-Stability\uff08PCS\uff09\u539f\u7406\u4e3a\u6307\u5bfc\u3002\u7cfb\u7edf\u91c7\u7528\u6a21\u5757\u5316\u8bbe\u8ba1\uff0c\u5c06\u6570\u636e\u79d1\u5b66\u6d41\u7a0b\u5206\u89e3\u4e3a\u6570\u636e\u6e05\u6d17\u3001\u7279\u5f81\u5de5\u7a0b\u3001\u5efa\u6a21\u548c\u8bc4\u4f30\u56db\u4e2a\u9636\u6bb5\uff0c\u6bcf\u4e2a\u9636\u6bb5\u7531\u4e00\u4e2a\u72ec\u7acb\u7684\u667a\u80fd\u4f53\u8d1f\u8d23\u3002\u8fd9\u4e9b\u667a\u80fd\u4f53\u5728\u6267\u884c\u4efb\u52a1\u65f6\uff0c\u4f1a\u96c6\u6210\u6270\u52a8\u5206\u6790\u3001\u5355\u5143\u6d4b\u8bd5\u548c\u6a21\u578b\u9a8c\u8bc1\u7b49\u6280\u672f\uff0c\u4ee5\u786e\u4fdd\u5176\u8f93\u51fa\u7684\u6709\u6548\u6027\u548c\u79d1\u5b66\u4e0a\u7684\u53ef\u5ba1\u8ba1\u6027\u3002", "result": "\u5728\u4e5d\u4e2a\u4e0d\u540c\u7279\u5f81\u7684\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8bc4\u4f30\u8868\u660e\uff0cVDSAgents\u5728\u6027\u80fd\u4e0a\u8d85\u8d8a\u4e86AutoKaggle\u548cDataInterpreter\u7b49\u5148\u8fdb\u7684\u7aef\u5230\u7aef\u6570\u636e\u79d1\u5b66\u7cfb\u7edf\u3002\u8fd9\u5145\u5206\u8bc1\u660e\u4e86\u5c06PCS\u539f\u7406\u6210\u529f\u878d\u5165LLM\u9a71\u52a8\u7684\u6570\u636e\u79d1\u5b66\u81ea\u52a8\u5316\u662f\u53ef\u884c\u7684\uff0c\u5e76\u4e14\u80fd\u591f\u6709\u6548\u63d0\u5347\u7cfb\u7edf\u7684\u6027\u80fd\u548c\u53ef\u9760\u6027\u3002", "conclusion": "\u672c\u6587\u6210\u529f\u5730\u63d0\u51fa\u4e86VDSAgents\uff0c\u4e00\u4e2a\u5c06Veridical Data Science\uff08VDS\uff09\u6846\u67b6\u7684PCS\u539f\u7406\u5e94\u7528\u4e8eLLM\u9a71\u52a8\u7684\u6570\u636e\u79d1\u5b66\u81ea\u52a8\u5316\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u3002\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u5728\u63d0\u9ad8\u6570\u636e\u79d1\u5b66\u81ea\u52a8\u5316\u7cfb\u7edf\u6027\u80fd\u548c\u53ef\u4fe1\u5ea6\u65b9\u9762\u7684\u6709\u6548\u6027\u3002\u8fd9\u9879\u5de5\u4f5c\u4e3a\u6784\u5efa\u66f4\u53ef\u9760\u3001\u53ef\u5ba1\u8ba1\u7684\u6570\u636e\u79d1\u5b66\u5de5\u5177\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5e76\u4e3a\u672a\u6765\u5728LLM\u9a71\u52a8\u7684\u81ea\u52a8\u5316\u7cfb\u7edf\u4e2d\u878d\u5165\u79d1\u5b66\u7406\u8bba\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u3002\u672a\u6765\u7684\u7814\u7a76\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63a2\u7d22\u66f4\u590d\u6742\u7684PCS\u539f\u7406\u96c6\u6210\u548c\u667a\u80fd\u4f53\u95f4\u7684\u534f\u4f5c\u4f18\u5316\u3002"}}
{"id": "2510.24222", "categories": ["cs.CL", "I.2.7"], "pdf": "https://arxiv.org/pdf/2510.24222", "abs": "https://arxiv.org/abs/2510.24222", "authors": ["Adi Simhi", "Jonathan Herzig", "Itay Itzhak", "Dana Arad", "Zorik Gekhman", "Roi Reichart", "Fazl Barez", "Gabriel Stanovsky", "Idan Szpektor", "Yonatan Belinkov"], "title": "HACK: Hallucinations Along Certainty and Knowledge Axes", "comment": "The code is available at\n  https://github.com/technion-cs-nlp/HACK_Hallucinations_Along_Certainty_and_Knowledge_axes", "summary": "Hallucinations in LLMs present a critical barrier to their reliable usage.\nExisting research usually categorizes hallucination by their external\nproperties rather than by the LLMs' underlying internal properties. This\nexternal focus overlooks that hallucinations may require tailored mitigation\nstrategies based on their underlying mechanism. We propose a framework for\ncategorizing hallucinations along two axes: knowledge and certainty. Since\nparametric knowledge and certainty may vary across models, our categorization\nmethod involves a model-specific dataset construction process that\ndifferentiates between those types of hallucinations. Along the knowledge axis,\nwe distinguish between hallucinations caused by a lack of knowledge and those\noccurring despite the model having the knowledge of the correct response. To\nvalidate our framework along the knowledge axis, we apply steering mitigation,\nwhich relies on the existence of parametric knowledge to manipulate model\nactivations. This addresses the lack of existing methods to validate knowledge\ncategorization by showing a significant difference between the two\nhallucination types. We further analyze the distinct knowledge and\nhallucination patterns between models, showing that different hallucinations do\noccur despite shared parametric knowledge. Turning to the certainty axis, we\nidentify a particularly concerning subset of hallucinations where models\nhallucinate with certainty despite having the correct knowledge internally. We\nintroduce a new evaluation metric to measure the effectiveness of mitigation\nmethods on this subset, revealing that while some methods perform well on\naverage, they fail disproportionately on these critical cases. Our findings\nhighlight the importance of considering both knowledge and certainty in\nhallucination analysis and call for targeted mitigation approaches that\nconsider the hallucination underlying factors.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5e7b\u89c9\u95ee\u9898\u963b\u788d\u4e86\u5176\u53ef\u9760\u5e94\u7528\u3002\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8\u5e7b\u89c9\u7684\u5916\u5728\u8868\u73b0\uff0c\u5ffd\u89c6\u4e86\u5176\u5185\u5728\u673a\u5236\u7684\u5dee\u5f02\u3002\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u201c\u77e5\u8bc6\u201d\u548c\u201c\u786e\u5b9a\u6027\u201d\u53cc\u8f74\u7684\u5e7b\u89c9\u5206\u7c7b\u6846\u67b6\uff0c\u5e76\u636e\u6b64\u5f00\u53d1\u4e86\u6a21\u578b\u7279\u5b9a\u7684\u6570\u636e\u96c6\u3002\u5728\u201c\u77e5\u8bc6\u201d\u8f74\u4e0a\uff0c\u533a\u5206\u4e86\u56e0\u7f3a\u4e4f\u77e5\u8bc6\u548c\u5c3d\u7ba1\u62e5\u6709\u77e5\u8bc6\u5374\u4ea7\u751f\u5e7b\u89c9\u4e24\u79cd\u60c5\u51b5\uff0c\u5e76\u901a\u8fc7\u201c\u5f15\u5bfc\u201d\u5e72\u9884\u65b9\u6cd5\u9a8c\u8bc1\u4e86\u8fd9\u4e00\u5206\u7c7b\u7684\u6709\u6548\u6027\uff0c\u8bc1\u660e\u4e86\u4e24\u79cd\u5e7b\u89c9\u5728\u5e72\u9884\u4e0b\u7684\u663e\u8457\u5dee\u5f02\u3002\u7814\u7a76\u8fd8\u63ed\u793a\u4e86\u4e0d\u540c\u6a21\u578b\u5373\u4f7f\u62e5\u6709\u5171\u4eab\u7684\u53c2\u6570\u77e5\u8bc6\uff0c\u4e5f\u4f1a\u4ea7\u751f\u4e0d\u540c\u7684\u5e7b\u89c9\u6a21\u5f0f\u3002\u201c\u786e\u5b9a\u6027\u201d\u8f74\u4e0a\uff0c\u8bc6\u522b\u51fa\u6a21\u578b\u5728\u62e5\u6709\u6b63\u786e\u77e5\u8bc6\u65f6\u5374\u201c\u786e\u4fe1\u5730\u201d\u4ea7\u751f\u5e7b\u89c9\u7684\u7279\u5b9a\u5b50\u96c6\uff0c\u5e76\u63d0\u51fa\u65b0\u7684\u8bc4\u4f30\u6307\u6807\uff0c\u53d1\u73b0\u73b0\u6709\u7f13\u89e3\u65b9\u6cd5\u5728\u5e73\u5747\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u8fd9\u4e9b\u5173\u952e\u6848\u4f8b\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002\u7814\u7a76\u5f3a\u8c03\u4e86\u8003\u8651\u77e5\u8bc6\u548c\u786e\u5b9a\u6027\u5728\u5e7b\u89c9\u5206\u6790\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u5e76\u547c\u5401\u5f00\u53d1\u9488\u5bf9\u5e7b\u89c9\u5185\u5728\u56e0\u7d20\u7684\u5b9a\u5236\u5316\u7f13\u89e3\u7b56\u7565\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u751f\u6210\u5185\u5bb9\u65f6\u51fa\u73b0\u7684\u201c\u5e7b\u89c9\u201d\u73b0\u8c61\uff08\u5373\u751f\u6210\u4e0d\u51c6\u786e\u6216\u865a\u5047\u4fe1\u606f\uff09\u662f\u5176\u5e7f\u6cdb\u53ef\u9760\u5e94\u7528\u7684\u4e3b\u8981\u969c\u788d\u3002\u5f53\u524d\u7684\u5b66\u672f\u7814\u7a76\u5927\u591a\u4ece\u5916\u90e8\u7279\u5f81\u5165\u624b\u5bf9\u5e7b\u89c9\u8fdb\u884c\u5206\u7c7b\uff0c\u800c\u672a\u80fd\u6df1\u5165\u63a2\u7a76\u5bfc\u81f4\u5e7b\u89c9\u4ea7\u751f\u7684\u5185\u90e8\u673a\u5236\u3002\u8fd9\u79cd\u5916\u90e8\u89c6\u89d2\u53ef\u80fd\u5bfc\u81f4\u6240\u63d0\u51fa\u7684\u7f13\u89e3\u7b56\u7565\u4e0d\u591f\u7cbe\u786e\uff0c\u56e0\u4e3a\u4e0d\u540c\u673a\u5236\u7684\u5e7b\u89c9\u9700\u8981\u4e0d\u540c\u7684\u89e3\u51b3\u65b9\u6848\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u65e8\u5728\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\uff0c\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u5e7b\u89c9\u5206\u7c7b\u6846\u67b6\uff0c\u4ee5\u671f\u4e3a\u5f00\u53d1\u66f4\u6709\u6548\u7684\u5e7b\u89c9\u7f13\u89e3\u65b9\u6cd5\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u8df5\u6307\u5bfc\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e00\u4e2a\u521b\u65b0\u7684\u5e7b\u89c9\u5206\u7c7b\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u6cbf\u201c\u77e5\u8bc6\u201d\uff08knowledge\uff09\u548c\u201c\u786e\u5b9a\u6027\u201d\uff08certainty\uff09\u4e24\u4e2a\u7ef4\u5ea6\u5bf9\u5e7b\u89c9\u8fdb\u884c\u5212\u5206\u3002\u4e3a\u4e86\u5b9e\u73b0\u8fd9\u4e00\u5206\u7c7b\uff0c\u7814\u7a76\u4eba\u5458\u6784\u5efa\u4e86\u6a21\u578b\u7279\u5b9a\u7684\u6570\u636e\u96c6\uff0c\u8fd9\u662f\u56e0\u4e3a\u53c2\u6570\u77e5\u8bc6\u548c\u786e\u5b9a\u6027\u5728\u4e0d\u540c\u6a21\u578b\u4e4b\u95f4\u53ef\u80fd\u5b58\u5728\u5dee\u5f02\u3002\u5728\u201c\u77e5\u8bc6\u201d\u7ef4\u5ea6\u4e0a\uff0c\u7814\u7a76\u533a\u5206\u4e86\u4e24\u79cd\u7c7b\u578b\u7684\u5e7b\u89c9\uff1a\u4e00\u662f\u7531\u4e8e\u6a21\u578b\u7f3a\u4e4f\u76f8\u5173\u77e5\u8bc6\u800c\u4ea7\u751f\u7684\u5e7b\u89c9\uff1b\u4e8c\u662f\u5c3d\u7ba1\u6a21\u578b\u5185\u90e8\u62e5\u6709\u6b63\u786e\u77e5\u8bc6\uff0c\u4f46\u4ecd\u7136\u4ea7\u751f\u4e86\u9519\u8bef\u4fe1\u606f\u3002\u4e3a\u4e86\u9a8c\u8bc1\u201c\u77e5\u8bc6\u201d\u7ef4\u5ea6\u7684\u5206\u7c7b\u6709\u6548\u6027\uff0c\u7814\u7a76\u91c7\u7528\u4e86\u201c\u5f15\u5bfc\u201d\uff08steering\uff09\u5e72\u9884\u65b9\u6cd5\u3002\u8fd9\u79cd\u65b9\u6cd5\u5229\u7528\u4e86\u6a21\u578b\u53c2\u6570\u77e5\u8bc6\u7684\u5b58\u5728\uff0c\u901a\u8fc7\u64cd\u63a7\u6a21\u578b\u6fc0\u6d3b\u6765\u5f71\u54cd\u5176\u8f93\u51fa\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u901a\u8fc7\u5f15\u5bfc\u5e72\u9884\uff0c\u8fd9\u4e24\u79cd\u7c7b\u578b\u7684\u5e7b\u89c9\u5728\u6a21\u578b\u884c\u4e3a\u4e0a\u8868\u73b0\u51fa\u663e\u8457\u5dee\u5f02\uff0c\u4ece\u800c\u8bc1\u660e\u4e86\u8be5\u5206\u7c7b\u7684\u6709\u6548\u6027\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u5206\u6790\u4e86\u4e0d\u540c\u6a21\u578b\u5728\u77e5\u8bc6\u548c\u5e7b\u89c9\u6a21\u5f0f\u4e0a\u7684\u5dee\u5f02\uff0c\u5373\u4f7f\u5728\u62e5\u6709\u76f8\u540c\u53c2\u6570\u77e5\u8bc6\u7684\u60c5\u51b5\u4e0b\u4e5f\u662f\u5982\u6b64\u3002\u5728\u201c\u786e\u5b9a\u6027\u201d\u7ef4\u5ea6\u4e0a\uff0c\u7814\u7a76\u7279\u522b\u5173\u6ce8\u4e86\u4e00\u4e2a\u4ee4\u4eba\u62c5\u5fe7\u7684\u5b50\u96c6\uff1a\u6a21\u578b\u5728\u62e5\u6709\u6b63\u786e\u5185\u90e8\u77e5\u8bc6\u7684\u60c5\u51b5\u4e0b\uff0c\u5374\u4ee5\u9ad8\u5ea6\u786e\u5b9a\u7684\u65b9\u5f0f\u4ea7\u751f\u5e7b\u89c9\u3002\u4e3a\u4e86\u8bc4\u4f30\u7f13\u89e3\u65b9\u6cd5\u5728\u8fd9\u4e00\u7279\u5b9a\u5b50\u96c6\u4e0a\u7684\u6548\u679c\uff0c\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u7684\u8bc4\u4f30\u6307\u6807\u3002\u901a\u8fc7\u8be5\u6307\u6807\u7684\u5206\u6790\uff0c\u7814\u7a76\u53d1\u73b0\uff0c\u5c3d\u7ba1\u4e00\u4e9b\u73b0\u6709\u7684\u7f13\u89e3\u65b9\u6cd5\u5728\u5e73\u5747\u6c34\u5e73\u4e0a\u8868\u73b0\u5c1a\u53ef\uff0c\u4f46\u5728\u8fd9\u4e9b\u5173\u952e\u7684\u201c\u786e\u4fe1\u5e7b\u89c9\u201d\u6848\u4f8b\u4e0a\u5374\u8868\u73b0\u4e0d\u4f73\u3002", "result": "\u672c\u7814\u7a76\u7684\u4e3b\u8981\u53d1\u73b0\u5305\u62ec\uff1a1. \u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u5e7b\u89c9\u5206\u7c7b\u6846\u67b6\uff0c\u533a\u5206\u4e86\u201c\u77e5\u8bc6\u201d\u548c\u201c\u786e\u5b9a\u6027\u201d\u4e24\u4e2a\u7ef4\u5ea6\u30022. \u5728\u201c\u77e5\u8bc6\u201d\u7ef4\u5ea6\u4e0a\uff0c\u6210\u529f\u533a\u5206\u4e86\u56e0\u7f3a\u4e4f\u77e5\u8bc6\u548c\u62e5\u6709\u77e5\u8bc6\u5374\u4ea7\u751f\u5e7b\u89c9\u7684\u4e24\u79cd\u60c5\u51b5\uff0c\u5e76\u901a\u8fc7\u5f15\u5bfc\u5e72\u9884\u65b9\u6cd5\u9a8c\u8bc1\u4e86\u8fd9\u79cd\u533a\u5206\u7684\u6709\u6548\u6027\uff0c\u663e\u793a\u51fa\u4e24\u79cd\u5e7b\u89c9\u5728\u5e72\u9884\u4e0b\u7684\u663e\u8457\u4e0d\u540c\u30023. \u5206\u6790\u8868\u660e\uff0c\u5373\u4f7f\u6a21\u578b\u5171\u4eab\u76f8\u540c\u7684\u53c2\u6570\u77e5\u8bc6\uff0c\u5b83\u4eec\u5728\u5e7b\u89c9\u6a21\u5f0f\u4e0a\u4e5f\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u63ed\u793a\u4e86\u6a21\u578b\u5c42\u9762\u7684\u5f02\u8d28\u6027\u30024. \u8bc6\u522b\u51fa\u4e00\u79cd\u7279\u522b\u4ee4\u4eba\u62c5\u5fe7\u7684\u5e7b\u89c9\u5b50\u96c6\uff0c\u5373\u6a21\u578b\u5728\u62e5\u6709\u6b63\u786e\u77e5\u8bc6\u65f6\u5374\u201c\u786e\u4fe1\u5730\u201d\u4ea7\u751f\u5e7b\u89c9\u30025. \u5f15\u5165\u7684\u65b0\u8bc4\u4f30\u6307\u6807\u63ed\u793a\u4e86\u73b0\u6709\u7f13\u89e3\u65b9\u6cd5\u5728\u5904\u7406\u8fd9\u79cd\u201c\u786e\u4fe1\u5e7b\u89c9\u201d\u65f6\u7684\u4e0d\u8db3\uff0c\u5373\u5e73\u5747\u8868\u73b0\u826f\u597d\u4f46\u5728\u5173\u952e\u6848\u4f8b\u4e0a\u5931\u6548\u3002", "conclusion": "\u672c\u7814\u7a76\u5f3a\u8c03\u4e86\u5728\u5206\u6790\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5e7b\u89c9\u95ee\u9898\u65f6\uff0c\u5fc5\u987b\u540c\u65f6\u8003\u8651\u201c\u77e5\u8bc6\u201d\u7684\u53ef\u7528\u6027\u548c\u201c\u786e\u5b9a\u6027\u201d\u7684\u6c34\u5e73\u3002\u73b0\u6709\u7684\u5e7b\u89c9\u5206\u7c7b\u65b9\u6cd5\u8fc7\u4e8e\u4fa7\u91cd\u5916\u90e8\u8868\u73b0\uff0c\u800c\u5ffd\u7565\u4e86\u5185\u90e8\u673a\u5236\u7684\u91cd\u8981\u6027\u3002\u672c\u6587\u63d0\u51fa\u7684\u53cc\u8f74\u5206\u7c7b\u6846\u67b6\u4e3a\u7406\u89e3\u548c\u89e3\u51b3\u5e7b\u89c9\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u4e0d\u540c\u7c7b\u578b\u7684\u5e7b\u89c9\u9700\u8981\u5b9a\u5236\u5316\u7684\u7f13\u89e3\u7b56\u7565\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u90a3\u4e9b\u6a21\u578b\u201c\u786e\u4fe1\u5730\u201d\u4ea7\u751f\u5e7b\u89c9\u7684\u6848\u4f8b\uff0c\u73b0\u6709\u7684\u901a\u7528\u7f13\u89e3\u65b9\u6cd5\u6548\u679c\u6709\u9650\u3002\u672a\u6765\u7684\u5de5\u4f5c\u5e94\u7740\u91cd\u4e8e\u5f00\u53d1\u80fd\u591f\u7cbe\u786e\u8bc6\u522b\u548c\u6709\u6548\u5e72\u9884\u8fd9\u4e9b\u7279\u5b9a\u5e7b\u89c9\u7c7b\u578b\u7684\u6280\u672f\uff0c\u4ee5\u63d0\u5347LLM\u7684\u53ef\u9760\u6027\u548c\u53ef\u7528\u6027\u3002\u672c\u7814\u7a76\u7684\u5c40\u9650\u6027\u5728\u4e8e\u6a21\u578b\u7279\u5b9a\u7684\u6570\u636e\u96c6\u6784\u5efa\u8fc7\u7a0b\u53ef\u80fd\u9700\u8981\u5927\u91cf\u6807\u6ce8\u5de5\u4f5c\uff0c\u5e76\u4e14\u5f15\u5bfc\u5e72\u9884\u65b9\u6cd5\u7684\u666e\u9002\u6027\u6709\u5f85\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u3002"}}
{"id": "2510.24359", "categories": ["cs.AI", "cs.SY", "eess.SY", "q-bio.QM", "stat.AP"], "pdf": "https://arxiv.org/pdf/2510.24359", "abs": "https://arxiv.org/abs/2510.24359", "authors": ["Pedram Fard", "Alaleh Azhir", "Neguine Rezaii", "Jiazi Tian", "Hossein Estiri"], "title": "An N-of-1 Artificial Intelligence Ecosystem for Precision Medicine", "comment": "This study has been supported by grants from the National Institutes\n  of Health: The National Institute on Aging R01AG074372 and The National\n  Institute of Allergy and Infectious Diseases R01AI165535", "summary": "Artificial intelligence in medicine is built to serve the average patient. By\nminimizing error across large datasets, most systems deliver strong aggregate\naccuracy yet falter at the margins: patients with rare variants,\nmultimorbidity, or underrepresented demographics. This average patient fallacy\nerodes both equity and trust. We propose a different design: a multi-agent\necosystem for N-of-1 decision support. In this environment, agents clustered by\norgan systems, patient populations, and analytic modalities draw on a shared\nlibrary of models and evidence synthesis tools. Their results converge in a\ncoordination layer that weighs reliability, uncertainty, and data density\nbefore presenting the clinician with a decision-support packet: risk estimates\nbounded by confidence ranges, outlier flags, and linked evidence. Validation\nshifts from population averages to individual reliability, measured by error in\nlow-density regions, calibration in the small, and risk--coverage trade-offs.\nAnticipated challenges include computational demands, automation bias, and\nregulatory fit, addressed through caching strategies, consensus checks, and\nadaptive trial frameworks. By moving from monolithic models to orchestrated\nintelligence, this approach seeks to align medical AI with the first principle\nof medicine: care that is transparent, equitable, and centered on the\nindividual.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.24236", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24236", "abs": "https://arxiv.org/abs/2510.24236", "authors": ["Teague McMillan", "Gabriele Dominici", "Martin Gjoreski", "Marc Langheinrich"], "title": "Towards Transparent Reasoning: What Drives Faithfulness in Large Language Models?", "comment": "39th Conference on Neural Information Processing Systems (NeurIPS\n  2025) Workshop: NeurIPS 2025 Workshop on Evaluating the Evolving LLM\n  Lifecycle: Benchmarks, Emergent Abilities, and Scaling", "summary": "Large Language Models (LLMs) often produce explanations that do not\nfaithfully reflect the factors driving their predictions. In healthcare\nsettings, such unfaithfulness is especially problematic: explanations that omit\nsalient clinical cues or mask spurious shortcuts can undermine clinician trust\nand lead to unsafe decision support. We study how inference and training-time\nchoices shape explanation faithfulness, focusing on factors practitioners can\ncontrol at deployment. We evaluate three LLMs (GPT-4.1-mini, LLaMA 70B, LLaMA\n8B) on two datasets-BBQ (social bias) and MedQA (medical licensing questions),\nand manipulate the number and type of few-shot examples, prompting strategies,\nand training procedure. Our results show: (i) both the quantity and quality of\nfew-shot examples significantly impact model faithfulness; (ii) faithfulness is\nsensitive to prompting design; (iii) the instruction-tuning phase improves\nmeasured faithfulness on MedQA. These findings offer insights into strategies\nfor enhancing the interpretability and trustworthiness of LLMs in sensitive\ndomains.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.24247", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24247", "abs": "https://arxiv.org/abs/2510.24247", "authors": ["Ahmad Ghannam", "Naif Alharthi", "Faris Alasmary", "Kholood Al Tabash", "Shouq Sadah", "Lahouari Ghouti"], "title": "Abjad AI at NADI 2025: CATT-Whisper: Multimodal Diacritic Restoration Using Text and Speech Representations", "comment": null, "summary": "In this work, we tackle the Diacritic Restoration (DR) task for Arabic\ndialectal sentences using a multimodal approach that combines both textual and\nspeech information. We propose a model that represents the text modality using\nan encoder extracted from our own pre-trained model named CATT. The speech\ncomponent is handled by the encoder module of the OpenAI Whisper base model.\nOur solution is designed following two integration strategies. The former\nconsists of fusing the speech tokens with the input at an early stage, where\nthe 1500 frames of the audio segment are averaged over 10 consecutive frames,\nresulting in 150 speech tokens. To ensure embedding compatibility, these\naveraged tokens are processed through a linear projection layer prior to\nmerging them with the text tokens. Contextual encoding is guaranteed by the\nCATT encoder module. The latter strategy relies on cross-attention, where text\nand speech embeddings are fused. The cross-attention output is then fed to the\nCATT classification head for token-level diacritic prediction. To further\nimprove model robustness, we randomly deactivate the speech input during\ntraining, allowing the model to perform well with or without speech. Our\nexperiments show that the proposed approach achieves a word error rate (WER) of\n0.25 and a character error rate (CER) of 0.9 on the development set. On the\ntest set, our model achieved WER and CER scores of 0.55 and 0.13, respectively.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.24390", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24390", "abs": "https://arxiv.org/abs/2510.24390", "authors": ["Xianjun Gao", "Jianchun Liu", "Hongli Xu", "Liusheng Huang"], "title": "Improving LLM Reasoning via Dependency-Aware Query Decomposition and Logic-Parallel Content Expansion", "comment": null, "summary": "The integration of Large Language Models (LLMs) into real-time Web\napplications, such as AI-powered search and conversational agents, presents a\nfundamental Web infrastructure challenge: reconciling the demand for\nhigh-quality, complex reasoning with the stringent low-latency and\nhigh-throughput requirements of interactive services. Current LLM reasoning,\nhindered by computationally inefficient sequential generation and rigid\nreasoning strategies, creates a critical bottleneck for the Web services.\nExisting approaches typically optimize the LLM reasoning for either efficiency\nor quality but struggle to achieve both, and thus fail to meet the dual\nrequirements of modern Web platforms. To overcome these limitations, we propose\nOrion, a novel and efficient reasoning framework that enables dependency-aware\nquery decomposition and logic-parallel content expansion. Concretely, Orion\ndecomposes a single query reasoning process into two synergistic phases: (1)\n\\textit{key point generation}, which distills logically structured key points\nthrough retrieval-augmented few-shot prompting, and (2) \\textit{content\nparallel expansion}, which concurrently elaborates on these points based on a\ndependency graph to ensure logical consistency. Furthermore, Orion introduces a\npipeline scheduling mechanism that exploits the complementary computational\ncharacteristics of the two phases (generation imposes pressure on GPU computing\nand expansion stresses on GPU memory) across multiple queries, enabling\ncross-query parallelism and dramatically improving reasoning performance (\\ie,\nefficiency and quality). Experiments on diverse benchmarks show that Orion not\nonly delivers up to 4.33x higher token generation speed and 3.42x lower answer\nlatency over the baselines but also improves reasoning quality by up to 18.75%\nthrough explicitly modeling inter-point dependencies.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.24250", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24250", "abs": "https://arxiv.org/abs/2510.24250", "authors": ["Syed Zohaib Hassan", "P\u00e5l Halvorsen", "Miriam S. Johnson", "Pierre Lison"], "title": "Evaluating LLMs on Generating Age-Appropriate Child-Like Conversations", "comment": "11 pages excluding references and appendix. 3 figures and 6 tables", "summary": "Large Language Models (LLMs), predominantly trained on adult conversational\ndata, face significant challenges when generating authentic, child-like\ndialogue for specialized applications. We present a comparative study\nevaluating five different LLMs (GPT-4, RUTER-LLAMA-2-13b, GPTSW, NorMistral-7b,\nand NorBloom-7b) to generate age-appropriate Norwegian conversations for\nchildren aged 5 and 9 years. Through a blind evaluation by eleven education\nprofessionals using both real child interview data and LLM-generated text\nsamples, we assessed authenticity and developmental appropriateness. Our\nresults show that evaluators achieved strong inter-rater reliability (ICC=0.75)\nand demonstrated higher accuracy in age prediction for younger children\n(5-year-olds) compared to older children (9-year-olds). While GPT-4 and\nNorBloom-7b performed relatively well, most models generated language perceived\nas more linguistically advanced than the target age groups. These findings\nhighlight critical data-related challenges in developing LLM systems for\nspecialized applications involving children, particularly in low-resource\nlanguages where comprehensive age-appropriate lexical resources are scarce.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.24397", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24397", "abs": "https://arxiv.org/abs/2510.24397", "authors": ["Jiarui Qin", "Yunjia Xi", "Junjie Huang", "Renting Rui", "Di Yin", "Weiwen Liu", "Yong Yu", "Weinan Zhang", "Xing Sun"], "title": "APTBench: Benchmarking Agentic Potential of Base LLMs During Pre-Training", "comment": "46 pages", "summary": "With the rapid development of LLM-based agents, there is a growing trend to\nincorporate agent-specific data into the pre-training stage of LLMs, aiming to\nbetter align LLMs with real-world autonomous task execution. However, current\npre-training benchmarks primarily focus on isolated and static skills, e.g.,\ncommon knowledge or mathematical/code reasoning, and fail to reflect model's\nagentic capabilities. On the other hand, agent benchmarks are typically\ndesigned for post-trained models, requiring multi-turn task execution abilities\nthat base models struggle to support. Thus, there is a compelling need for a\nbenchmark that can evaluate agentic potentials during pre-training and guide\nthe model training more effectively. To address this gap, we propose APTBench,\na framework that converts real-world agent tasks and successful trajectories\ninto multiple-choice or text completion questions tailored for base models. It\nfocuses on core agentic abilities, e.g., planning and action, and covers key\nagent scenarios, software engineering and deep research. Compared to existing\ngeneral-purpose benchmarks, APTBench offers a more predictive signal of a\nmodel's downstream performance as an agent, while remaining significantly more\nlightweight and cost-effective than full-scale, end-to-end agent evaluations\nafter post-training.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.24259", "categories": ["cs.CL", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.24259", "abs": "https://arxiv.org/abs/2510.24259", "authors": ["Ziqi Ma", "Sao Mai Nguyen", "Philippe Xu"], "title": "Can LLMs Translate Human Instructions into a Reinforcement Learning Agent's Internal Emergent Symbolic Representation?", "comment": null, "summary": "Emergent symbolic representations are critical for enabling developmental\nlearning agents to plan and generalize across tasks. In this work, we\ninvestigate whether large language models (LLMs) can translate human natural\nlanguage instructions into the internal symbolic representations that emerge\nduring hierarchical reinforcement learning. We apply a structured evaluation\nframework to measure the translation performance of commonly seen LLMs -- GPT,\nClaude, Deepseek and Grok -- across different internal symbolic partitions\ngenerated by a hierarchical reinforcement learning algorithm in the Ant Maze\nand Ant Fall environments. Our findings reveal that although LLMs demonstrate\nsome ability to translate natural language into a symbolic representation of\nthe environment dynamics, their performance is highly sensitive to partition\ngranularity and task complexity. The results expose limitations in current LLMs\ncapacity for representation alignment, highlighting the need for further\nresearch on robust alignment between language and internal agent\nrepresentations.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u80fd\u5426\u5c06\u4eba\u7c7b\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u7ffb\u8bd1\u6210\u5c42\u6b21\u5316\u5f3a\u5316\u5b66\u4e60\uff08HRL\uff09\u4e2d\u51fa\u73b0\u7684\u5185\u90e8\u7b26\u53f7\u8868\u793a\uff0c\u4ee5\u5b9e\u73b0\u5f00\u53d1\u5b66\u4e60\u667a\u80fd\u4f53\u8fdb\u884c\u89c4\u5212\u548c\u6cdb\u5316\u3002\u7814\u7a76\u53d1\u73b0\u5728Ant Maze\u548cAnt Fall\u73af\u5883\u4e2d\uff0cLLMs\uff08\u5305\u62ecGPT\u3001Claude\u3001Deepseek\u548cGrok\uff09\u5728\u7ffb\u8bd1\u8bed\u8a00\u5230\u73af\u5883\u52a8\u529b\u5b66\u7b26\u53f7\u8868\u793a\u65b9\u9762\u8868\u73b0\u51fa\u4e00\u5b9a\u80fd\u529b\uff0c\u4f46\u6027\u80fd\u9ad8\u5ea6\u4f9d\u8d56\u4e8e\u5206\u533a\u7c92\u5ea6\u548c\u4efb\u52a1\u590d\u6742\u5ea6\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5f53\u524dLLMs\u5728\u8868\u793a\u5bf9\u9f50\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee5\u5b9e\u73b0\u8bed\u8a00\u4e0e\u667a\u80fd\u4f53\u5185\u90e8\u8868\u793a\u4e4b\u95f4\u7684\u7a33\u5065\u5bf9\u9f50\u3002", "motivation": "\u5f00\u53d1\u5b66\u4e60\u667a\u80fd\u4f53\u9700\u8981\u80fd\u591f\u89c4\u5212\u548c\u6cdb\u5316\u4efb\u52a1\u7684\u6d8c\u73b0\u5f0f\u7b26\u53f7\u8868\u793a\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u662f\u5426\u80fd\u5c06\u4eba\u7c7b\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u6709\u6548\u7ffb\u8bd1\u6210\u5c42\u6b21\u5316\u5f3a\u5316\u5b66\u4e60\uff08HRL\uff09\u8fc7\u7a0b\u4e2d\u51fa\u73b0\u7684\u5185\u90e8\u7b26\u53f7\u8868\u793a\uff0c\u4ee5\u5f25\u5408\u8bed\u8a00\u7406\u89e3\u4e0e\u667a\u80fd\u4f53\u5185\u90e8\u8868\u5f81\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u7814\u7a76\u4eba\u5458\u5c06LLMs\uff08GPT\u3001Claude\u3001Deepseek\u548cGrok\uff09\u5e94\u7528\u4e8eAnt Maze\u548cAnt Fall\u73af\u5883\uff0c\u5e76\u4f7f\u7528\u5c42\u6b21\u5316\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u751f\u6210\u7684\u4e0d\u540c\u5185\u90e8\u7b26\u53f7\u5206\u533a\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u8bc4\u4f30\u6846\u67b6\u6765\u8861\u91cfLLMs\u7684\u7ffb\u8bd1\u6027\u80fd\u3002\u8bc4\u4f30\u6807\u51c6\u5305\u62ec\u4e0d\u540c\u7b26\u53f7\u5206\u533a\u7c92\u5ea6\u548c\u4efb\u52a1\u590d\u6742\u5ea6\u4e0b\u7684\u7ffb\u8bd1\u51c6\u786e\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u867d\u7136LLMs\u5728\u5c06\u81ea\u7136\u8bed\u8a00\u7ffb\u8bd1\u6210\u73af\u5883\u52a8\u529b\u5b66\u7684\u7b26\u53f7\u8868\u793a\u65b9\u9762\u663e\u793a\u51fa\u4e00\u5b9a\u7684\u6f5c\u529b\uff0c\u4f46\u5176\u6027\u80fd\u53d7\u5230\u5206\u533a\u7c92\u5ea6\u548c\u4efb\u52a1\u590d\u6742\u5ea6\u7684\u663e\u8457\u5f71\u54cd\u3002\u8fd9\u79cd\u654f\u611f\u6027\u66b4\u9732\u4e86\u5f53\u524dLLMs\u5728\u8868\u793a\u5bf9\u9f50\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u8868\u660e\u5b83\u4eec\u5728\u7406\u89e3\u548c\u6620\u5c04\u590d\u6742\u7b26\u53f7\u7ed3\u6784\u65b9\u9762\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\u3002", "conclusion": "\u672c\u7814\u7a76\u63ed\u793a\u4e86\u5f53\u524dLLMs\u5728\u5c06\u81ea\u7136\u8bed\u8a00\u6307\u4ee4\u4e0e\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u7684\u5185\u90e8\u7b26\u53f7\u8868\u793a\u5bf9\u9f50\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\u3002\u5c3d\u7ba1LLMs\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u53ef\u4ee5\u8fdb\u884c\u7ffb\u8bd1\uff0c\u4f46\u5176\u6027\u80fd\u4e0d\u7a33\u5b9a\uff0c\u6613\u53d7\u8868\u793a\u7c92\u5ea6\u548c\u4efb\u52a1\u590d\u6742\u6027\u7684\u5f71\u54cd\u3002\u8fd9\u5f3a\u8c03\u4e86\u5728\u5f00\u53d1\u66f4\u901a\u7528\u7684AI\u667a\u80fd\u4f53\u65b9\u9762\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u63a2\u7d22\u548c\u6539\u8fdb\u8bed\u8a00\u4e0e\u5185\u90e8\u8868\u5f81\u4e4b\u95f4\u7684\u7a33\u5065\u5bf9\u9f50\u673a\u5236\u3002\u672a\u6765\u7684\u7814\u7a76\u5e94\u5173\u6ce8\u5982\u4f55\u63d0\u9ad8LLMs\u5728\u5904\u7406\u4e0d\u540c\u7c92\u5ea6\u548c\u590d\u6742\u5ea6\u7684\u7b26\u53f7\u8868\u793a\u65f6\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2510.24435", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24435", "abs": "https://arxiv.org/abs/2510.24435", "authors": ["Benjamin Grando Moreira"], "title": "Human-Level Reasoning: A Comparative Study of Large Language Models on Logical and Abstract Reasoning", "comment": "12 pages", "summary": "Evaluating reasoning ability in Large Language Models (LLMs) is important for\nadvancing artificial intelligence, as it transcends mere linguistic task\nperformance. It involves understanding whether these models truly understand\ninformation, perform inferences, and are able to draw conclusions in a logical\nand valid way. This study compare logical and abstract reasoning skills of\nseveral LLMs - including GPT, Claude, DeepSeek, Gemini, Grok, Llama, Mistral,\nPerplexity, and Sabi\\'a - using a set of eight custom-designed reasoning\nquestions. The LLM results are benchmarked against human performance on the\nsame tasks, revealing significant differences and indicating areas where LLMs\nstruggle with deduction.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86\u5305\u62ecGPT\u3001Claude\u3001DeepSeek\u3001Gemini\u3001Grok\u3001Llama\u3001Mistral\u3001Perplexity\u548cSabi'a\u5728\u5185\u7684\u591a\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u903b\u8f91\u548c\u62bd\u8c61\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u4e0e\u4eba\u7c7b\u8868\u73b0\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53d1\u73b0\u4e86LLMs\u5728\u6f14\u7ece\u63a8\u7406\u65b9\u9762\u5b58\u5728\u7684\u663e\u8457\u5dee\u5f02\u548c\u6311\u6218\u3002", "motivation": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u63a8\u7406\u80fd\u529b\u5bf9\u4e8e\u63a8\u52a8\u4eba\u5de5\u667a\u80fd\u53d1\u5c55\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u4e3a\u5b83\u8d85\u8d8a\u4e86\u5355\u7eaf\u7684\u8bed\u8a00\u4efb\u52a1\u8868\u73b0\u3002\u8fd9\u6d89\u53ca\u5230\u7406\u89e3\u6a21\u578b\u662f\u5426\u771f\u6b63\u7406\u89e3\u4fe1\u606f\u3001\u6267\u884c\u63a8\u7406\u4ee5\u53ca\u80fd\u5426\u4ee5\u5408\u4e4e\u903b\u8f91\u4e14\u6709\u6548\u7684\u65b9\u5f0f\u5f97\u51fa\u7ed3\u8bba\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u4e86\u4e00\u5957\u516b\u4e2a\u5b9a\u5236\u8bbe\u8ba1\u7684\u63a8\u7406\u95ee\u9898\u6765\u6bd4\u8f83\u591a\u4e2aLLMs\uff08\u5305\u62ecGPT\u3001Claude\u3001DeepSeek\u3001Gemini\u3001Grok\u3001Llama\u3001Mistral\u3001Perplexity\u548cSabi'a\uff09\u7684\u903b\u8f91\u548c\u62bd\u8c61\u63a8\u7406\u6280\u80fd\u3002LLM\u7684\u7ed3\u679c\u4e0e\u4eba\u7c7b\u5728\u76f8\u540c\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0c\u5728\u6240\u6d4b\u8bd5\u7684LLMs\u4e0e\u4eba\u7c7b\u8868\u73b0\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u7a81\u663e\u4e86LLMs\u5728\u6f14\u7ece\u63a8\u7406\u65b9\u9762\u5b58\u5728\u7684\u4e0d\u8db3\u4e4b\u5904\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u5bf9\u6bd4\u591a\u4e2a\u4eba\u5de5\u667a\u80fd\u6a21\u578b\u548c\u4eba\u7c7b\u5728\u7279\u5b9a\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u63ed\u793a\u4e86\u5f53\u524dLLMs\u5728\u903b\u8f91\u548c\u62bd\u8c61\u63a8\u7406\u80fd\u529b\u4e0a\u7684\u5c40\u9650\u6027\uff0c\u5e76\u4e3a\u672a\u6765\u6539\u8fdb\u8fd9\u4e9b\u6a21\u578b\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2510.24295", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24295", "abs": "https://arxiv.org/abs/2510.24295", "authors": ["M\u0103d\u0103lina Zgreab\u0103n", "Tejaswini Deoskar", "Lasha Abzianidze"], "title": "MERGE: Minimal Expression-Replacement GEneralization Test for Natural Language Inference", "comment": "Pre-print", "summary": "In recent years, many generalization benchmarks have shown language models'\nlack of robustness in natural language inference (NLI). However, manually\ncreating new benchmarks is costly, while automatically generating high-quality\nones, even by modifying existing benchmarks, is extremely difficult. In this\npaper, we propose a methodology for automatically generating high-quality\nvariants of original NLI problems by replacing open-class words, while\ncrucially preserving their underlying reasoning. We dub our generalization test\nas MERGE (Minimal Expression-Replacements GEneralization), which evaluates the\ncorrectness of models' predictions across reasoning-preserving variants of the\noriginal problem. Our results show that NLI models' perform 4-20% worse on\nvariants, suggesting low generalizability even on such minimally altered\nproblems. We also analyse how word class of the replacements, word probability,\nand plausibility influence NLI models' performance.", "AI": {"tldr": "\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u63a8\u7406\uff08NLI\uff09\u65b9\u9762\u7f3a\u4e4f\u9c81\u68d2\u6027\uff0c\u4f46\u521b\u5efa\u65b0\u57fa\u51c6\u7684\u6210\u672c\u9ad8\u6602\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMERGE\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u66ff\u6362\u5f00\u653e\u7c7b\u8bcd\u8bed\u5e76\u4fdd\u7559\u63a8\u7406\u6765\u81ea\u52a8\u751f\u6210NLI\u95ee\u9898\u7684\u53d8\u4f53\uff0c\u4ee5\u8bc4\u4f30\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002\u7ed3\u679c\u663e\u793a\uff0c\u6a21\u578b\u5728\u8fd9\u4e9b\u5fae\u5c0f\u6539\u52a8\u7684\u95ee\u9898\u4e0a\u7684\u8868\u73b0\u4e0b\u964d\u4e864-20%\uff0c\u8868\u660e\u5176\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u3002\u7814\u7a76\u8fd8\u5206\u6790\u4e86\u66ff\u6362\u8bcd\u7684\u8bcd\u7c7b\u3001\u8bcd\u9891\u548c\u53ef\u4fe1\u5ea6\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "motivation": "\u5c3d\u7ba1\u5df2\u6709\u7814\u7a76\u8868\u660e\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u63a8\u7406\uff08NLI\uff09\u4efb\u52a1\u4e0a\u5b58\u5728\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u4f46\u624b\u52a8\u521b\u5efa\u65b0\u7684\u6d4b\u8bd5\u57fa\u51c6\u65e2\u8017\u65f6\u53c8\u6602\u8d35\uff0c\u800c\u81ea\u52a8\u751f\u6210\u9ad8\u8d28\u91cf\u7684NLI\u53d8\u4f53\uff08\u5373\u4f7f\u662f\u4fee\u6539\u73b0\u6709\u57fa\u51c6\uff09\u4e5f\u6781\u5176\u56f0\u96be\u3002\u56e0\u6b64\uff0c\u8feb\u5207\u9700\u8981\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u81ea\u52a8\u751f\u6210\u80fd\u591f\u8bc4\u4f30\u6a21\u578b\u9c81\u68d2\u6027\u7684NLI\u53d8\u4f53\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMERGE\uff08Minimal Expression-Replacements GEneralization\uff09\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u81ea\u52a8\u751f\u6210NLI\u95ee\u9898\u7684\u53d8\u4f53\u3002\u8be5\u65b9\u6cd5\u7684\u6838\u5fc3\u5728\u4e8e\u901a\u8fc7\u66ff\u6362\u95ee\u9898\u4e2d\u7684\u5f00\u653e\u7c7b\u8bcd\u8bed\uff08\u5982\u540d\u8bcd\u3001\u52a8\u8bcd\u3001\u5f62\u5bb9\u8bcd\u3001\u526f\u8bcd\uff09\u6765\u521b\u5efa\u65b0\u53d8\u4f53\uff0c\u540c\u65f6\u786e\u4fdd\u8fd9\u4e9b\u66ff\u6362\u4e0d\u4f1a\u6539\u53d8\u95ee\u9898\u7684\u57fa\u672c\u63a8\u7406\u7ed3\u6784\u3002\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\uff0cMERGE\u751f\u6210\u4e86\u80fd\u591f\u4e25\u683c\u8bc4\u4f30\u6a21\u578b\u5728\u7ec6\u5fae\u53d8\u5316\u4e0b\u63a8\u7406\u80fd\u529b\u7684\u65b0\u6d4b\u8bd5\u96c6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728MERGE\u751f\u6210\u7684\u53d8\u4f53\u4e0a\uff0cNLI\u6a21\u578b\u7684\u8868\u73b0\u6bd4\u5728\u539f\u59cb\u95ee\u9898\u4e0a\u5dee4-20%\u3002\u8fd9\u4e00\u7ed3\u679c\u51f8\u663e\u4e86\u5373\u4f7f\u662f\u7ecf\u8fc7\u6700\u5c0f\u5316\u6539\u52a8\u7684NLI\u95ee\u9898\uff0c\u73b0\u6709\u6a21\u578b\u4e5f\u8868\u73b0\u51fa\u8f83\u4f4e\u7684\u6cdb\u5316\u80fd\u529b\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u6df1\u5165\u5206\u6790\u4e86\u66ff\u6362\u8bcd\u7684\u8bcd\u7c7b\u3001\u8bcd\u9891\u4ee5\u53ca\u53ef\u4fe1\u5ea6\u7b49\u56e0\u7d20\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u4e3a\u7406\u89e3\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u7684\u5c40\u9650\u6027\u63d0\u4f9b\u4e86\u66f4\u7ec6\u81f4\u7684\u89c6\u89d2\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684MERGE\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u81ea\u52a8\u751f\u6210NLI\u95ee\u9898\u7684\u53d8\u4f53\uff0c\u4e3a\u8bc4\u4f30\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u9896\u4e14\u6210\u672c\u6548\u76ca\u9ad8\u7684\u65b9\u5f0f\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u73b0\u6709NLI\u6a21\u578b\u5728\u8fd9\u4e9b\u7ecf\u8fc7\u5fae\u5c0f\u6539\u52a8\u7684\u53d8\u4f53\u4e0a\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u8868\u660e\u5176\u6cdb\u5316\u80fd\u529b\u4ecd\u6709\u5f85\u63d0\u9ad8\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63a2\u7d22MERGE\u65b9\u6cd5\u7684\u6269\u5c55\u6027\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u5176\u4ed6\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\uff0c\u4ee5\u66f4\u5168\u9762\u5730\u8bc4\u4f30\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2510.24302", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24302", "abs": "https://arxiv.org/abs/2510.24302", "authors": ["Shangyu Xing", "Siyuan Wang", "Chenyuan Yang", "Xinyu Dai", "Xiang Ren"], "title": "Lookahead Tree-Based Rollouts for Enhanced Trajectory-Level Exploration in Reinforcement Learning with Verifiable Rewards", "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR), particularly with\nalgorithms like Group Relative Policy Optimization (GRPO), has proven highly\neffective in enhancing the reasoning capabilities of large language models.\nHowever, a critical bottleneck in current pipelines lies in the limited\ndiversity of sampled trajectories during group rollouts. Homogeneous\ntrajectories and their associated rewards would diminish the return signals for\npolicy updates, thereby hindering effective policy learning. This lack of\ndiversity stems primarily from token-level stochastic sampling, where local\nvariations are likely to collapse into near-identical reasoning paths. To\naddress this limitation, we propose Lookahead Tree-Based Rollouts (LATR), a\nnovel rollout strategy designed to explicitly promotes trajectory-level\ndiversity by enforcing branching into different candidate tokens likely to\nyield distinct continuations. Specifically, LATR iteratively operates in three\nstages: (1) branching at high-uncertainty generation steps, (2) performing\nlookahead simulation for each new branch, and (3) pruning branches that\nexhibits prolonged similarity during simulation. Compared with stochastic\nSampling, LATR accelerates policy learning by 131% on average and improves\nfinal pass@1 performance by 4.2% on both GRPO and Dynamic sAmpling Policy\nOptimization (DAPO) algorithms across different reasoning tasks. Our code and\ndata are publicly available at https://github.com/starreeze/latr.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u548c\u53ef\u9a8c\u8bc1\u5956\u52b1\uff08RLVR\uff09\u7684\u80cc\u666f\u4e0b\uff0c\u7279\u522b\u662f\u4f7f\u7528GRPO\u7b49\u7b97\u6cd5\uff0c\u5176\u63a8\u7406\u80fd\u529b\u5f97\u5230\u4e86\u663e\u8457\u63d0\u5347\u3002\u7136\u800c\uff0c\u5f53\u524d\u6d41\u7a0b\u7684\u4e00\u4e2a\u5173\u952e\u74f6\u9888\u5728\u4e8e\uff0c\u5728\u7fa4\u4f53\u56de\u653e\u8fc7\u7a0b\u4e2d\uff0c\u91c7\u6837\u8f68\u8ff9\u7684\u591a\u6837\u6027\u6709\u9650\u3002\u540c\u8d28\u5316\u8f68\u8ff9\u53ca\u5176\u76f8\u5173\u5956\u52b1\u4f1a\u524a\u5f31\u7b56\u7565\u66f4\u65b0\u7684\u56de\u62a5\u4fe1\u53f7\uff0c\u4ece\u800c\u963b\u788d\u6709\u6548\u7684\u7b56\u7565\u5b66\u4e60\u3002\u8fd9\u79cd\u591a\u6837\u6027\u4e0d\u8db3\u4e3b\u8981\u662f\u7531\u4e8etoken\u7ea7\u522b\u7684\u968f\u673a\u91c7\u6837\uff0c\u5c40\u90e8\u53d8\u5316\u5f88\u53ef\u80fd\u6536\u655b\u5230\u51e0\u4e4e\u76f8\u540c\u7684\u63a8\u7406\u8def\u5f84\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u9650\u5236\uff0c\u6211\u4eec\u63d0\u51fa\u4e86Lookahead Tree-Based Rollouts\uff08LATR\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u9896\u7684\u56de\u653e\u7b56\u7565\uff0c\u65e8\u5728\u901a\u8fc7\u5f3a\u5236\u8fdb\u884c\u5206\u652f\u5230\u53ef\u80fd\u4ea7\u751f\u4e0d\u540c\u5ef6\u7eed\u7684\u5019\u9009token\u6765\u660e\u786e\u5730\u4fc3\u8fdb\u8f68\u8ff9\u7ea7\u522b\u7684\u591a\u6837\u6027\u3002\u4e0e\u968f\u673a\u91c7\u6837\u76f8\u6bd4\uff0cLATR\u5728GRPO\u548cDAPO\u7b97\u6cd5\u4e0a\u5206\u522b\u5e73\u5747\u5c06\u7b56\u7565\u5b66\u4e60\u901f\u5ea6\u63d0\u9ad8\u4e86131%\uff0c\u5e76\u5c06\u6700\u7ec8\u7684pass@1\u6027\u80fd\u63d0\u9ad8\u4e864.2%\u3002", "motivation": "\u5f53\u524d\u7528\u4e8e\u589e\u5f3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u63a8\u7406\u80fd\u529b\u7684\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u57fa\u4e8e\u53ef\u9a8c\u8bc1\u5956\u52b1\uff08RLVR\uff09\u7684\u7b97\u6cd5\uff08\u5982Group Relative Policy Optimization, GRPO\uff09\uff0c\u5728\u5b9e\u8df5\u4e2d\u53d7\u5230\u91c7\u6837\u8f68\u8ff9\u591a\u6837\u6027\u4e0d\u8db3\u7684\u9650\u5236\u3002\u8fd9\u79cd\u591a\u6837\u6027\u4e0d\u8db3\u6e90\u4e8etoken\u7ea7\u522b\u7684\u968f\u673a\u91c7\u6837\uff0c\u5bfc\u81f4\u751f\u6210\u7684\u8f68\u8ff9\u8d8b\u4e8e\u540c\u8d28\u5316\uff0c\u4ece\u800c\u524a\u5f31\u4e86\u7b56\u7565\u66f4\u65b0\u4fe1\u53f7\uff0c\u963b\u788d\u4e86\u6a21\u578b\u7684\u6709\u6548\u5b66\u4e60\u3002\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u5bf9\u4e8e\u8fdb\u4e00\u6b65\u63d0\u5347LLM\u7684\u63a8\u7406\u80fd\u529b\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLookahead Tree-Based Rollouts\uff08LATR\uff09\u7684\u65b0\u578b\u56de\u653e\u7b56\u7565\uff0c\u65e8\u5728\u901a\u8fc7\u663e\u5f0f\u5730\u4fc3\u8fdb\u8f68\u8ff9\u5c42\u9762\u7684\u591a\u6837\u6027\u6765\u514b\u670d\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002LATR\u901a\u8fc7\u4ee5\u4e0b\u4e09\u4e2a\u9636\u6bb5\u8fed\u4ee3\u8fdb\u884c\uff1a1.\u5728\u751f\u6210\u4e0d\u786e\u5b9a\u6027\u9ad8\u7684\u6b65\u9aa4\u8fdb\u884c\u5206\u652f\uff1b2.\u5bf9\u6bcf\u4e2a\u65b0\u5206\u652f\u8fdb\u884c\u524d\u77bb\u6027\u6a21\u62df\uff1b3.\u4fee\u526a\u5728\u6a21\u62df\u8fc7\u7a0b\u4e2d\u8868\u73b0\u51fa\u957f\u671f\u76f8\u4f3c\u6027\u7684\u5206\u652f\u3002\u8be5\u65b9\u6cd5\u65e8\u5728\u901a\u8fc7\u63a2\u7d22\u66f4\u591a\u6837\u5316\u7684\u63a8\u7406\u8def\u5f84\u6765\u4e30\u5bcc\u7b56\u7565\u66f4\u65b0\u4fe1\u53f7\u3002", "result": "\u4e0e\u6807\u51c6\u7684\u968f\u673a\u91c7\u6837\u65b9\u6cd5\u76f8\u6bd4\uff0cLATR\u5728GRPO\u548cDynamic sAmpling Policy Optimization (DAPO)\u7b97\u6cd5\u4e0a\u5747\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cLATR\u5e73\u5747\u5c06\u7b56\u7565\u5b66\u4e60\u901f\u5ea6\u63d0\u9ad8\u4e86131%\uff0c\u5e76\u5c06\u6700\u7ec8\u7684pass@1\u6027\u80fd\u63d0\u9ad8\u4e864.2%\u3002\u8fd9\u4e9b\u6539\u8fdb\u5728\u4e0d\u540c\u7684\u63a8\u7406\u4efb\u52a1\u4e0a\u5f97\u5230\u4e86\u9a8c\u8bc1\u3002", "conclusion": "Lookahead Tree-Based Rollouts\uff08LATR\uff09\u662f\u4e00\u79cd\u6709\u6548\u7684\u65b0\u578b\u56de\u653e\u7b56\u7565\uff0c\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u57fa\u4e8eRLVR\u7684LLM\u7684\u7b56\u7565\u5b66\u4e60\u6548\u7387\u548c\u63a8\u7406\u6027\u80fd\u3002\u901a\u8fc7\u5f3a\u5236\u7b56\u7565\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u63a2\u7d22\u66f4\u591a\u6837\u5316\u7684\u8def\u5f84\uff0cLATR\u514b\u670d\u4e86\u4f20\u7edf\u968f\u673a\u91c7\u6837\u65b9\u6cd5\u5e26\u6765\u7684\u591a\u6837\u6027\u4e0d\u8db3\u95ee\u9898\uff0c\u4ece\u800c\u52a0\u901f\u4e86\u7b56\u7565\u5b66\u4e60\u5e76\u63d0\u5347\u4e86\u6700\u7ec8\u7684\u6a21\u578b\u8868\u73b0\u3002\u8be5\u7814\u7a76\u4e3a\u672a\u6765\u5728LLM\u63a8\u7406\u80fd\u529b\u65b9\u9762\u7684\u5de5\u4f5c\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u548c\u6539\u8fdb\u65b9\u5411\u3002"}}
{"id": "2510.24320", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24320", "abs": "https://arxiv.org/abs/2510.24320", "authors": ["Zhiheng Xi", "Jixuan Huang", "Xin Guo", "Boyang Hong", "Dingwen Yang", "Xiaoran Fan", "Shuo Li", "Zehui Chen", "Junjie Ye", "Siyu Yuan", "Zhengyin Du", "Xuesong Yao", "Yufei Xu", "Jiecao Chen", "Rui Zheng", "Tao Gui", "Qi Zhang", "Xuanjing Huang"], "title": "Critique-RL: Training Language Models for Critiquing through Two-Stage Reinforcement Learning", "comment": "Preprint, 25 pages, 9 figures. Code:\n  https://github.com/WooooDyy/Critique-RL", "summary": "Training critiquing language models to assess and provide feedback on model\noutputs is a promising way to improve LLMs for complex reasoning tasks.\nHowever, existing approaches typically rely on stronger supervisors for\nannotating critique data. To address this, we propose Critique-RL, an online RL\napproach for developing critiquing language models without stronger\nsupervision. Our approach operates on a two-player paradigm: the actor\ngenerates a response, the critic provides feedback, and the actor refines the\nresponse accordingly. We first reveal that relying solely on indirect reward\nsignals from the actor's outputs for RL optimization often leads to\nunsatisfactory critics: while their helpfulness (i.e., providing constructive\nfeedback) improves, the discriminability (i.e., determining whether a response\nis high-quality or not) remains poor, resulting in marginal performance gains.\nTo overcome this, Critique-RL adopts a two-stage optimization strategy. In\nstage I, it reinforces the discriminability of the critic with direct\nrule-based reward signals; in stage II, it introduces indirect rewards based on\nactor refinement to improve the critic's helpfulness, while maintaining its\ndiscriminability via appropriate regularization. Extensive experiments across\nvarious tasks and models show that Critique-RL delivers substantial performance\nimprovements. For example, it achieves a 9.02% gain on in-domain tasks and a\n5.70% gain on out-of-domain tasks for Qwen2.5-7B, highlighting its potential.", "AI": {"tldr": "Critique-RL\u662f\u4e00\u79cd\u65e0\u9700\u66f4\u5f3a\u76d1\u7763\u5373\u53ef\u5f00\u53d1\u6279\u8bc4\u6027\u8bed\u8a00\u6a21\u578b\u7684\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u3002\u5b83\u91c7\u7528\u4e24\u9636\u6bb5\u4f18\u5316\u7b56\u7565\uff0c\u9996\u5148\u7528\u57fa\u4e8e\u89c4\u5219\u7684\u5956\u52b1\u4fe1\u53f7\u5f3a\u5316\u6279\u8bc4\u8005\u7684\u8fa8\u522b\u80fd\u529b\uff0c\u7136\u540e\u5f15\u5165\u57fa\u4e8e\u6f14\u5458\u6539\u8fdb\u7684\u95f4\u63a5\u5956\u52b1\u6765\u63d0\u9ad8\u6279\u8bc4\u8005\u7684\u6709\u7528\u6027\uff0c\u540c\u65f6\u901a\u8fc7\u9002\u5f53\u7684\u6b63\u5219\u5316\u6765\u4fdd\u6301\u5176\u8fa8\u522b\u80fd\u529b\u3002\u5b9e\u9a8c\u8868\u660e\uff0cCritique-RL \u5728\u5404\u79cd\u4efb\u52a1\u548c\u6a21\u578b\u4e0a\u5747\u53ef\u5e26\u6765\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u7684\u6279\u8bc4\u6027\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u4e8e\u66f4\u5f3a\u7684\u76d1\u7763\u8005\u6765\u6ce8\u91ca\u6279\u8bc4\u6570\u636e\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u53ef\u6269\u5c55\u6027\u548c\u5e94\u7528\u8303\u56f4\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u4e00\u79cd\u65e0\u9700\u66f4\u5f3a\u76d1\u7763\u5373\u53ef\u5f00\u53d1\u6279\u8bc4\u6027\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "method": "Critique-RL \u662f\u4e00\u79cd\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u91c7\u7528\u4e24\u65b9\u535a\u5f08\u8303\u5f0f\uff1a\u6f14\u5458\u751f\u6210\u54cd\u5e94\uff0c\u6279\u8bc4\u8005\u63d0\u4f9b\u53cd\u9988\uff0c\u6f14\u5458\u6839\u636e\u53cd\u9988\u8fdb\u884c\u4f18\u5316\u3002\u8be5\u65b9\u6cd5\u5305\u542b\u4e24\u4e2a\u4f18\u5316\u9636\u6bb5\uff1a\u7b2c\u4e00\u9636\u6bb5\uff0c\u5229\u7528\u57fa\u4e8e\u89c4\u5219\u7684\u76f4\u63a5\u5956\u52b1\u4fe1\u53f7\u6765\u589e\u5f3a\u6279\u8bc4\u8005\u7684\u8fa8\u522b\u80fd\u529b\uff08\u533a\u5206\u54cd\u5e94\u8d28\u91cf\uff09\uff1b\u7b2c\u4e8c\u9636\u6bb5\uff0c\u5f15\u5165\u57fa\u4e8e\u6f14\u5458\u6539\u8fdb\u7684\u95f4\u63a5\u5956\u52b1\u6765\u63d0\u9ad8\u6279\u8bc4\u8005\u7684\u6709\u7528\u6027\uff08\u63d0\u4f9b\u5efa\u8bbe\u6027\u53cd\u9988\uff09\uff0c\u540c\u65f6\u901a\u8fc7\u6b63\u5219\u5316\u6280\u672f\u4fdd\u6301\u6279\u8bc4\u8005\u7684\u8fa8\u522b\u80fd\u529b\u3002", "result": "\u901a\u8fc7\u5728 Qwen2.5-7B \u6a21\u578b\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0cCritique-RL \u5728\u9886\u57df\u5185\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e86 9.02% \u7684\u6027\u80fd\u63d0\u5347\uff0c\u5728\u9886\u57df\u5916\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e86 5.70% \u7684\u6027\u80fd\u63d0\u5347\u3002\u8fd9\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "Critique-RL \u6210\u529f\u5730\u5f00\u53d1\u4e86\u4e00\u79cd\u65e0\u9700\u66f4\u5f3a\u76d1\u7763\u5373\u53ef\u8bad\u7ec3\u6279\u8bc4\u6027\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u5e76\u5728\u591a\u4e2a\u4efb\u52a1\u548c\u6a21\u578b\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002\u8be5\u7814\u7a76\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5bf9\u5f3a\u76d1\u7763\u7684\u4f9d\u8d56\u95ee\u9898\uff0c\u4e3a\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u9014\u5f84\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63a2\u7d22\u8be5\u65b9\u6cd5\u7684\u6269\u5c55\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2510.24328", "categories": ["cs.CL", "cs.AI", "68T50", "F.2.2; I.2.7"], "pdf": "https://arxiv.org/pdf/2510.24328", "abs": "https://arxiv.org/abs/2510.24328", "authors": ["Hunzalah Hassan Bhatti", "Firoj Alam"], "title": "Beyond MCQ: An Open-Ended Arabic Cultural QA Benchmark with Dialect Variants", "comment": "Cultural Knowledge, Everyday Knowledge, Open-Ended Question,\n  Chain-of-Thought, Large Language Models, Native, Multilingual, Language\n  Diversity", "summary": "Large Language Models (LLMs) are increasingly used to answer everyday\nquestions, yet their performance on culturally grounded and dialectal content\nremains uneven across languages. We propose a comprehensive method that (i)\ntranslates Modern Standard Arabic (MSA) multiple-choice questions (MCQs) into\nEnglish and several Arabic dialects, (ii) converts them into open-ended\nquestions (OEQs), (iii) benchmarks a range of zero-shot and fine-tuned LLMs\nunder both MCQ and OEQ settings, and (iv) generates chain-of-thought (CoT)\nrationales to fine-tune models for step-by-step reasoning. Using this method,\nwe extend an existing dataset in which QAs are parallelly aligned across\nmultiple language varieties, making it, to our knowledge, the first of its\nkind. We conduct extensive experiments with both open and closed models. Our\nfindings show that (i) models underperform on Arabic dialects, revealing\npersistent gaps in culturally grounded and dialect-specific knowledge; (ii)\nArabic-centric models perform well on MCQs but struggle with OEQs; and (iii)\nCoT improves judged correctness while yielding mixed n-gram-based metrics. The\ndeveloped dataset will be publicly released to support further research on\nculturally and linguistically inclusive evaluation.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7efc\u5408\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u548c\u6539\u8fdb\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5904\u7406\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00\u548c\u6587\u5316\u80cc\u666f\u95ee\u9898\u65b9\u9762\u7684\u80fd\u529b\u3002\u7814\u7a76\u5c06\u73b0\u4ee3\u6807\u51c6\u963f\u62c9\u4f2f\u8bed\u95ee\u9898\u7ffb\u8bd1\u6210\u82f1\u8bed\u548c\u591a\u79cd\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00\uff0c\u5e76\u5c06\u5176\u8f6c\u6362\u4e3a\u9009\u62e9\u9898\uff08MCQ\uff09\u548c\u5f00\u653e\u5f0f\u95ee\u9898\uff08OEQ\uff09\u4e24\u79cd\u5f62\u5f0f\u3002\u901a\u8fc7\u5bf9\u4e0d\u540cLLMs\u8fdb\u884c\u96f6\u6837\u672c\u548c\u5fae\u8c03\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u5f15\u5165\u601d\u7ef4\u94fe\uff08CoT\uff09\u8fdb\u884c\u9010\u6b65\u63a8\u7406\u5fae\u8c03\uff0c\u7814\u7a76\u6784\u5efa\u4e86\u4e00\u4e2a\u8de8\u8bed\u8a00\u548c\u65b9\u8a00\u7684QA\u6570\u636e\u96c6\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cLLMs\u5728\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00\u4e0a\u7684\u8868\u73b0\u4e0d\u4f73\uff0c\u5b58\u5728\u6587\u5316\u548c\u65b9\u8a00\u77e5\u8bc6\u7684\u5dee\u8ddd\uff1b\u4ee5\u963f\u62c9\u4f2f\u8bed\u4e3a\u4e2d\u5fc3\u7684\u6a21\u578b\u5728MCQ\u4e0a\u8868\u73b0\u8f83\u597d\uff0c\u4f46\u5728OEQ\u4e0a\u9047\u5230\u56f0\u96be\uff1bCoT\u7684\u5f15\u5165\u63d0\u9ad8\u4e86\u5224\u65ad\u7684\u6b63\u786e\u6027\uff0c\u4f46\u5bf9\u57fa\u4e8eN-gram\u7684\u6307\u6807\u5f71\u54cd\u4e0d\u4e00\u3002\u8be5\u7814\u7a76\u53d1\u5e03\u7684\u6570\u636e\u96c6\u662f\u9996\u4e2a\u6b64\u7c7b\u6570\u636e\u96c6\uff0c\u65e8\u5728\u4fc3\u8fdb\u5bf9\u6587\u5316\u548c\u8bed\u8a00\u5305\u5bb9\u6027\u8bc4\u4f30\u7684\u7814\u7a76\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u56de\u7b54\u65e5\u5e38\u95ee\u9898\u65b9\u9762\u8868\u73b0\u65e5\u76ca\u51fa\u8272\uff0c\u4f46\u5728\u5904\u7406\u5177\u6709\u6587\u5316\u80cc\u666f\u548c\u65b9\u8a00\u7684\u5185\u5bb9\u65f6\uff0c\u5176\u5728\u4e0d\u540c\u8bed\u8a00\u4e0a\u7684\u8868\u73b0\u5e76\u4e0d\u5747\u8861\u3002\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3LLMs\u5728\u963f\u62c9\u4f2f\u8bed\u53ca\u5176\u591a\u79cd\u65b9\u8a00\u4e0a\u7684\u8fd9\u4e00\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u6587\u5316\u548c\u65b9\u8a00\u7279\u6709\u77e5\u8bc6\u65b9\u9762\u7684\u4e0d\u8db3\u3002\u901a\u8fc7\u8bc4\u4f30\u548c\u6539\u8fdb\u6a21\u578b\u5728\u8fd9\u4e9b\u65b9\u9762\u7684\u80fd\u529b\uff0c\u53ef\u4ee5\u4fc3\u8fdb\u66f4\u5177\u5305\u5bb9\u6027\u548c\u51c6\u786e\u6027\u7684\u8bed\u8a00\u6280\u672f\u53d1\u5c55\uff0c\u586b\u8865\u5f53\u524d\u7814\u7a76\u4e2d\u7684\u7a7a\u767d\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7efc\u5408\u65b9\u6cd5\uff0c\u5305\u62ec\u56db\u4e2a\u4e3b\u8981\u6b65\u9aa4\uff1a1. \u5c06\u73b0\u4ee3\u6807\u51c6\u963f\u62c9\u4f2f\u8bed\uff08MSA\uff09\u9009\u62e9\u9898\uff08MCQs\uff09\u7ffb\u8bd1\u6210\u82f1\u8bed\u548c\u591a\u79cd\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00\u30022. \u5c06MCQs\u8f6c\u6362\u4e3a\u5f00\u653e\u5f0f\u95ee\u9898\uff08OEQs\uff09\u30023. \u5bf9\u4e00\u7cfb\u5217\u96f6\u6837\u672c\u548c\u5fae\u8c03\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728MCQ\u548cOEQ\u8bbe\u7f6e\u4e0b\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u30024. \u751f\u6210\u601d\u7ef4\u94fe\uff08CoT\uff09\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u4ee5\u5fae\u8c03\u6a21\u578b\u8fdb\u884c\u9010\u6b65\u63a8\u7406\u3002\u57fa\u4e8e\u6b64\u65b9\u6cd5\uff0c\u7814\u7a76\u6269\u5c55\u4e86\u4e00\u4e2a\u73b0\u6709\u7684\u3001\u8de8\u591a\u79cd\u8bed\u8a00\u53d8\u4f53\u5e76\u884c\u5bf9\u9f50\u7684QA\u6570\u636e\u96c6\uff0c\u5e76\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0c\u5305\u62ec\u5f00\u653e\u548c\u5c01\u95ed\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff1a\uff081\uff09LLMs\u5728\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00\u4e0a\u7684\u8868\u73b0\u666e\u904d\u8f83\u5dee\uff0c\u8fd9\u63ed\u793a\u4e86\u5728\u6587\u5316\u80cc\u666f\u548c\u65b9\u8a00\u7279\u6709\u77e5\u8bc6\u65b9\u9762\u5b58\u5728\u7684\u6301\u7eed\u6027\u5dee\u8ddd\u3002\uff082\uff09\u4ee5\u963f\u62c9\u4f2f\u8bed\u4e3a\u4e2d\u5fc3\u7684\u6a21\u578b\u5728\u5904\u7406\u9009\u62e9\u9898\uff08MCQs\uff09\u65f6\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u5904\u7406\u5f00\u653e\u5f0f\u95ee\u9898\uff08OEQs\uff09\u65f6\u9047\u5230\u4e86\u56f0\u96be\u3002\uff083\uff09\u601d\u7ef4\u94fe\uff08CoT\uff09\u7684\u5f15\u5165\u5728\u4e3b\u89c2\u5224\u65ad\u7684\u6b63\u786e\u6027\u65b9\u9762\u6709\u6240\u63d0\u9ad8\uff0c\u4f46\u5728\u5ba2\u89c2\u7684N-gram\u7c7b\u6307\u6807\u4e0a\uff0c\u7ed3\u679c\u597d\u574f\u53c2\u534a\u3002", "conclusion": "\u672c\u7814\u7a76\u901a\u8fc7\u63d0\u51fa\u4e00\u79cd\u7efc\u5408\u65b9\u6cd5\uff0c\u5e76\u6784\u5efa\u4e86\u4e00\u4e2a\u8de8\u8bed\u8a00\u548c\u65b9\u8a00\u7684QA\u6570\u636e\u96c6\uff0c\u6df1\u5165\u5206\u6790\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u963f\u62c9\u4f2f\u8bed\u53ca\u5176\u65b9\u8a00\u4e0a\u7684\u8868\u73b0\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u6a21\u578b\u5728\u5904\u7406\u65b9\u8a00\u548c\u6587\u5316\u80cc\u666f\u5185\u5bb9\u65f6\u5b58\u5728\u663e\u8457\u4e0d\u8db3\uff0c\u5c24\u5176\u662f\u5728\u5f00\u653e\u5f0f\u95ee\u9898\u4e0a\u3002\u601d\u7ef4\u94fe\uff08CoT\uff09\u7684\u5f15\u5165\u5728\u63d0\u9ad8\u95ee\u9898\u56de\u7b54\u7684\u51c6\u786e\u6027\u65b9\u9762\u663e\u793a\u51fa\u6f5c\u529b\u3002\u8be5\u7814\u7a76\u5f3a\u8c03\u4e86\u5f00\u53d1\u66f4\u5177\u6587\u5316\u548c\u8bed\u8a00\u5305\u5bb9\u6027\u7684LLM\u8bc4\u4f30\u65b9\u6cd5\u7684\u91cd\u8981\u6027\uff0c\u5e76\u8ba1\u5212\u516c\u5f00\u6570\u636e\u96c6\u4ee5\u652f\u6301\u672a\u6765\u7684\u76f8\u5173\u7814\u7a76\u3002"}}
{"id": "2510.24528", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24528", "abs": "https://arxiv.org/abs/2510.24528", "authors": ["Zihan Chen", "Song Wang", "Xingbo Fu", "Chengshuai Shi", "Zhenyu Lei", "Cong Shen", "Jundong Li"], "title": "From Cross-Task Examples to In-Task Prompts: A Graph-Based Pseudo-Labeling Framework for In-context Learning", "comment": null, "summary": "The capability of in-context learning (ICL) enables large language models\n(LLMs) to perform novel tasks without parameter updates by conditioning on a\nfew input-output examples. However, collecting high-quality examples for new or\nchallenging tasks can be costly and labor-intensive. In this work, we propose a\ncost-efficient two-stage pipeline that reduces reliance on LLMs for data\nlabeling. Our approach first leverages readily available cross-task examples to\nprompt an LLM and pseudo-label a small set of target task instances. We then\nintroduce a graph-based label propagation method that spreads label information\nto the remaining target examples without additional LLM queries. The resulting\nfully pseudo-labeled dataset is used to construct in-task demonstrations for\nICL. This pipeline combines the flexibility of cross-task supervision with the\nscalability of LLM-free propagation. Experiments across five tasks demonstrate\nthat our method achieves strong performance while lowering labeling costs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u4e24\u9636\u6bb5\u65b9\u6cd5\uff0c\u5229\u7528\u5c11\u91cf\u8de8\u4efb\u52a1\u793a\u4f8b\u548c\u56fe\u57fa\u6807\u7b7e\u4f20\u64ad\u6280\u672f\uff0c\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u4f2a\u6807\u7b7e\u6570\u636e\uff0c\u7528\u4e8e\u5728\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\uff0c\u4ece\u800c\u964d\u4f4e\u6570\u636e\u6807\u6ce8\u6210\u672c\u5e76\u63d0\u9ad8\u6548\u7387\u3002", "motivation": "\u5728\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\u4e2d\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u65e0\u9700\u66f4\u65b0\u53c2\u6570\u5373\u53ef\u6267\u884c\u65b0\u4efb\u52a1\uff0c\u4f46\u6536\u96c6\u9ad8\u8d28\u91cf\u7684\u793a\u4f8b\u6210\u672c\u9ad8\u6602\u3002\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3LLM\u5728\u6570\u636e\u6807\u6ce8\u65b9\u9762\u7684\u6210\u672c\u548c\u4eba\u529b\u6295\u5165\u95ee\u9898\uff0c\u63d0\u51fa\u4e00\u79cd\u66f4\u7ecf\u6d4e\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u8be5\u65b9\u6cd5\u91c7\u7528\u4e24\u9636\u6bb5\u6d41\u7a0b\uff1a1. \u5229\u7528\u73b0\u6709\u7684\u8de8\u4efb\u52a1\u793a\u4f8b\uff0c\u63d0\u793aLLM\u4e3a\u5c11\u91cf\u76ee\u6807\u4efb\u52a1\u5b9e\u4f8b\u751f\u6210\u4f2a\u6807\u7b7e\u30022. \u5f15\u5165\u4e00\u79cd\u57fa\u4e8e\u56fe\u7684\u6807\u7b7e\u4f20\u64ad\u65b9\u6cd5\uff0c\u5728\u4e0d\u8fdb\u884c\u989d\u5916LLM\u67e5\u8be2\u7684\u60c5\u51b5\u4e0b\uff0c\u5c06\u6807\u7b7e\u4fe1\u606f\u4f20\u64ad\u7ed9\u5269\u4f59\u7684\u76ee\u6807\u793a\u4f8b\u3002\u6700\u540e\uff0c\u4f7f\u7528\u5b8c\u5168\u4f2a\u6807\u7b7e\u7684\u6570\u636e\u96c6\u6784\u5efa\u7528\u4e8eICL\u7684 in-task \u6f14\u793a\u3002", "result": "\u5728\u4e94\u4e2a\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u964d\u4f4e\u6807\u6ce8\u6210\u672c\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u5f3a\u5927\u7684\u6027\u80fd\u3002\u5177\u4f53\u6027\u80fd\u63d0\u5347\u548c\u4e0e\u73b0\u6709\u65b9\u6cd5\u7684\u5bf9\u6bd4\u5728\u5b9e\u9a8c\u90e8\u5206\u8fdb\u884c\u4e86\u8be6\u7ec6\u9610\u8ff0\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u8de8\u4efb\u52a1\u76d1\u7763\u7684\u7075\u6d3b\u6027\u548c\u65e0LLM\u4f20\u64ad\u7684\u53ef\u6269\u5c55\u6027\uff0c\u6709\u6548\u964d\u4f4e\u4e86ICL\u7684\u6570\u636e\u6807\u6ce8\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u826f\u597d\u7684\u6027\u80fd\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u63a2\u7d22\u66f4\u590d\u6742\u7684\u56fe\u7ed3\u6784\u6216\u4f20\u64ad\u7b97\u6cd5\uff0c\u4ee5\u8fdb\u4e00\u6b65\u63d0\u9ad8\u6807\u7b7e\u4f20\u64ad\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2510.24345", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24345", "abs": "https://arxiv.org/abs/2510.24345", "authors": ["Zikai Xiao", "Fei Huang", "Jianhong Tu", "Jianhui Wei", "Wen Ma", "Yuxuan Zhou", "Jian Wu", "Bowen Yu", "Zuozhu Liu", "Junyang Lin"], "title": "LongWeave: A Long-Form Generation Benchmark Bridging Real-World Relevance and Verifiability", "comment": "EMNLP Findings 2025", "summary": "Generating long, informative, and factual outputs remains a major challenge\nfor Large Language Models (LLMs). Existing benchmarks for long-form generation\ntypically assess real-world queries with hard-to-verify metrics or use\nsynthetic setups that ease evaluation but overlook real-world intricacies. In\nthis paper, we introduce \\textbf{LongWeave}, which balances real-world and\nverifiable assessment with Constraint-Verifier Evaluation (CoV-Eval). CoV-Eval\nconstructs tasks by first defining verifiable targets within real-world\nscenarios, then systematically generating corresponding queries, textual\nmaterials, and constraints based on these targets. This ensures that tasks are\nboth realistic and objectively assessable, enabling rigorous assessment of\nmodel capabilities in meeting complex real-world constraints. LongWeave\nsupports customizable input/output lengths (up to 64K/8K tokens) across seven\ndistinct tasks. Evaluation on 23 LLMs shows that even state-of-the-art models\nencounter significant challenges in long-form generation as real-world\ncomplexity and output length increase.", "AI": {"tldr": "\u957f\u6587\u672c\u751f\u6210 LLMs \u7684\u6311\u6218\uff1a\u63d0\u51fa CoV-Eval \u8bc4\u4f30\u6846\u67b6\uff0c\u5728\u771f\u5b9e\u573a\u666f\u4e0b\u53ef\u9a8c\u8bc1\u5730\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\uff0c\u5e76\u5bf9 23 \u4e2a LLMs \u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793a\u957f\u6587\u672c\u751f\u6210\u4ecd\u5177\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u957f\u6587\u672c\u751f\u6210\u8bc4\u4f30\u57fa\u51c6\u8981\u4e48\u96be\u4ee5\u9a8c\u8bc1\uff0c\u8981\u4e48\u8fc7\u4e8e\u7b80\u5316\uff0c\u65e0\u6cd5\u53cd\u6620\u771f\u5b9e\u4e16\u754c\u590d\u6742\u6027\u3002LLMs \u5728\u751f\u6210\u957f\u800c\u4fe1\u606f\u4e30\u5bcc\u4e14\u7b26\u5408\u7ea6\u675f\u7684\u6587\u672c\u65b9\u9762\u9762\u4e34\u6311\u6218\u3002", "method": "\u63d0\u51fa CoV-Eval \u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u5b9a\u4e49\u53ef\u9a8c\u8bc1\u76ee\u6807\uff0c\u751f\u6210\u5305\u542b\u771f\u5b9e\u573a\u666f\u3001\u6750\u6599\u548c\u7ea6\u675f\u7684\u4efb\u52a1\u3002\u652f\u6301\u957f\u8f93\u5165/\u8f93\u51fa\uff0864K/8K token\uff09\uff0c\u5305\u542b\u4e03\u79cd\u4efb\u52a1\u3002\u5728 23 \u4e2a LLMs \u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u8bc4\u4f30\u663e\u793a\uff0c\u968f\u7740\u771f\u5b9e\u4e16\u754c\u590d\u6742\u6027\u548c\u8f93\u51fa\u957f\u5ea6\u7684\u589e\u52a0\uff0c\u5373\u4f7f\u662f\u6700\u5148\u8fdb\u7684\u6a21\u578b\u5728\u957f\u6587\u672c\u751f\u6210\u65b9\u9762\u4e5f\u9762\u4e34\u663e\u8457\u6311\u6218\u3002", "conclusion": "\u957f\u6587\u672c\u751f\u6210\uff0c\u5c24\u5176\u662f\u5728\u771f\u5b9e\u590d\u6742\u573a\u666f\u4e0b\uff0c\u5bf9 LLMs \u6765\u8bf4\u4ecd\u7136\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\u3002CoV-Eval \u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u884c\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u672a\u6765\u5de5\u4f5c\u53ef\u8fdb\u4e00\u6b65\u6539\u8fdb\u6a21\u578b\u6027\u80fd\u548c\u8bc4\u4f30\u6846\u67b6\u3002"}}
{"id": "2510.24425", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24425", "abs": "https://arxiv.org/abs/2510.24425", "authors": ["Guangyu Xie", "Yice Zhang", "Jianzhu Bao", "Qianlong Wang", "Yang Sun", "Bingbing Wang", "Ruifeng Xu"], "title": "Comprehensive and Efficient Distillation for Lightweight Sentiment Analysis Models", "comment": "Accepted by EMNLP 2025. 22 pages, 9 figures. The first two authors\n  contribute equally", "summary": "Recent efforts leverage knowledge distillation techniques to develop\nlightweight and practical sentiment analysis models. These methods are grounded\nin human-written instructions and large-scale user texts. Despite the promising\nresults, two key challenges remain: (1) manually written instructions are\nlimited in diversity and quantity, making them insufficient to ensure\ncomprehensive coverage of distilled knowledge; (2) large-scale user texts incur\nhigh computational cost, hindering the practicality of these methods. To this\nend, we introduce COMPEFFDIST, a comprehensive and efficient distillation\nframework for sentiment analysis. Our framework consists of two key modules:\nattribute-based automatic instruction construction and difficulty-based data\nfiltering, which correspondingly tackle the aforementioned challenges. Applying\nour method across multiple model series (Llama-3, Qwen-3, and Gemma-3), we\nenable 3B student models to match the performance of 20x larger teacher models\non most tasks. In addition, our approach greatly outperforms baseline methods\nin data efficiency, attaining the same performance level with only 10% of the\ndata.", "AI": {"tldr": "COMPEFFDIST\u662f\u4e00\u4e2a\u5168\u9762\u7684\u3001\u9ad8\u6548\u7684\u77e5\u8bc6\u84b8\u998f\u6846\u67b6\uff0c\u7528\u4e8e\u60c5\u611f\u5206\u6790\u3002\u5b83\u901a\u8fc7\u81ea\u52a8\u6784\u5efa\u57fa\u4e8e\u5c5e\u6027\u7684\u6307\u4ee4\u548c\u57fa\u4e8e\u96be\u5ea6\u7684 D \u6570\u636e\u8fc7\u6ee4\u6765\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6570\u636e\u6548\u7387\uff0c\u4f7f\u5c0f\u578b\u6a21\u578b\uff08\u5982 3B \u5b66\u751f\u6a21\u578b\uff09\u80fd\u591f\u5339\u914d\u5927\u578b\u6a21\u578b\uff08\u5982 20 \u500d\uff09\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u77e5\u8bc6\u84b8\u998f\u7684\u60c5\u611f\u5206\u6790\u6a21\u578b\u5728\u5b9e\u7528\u6027\u548c\u6027\u80fd\u65b9\u9762\u9762\u4e34\u4e24\u5927\u6311\u6218\uff1a1. \u4eba\u5de5\u7f16\u5199\u7684\u6307\u4ee4\u7f3a\u4e4f\u591a\u6837\u6027\u548c\u6570\u91cf\uff0c\u96be\u4ee5\u8986\u76d6\u84b8\u998f\u6240\u9700\u7684\u5168\u90e8\u77e5\u8bc6\u30022. \u5927\u89c4\u6a21\u7528\u6237\u6587\u672c\u5904\u7406\u6210\u672c\u9ad8\u6602\uff0c\u5f71\u54cd\u4e86\u6a21\u578b\u7684\u5b9e\u9645\u5e94\u7528\u3002\u8fd9\u4e9b\u95ee\u9898\u963b\u788d\u4e86\u8f7b\u91cf\u7ea7\u4e14\u9ad8\u6548\u7684\u60c5\u611f\u5206\u6790\u6a21\u578b\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002", "method": "COMPEFFDIST\u6846\u67b6\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u6a21\u5757\uff1a1. \u57fa\u4e8e\u5c5e\u6027\u7684\u81ea\u52a8\u6307\u4ee4\u6784\u5efa\uff1a\u81ea\u52a8\u751f\u6210\u591a\u6837\u5316\u7684\u6307\u4ee4\uff0c\u514b\u670d\u4eba\u5de5\u6307\u4ee4\u7684\u5c40\u9650\u6027\u30022. \u57fa\u4e8e\u96be\u5ea6\u7684 D \u6570\u636e\u8fc7\u6ee4\uff1a\u7b5b\u9009\u51fa\u5bf9\u6a21\u578b\u5b66\u4e60\u6700\u6709\u4ef7\u503c\u7684\u6570\u636e\uff0c\u63d0\u9ad8\u6570\u636e\u6548\u7387\u3002\u8be5\u65b9\u6cd5\u5728 Llama-3\u3001Qwen-3 \u548c Gemma-3 \u7b49\u591a\u4e2a\u6a21\u578b\u7cfb\u5217\u4e0a\u8fdb\u884c\u4e86\u6d4b\u8bd5\u3002", "result": "\u5728 Llama-3\u3001Qwen-3 \u548c Gemma-3 \u6a21\u578b\u7cfb\u5217\u4e0a\uff0c3B \u5b66\u751f\u6a21\u578b\u5728\u5927\u591a\u6570\u4efb\u52a1\u4e0a\u8fbe\u5230\u4e86 20 \u500d\u5927\u6559\u5e08\u6a21\u578b\u7684\u6027\u80fd\u6c34\u5e73\u3002\u4e0e\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0cCOMPEFFDIST\u5728\u6570\u636e\u6548\u7387\u65b9\u9762\u8868\u73b0\u4f18\u8d8a\uff0c\u4ec5\u4f7f\u7528 10% \u7684\u6570\u636e\u5373\u53ef\u8fbe\u5230\u76f8\u540c\u7684\u6027\u80fd\u6c34\u5e73\u3002", "conclusion": "COMPEFFDIST\u6846\u67b6\u901a\u8fc7\u521b\u65b0\u7684\u81ea\u52a8\u6307\u4ee4\u6784\u5efa\u548c\u6570\u636e\u8fc7\u6ee4\u6280\u672f\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u77e5\u8bc6\u84b8\u998f\u5728\u60c5\u611f\u5206\u6790\u4e2d\u7684\u6548\u7387\u548c\u6027\u80fd\u74f6\u9888\uff0c\u5b9e\u73b0\u4e86\u5c0f\u578b\u6a21\u578b\u4e0e\u5927\u578b\u6a21\u578b\u7684\u6027\u80fd\u76f8\u5f53\uff0c\u5e76\u5927\u5e45\u63d0\u5347\u4e86\u6570\u636e\u6548\u7387\u3002\u8fd9\u4e3a\u5f00\u53d1\u66f4\u8f7b\u4fbf\u3001\u66f4\u5b9e\u7528\u7684\u60c5\u611f\u5206\u6790\u6a21\u578b\u63d0\u4f9b\u4e86\u65b0\u7684\u9014\u5f84\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u63a2\u7d22\u8be5\u6846\u67b6\u5728\u66f4\u591a NLP \u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u4ee5\u53ca\u8fdb\u4e00\u6b65\u4f18\u5316\u5176\u6548\u7387\u3002"}}
{"id": "2510.24650", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24650", "abs": "https://arxiv.org/abs/2510.24650", "authors": ["Nitin Rai", "Daeun", "Choi", "Nathan S. Boyd", "Arnold W. Schumann"], "title": "Advancing site-specific disease and pest management in precision agriculture: From reasoning-driven foundation models to adaptive, feedback-based learning", "comment": "26 pages, 8 figures, and 2 tables", "summary": "Site-specific disease management (SSDM) in crops has advanced rapidly through\nmachine and deep learning (ML and DL) for real-time computer vision. Research\nevolved from handcrafted feature extraction to large-scale automated feature\nlearning. With foundation models (FMs), crop disease datasets are now processed\nin fundamentally new ways. Unlike traditional neural networks, FMs integrate\nvisual and textual data, interpret symptoms in text, reason about\nsymptom-management relationships, and support interactive QA for growers and\neducators. Adaptive and imitation learning in robotics further enables\nfield-based disease management. This review screened approx. 40 articles on FM\napplications for SSDM, focusing on large-language models (LLMs) and\nvision-language models (VLMs), and discussing their role in adaptive learning\n(AL), reinforcement learning (RL), and digital twin frameworks for targeted\nspraying. Key findings: (a) FMs are gaining traction with surging literature in\n2023-24; (b) VLMs outpace LLMs, with a 5-10x increase in publications; (c) RL\nand AL are still nascent for smart spraying; (d) digital twins with RL can\nsimulate targeted spraying virtually; (e) addressing the sim-to-real gap is\ncritical for real-world deployment; (f) human-robot collaboration remains\nlimited, especially in human-in-the-loop approaches where robots detect early\nsymptoms and humans validate uncertain cases; (g) multi-modal FMs with\nreal-time feedback will drive next-gen SSDM. For updates, resources, and\ncontributions, visit, https://github.com/nitin-dominic/AgriPathogenDatabase, to\nsubmit papers, code, or datasets.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u57fa\u7840\u6a21\u578b\uff08FMs\uff09\u5728\u4f5c\u7269\u75c5\u5bb3\u7cbe\u51c6\u7ba1\u7406\uff08SSDM\uff09\u4e2d\u7684\u5e94\u7528\uff0c\u91cd\u70b9\u4ecb\u7ecd\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u5728\u56fe\u50cf\u8bc6\u522b\u3001\u6587\u672c\u5206\u6790\u548c\u667a\u80fd\u51b3\u7b56\u65b9\u9762\u7684\u6f5c\u529b\u3002\u7814\u7a76\u53d1\u73b0\uff0cFMs\uff0c\u7279\u522b\u662fVLMs\uff0c\u5728\u5904\u7406\u4f5c\u7269\u75c5\u5bb3\u6570\u636e\u96c6\u65b9\u9762\u5c55\u73b0\u51fa\u5de8\u5927\u4f18\u52bf\uff0c\u5e76\u4e14\u5728\u81ea\u9002\u5e94\u5b66\u4e60\uff08AL\uff09\u3001\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u548c\u6570\u5b57\u5b6a\u751f\u6846\u67b6\u7684\u7ed3\u5408\u4e0b\uff0c\u4e3a\u7cbe\u51c6\u55b7\u6d12\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002\u5c3d\u7ba1RL\u548cAL\u5728\u667a\u80fd\u55b7\u6d12\u65b9\u9762\u7684\u5e94\u7528\u5c1a\u5904\u4e8e\u65e9\u671f\u9636\u6bb5\uff0c\u4f46\u6570\u5b57\u5b6a\u751f\u7ed3\u5408RL\u7684\u865a\u62df\u6a21\u62df\u80fd\u529b\u9884\u793a\u7740\u672a\u6765\u7684\u53d1\u5c55\u65b9\u5411\u3002\u6587\u7ae0\u5f3a\u8c03\u4e86\u5f25\u5408\u6a21\u62df\u4e0e\u73b0\u5b9e\u5dee\u8ddd\u3001\u52a0\u5f3a\u4eba\u673a\u534f\u4f5c\u4ee5\u53ca\u5229\u7528\u591a\u6a21\u6001FMs\u8fdb\u884c\u5b9e\u65f6\u53cd\u9988\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u4e0b\u4e00\u4ee3SSDM\u7684\u53d1\u5c55\u6307\u660e\u4e86\u65b9\u5411\u3002", "motivation": "\u4f5c\u7269\u75c5\u5bb3\u7684\u7cbe\u51c6\u7ba1\u7406\uff08SSDM\uff09\u662f\u63d0\u9ad8\u4f5c\u7269\u4ea7\u91cf\u548c\u8d28\u91cf\u7684\u5173\u952e\u3002\u8fd1\u5e74\u6765\uff0c\u673a\u5668\u5b66\u4e60\uff08ML\uff09\u548c\u6df1\u5ea6\u5b66\u4e60\uff08DL\uff09\u5728\u5b9e\u65f6\u8ba1\u7b97\u673a\u89c6\u89c9\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f7f\u5f97\u4ece\u624b\u5de5\u7279\u5f81\u63d0\u53d6\u5230\u5927\u89c4\u6a21\u81ea\u52a8\u5316\u7279\u5f81\u5b66\u4e60\u7684\u7814\u7a76\u8303\u5f0f\u53d1\u751f\u4e86\u8f6c\u53d8\u3002\u57fa\u7840\u6a21\u578b\uff08FMs\uff09\u7684\u51fa\u73b0\uff0c\u4e3a\u5904\u7406\u4f5c\u7269\u75c5\u5bb3\u6570\u636e\u96c6\u63d0\u4f9b\u4e86\u6839\u672c\u6027\u7684\u65b0\u65b9\u6cd5\u3002FMs\u80fd\u591f\u6574\u5408\u89c6\u89c9\u548c\u6587\u672c\u6570\u636e\uff0c\u7406\u89e3\u75c5\u5bb3\u75c7\u72b6\u7684\u6587\u672c\u63cf\u8ff0\uff0c\u63a8\u7406\u75c7\u72b6\u4e0e\u7ba1\u7406\u63aa\u65bd\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5e76\u652f\u6301\u4ea4\u4e92\u5f0f\u95ee\u7b54\uff0c\u4ece\u800c\u4e3a\u79cd\u690d\u8005\u548c\u6559\u80b2\u8005\u63d0\u4f9b\u66f4\u667a\u80fd\u5316\u7684\u652f\u6301\u3002\u56e0\u6b64\uff0c\u6df1\u5165\u63a2\u8ba8FMs\u5728SSDM\u4e2d\u7684\u5e94\u7528\uff0c\u7279\u522b\u662fLLMs\u548cVLMs\uff0c\u4ee5\u53ca\u5b83\u4eec\u4e0e\u673a\u5668\u4eba\u6280\u672f\uff08\u5982\u81ea\u9002\u5e94\u5b66\u4e60\u548c\u6a21\u4eff\u5b66\u4e60\uff09\u7684\u7ed3\u5408\uff0c\u5bf9\u4e8e\u63a8\u52a8SSDM\u6280\u672f\u7684\u53d1\u5c55\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u672c\u7efc\u8ff0\u7b5b\u9009\u4e86\u5927\u7ea640\u7bc7\u5173\u4e8eFM\u5e94\u7528\u4e8eSSDM\u7684\u6587\u7ae0\uff0c\u91cd\u70b9\u5173\u6ce8\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u3002\u6587\u7ae0\u6df1\u5165\u63a2\u8ba8\u4e86\u8fd9\u4e9b\u6a21\u578b\u5728\u81ea\u9002\u5e94\u5b66\u4e60\uff08AL\uff09\u3001\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u4ee5\u53ca\u6570\u5b57\u5b6a\u751f\u6846\u67b6\u4e2d\u7684\u4f5c\u7528\uff0c\u7279\u522b\u662f\u5b83\u4eec\u5982\u4f55\u652f\u6301\u76ee\u6807\u55b7\u6d12\u7b49\u5e94\u7528\u3002\u7efc\u8ff0\u5206\u6790\u4e86\u76f8\u5173\u7814\u7a76\u5728\u6570\u636e\u5904\u7406\u3001\u6a21\u578b\u96c6\u6210\u3001\u5b66\u4e60\u8303\u5f0f\u4ee5\u53ca\u4eba\u673a\u534f\u4f5c\u7b49\u65b9\u9762\u7684\u5177\u4f53\u6280\u672f\u548c\u65b9\u6cd5\uff0c\u5e76\u8ba8\u8bba\u4e86\u5c06\u6a21\u62df\u73af\u5883\u4e2d\u7684\u5b66\u4e60\u6210\u679c\u8fc1\u79fb\u5230\u73b0\u5b9e\u4e16\u754c\u4e2d\u6240\u9762\u4e34\u7684\u6311\u6218\uff0c\u4f8b\u5982\u201c\u6a21\u62df\u5230\u73b0\u5b9e\u201d\u7684\u5dee\u8ddd\uff08sim-to-real gap\uff09\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0cFMs\u5728SSDM\u9886\u57df\u7684\u5e94\u7528\u6b63\u5728\u8fc5\u901f\u589e\u957f\uff0c\u5c24\u5176\u662f\u57282023-2024\u5e74\u95f4\uff0c\u76f8\u5173\u6587\u732e\u6570\u91cf\u6fc0\u589e\u3002\u5176\u4e2d\uff0c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u7684\u53d1\u5c55\u52bf\u5934\u660e\u663e\u4f18\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\uff0c\u53d1\u8868\u7684\u51fa\u7248\u7269\u6570\u91cf\u589e\u52a0\u4e865\u523010\u500d\u3002\u7136\u800c\uff0c\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u548c\u81ea\u9002\u5e94\u5b66\u4e60\uff08AL\uff09\u5728\u667a\u80fd\u55b7\u6d12\u9886\u57df\u7684\u5e94\u7528\u4ecd\u5904\u4e8e\u521d\u6b65\u63a2\u7d22\u9636\u6bb5\u3002\u6570\u5b57\u5b6a\u751f\u6280\u672f\u7ed3\u5408RL\uff0c\u80fd\u591f\u5728\u865a\u62df\u73af\u5883\u4e2d\u6a21\u62df\u7cbe\u51c6\u55b7\u6d12\u8fc7\u7a0b\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u6307\u5bfc\u3002\u5f25\u5408\u6a21\u62df\u4e0e\u73b0\u5b9e\u4e4b\u95f4\u7684\u5dee\u8ddd\u662f\u5b9e\u73b0\u5927\u89c4\u6a21\u5b9e\u9645\u90e8\u7f72\u7684\u5173\u952e\u6311\u6218\u3002\u6b64\u5916\uff0c\u4eba\u673a\u534f\u4f5c\uff0c\u7279\u522b\u662f\u201c\u4eba\u5728\u56de\u8def\u201d\u7684\u6a21\u5f0f\uff08\u5373\u673a\u5668\u4eba\u68c0\u6d4b\u65e9\u671f\u75c5\u5bb3\uff0c\u4eba\u7c7b\u9a8c\u8bc1\u4e0d\u786e\u5b9a\u60c5\u51b5\uff09\u7684\u6f5c\u529b\u5c1a\u672a\u5f97\u5230\u5145\u5206\u53d1\u6325\u3002", "conclusion": "\u57fa\u7840\u6a21\u578b\uff08FMs\uff09\uff0c\u7279\u522b\u662f\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\uff0c\u4e3a\u4f5c\u7269\u75c5\u5bb3\u7cbe\u51c6\u7ba1\u7406\uff08SSDM\uff09\u5e26\u6765\u4e86\u9769\u547d\u6027\u7684\u53d8\u5316\uff0c\u80fd\u591f\u5904\u7406\u591a\u6a21\u6001\u6570\u636e\u5e76\u8fdb\u884c\u590d\u6742\u7684\u63a8\u7406\u3002\u5c3d\u7ba1RL\u548cAL\u5728\u667a\u80fd\u55b7\u6d12\u4e2d\u7684\u5e94\u7528\u5c1a\u4e0d\u6210\u719f\uff0c\u4f46\u6570\u5b57\u5b6a\u751f\u6280\u672f\u4e3a\u8fd9\u4e9b\u6280\u672f\u7684\u865a\u62df\u6d4b\u8bd5\u548c\u4f18\u5316\u63d0\u4f9b\u4e86\u5e73\u53f0\u3002\u672a\u6765\u7684\u7814\u7a76\u5e94\u91cd\u70b9\u5173\u6ce8\u7f29\u5c0f\u6a21\u62df\u4e0e\u73b0\u5b9e\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u5e76\u52a0\u5f3a\u4eba\u673a\u534f\u4f5c\uff0c\u4ee5\u5b9e\u73b0\u66f4\u9ad8\u6548\u3001\u66f4\u53ef\u9760\u7684SSDM\u7cfb\u7edf\u3002\u591a\u6a21\u6001FMs\u7ed3\u5408\u5b9e\u65f6\u53cd\u9988\u5c06\u662f\u9a71\u52a8\u4e0b\u4e00\u4ee3SSDM\u53d1\u5c55\u7684\u5173\u952e\u3002"}}
{"id": "2510.24427", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24427", "abs": "https://arxiv.org/abs/2510.24427", "authors": ["Ken Gu", "Advait Bhat", "Mike A Merrill", "Robert West", "Xin Liu", "Daniel McDuff", "Tim Althoff"], "title": "SynthWorlds: Controlled Parallel Worlds for Disentangling Reasoning and Knowledge in Language Models", "comment": null, "summary": "Evaluating the reasoning ability of language models (LMs) is complicated by\ntheir extensive parametric world knowledge, where benchmark performance often\nreflects factual recall rather than genuine reasoning. Existing datasets and\napproaches (e.g., temporal filtering, paraphrasing, adversarial substitution)\ncannot cleanly separate the two. We present SynthWorlds, a framework that\ndisentangles task reasoning complexity from factual knowledge. In SynthWorlds,\nwe construct parallel corpora representing two worlds with identical\ninterconnected structure: a real-mapped world, where models may exploit\nparametric knowledge, and a synthetic-mapped world, where such knowledge is\nmeaningless. On top of these corpora, we design two mirrored tasks as case\nstudies: multi-hop question answering and page navigation, which maintain equal\nreasoning difficulty across worlds. Experiments in parametric-only (e.g.,\nclosed-book QA) and knowledge-augmented (e.g., retrieval-augmented) LM settings\nreveal a persistent knowledge advantage gap, defined as the performance boost\nmodels gain from memorized parametric world knowledge. Knowledge acquisition\nand integration mechanisms reduce but do not eliminate this gap, highlighting\nopportunities for system improvements. Fully automatic and scalable,\nSynthWorlds provides a controlled environment for evaluating LMs in ways that\nwere previously challenging, enabling precise and testable comparisons of\nreasoning and memorization.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.24663", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24663", "abs": "https://arxiv.org/abs/2510.24663", "authors": ["Yifu Lu", "Shengjie Liu", "Li Dong"], "title": "OrchDAG: Complex Tool Orchestration in Multi-Turn Interactions with Plan DAGs", "comment": "9 pages, 4 figures", "summary": "Agentic tool use has gained traction with the rise of agentic tool calling,\nyet most existing work overlooks the complexity of multi-turn tool\ninteractions. We introduce OrchDAG, a synthetic data generation pipeline that\nmodels tool execution as directed acyclic graphs (DAGs) with controllable\ncomplexity. Using this dataset, we benchmark model performance and propose a\ngraph-based reward to enhance RLVR training. Experiments show that the dataset\npresents a challenging but solvable benchmark, and the proposed reward is\neffective when combined with GRPO-style algorithms, highlighting the importance\nof leveraging topological structure and data complexity in multi-turn tool use.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.24434", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24434", "abs": "https://arxiv.org/abs/2510.24434", "authors": ["Julian Valline", "Cedric Lothritz", "Jordi Cabot"], "title": "LuxIT: A Luxembourgish Instruction Tuning Dataset from Monolingual Seed Data", "comment": null, "summary": "The effectiveness of instruction-tuned Large Language Models (LLMs) is often\nlimited in low-resource linguistic settings due to a lack of high-quality\ntraining data. We introduce LuxIT, a novel, monolingual instruction tuning\ndataset for Luxembourgish developed to mitigate this challenge. We synthesize\nthe dataset from a corpus of native Luxembourgish texts, utilizing\nDeepSeek-R1-0528, chosen for its shown proficiency in Luxembourgish. Following\ngeneration, we apply a quality assurance process, employing an LLM-as-a-judge\napproach. To investigate the practical utility of the dataset, we fine-tune\nseveral smaller-scale LLMs on LuxIT. Subsequent benchmarking against their base\nmodels on Luxembourgish language proficiency examinations, however, yields\nmixed results, with performance varying significantly across different models.\nLuxIT represents a critical contribution to Luxembourgish natural language\nprocessing and offers a replicable monolingual methodology, though our findings\nhighlight the need for further research to optimize its application.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.24690", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24690", "abs": "https://arxiv.org/abs/2510.24690", "authors": ["Shengjie Liu", "Li Dong", "Zhenyu Zhang"], "title": "Bridging Tool Dependencies and Domain Knowledge: A Graph-Based Framework for In-Context Planning", "comment": "4 pages, 2 figures, short paper, NeurIPS 2025 workshop on Bridging\n  Language, Agent, and World Models for Reasoning and Planning", "summary": "We present a framework for uncovering and exploiting dependencies among tools\nand documents to enhance exemplar artifact generation. Our method begins by\nconstructing a tool knowledge graph from tool schemas,including descriptions,\narguments, and output payloads, using a DeepResearch-inspired analysis. In\nparallel, we derive a complementary knowledge graph from internal documents and\nSOPs, which is then fused with the tool graph. To generate exemplar plans, we\nadopt a deep-sparse integration strategy that aligns structural tool\ndependencies with procedural knowledge. Experiments demonstrate that this\nunified framework effectively models tool interactions and improves plan\ngeneration, underscoring the benefits of linking tool graphs with domain\nknowledge graphs for tool-augmented reasoning and planning.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2411.09539", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2411.09539", "abs": "https://arxiv.org/abs/2411.09539", "authors": ["Marton Szep", "Daniel Rueckert", "R\u00fcdiger von Eisenhart-Rothe", "Florian Hinterwimmer"], "title": "Fine-tuning Large Language Models with Limited Data: A Survey and Practical Guide", "comment": "Accepted to TACL. Pre-MIT Press version. Major restructuring; added\n  preference alignment section and additional tables. 36 pages", "summary": "Fine-tuning large language models (LLMs) with limited data poses a practical\nchallenge in low-resource languages, specialized domains, and constrained\ndeployment settings. While pre-trained LLMs provide strong foundations,\neffective adaptation under data scarcity requires focused and efficient\nfine-tuning techniques. This paper presents a structured and practical survey\nof recent methods for fine-tuning LLMs in data-scarce scenarios. We\nsystematically review parameter-efficient fine-tuning techniques that lower\ntraining and deployment costs, domain and cross-lingual adaptation methods for\nboth encoder and decoder models, and model specialization strategies. We\nfurther examine preference alignment approaches that guide model behavior using\nlimited human or synthetic feedback, emphasizing sample and compute efficiency.\nThroughout, we highlight empirical trade-offs, selection criteria, and best\npractices for choosing suitable techniques based on task constraints, including\nmodel scaling, data scaling, and the mitigation of catastrophic forgetting. The\naim is to equip researchers and practitioners with actionable insights for\neffectively fine-tuning LLMs when data and resources are limited.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.24446", "categories": ["cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24446", "abs": "https://arxiv.org/abs/2510.24446", "authors": ["Viktoriia Zinkovich", "Anton Antonov", "Andrei Spiridonov", "Denis Shepelev", "Andrey Moskalenko", "Daria Pugacheva", "Elena Tutubalina", "Andrey Kuznetsov", "Vlad Shakhuro"], "title": "SPARTA: Evaluating Reasoning Segmentation Robustness through Black-Box Adversarial Paraphrasing in Text Autoencoder Latent Space", "comment": null, "summary": "Multimodal large language models (MLLMs) have shown impressive capabilities\nin vision-language tasks such as reasoning segmentation, where models generate\nsegmentation masks based on textual queries. While prior work has primarily\nfocused on perturbing image inputs, semantically equivalent textual\nparaphrases-crucial in real-world applications where users express the same\nintent in varied ways-remain underexplored. To address this gap, we introduce a\nnovel adversarial paraphrasing task: generating grammatically correct\nparaphrases that preserve the original query meaning while degrading\nsegmentation performance. To evaluate the quality of adversarial paraphrases,\nwe develop a comprehensive automatic evaluation protocol validated with human\nstudies. Furthermore, we introduce SPARTA-a black-box, sentence-level\noptimization method that operates in the low-dimensional semantic latent space\nof a text autoencoder, guided by reinforcement learning. SPARTA achieves\nsignificantly higher success rates, outperforming prior methods by up to 2x on\nboth the ReasonSeg and LLMSeg-40k datasets. We use SPARTA and competitive\nbaselines to assess the robustness of advanced reasoning segmentation models.\nWe reveal that they remain vulnerable to adversarial paraphrasing-even under\nstrict semantic and grammatical constraints. All code and data will be released\npublicly upon acceptance.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.24450", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24450", "abs": "https://arxiv.org/abs/2510.24450", "authors": ["\u0160pela Vintar", "Taja Kuzman Punger\u0161ek", "Mojca Brglez", "Nikola Ljube\u0161i\u0107"], "title": "Charting the European LLM Benchmarking Landscape: A New Taxonomy and a Set of Best Practices", "comment": "12 pages, 1 figure. Submitted to the LREC 2026 conference", "summary": "While new benchmarks for large language models (LLMs) are being developed\ncontinuously to catch up with the growing capabilities of new models and AI in\ngeneral, using and evaluating LLMs in non-English languages remains a\nlittle-charted landscape. We give a concise overview of recent developments in\nLLM benchmarking, and then propose a new taxonomy for the categorization of\nbenchmarks that is tailored to multilingual or non-English use scenarios. We\nfurther propose a set of best practices and quality standards that could lead\nto a more coordinated development of benchmarks for European languages. Among\nother recommendations, we advocate for a higher language and culture\nsensitivity of evaluation methods.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.24469", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2510.24469", "abs": "https://arxiv.org/abs/2510.24469", "authors": ["Durga Prasad Maram", "Dhruvin Gandhi", "Zonghai Yao", "Gayathri Akkinapalli", "Franck Dernoncourt", "Yu Wang", "Ryan A. Rossi", "Nesreen K. Ahmed"], "title": "Iterative Critique-Refine Framework for Enhancing LLM Personalization", "comment": null, "summary": "Personalized text generation requires models not only to produce coherent\ntext but also to align with a target user's style, tone, and topical focus.\nExisting retrieval-augmented approaches such as LaMP and PGraphRAG enrich\nprofiles with user and neighbor histories, but they stop at generation and\noften yield outputs that drift in tone, topic, or style. We present PerFine, a\nunified, training-free critique-refine framework that enhances personalization\nthrough iterative, profile-grounded feedback. In each iteration, an LLM\ngenerator produces a draft conditioned on the retrieved profile, and a critic\nLLM - also conditioned on the same profile - provides structured feedback on\ntone, vocabulary, sentence structure, and topicality. The generator then\nrevises, while a novel knockout strategy retains the stronger draft across\niterations. We further study additional inference-time strategies such as\nBest-of-N and Topic Extraction to balance quality and efficiency. Across Yelp,\nGoodreads, and Amazon datasets, PerFine consistently improves personalization\nover PGraphRAG, with GEval gains of +7-13%, steady improvements over 3-5\nrefinement iterations, and scalability with increasing critic size. These\nresults highlight that post-hoc, profile-aware feedback offers a powerful\nparadigm for personalized LLM generation that is both training-free and\nmodel-agnostic.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.24476", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24476", "abs": "https://arxiv.org/abs/2510.24476", "authors": ["Yihan Li", "Xiyuan Fu", "Ghanshyam Verma", "Paul Buitelaar", "Mingming Liu"], "title": "Mitigating Hallucination in Large Language Models (LLMs): An Application-Oriented Survey on RAG, Reasoning, and Agentic Systems", "comment": "25 pages, 7 figures, 3 tables", "summary": "Hallucination remains one of the key obstacles to the reliable deployment of\nlarge language models (LLMs), particularly in real-world applications. Among\nvarious mitigation strategies, Retrieval-Augmented Generation (RAG) and\nreasoning enhancement have emerged as two of the most effective and widely\nadopted approaches, marking a shift from merely suppressing hallucinations to\nbalancing creativity and reliability. However, their synergistic potential and\nunderlying mechanisms for hallucination mitigation have not yet been\nsystematically examined. This survey adopts an application-oriented perspective\nof capability enhancement to analyze how RAG, reasoning enhancement, and their\nintegration in Agentic Systems mitigate hallucinations. We propose a taxonomy\ndistinguishing knowledge-based and logic-based hallucinations, systematically\nexamine how RAG and reasoning address each, and present a unified framework\nsupported by real-world applications, evaluations, and benchmarks.", "AI": {"tldr": "\u672c\u6587\u8c03\u67e5\u4e86\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u548c\u63a8\u7406\u589e\u5f3a\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e2d\u51cf\u5c11\u5e7b\u89c9\u7684\u5e94\u7528\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u533a\u5206\u77e5\u8bc6\u548c\u903b\u8f91\u5e7b\u89c9\u7684\u5206\u7c7b\u6cd5\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\u6765\u5206\u6790\u5b83\u4eec\u7684\u534f\u540c\u4f5c\u7528\uff0c\u7279\u522b\u662f\u5728Agentic\u7cfb\u7edf\u4e2d\u3002", "motivation": "\u5e7b\u89c9\u662f\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u53ef\u9760\u90e8\u7f72\u7684\u5173\u952e\u969c\u788d\uff0c\u5c24\u5176\u662f\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u3002\u5c3d\u7ba1\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u548c\u63a8\u7406\u589e\u5f3a\u662f\u4e24\u79cd\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u4f46\u5b83\u4eec\u534f\u540c\u4f5c\u7528\u4ee5\u53ca\u51cf\u5c11\u5e7b\u89c9\u7684\u673a\u5236\u5c1a\u672a\u5f97\u5230\u7cfb\u7edf\u7814\u7a76\u3002", "method": "\u8be5\u8c03\u67e5\u4ece\u5e94\u7528\u5bfc\u5411\u7684\u80fd\u529b\u589e\u5f3a\u89c6\u89d2\u51fa\u53d1\uff0c\u5206\u6790\u4e86RAG\u3001\u63a8\u7406\u589e\u5f3a\u53ca\u5176\u5728Agentic\u7cfb\u7edf\u4e2d\u7684\u96c6\u6210\u5982\u4f55\u51cf\u5c11\u5e7b\u89c9\u3002\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u533a\u5206\u77e5\u8bc6\u578b\u548c\u903b\u8f91\u578b\u5e7b\u89c9\u7684\u5206\u7c7b\u6cd5\uff0c\u5e76\u7cfb\u7edf\u5730\u7814\u7a76\u4e86RAG\u548c\u63a8\u7406\u5982\u4f55\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0cRAG\u548c\u63a8\u7406\u589e\u5f3a\u5728\u51cf\u5c11LLM\u5e7b\u89c9\u65b9\u9762\u5177\u6709\u534f\u540c\u6f5c\u529b\uff0c\u5c24\u5176\u662f\u5728Agentic\u7cfb\u7edf\u4e2d\u3002\u8be5\u8c03\u67e5\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u5e76\u4ee5\u5b9e\u9645\u5e94\u7528\u3001\u8bc4\u4f30\u548c\u57fa\u51c6\u6d4b\u8bd5\u4e3a\u652f\u6491\u3002", "conclusion": "\u8be5\u8c03\u67e5\u7cfb\u7edf\u5730\u8003\u5bdf\u4e86RAG\u548c\u63a8\u7406\u589e\u5f3a\u5728\u51cf\u5c11LLM\u5e7b\u89c9\u65b9\u9762\u7684\u4f5c\u7528\uff0c\u7279\u522b\u662f\u5728Agentic\u7cfb\u7edf\u4e2d\u7684\u5e94\u7528\u3002\u901a\u8fc7\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u5e7b\u89c9\u5206\u7c7b\u6cd5\u548c\u7edf\u4e00\u7684\u5206\u6790\u6846\u67b6\uff0c\u8be5\u7814\u7a76\u4e3a\u672a\u6765\u5f00\u53d1\u66f4\u53ef\u9760\u3001\u66f4\u5177\u521b\u9020\u6027\u7684LLM\u63d0\u4f9b\u4e86\u89c1\u89e3\u548c\u65b9\u5411\u3002"}}
{"id": "2510.24478", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24478", "abs": "https://arxiv.org/abs/2510.24478", "authors": ["Frederik Broy", "Maike Z\u00fcfle", "Jan Niehues"], "title": "Talk2Ref: A Dataset for Reference Prediction from Scientific Talks", "comment": null, "summary": "Scientific talks are a growing medium for disseminating research, and\nautomatically identifying relevant literature that grounds or enriches a talk\nwould be highly valuable for researchers and students alike. We introduce\nReference Prediction from Talks (RPT), a new task that maps long, and\nunstructured scientific presentations to relevant papers. To support research\non RPT, we present Talk2Ref, the first large-scale dataset of its kind,\ncontaining 6,279 talks and 43,429 cited papers (26 per talk on average), where\nrelevance is approximated by the papers cited in the talk's corresponding\nsource publication. We establish strong baselines by evaluating\nstate-of-the-art text embedding models in zero-shot retrieval scenarios, and\npropose a dual-encoder architecture trained on Talk2Ref. We further explore\nstrategies for handling long transcripts, as well as training for domain\nadaptation. Our results show that fine-tuning on Talk2Ref significantly\nimproves citation prediction performance, demonstrating both the challenges of\nthe task and the effectiveness of our dataset for learning semantic\nrepresentations from spoken scientific content. The dataset and trained models\nare released under an open license to foster future research on integrating\nspoken scientific communication into citation recommendation systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201cTalk2Ref\u201d\u7684\u65b0\u578b\u6570\u636e\u96c6\u548c\u76f8\u5173\u65b9\u6cd5\uff0c\u65e8\u5728\u89e3\u51b3\u4ece\u79d1\u5b66\u8bb2\u5ea7\u4e2d\u81ea\u52a8\u8bc6\u522b\u76f8\u5173\u6587\u732e\u7684\u4efb\u52a1\uff08Reference Prediction from Talks, RPT\uff09\u3002\u8be5\u6570\u636e\u96c6\u5305\u542b6,279\u4e2a\u8bb2\u5ea7\u548c43,429\u7bc7\u5f15\u7528\u7684\u8bba\u6587\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5927\u89c4\u6a21\u7684\u8d44\u6e90\u6765\u8bad\u7ec3\u548c\u8bc4\u4f30\u6a21\u578b\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u901a\u8fc7\u5728Talk2Ref\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5fae\u8c03\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u57fa\u4e8e\u6587\u672c\u5d4c\u5165\u6a21\u578b\u7684\u5f15\u7528\u9884\u6d4b\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u957f\u7bc7\u8bb2\u5ea7\u6587\u672c\u65b9\u9762\u3002", "motivation": "\u79d1\u5b66\u8bb2\u5ea7\u662f\u4f20\u64ad\u7814\u7a76\u6210\u679c\u7684\u91cd\u8981\u9014\u5f84\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u81ea\u52a8\u8bc6\u522b\u4e0e\u8bb2\u5ea7\u5185\u5bb9\u76f8\u5173\u7684\u6587\u732e\u7684\u5de5\u5177\u3002\u8fd9\u4f7f\u5f97\u7814\u7a76\u4eba\u5458\u548c\u5b66\u751f\u5728\u67e5\u627e\u652f\u6491\u6216\u4e30\u5bcc\u8bb2\u5ea7\u5185\u5bb9\u7684\u6587\u732e\u65f6\u9762\u4e34\u6311\u6218\u3002\u56e0\u6b64\uff0c\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u5c06\u975e\u7ed3\u6784\u5316\u7684\u79d1\u5b66\u8bb2\u5ea7\u5185\u5bb9\u6620\u5c04\u5230\u76f8\u5173\u6587\u732e\u7684\u7cfb\u7edf\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002", "method": "\u7814\u7a76\u4eba\u5458\u63d0\u51fa\u4e86\u201cReference Prediction from Talks (RPT)\u201d\u8fd9\u4e00\u65b0\u4efb\u52a1\uff0c\u5e76\u521b\u5efa\u4e86\u9996\u4e2a\u5927\u89c4\u6a21\u6570\u636e\u96c6\u201cTalk2Ref\u201d\uff0c\u5176\u4e2d\u5305\u542b6,279\u4e2a\u8bb2\u5ea7\u548c43,429\u7bc7\u5f15\u7528\u8bba\u6587\u3002\u4ed6\u4eec\u9996\u5148\u5728\u96f6\u6837\u672c\u68c0\u7d22\u573a\u666f\u4e0b\u8bc4\u4f30\u4e86\u5148\u8fdb\u7684\u6587\u672c\u5d4c\u5165\u6a21\u578b\u4f5c\u4e3a\u57fa\u7ebf\u3002\u968f\u540e\uff0c\u4ed6\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53cc\u7f16\u7801\u5668\u67b6\u6784\u5e76\u5728Talk2Ref\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\u7684\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u8fd8\u63a2\u7d22\u4e86\u5904\u7406\u957f\u7bc7\u8bb2\u5ea7\u6587\u672c\u7684\u7b56\u7565\u4ee5\u53ca\u9886\u57df\u81ea\u9002\u5e94\u7684\u8bad\u7ec3\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728Talk2Ref\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5fae\u8c03\u80fd\u591f\u663e\u8457\u63d0\u5347\u5f15\u7528\u9884\u6d4b\u7684\u6027\u80fd\u3002\u8fd9\u4e0d\u4ec5\u51f8\u663e\u4e86RPT\u4efb\u52a1\u7684\u6311\u6218\u6027\uff0c\u4e5f\u8bc1\u660e\u4e86\u8be5\u6570\u636e\u96c6\u5728\u5b66\u4e60\u53e3\u5934\u79d1\u5b66\u5185\u5bb9\u8bed\u4e49\u8868\u793a\u65b9\u9762\u7684\u6709\u6548\u6027\u3002\u7814\u7a76\u63d0\u51fa\u7684\u53cc\u7f16\u7801\u5668\u6a21\u578b\u5728\u5904\u7406\u957f\u6587\u672c\u548c\u9886\u57df\u9002\u5e94\u65b9\u9762\u4e5f\u8868\u73b0\u51fa\u826f\u597d\u7684\u6f5c\u529b\u3002", "conclusion": "\u672c\u6587\u6210\u529f\u6784\u5efa\u4e86Talk2Ref\u6570\u636e\u96c6\u5e76\u63d0\u51fa\u4e86\u76f8\u5e94\u7684\u57fa\u7ebf\u6a21\u578b\u548c\u6539\u8fdb\u7b56\u7565\uff0c\u4e3a\u79d1\u5b66\u8bb2\u5ea7\u6587\u732e\u5f15\u7528\u9884\u6d4b\u4efb\u52a1\u5960\u5b9a\u4e86\u57fa\u7840\u3002\u8be5\u6570\u636e\u96c6\u548c\u6a21\u578b\u6709\u671b\u4fc3\u8fdb\u672a\u6765\u5728\u53e3\u5934\u79d1\u5b66\u4ea4\u6d41\u4e0e\u5f15\u7528\u63a8\u8350\u7cfb\u7edf\u96c6\u6210\u65b9\u9762\u7684\u7814\u7a76\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u7ee7\u7eed\u63a2\u7d22\u66f4\u590d\u6742\u7684\u6a21\u578b\u7ed3\u6784\u548c\u591a\u6a21\u6001\u4fe1\u606f\uff0c\u4ee5\u8fdb\u4e00\u6b65\u63d0\u5347\u5f15\u7528\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2510.24505", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24505", "abs": "https://arxiv.org/abs/2510.24505", "authors": ["Qing Zong", "Jiayu Liu", "Tianshi Zheng", "Chunyang Li", "Baixuan Xu", "Haochen Shi", "Weiqi Wang", "Zhaowei Wang", "Chunkit Chan", "Yangqiu Song"], "title": "CritiCal: Can Critique Help LLM Uncertainty or Confidence Calibration?", "comment": null, "summary": "Accurate confidence calibration in Large Language Models (LLMs) is critical\nfor safe use in high-stakes domains, where clear verbalized confidence enhances\nuser trust. Traditional methods that mimic reference confidence expressions\noften fail to capture the reasoning needed for accurate confidence assessment.\nWe propose natural language critiques as a solution, ideally suited for\nconfidence calibration, as precise gold confidence labels are hard to obtain\nand often require multiple generations. This paper studies how natural language\ncritiques can enhance verbalized confidence, addressing: (1) What to critique:\nuncertainty (question-focused) or confidence (answer-specific)? Analysis shows\nconfidence suits multiple-choice tasks, while uncertainty excels in open-ended\nscenarios. (2) How to critique: self-critique or critique calibration training?\nWe propose Self-Critique, enabling LLMs to critique and optimize their\nconfidence beyond mere accuracy, and CritiCal, a novel Critique Calibration\ntraining method that leverages natural language critiques to improve confidence\ncalibration, moving beyond direct numerical optimization. Experiments show that\nCritiCal significantly outperforms Self-Critique and other competitive\nbaselines, even surpassing its teacher model, GPT-4o, in complex reasoning\ntasks. CritiCal also shows robust generalization in out-of-distribution\nsettings, advancing LLM's reliability.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u6279\u5224\u6765\u6821\u51c6\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u7f6e\u4fe1\u5ea6\uff0c\u4ee5\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u5728\u751f\u6210\u51c6\u786e\u4e14\u53ef\u4fe1\u7684\u7f6e\u4fe1\u5ea6\u8868\u8fbe\u65b9\u9762\u7684\u4e0d\u8db3\u3002\u7814\u7a76\u63a2\u7d22\u4e86\u4e24\u79cd\u6279\u5224\u65b9\u5f0f\uff1a\u201c\u4e0d\u786e\u5b9a\u6027\u201d\u548c\u201c\u7f6e\u4fe1\u5ea6\u201d\uff0c\u5e76\u63d0\u51fa\u4e86\u4e24\u79cd\u65b9\u6cd5\uff1a\u201c\u81ea\u6211\u6279\u5224\u201d\u548c\u201cCritiCal\u201d\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u201cCritiCal\u201d\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u57fa\u7ebf\u548c\u6559\u5e08\u6a21\u578bGPT-4o\uff0c\u5e76\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u91d1\u878d\u3001\u533b\u7597\u7b49\u9ad8\u98ce\u9669\u9886\u57df\u7684\u5b89\u5168\u5e94\u7528\uff0c\u9700\u8981\u7cbe\u786e\u7684\u7f6e\u4fe1\u5ea6\u6821\u51c6\uff0c\u4ee5\u589e\u5f3a\u7528\u6237\u4fe1\u4efb\u3002\u7136\u800c\uff0c\u4f20\u7edf\u7684\u7f6e\u4fe1\u5ea6\u8868\u8fbe\u65b9\u6cd5\u5f80\u5f80\u65e0\u6cd5\u6355\u6349\u5230\u8fdb\u884c\u51c6\u786e\u7f6e\u4fe1\u5ea6\u8bc4\u4f30\u6240\u9700\u7684\u63a8\u7406\u8fc7\u7a0b\u3002\u6b64\u5916\uff0c\u83b7\u53d6\u7cbe\u786e\u7684\u7f6e\u4fe1\u5ea6\u6807\u7b7e\u56f0\u96be\u4e14\u8017\u65f6\uff0c\u5e38\u5e38\u9700\u8981\u591a\u6b21\u751f\u6210\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u7684\u52a8\u673a\u662f\u63a2\u7d22\u4e00\u79cd\u66f4\u6709\u6548\u7684\u65b9\u6cd5\u6765\u6821\u51c6LLM\u7684\u7f6e\u4fe1\u5ea6\uff0c\u7279\u522b\u662f\u5229\u7528\u81ea\u7136\u8bed\u8a00\u6279\u5224\u6765\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\u3002", "method": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u5229\u7528\u81ea\u7136\u8bed\u8a00\u6279\u5224\u6765\u589e\u5f3aLLM\u7684\u7f6e\u4fe1\u5ea6\u6821\u51c6\u3002\u7814\u7a76\u4eba\u5458\u63a2\u8ba8\u4e86\u4e24\u79cd\u6279\u5224\u65b9\u5f0f\uff1a1\uff09\u5173\u6ce8\u4e0d\u786e\u5b9a\u6027\uff08\u95ee\u9898\u5bfc\u5411\uff09\u62162\uff09\u5173\u6ce8\u7f6e\u4fe1\u5ea6\uff08\u7b54\u6848\u7279\u5b9a\uff09\u3002\u5206\u6790\u8868\u660e\uff0c\u7f6e\u4fe1\u5ea6\u9002\u5408\u591a\u9879\u9009\u62e9\u4efb\u52a1\uff0c\u800c\u4e0d\u786e\u5b9a\u6027\u5728\u5f00\u653e\u5f0f\u573a\u666f\u4e2d\u8868\u73b0\u66f4\u597d\u3002\u5728\u6b64\u57fa\u7840\u4e0a\uff0c\u7814\u7a76\u63d0\u51fa\u4e86\u4e24\u79cd\u65b9\u6cd5\uff1a1\uff09\u81ea\u6211\u6279\u5224\uff08Self-Critique\uff09\uff0c\u8ba9LLM\u80fd\u591f\u6279\u5224\u548c\u4f18\u5316\u5176\u7f6e\u4fe1\u5ea6\uff0c\u8d85\u8d8a\u5355\u7eaf\u7684\u51c6\u786e\u6027\uff1b2\uff09CritiCal\uff0c\u4e00\u79cd\u65b0\u9896\u7684\u6279\u5224\u6821\u51c6\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5229\u7528\u81ea\u7136\u8bed\u8a00\u6279\u5224\u6765\u6539\u8fdb\u7f6e\u4fe1\u5ea6\u6821\u51c6\uff0c\u800c\u4e0d\u662f\u76f4\u63a5\u8fdb\u884c\u6570\u503c\u4f18\u5316\u3002\u5b9e\u9a8c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u5e76\u5c06CritiCal\u4e0eSelf-Critique\u4ee5\u53ca\u5176\u4ed6\u7ade\u4e89\u6027\u57fa\u7ebf\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cCritiCal\u5728\u7f6e\u4fe1\u5ea6\u6821\u51c6\u65b9\u9762\u663e\u8457\u4f18\u4e8eSelf-Critique\u548c\u5176\u4ed6\u7ade\u4e89\u6027\u57fa\u7ebf\u3002\u7279\u522b\u662f\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\uff0cCritiCal\u7684\u8868\u73b0\u751a\u81f3\u8d85\u8fc7\u4e86\u5176\u6559\u5e08\u6a21\u578bGPT-4o\u3002\u6b64\u5916\uff0cCritiCal\u5728\u4e0d\u540c\u7684\u3001\u672a\u89c1\u8fc7\u7684\u6570\u636e\u5206\u5e03\uff08out-of-distribution\uff09\u8bbe\u7f6e\u4e0b\u4e5f\u5c55\u73b0\u51fa\u9c81\u68d2\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u8868\u660e\u5176\u5728\u63d0\u9ad8LLM\u53ef\u9760\u6027\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\u3002", "conclusion": "\u672c\u7814\u7a76\u6210\u529f\u5730\u63d0\u51fa\u4e86\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u6279\u5224\u6765\u6821\u51c6LLM\u7f6e\u4fe1\u5ea6\u7684\u65b9\u6cd5\uff0c\u5e76\u5f00\u53d1\u4e86\u540d\u4e3aCritiCal\u7684\u6709\u6548\u8bad\u7ec3\u6846\u67b6\u3002\u7814\u7a76\u8bc1\u660e\u4e86\u81ea\u7136\u8bed\u8a00\u6279\u5224\u5728\u63d0\u9ad8LLM\u7f6e\u4fe1\u5ea6\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u5c24\u5176\u662f\u5728\u590d\u6742\u63a8\u7406\u548c\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u3002CritiCal\u7684\u4f18\u8d8a\u6027\u80fd\u53ca\u5176\u8d85\u8d8a\u6559\u5e08\u6a21\u578b\u7684\u8868\u73b0\uff0c\u6807\u5fd7\u7740LLM\u5b89\u5168\u5e94\u7528\u9886\u57df\u7684\u91cd\u8981\u4e00\u6b65\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63a2\u7d22\u4e0d\u540c\u7c7b\u578b\u7684\u6279\u5224\u3001\u66f4\u5e7f\u6cdb\u7684\u5e94\u7528\u573a\u666f\u4ee5\u53ca\u66f4\u7cbe\u7ec6\u5316\u7684\u6821\u51c6\u6280\u672f\u3002"}}
{"id": "2510.24530", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24530", "abs": "https://arxiv.org/abs/2510.24530", "authors": ["Eric G. C. Laporte"], "title": "Lev\u00e9e d'ambigu\u00eft\u00e9s par grammaires locales", "comment": "in French language", "summary": "Many words are ambiguous in terms of their part of speech (POS). However,\nwhen a word appears in a text, this ambiguity is generally much reduced.\nDisambiguating POS involves using context to reduce the number of POS\nassociated with words, and is one of the main challenges of lexical tagging.\nThe problem of labeling words by POS frequently arises in natural language\nprocessing, for example for spelling correction, grammar or style checking,\nexpression recognition, text-to-speech conversion, text corpus analysis, etc.\nLexical tagging systems are thus useful as an initial component of many natural\nlanguage processing systems. A number of recent lexical tagging systems produce\nmultiple solutions when the text is lexically ambiguous or the uniquely correct\nsolution cannot be found. These contributions aim to guarantee a zero silence\nrate: the correct tag(s) for a word must never be discarded. This objective is\nunrealistic for systems that tag each word uniquely. This article concerns a\nlexical disambiguation method adapted to the objective of a zero silence rate\nand implemented in Silberztein's INTEX system (1993). We present here a formal\ndescription of this method. We show that to verify a local disambiguation\ngrammar in this framework, it is not sufficient to consider the transducer\npaths separately: one needs to verify their interactions. Similarly, if a\ncombination of multiple transducers is used, the result cannot be predicted by\nconsidering them in isolation. Furthermore, when examining the initial labeling\nof a text as produced by INTEX, ideas for disambiguation rules come\nspontaneously, but grammatical intuitions may turn out to be inaccurate, often\ndue to an unforeseen construction or ambiguity. If a zero silence rate is\ntargeted, local grammars must be carefully tested. This is where a detailed\nspecification of what a grammar will do once applied to texts would be\nnecessary.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u8bcd\u6027\u6807\u6ce8\uff08POS\uff09\u7684\u8bcd\u4e49\u6d88\u6b67\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u9002\u7528\u4e8eINTEX\u7cfb\u7edf\uff0c\u65e8\u5728\u5b9e\u73b0\u96f6\u6f0f\u62a5\u7387\uff08\u5373\u4e0d\u4e22\u5f03\u4efb\u4f55\u6b63\u786e\u7684\u8bcd\u6027\u6807\u7b7e\uff09\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u9a8c\u8bc1\u5c40\u90e8\u6d88\u6b67\u8bed\u6cd5\u65f6\uff0c\u5fc5\u987b\u8003\u8651\u53d8\u6d41\u5668\u8def\u5f84\u7684\u4ea4\u4e92\u4f5c\u7528\uff0c\u5e76\u4e14\u4e0d\u80fd\u5b64\u7acb\u5730\u9884\u6d4b\u7ec4\u5408\u591a\u4e2a\u53d8\u6d41\u5668\u7684\u7ed3\u679c\u3002\u6b64\u5916\uff0c\u4e3a\u4e86\u5b9e\u73b0\u96f6\u6f0f\u62a5\u7387\uff0c\u5fc5\u987b\u4ed4\u7ec6\u6d4b\u8bd5\u5c40\u90e8\u8bed\u6cd5\uff0c\u56e0\u4e3a\u7eaf\u7cb9\u7684\u8bed\u6cd5\u76f4\u89c9\u53ef\u80fd\u56e0\u610f\u5916\u7684\u6784\u9020\u6216\u6b67\u4e49\u800c\u4e0d\u51c6\u786e\u3002", "motivation": "\u8bcd\u8bed\u7684\u8bcd\u6027\uff08POS\uff09\u5b58\u5728\u6b67\u4e49\uff0c\u4f46\u5728\u7279\u5b9a\u6587\u672c\u4e0a\u4e0b\u6587\u4e2d\uff0c\u8fd9\u79cd\u6b67\u4e49\u901a\u5e38\u4f1a\u5927\u5927\u51cf\u5c11\u3002\u8bcd\u6027\u6d88\u6b67\u662f\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u7684\u4e00\u4e2a\u91cd\u8981\u6311\u6218\uff0c\u5e7f\u6cdb\u5e94\u7528\u4e8e\u62fc\u5199\u68c0\u67e5\u3001\u8bed\u6cd5\u98ce\u683c\u68c0\u67e5\u3001\u8868\u8fbe\u8bc6\u522b\u3001\u6587\u672c\u5230\u8bed\u97f3\u8f6c\u6362\u548c\u6587\u672c\u8bed\u6599\u5e93\u5206\u6790\u7b49\u9886\u57df\u3002\u56e0\u6b64\uff0c\u8bcd\u6027\u6807\u6ce8\u7cfb\u7edf\u662f\u8bb8\u591a\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7cfb\u7edf\u7684\u5173\u952e\u7ec4\u6210\u90e8\u5206\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u8bcd\u6027\u6807\u6ce8\u7cfb\u7edf\u5728\u5904\u7406\u6b67\u4e49\u6216\u65e0\u6cd5\u627e\u5230\u552f\u4e00\u6b63\u786e\u6807\u7b7e\u65f6\uff0c\u53ef\u80fd\u4f1a\u4ea7\u751f\u591a\u4e2a\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u5b58\u5728\u4e22\u5f03\u6b63\u786e\u6807\u7b7e\u7684\u98ce\u9669\u3002", "method": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u9002\u7528\u4e8e\u5b9e\u73b0\u96f6\u6f0f\u62a5\u7387\u76ee\u6807\u7684\u8bcd\u4e49\u6d88\u6b67\u65b9\u6cd5\uff0c\u5e76\u5c06\u5176\u96c6\u6210\u5230Silberztein\u7684INTEX\u7cfb\u7edf\u4e2d\u3002\u7814\u7a76\u4eba\u5458\u5bf9\u8be5\u65b9\u6cd5\u8fdb\u884c\u4e86\u5f62\u5f0f\u5316\u63cf\u8ff0\uff0c\u5e76\u5f3a\u8c03\u4e86\u5728\u9a8c\u8bc1\u5c40\u90e8\u6d88\u6b67\u8bed\u6cd5\u65f6\uff0c\u9700\u8981\u8003\u8651\u53d8\u6d41\u5668\u8def\u5f84\u4e4b\u95f4\u7684\u4ea4\u4e92\u4f5c\u7528\uff0c\u800c\u975e\u5b64\u7acb\u5206\u6790\u3002\u540c\u6837\uff0c\u5f53\u7ec4\u5408\u4f7f\u7528\u591a\u4e2a\u53d8\u6d41\u5668\u65f6\uff0c\u5176\u7ed3\u679c\u4e5f\u65e0\u6cd5\u4ec5\u51ed\u5355\u72ec\u5206\u6790\u6765\u9884\u6d4b\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u5728INTEX\u7cfb\u7edf\u4e2d\u8fdb\u884c\u521d\u6b65\u6807\u6ce8\u540e\uff0c\u5c3d\u7ba1\u53ef\u4ee5\u81ea\u7136\u5730\u4ea7\u751f\u6d88\u6b67\u89c4\u5219\uff0c\u4f46\u8bed\u6cd5\u76f4\u89c9\u53ef\u80fd\u5e76\u4e0d\u603b\u662f\u51c6\u786e\u7684\uff0c\u8fd9\u53ef\u80fd\u662f\u7531\u4e8e\u610f\u5916\u7684\u6587\u672c\u7ed3\u6784\u6216\u6b67\u4e49\u6240\u81f4\u3002\u5982\u679c\u76ee\u6807\u662f\u5b9e\u73b0\u96f6\u6f0f\u62a5\u7387\uff0c\u90a3\u4e48\u5bf9\u5c40\u90e8\u8bed\u6cd5\u8fdb\u884c\u7ec6\u81f4\u7684\u6d4b\u8bd5\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u8be6\u7ec6\u8bf4\u660e\u8bed\u6cd5\u5728\u5e94\u7528\u4e8e\u6587\u672c\u65f6\u5c06\u4ea7\u751f\u7684\u5177\u4f53\u6548\u679c\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u8bcd\u6027\u6d88\u6b67\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u96c6\u6210\u5728INTEX\u7cfb\u7edf\u4e2d\uff0c\u5e76\u4e13\u6ce8\u4e8e\u5b9e\u73b0\u96f6\u6f0f\u62a5\u7387\u3002\u7814\u7a76\u5f3a\u8c03\u4e86\u5728\u9a8c\u8bc1\u6d88\u6b67\u65b9\u6cd5\u65f6\u8003\u8651\u7ec4\u4ef6\u4ea4\u4e92\u4f5c\u7528\u7684\u91cd\u8981\u6027\uff0c\u5e76\u6307\u51fa\u5728\u8ffd\u6c42\u96f6\u6f0f\u62a5\u7387\u65f6\uff0c\u7ec6\u81f4\u7684\u8bed\u6cd5\u6d4b\u8bd5\u548c\u660e\u786e\u7684\u8bed\u6cd5\u884c\u4e3a\u89c4\u8303\u662f\u5fc5\u4e0d\u53ef\u5c11\u7684\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u80fd\u9700\u8981\u66f4\u6df1\u5165\u5730\u7814\u7a76\u5982\u4f55\u81ea\u52a8\u751f\u6210\u548c\u9a8c\u8bc1\u8fd9\u4e9b\u5c40\u90e8\u8bed\u6cd5\uff0c\u4ee5\u5e94\u5bf9\u590d\u6742\u7684\u8bed\u8a00\u73b0\u8c61\u3002"}}
{"id": "2510.24538", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24538", "abs": "https://arxiv.org/abs/2510.24538", "authors": ["Venkata S Govindarajan", "Laura Biester"], "title": "Dark & Stormy: Modeling Humor in the Worst Sentences Ever Written", "comment": null, "summary": "Textual humor is enormously diverse and computational studies need to account\nfor this range, including intentionally bad humor. In this paper, we curate and\nanalyze a novel corpus of sentences from the Bulwer-Lytton Fiction Contest to\nbetter understand \"bad\" humor in English. Standard humor detection models\nperform poorly on our corpus, and an analysis of literary devices finds that\nthese sentences combine features common in existing humor datasets (e.g., puns,\nirony) with metaphor, metafiction and simile. LLMs prompted to synthesize\ncontest-style sentences imitate the form but exaggerate the effect by\nover-using certain literary devices, and including far more novel\nadjective-noun bigrams than human writers. Data, code and analysis are\navailable at https://github.com/venkatasg/bulwer-lytton", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u5e76\u5206\u6790\u4e86\u4e00\u4e2a\u5305\u542b\u201c\u7cdf\u7cd5\u201d\u5e7d\u9ed8\u7684\u82f1\u6587\u8bed\u6599\u5e93\uff0c\u53d1\u73b0\u73b0\u6709\u5e7d\u9ed8\u68c0\u6d4b\u6a21\u578b\u8868\u73b0\u4e0d\u4f73\uff0c\u5e76\u63ed\u793a\u4e86\u8be5\u7c7b\u5e7d\u9ed8\u7ed3\u5408\u4e86\u5e38\u89c1\u5e7d\u9ed8\u7279\u5f81\u4e0e\u6587\u5b66\u624b\u6cd5\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u53d1\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6a21\u4eff\u6b64\u7c7b\u5e7d\u9ed8\u65f6\uff0c\u867d\u7136\u5f62\u5f0f\u4e0a\u76f8\u4f3c\uff0c\u4f46\u4f1a\u8fc7\u5ea6\u4f7f\u7528\u67d0\u4e9b\u6587\u5b66\u624b\u6cd5\u5e76\u751f\u6210\u6bd4\u4eba\u7c7b\u4f5c\u8005\u66f4\u591a\u7684\u201c\u65b0\u9896\u5f62\u5bb9\u8bcd-\u540d\u8bcd\u201d\u4e8c\u5143\u7ec4\u3002", "motivation": "\u6587\u672c\u5e7d\u9ed8\u5f62\u5f0f\u591a\u6837\uff0c\u73b0\u6709\u8ba1\u7b97\u65b9\u6cd5\u9700\u8981\u66f4\u5e7f\u6cdb\u5730\u8986\u76d6\uff0c\u5305\u62ec\u523b\u610f\u8425\u9020\u7684\u201c\u7cdf\u7cd5\u201d\u5e7d\u9ed8\u3002\u7406\u89e3\u8fd9\u7c7b\u5e7d\u9ed8\u6709\u52a9\u4e8e\u6539\u8fdb\u5e7d\u9ed8\u68c0\u6d4b\u6a21\u578b\u548c\u5e7d\u9ed8\u751f\u6210\u6280\u672f\u3002", "method": "1. \u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u201c\u7cdf\u7cd5\u201d\u5e7d\u9ed8\u4f8b\u53e5\u7684\u65b0\u578b\u8bed\u6599\u5e93\uff0c\u6570\u636e\u6765\u6e90\u4e8eBulwer-Lytton\u5c0f\u8bf4\u7ade\u8d5b\u3002\n2. \u5206\u6790\u4e86\u8be5\u8bed\u6599\u5e93\u7684\u7279\u5f81\uff0c\u5e76\u6d4b\u8bd5\u4e86\u6807\u51c6\u5e7d\u9ed8\u68c0\u6d4b\u6a21\u578b\u5728\u8be5\u8bed\u6599\u5e93\u4e0a\u7684\u8868\u73b0\u3002\n3. \u8bc6\u522b\u4e86\u6784\u6210\u201c\u7cdf\u7cd5\u201d\u5e7d\u9ed8\u7684\u6587\u5b66\u4fee\u8f9e\u624b\u6cd5\uff0c\u5982\u53cc\u5173\u3001\u8bbd\u523a\u3001\u9690\u55bb\u3001\u5143\u5c0f\u8bf4\u548c\u660e\u55bb\u3002\n4. \u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u6a21\u4eff\u751f\u6210\u7ade\u8d5b\u98ce\u683c\u7684\u53e5\u5b50\uff0c\u5e76\u5206\u6790\u5176\u751f\u6210\u5185\u5bb9\u7684\u7279\u5f81\u3002", "result": "1. \u6807\u51c6\u5e7d\u9ed8\u68c0\u6d4b\u6a21\u578b\u5728\u672c\u6587\u6784\u5efa\u7684\u201c\u7cdf\u7cd5\u201d\u5e7d\u9ed8\u8bed\u6599\u5e93\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002\n2. \u201c\u7cdf\u7cd5\u201d\u5e7d\u9ed8\u7684\u53e5\u5b50\u878d\u5408\u4e86\u5e38\u89c1\u5e7d\u9ed8\u7279\u5f81\uff08\u5982\u53cc\u5173\u3001\u8bbd\u523a\uff09\u4e0e\u6587\u5b66\u624b\u6cd5\uff08\u5982\u9690\u55bb\u3001\u5143\u5c0f\u8bf4\u3001\u660e\u55bb\uff09\u3002\n3. \u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6a21\u4eff\u751f\u6210\u7ade\u8d5b\u98ce\u683c\u53e5\u5b50\u65f6\uff0c\u867d\u7136\u5f62\u5f0f\u4e0a\u76f8\u4f3c\uff0c\u4f46\u5b58\u5728\u5938\u5927\u6548\u679c\u7684\u95ee\u9898\uff0c\u5177\u4f53\u8868\u73b0\u5728\u8fc7\u5ea6\u4f7f\u7528\u67d0\u4e9b\u6587\u5b66\u624b\u6cd5\uff0c\u5e76\u751f\u6210\u4e86\u6bd4\u4eba\u7c7b\u4f5c\u8005\u66f4\u591a\u7684\u201c\u65b0\u9896\u5f62\u5bb9\u8bcd-\u540d\u8bcd\u201d\u4e8c\u5143\u7ec4\u3002", "conclusion": "\u672c\u6587\u5bf9\u201c\u7cdf\u7cd5\u201d\u5e7d\u9ed8\u8fdb\u884c\u4e86\u5f00\u521b\u6027\u7684\u7814\u7a76\uff0c\u6784\u5efa\u4e86\u65b0\u7684\u8bed\u6599\u5e93\uff0c\u63ed\u793a\u4e86\u5176\u72ec\u7279\u7684\u8bed\u8a00\u7279\u5f81\uff0c\u5e76\u6307\u51fa\u4e86\u5f53\u524d\u5e7d\u9ed8\u68c0\u6d4b\u6a21\u578b\u7684\u5c40\u9650\u6027\u3002\u7814\u7a76\u8fd8\u8868\u660e\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u6b64\u7c7b\u5e7d\u9ed8\u65f6\u5b58\u5728\u4e0d\u8db3\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63a2\u7d22\u66f4\u590d\u6742\u7684\u5e7d\u9ed8\u751f\u6210\u6a21\u578b\uff0c\u4ee5\u53ca\u66f4\u7ec6\u81f4\u7684\u5e7d\u9ed8\u7279\u5f81\u5206\u6790\u3002"}}
{"id": "2510.24541", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24541", "abs": "https://arxiv.org/abs/2510.24541", "authors": ["Seyoung Song", "Nawon Kim", "Songeun Chae", "Kiwoong Park", "Jiho Jin", "Haneul Yoo", "Kyunghyun Cho", "Alice Oh"], "title": "Open Korean Historical Corpus: A Millennia-Scale Diachronic Collection of Public Domain Texts", "comment": "Dataset and code available at https://github.com/seyoungsong/OKHC", "summary": "The history of the Korean language is characterized by a discrepancy between\nits spoken and written forms and a pivotal shift from Chinese characters to the\nHangul alphabet. However, this linguistic evolution has remained largely\nunexplored in NLP due to a lack of accessible historical corpora. To address\nthis gap, we introduce the Open Korean Historical Corpus, a large-scale, openly\nlicensed dataset spanning 1,300 years and 6 languages, as well as\nunder-represented writing systems like Korean-style Sinitic (Idu) and\nHanja-Hangul mixed script. This corpus contains 18 million documents and 5\nbillion tokens from 19 sources, ranging from the 7th century to 2025. We\nleverage this resource to quantitatively analyze major linguistic shifts: (1)\nIdu usage peaked in the 1860s before declining sharply; (2) the transition from\nHanja to Hangul was a rapid transformation starting around 1890; and (3) North\nKorea's lexical divergence causes modern tokenizers to produce up to 51 times\nhigher out-of-vocabulary rates. This work provides a foundational resource for\nquantitative diachronic analysis by capturing the history of the Korean\nlanguage. Moreover, it can serve as a pre-training corpus for large language\nmodels, potentially improving their understanding of Sino-Korean vocabulary in\nmodern Hangul as well as archaic writing systems.", "AI": {"tldr": "\u9274\u4e8e\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u9886\u57df\u7f3a\u4e4f\u5386\u53f2\u97e9\u8bed\u8bed\u6599\u5e93\uff0c\u672c\u7814\u7a76\u53d1\u5e03\u4e86\u4e00\u4e2a\u5305\u542b1800\u4e07\u4efd\u6587\u6863\u300150\u4ebf\u8bcd\u5143\u7684\u5f00\u653e\u97e9\u8bed\u5386\u53f2\u8bed\u6599\u5e93\uff08Open Korean Historical Corpus\uff09\uff0c\u6db5\u76d6\u4e867\u4e16\u7eaa\u81f32025\u5e74\u76841300\u5e74\u95f4\uff0c\u5e76\u5206\u6790\u4e86\u4e3b\u8981\u8bed\u8a00\u8f6c\u53d8\uff0c\u5305\u62ec\u6c49\u5b57\u8bcd\uff08Idu\uff09\u4f7f\u7528\u91cf\u572819\u4e16\u7eaa60\u5e74\u4ee3\u8fbe\u5230\u5cf0\u503c\u540e\u4e0b\u964d\uff0c\u6c49\u5b57\u5411\u8c1a\u6587\uff08Hangul\uff09\u7684\u5feb\u901f\u8f6c\u53d8\uff08\u7ea61890\u5e74\u5f00\u59cb\uff09\uff0c\u4ee5\u53ca\u671d\u9c9c\u8bed\u8a00\u8bcd\u6c47\u5dee\u5f02\u5bfc\u81f4\u73b0\u4ee3\u5206\u8bcd\u5668\u8bcd\u6c47\u5916\uff08OOV\uff09\u6bd4\u7387\u9ad8\u8fbe51\u500d\u3002\u8be5\u8bed\u6599\u5e93\u4e3a\u5b9a\u91cf\u5386\u65f6\u5206\u6790\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u5e76\u53ef\u7528\u4e8e\u9884\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4ee5\u589e\u5f3a\u5176\u5bf9\u6c49\u97e9\u8bcd\u6c47\u548c\u53e4\u4ee3\u4e66\u5199\u7cfb\u7edf\u7684\u7406\u89e3\u3002", "motivation": "\u5f53\u524d\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u9886\u57df\u5bf9\u97e9\u8bed\u8bed\u8a00\u6f14\u53d8\u7684\u7814\u7a76\u4e0d\u8db3\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u7f3a\u4e4f\u53ef\u8bbf\u95ee\u7684\u5386\u53f2\u8bed\u6599\u5e93\uff0c\u65e0\u6cd5\u8fdb\u884c\u6df1\u5165\u7684\u5386\u65f6\u5206\u6790\u3002\u56e0\u6b64\uff0c\u672c\u7814\u7a76\u65e8\u5728\u5f25\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u901a\u8fc7\u6784\u5efa\u5e76\u516c\u5f00\u4e00\u4e2a\u5927\u89c4\u6a21\u7684\u5386\u53f2\u97e9\u8bed\u8bed\u6599\u5e93\uff0c\u4ee5\u652f\u6301\u5bf9\u97e9\u8bed\u5386\u53f2\u8bed\u8a00\u5b66\u8f6c\u53d8\u7684\u91cf\u5316\u7814\u7a76\uff0c\u5e76\u4fc3\u8fdbNLP\u6a21\u578b\u5bf9\u97e9\u8bed\u5386\u53f2\u8bed\u8a00\u7279\u5f81\u7684\u7406\u89e3\u3002", "method": "\u672c\u7814\u7a76\u6784\u5efa\u4e86\u4e00\u4e2a\u540d\u4e3a\u201c\u5f00\u653e\u97e9\u8bed\u5386\u53f2\u8bed\u6599\u5e93\u201d\uff08Open Korean Historical Corpus\uff09\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u8be5\u8bed\u6599\u5e93\u5305\u542b1800\u4e07\u4efd\u6587\u6863\u548c50\u4ebf\u8bcd\u5143\uff0c\u8986\u76d6\u4e86\u4ece7\u4e16\u7eaa\u52302025\u5e74\u76841300\u5e74\u95f4\uff0c\u5e76\u652f\u63016\u79cd\u8bed\u8a00\u4ee5\u53ca\u5305\u62ec\u97e9\u5f0f\u6c49\u5b57\uff08Idu\uff09\u548c\u6c49\u5b57\u8c1a\u6587\u6df7\u5199\u7b49\u4ee3\u8868\u6027\u4e66\u5199\u7cfb\u7edf\u3002\u7814\u7a76\u5229\u7528\u8be5\u8bed\u6599\u5e93\u5bf9\u97e9\u8bed\u5386\u53f2\u4e0a\u7684\u4e3b\u8981\u8bed\u8a00\u8f6c\u53d8\u8fdb\u884c\u4e86\u91cf\u5316\u5206\u6790\uff0c\u5305\u62ec\u5206\u6790\u7279\u5b9a\u4e66\u5199\u7cfb\u7edf\uff08\u5982Idu\uff09\u7684\u4f7f\u7528\u9891\u7387\u53d8\u5316\u3001\u4e66\u5199\u7cfb\u7edf\u8f6c\u53d8\uff08\u5982\u4ece\u6c49\u5b57\u5230\u8c1a\u6587\uff09\u7684\u65f6\u95f4\u70b9\u548c\u901f\u5ea6\uff0c\u4ee5\u53ca\u73b0\u4ee3\u5206\u8bcd\u5668\u5728\u5904\u7406\u6765\u81ea\u4e0d\u540c\u5730\u533a\uff08\u5982\u671d\u9c9c\uff09\u7684\u6587\u672c\u65f6\u4ea7\u751f\u7684\u8bcd\u6c47\u5916\uff08OOV\uff09\u6bd4\u7387\u5dee\u5f02\u3002", "result": "\u901a\u8fc7\u5bf9\u5f00\u653e\u97e9\u8bed\u5386\u53f2\u8bed\u6599\u5e93\u7684\u5206\u6790\uff0c\u7814\u7a76\u53d1\u73b0\uff1a1. \u97e9\u5f0f\u6c49\u5b57\uff08Idu\uff09\u7684\u4f7f\u7528\u91cf\u572819\u4e16\u7eaa60\u5e74\u4ee3\u8fbe\u5230\u9876\u5cf0\uff0c\u968f\u540e\u6025\u5267\u4e0b\u964d\uff1b2. \u4ece\u6c49\u5b57\u5411\u8c1a\u6587\uff08Hangul\uff09\u7684\u4e66\u5199\u7cfb\u7edf\u8f6c\u53d8\u662f\u4e00\u4e2a\u5927\u7ea6\u59cb\u4e8e1890\u5e74\u7684\u5feb\u901f\u8fc7\u7a0b\uff1b3. \u671d\u9c9c\u7684\u8bcd\u6c47\u5dee\u5f02\u5bfc\u81f4\u73b0\u4ee3\u5206\u8bcd\u5668\u5728\u5904\u7406\u5176\u6587\u672c\u65f6\uff0c\u8bcd\u6c47\u5916\uff08OOV\uff09\u6bd4\u7387\u6bd4\u5904\u7406\u97e9\u56fd\u6587\u672c\u65f6\u9ad8\u51fa\u9ad8\u8fbe51\u500d\u3002", "conclusion": "\u672c\u7814\u7a76\u6210\u529f\u6784\u5efa\u5e76\u53d1\u5e03\u4e86\u5f00\u653e\u97e9\u8bed\u5386\u53f2\u8bed\u6599\u5e93\uff0c\u4e3a\u97e9\u8bed\u7684\u5b9a\u91cf\u5386\u65f6\u5206\u6790\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u57fa\u7840\u8d44\u6e90\u3002\u8be5\u8bed\u6599\u5e93\u4e0d\u4ec5\u63ed\u793a\u4e86\u97e9\u8bed\u5386\u53f2\u4e0a\u5982\u6c49\u5f0f\u8bcd\uff08Idu\uff09\u4f7f\u7528\u91cf\u53d8\u5316\u3001\u6c49\u5b57\u5411\u8c1a\u6587\u8f6c\u53d8\u901f\u5ea6\u4ee5\u53ca\u671d\u97e9\u8bed\u8a00\u8bcd\u6c47\u5dee\u5f02\u7b49\u5173\u952e\u8bed\u8a00\u73b0\u8c61\uff0c\u800c\u4e14\u4e3a\u6539\u8fdb\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u53e4\u4eca\u97e9\u8bed\u53ca\u76f8\u5173\u8bcd\u6c47\u7684\u7406\u89e3\u63d0\u4f9b\u4e86\u6f5c\u529b\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u6269\u5c55\u8bed\u6599\u5e93\u7684\u8986\u76d6\u8303\u56f4\u548c\u8bed\u8a00\u591a\u6837\u6027\uff0c\u5e76\u63a2\u7d22\u66f4\u591a\u57fa\u4e8e\u8be5\u8bed\u6599\u5e93\u7684NLP\u5e94\u7528\uff0c\u4f8b\u5982\u5f00\u53d1\u4e13\u95e8\u9488\u5bf9\u5386\u53f2\u8bed\u8a00\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u3002"}}
{"id": "2510.24570", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24570", "abs": "https://arxiv.org/abs/2510.24570", "authors": ["Rapha\u00ebl Bagat", "Irina Illina", "Emmanuel Vincent"], "title": "BEST-RQ-Based Self-Supervised Learning for Whisper Domain Adaptation", "comment": "Submitted to ICASSP 2026", "summary": "Automatic Speech Recognition (ASR) systems, despite large multilingual\ntraining, struggle in out-of-domain and low-resource scenarios where labeled\ndata is scarce. We propose BEARD (BEST-RQ Encoder Adaptation with Re-training\nand Distillation), a novel framework designed to adapt Whisper's encoder using\nunlabeled data. Unlike traditional self-supervised learning methods, BEARD\nuniquely combines a BEST-RQ objective with knowledge distillation from a frozen\nteacher encoder, ensuring the encoder's complementarity with the pre-trained\ndecoder. Our experiments focus on the ATCO2 corpus from the challenging Air\nTraffic Control (ATC) communications domain, characterized by non-native\nspeech, noise, and specialized phraseology. Using about 5,000 hours of\nuntranscribed speech for BEARD and 2 hours of transcribed speech for\nfine-tuning, the proposed approach significantly outperforms previous baseline\nand fine-tuned model, achieving a relative improvement of 12% compared to the\nfine-tuned model. To the best of our knowledge, this is the first work to use a\nself-supervised learning objective for domain adaptation of Whisper.", "AI": {"tldr": "BEARD\u662f\u4e00\u4e2a\u65b0\u6846\u67b6\uff0c\u5b83\u4f7f\u7528\u65e0\u6807\u7b7e\u6570\u636e\u6765\u8c03\u6574Whisper\u7684\u7f16\u7801\u5668\uff0c\u901a\u8fc7\u7ed3\u5408BEST-RQ\u76ee\u6807\u548c\u77e5\u8bc6\u84b8\u998f\uff0c\u5728\u4f4e\u8d44\u6e90\u548c\u7279\u5b9a\u9886\u57df\uff08\u5982\u822a\u7a7a\u4ea4\u901a\u7ba1\u5236\u901a\u4fe1\uff09\u7684\u8bed\u97f3\u8bc6\u522b\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u76f8\u5bf9\u6539\u8fdb\u8fbe12%\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\uff08ASR\uff09\u7cfb\u7edf\uff0c\u5373\u4f7f\u7ecf\u8fc7\u5927\u89c4\u6a21\u591a\u8bed\u8a00\u8bad\u7ec3\uff0c\u5728\u9886\u57df\u5916\u548c\u4f4e\u8d44\u6e90\u573a\u666f\u4e0b\u8868\u73b0\u4e0d\u4f73\uff0c\u56e0\u4e3a\u8fd9\u4e9b\u573a\u666f\u4e0b\u7684\u6807\u6ce8\u6570\u636e\u975e\u5e38\u6709\u9650\u3002\u8fd9\u5728\u822a\u7a7a\u4ea4\u901a\u7ba1\u5236\uff08ATC\uff09\u7b49\u7279\u5b9a\u9886\u57df\u5c24\u4e3a\u660e\u663e\uff0c\u8be5\u9886\u57df\u8bed\u97f3\u8bc6\u522b\u9762\u4e34\u975e\u6bcd\u8bed\u8005\u53d1\u97f3\u3001\u566a\u58f0\u5927\u548c\u4e13\u4e1a\u672f\u8bed\u591a\u7b49\u6311\u6218\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u9002\u5e94\u8fd9\u4e9b\u5177\u6709\u6311\u6218\u6027\u7684\u573a\u666f\u3002", "method": "BEARD\uff08BEST-RQ Encoder Adaptation with Re-training and Distillation\uff09\u6846\u67b6\u65e8\u5728\u8c03\u6574Whisper\u6a21\u578b\u7684\u7f16\u7801\u5668\u3002\u5b83\u4e0d\u4f9d\u8d56\u4e8e\u4f20\u7edf\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff0c\u800c\u662f\u521b\u65b0\u6027\u5730\u7ed3\u5408\u4e86BEST-RQ\uff08\u4e00\u79cd\u65b0\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u76ee\u6807\uff09\u548c\u77e5\u8bc6\u84b8\u998f\u6280\u672f\u3002\u5728\u77e5\u8bc6\u84b8\u998f\u8fc7\u7a0b\u4e2d\uff0c\u4e00\u4e2a\u56fa\u5b9a\u7684\u6559\u5e08\u7f16\u7801\u5668\u7528\u4e8e\u6307\u5bfc\u5b66\u751f\u7f16\u7801\u5668\u7684\u5b66\u4e60\uff0c\u4ee5\u786e\u4fdd\u5176\u4e0e\u9884\u8bad\u7ec3\u7684\u89e3\u7801\u5668\u4fdd\u6301\u517c\u5bb9\u6027\u3002\u5b9e\u9a8c\u5728\u4e00\u4e2a\u5305\u542b\u7ea65000\u5c0f\u65f6\u672a\u8f6c\u5f55\u8bed\u97f3\u7684ATC\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u968f\u540e\u4f7f\u75282\u5c0f\u65f6\u7684\u8f6c\u5f55\u8bed\u97f3\u8fdb\u884c\u5fae\u8c03\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cBEARD\u6846\u67b6\u5728ATCO2\u8bed\u6599\u5e93\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002\u4e0e\u57fa\u7ebf\u6a21\u578b\u548c\u7ecf\u8fc7\u5fae\u8c03\u7684\u6a21\u578b\u76f8\u6bd4\uff0cBEARD\u5b9e\u73b0\u4e8612%\u7684\u76f8\u5bf9\u6027\u80fd\u6539\u8fdb\u3002\u8fd9\u8bc1\u660e\u4e86\u8be5\u6846\u67b6\u5728\u5904\u7406\u5177\u6709\u6311\u6218\u6027\u7684ATC\u901a\u4fe1\u6570\u636e\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "BEARD\u6846\u67b6\u9996\u6b21\u6210\u529f\u5730\u5229\u7528\u81ea\u76d1\u7763\u5b66\u4e60\u76ee\u6807\u5b9e\u73b0\u4e86Whisper\u6a21\u578b\u7684\u9886\u57df\u81ea\u9002\u5e94\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u7ed3\u5408BEST-RQ\u76ee\u6807\u548c\u77e5\u8bc6\u84b8\u998f\uff0c\u6709\u6548\u5730\u5229\u7528\u4e86\u65e0\u6807\u7b7e\u6570\u636e\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5728\u4f4e\u8d44\u6e90\u548c\u7279\u5b9a\u9886\u57df\uff08\u5982ATC\u901a\u4fe1\uff09\u7684\u8bed\u97f3\u8bc6\u522b\u6027\u80fd\u3002\u8fd9\u9879\u5de5\u4f5c\u4e3a\u89e3\u51b3ASR\u7cfb\u7edf\u5728\u6570\u636e\u7a00\u758f\u548c\u9886\u57df\u8f6c\u79fb\u95ee\u9898\u4e0a\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63a2\u7d22\u8be5\u6846\u67b6\u5728\u66f4\u591a\u9886\u57df\u548c\u8bed\u8a00\u4e0a\u7684\u5e94\u7528\u3002"}}
{"id": "2510.24591", "categories": ["cs.CL", "astro-ph.IM"], "pdf": "https://arxiv.org/pdf/2510.24591", "abs": "https://arxiv.org/abs/2510.24591", "authors": ["Christine Ye", "Sihan Yuan", "Suchetha Cooray", "Steven Dillmann", "Ian L. V. Roque", "Dalya Baron", "Philipp Frank", "Sergio Martin-Alvarez", "Nolan Koblischke", "Frank J Qu", "Diyi Yang", "Risa Wechsler", "Ioana Ciuca"], "title": "ReplicationBench: Can AI Agents Replicate Astrophysics Research Papers?", "comment": null, "summary": "Frontier AI agents show increasing promise as scientific research assistants,\nand may eventually be useful for extended, open-ended research workflows.\nHowever, in order to use agents for novel research, we must first assess the\nunderlying faithfulness and correctness of their work. To evaluate agents as\nresearch assistants, we introduce ReplicationBench, an evaluation framework\nthat tests whether agents can replicate entire research papers drawn from the\nastrophysics literature. Astrophysics, where research relies heavily on\narchival data and computational study while requiring little real-world\nexperimentation, is a particularly useful testbed for AI agents in scientific\nresearch. We split each paper into tasks which require agents to replicate the\npaper's core contributions, including the experimental setup, derivations, data\nanalysis, and codebase. Each task is co-developed with the original paper\nauthors and targets a key scientific result, enabling objective evaluation of\nboth faithfulness (adherence to original methods) and correctness (technical\naccuracy of results). ReplicationBench is extremely challenging for current\nfrontier language models: even the best-performing language models score under\n20%. We analyze ReplicationBench trajectories in collaboration with domain\nexperts and find a rich, diverse set of failure modes for agents in scientific\nresearch. ReplicationBench establishes the first benchmark of paper-scale,\nexpert-validated astrophysics research tasks, reveals insights about agent\nperformance generalizable to other domains of data-driven science, and provides\na scalable framework for measuring AI agents' reliability in scientific\nresearch.", "AI": {"tldr": "Frontier AI agents are promising for scientific research but require evaluation for faithfulness and correctness. We introduce ReplicationBench, a framework using astrophysics papers to test AI agents' ability to replicate research contributions, including experimental setup, derivations, data analysis, and code. Current frontier models score below 20% on this challenging benchmark. Analysis reveals diverse failure modes, providing insights into agent reliability for data-driven science and a scalable framework for future evaluation.", "motivation": "AI agents show potential as scientific research assistants for open-ended workflows, but their faithfulness and correctness must be rigorously assessed before deployment in novel research. Evaluating these capabilities is crucial for trusting AI in scientific discovery.", "method": "ReplicationBench was developed by splitting astrophysics research papers into tasks that require AI agents to replicate the paper's core contributions, such as experimental setup, derivations, data analysis, and codebase. Each task was co-developed with the original paper authors to ensure it targets a key scientific result, enabling objective evaluation of both faithfulness (adherence to original methods) and correctness (technical accuracy).", "result": "Current frontier language models perform poorly on ReplicationBench, with the best models scoring under 20%. Analysis of agent performance trajectories, in collaboration with domain experts, identified a diverse range of failure modes encountered by agents when attempting scientific research tasks.", "conclusion": "ReplicationBench provides the first benchmark for paper-scale, expert-validated astrophysics research tasks, offering valuable insights into the current limitations of AI agents in scientific research. The framework is generalizable to other data-driven scientific domains and establishes a scalable method for measuring the reliability of AI agents in research settings. Future work should focus on improving agent capabilities to address the identified failure modes and enhance their utility in scientific workflows."}}
{"id": "2510.24592", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24592", "abs": "https://arxiv.org/abs/2510.24592", "authors": ["Guoxin Chen", "Jing Wu", "Xinjie Chen", "Wayne Xin Zhao", "Ruihua Song", "Chengxi Li", "Kai Fan", "Dayiheng Liu", "Minpeng Liao"], "title": "ReForm: Reflective Autoformalization with Prospective Bounded Sequence Optimization", "comment": "Ongoing Work", "summary": "Autoformalization, which translates natural language mathematics into\nmachine-verifiable formal statements, is critical for using formal mathematical\nreasoning to solve math problems stated in natural language. While Large\nLanguage Models can generate syntactically correct formal statements, they\noften fail to preserve the original problem's semantic intent. This limitation\narises from the LLM approaches' treating autoformalization as a simplistic\ntranslation task which lacks mechanisms for self-reflection and iterative\nrefinement that human experts naturally employ. To address these issues, we\npropose ReForm, a Reflective Autoformalization method that tightly integrates\nsemantic consistency evaluation into the autoformalization process. This\nenables the model to iteratively generate formal statements, assess its\nsemantic fidelity, and self-correct identified errors through progressive\nrefinement. To effectively train this reflective model, we introduce\nProspective Bounded Sequence Optimization (PBSO), which employs different\nrewards at different sequence positions to ensure that the model develops both\naccurate autoformalization and correct semantic validations, preventing\nsuperficial critiques that would undermine the purpose of reflection. Extensive\nexperiments across four autoformalization benchmarks demonstrate that ReForm\nachieves an average improvement of 17.2 percentage points over the strongest\nbaselines. To further ensure evaluation reliability, we introduce\nConsistencyCheck, a benchmark of 859 expert-annotated items that not only\nvalidates LLMs as judges but also reveals that autoformalization is inherently\ndifficult: even human experts produce semantic errors in up to 38.5% of cases.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5c06\u81ea\u7136\u8bed\u8a00\u6570\u5b66\u7ffb\u8bd1\u6210\u673a\u5668\u53ef\u9a8c\u8bc1\u7684\u6b63\u5f0f\u8bed\u53e5\uff08\u81ea\u52a8\u5f62\u5f0f\u5316\uff09\u65b9\u9762\u5b58\u5728\u8bed\u4e49\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\u3002\u672c\u6587\u63d0\u51fa\u4e86 ReForm\uff0c\u4e00\u79cd\u7ed3\u5408\u4e86\u81ea\u6211\u53cd\u601d\u548c\u8fed\u4ee3\u4f18\u5316\u673a\u5236\u7684\u81ea\u52a8\u5f62\u5f0f\u5316\u65b9\u6cd5\uff0c\u4ee5\u89e3\u51b3\u6b64\u95ee\u9898\u3002ReForm \u901a\u8fc7\u8bc4\u4f30\u548c\u4fee\u6b63\u751f\u6210\u5f62\u5f0f\u8bed\u53e5\u7684\u8bed\u4e49\u4fdd\u771f\u5ea6\u6765\u5de5\u4f5c\u3002\u4e3a\u4e86\u8bad\u7ec3 ReForm\uff0c\u5f15\u5165\u4e86\u671f\u671b\u6709\u754c\u5e8f\u5217\u4f18\u5316\uff08PBSO\uff09\u6765\u786e\u4fdd\u6a21\u578b\u80fd\u591f\u8fdb\u884c\u51c6\u786e\u7684\u5f62\u5f0f\u5316\u548c\u6709\u6548\u7684\u8bed\u4e49\u9a8c\u8bc1\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86 ConsistencyCheck \u57fa\u51c6\u6765\u8bc4\u4f30 LLMs \u4f5c\u4e3a\u88c1\u5224\u7684\u53ef\u9760\u6027\uff0c\u5e76\u63ed\u793a\u4e86\u5373\u4f7f\u662f\u4eba\u7c7b\u4e13\u5bb6\u5728\u81ea\u52a8\u5f62\u5f0f\u5316\u4efb\u52a1\u4e2d\u4e5f\u53ef\u80fd\u51fa\u9519\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u52a8\u5f62\u5f0f\u5316\u65b9\u6cd5\uff0c\u5c3d\u7ba1\u80fd\u591f\u751f\u6210\u8bed\u6cd5\u6b63\u786e\u7684\u5f62\u5f0f\u5316\u6570\u5b66\u8bed\u53e5\uff0c\u4f46\u5e38\u5e38\u65e0\u6cd5\u4fdd\u7559\u539f\u59cb\u95ee\u9898\u7684\u8bed\u4e49\u610f\u56fe\u3002\u8fd9\u4e3b\u8981\u662f\u56e0\u4e3a\u5b83\u4eec\u5c06\u81ea\u52a8\u5f62\u5f0f\u5316\u89c6\u4e3a\u4e00\u4e2a\u7b80\u5355\u7684\u7ffb\u8bd1\u4efb\u52a1\uff0c\u7f3a\u4e4f\u4eba\u7c7b\u4e13\u5bb6\u5728\u89e3\u51b3\u6570\u5b66\u95ee\u9898\u65f6\u81ea\u7136\u4f1a\u4f7f\u7528\u7684\u81ea\u6211\u53cd\u601d\u548c\u8fed\u4ee3\u6539\u8fdb\u673a\u5236\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u81ea\u52a8\u5f62\u5f0f\u5316\u65b9\u6cd5\u4ee5\u63d0\u9ad8\u5176\u8bed\u4e49\u4fdd\u771f\u5ea6\u81f3\u5173\u91cd\u8981\uff0c\u8fd9\u5bf9\u4e8e\u5229\u7528\u5f62\u5f0f\u5316\u63a8\u7406\u89e3\u51b3\u81ea\u7136\u8bed\u8a00\u6570\u5b66\u95ee\u9898\u81f3\u5173\u91cd\u8981\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86 ReForm\uff0c\u4e00\u79cd\u53cd\u601d\u5f0f\u81ea\u52a8\u5f62\u5f0f\u5316\u65b9\u6cd5\u3002ReForm \u7684\u6838\u5fc3\u5728\u4e8e\u5c06\u8bed\u4e49\u4e00\u81f4\u6027\u8bc4\u4f30\u7d27\u5bc6\u96c6\u6210\u5230\u81ea\u52a8\u5f62\u5f0f\u5316\u8fc7\u7a0b\u4e2d\uff0c\u4f7f\u5176\u80fd\u591f\u8fed\u4ee3\u5730\u751f\u6210\u5f62\u5f0f\u8bed\u53e5\uff0c\u8bc4\u4f30\u5176\u8bed\u4e49\u4fdd\u771f\u5ea6\uff0c\u5e76\u901a\u8fc7\u6e10\u8fdb\u5f0f\u7cbe\u70bc\u6765\u7ea0\u6b63\u9519\u8bef\u3002\u4e3a\u4e86\u6709\u6548\u8bad\u7ec3\u8fd9\u79cd\u53cd\u601d\u6a21\u578b\uff0c\u7814\u7a76\u8005\u5f15\u5165\u4e86\u671f\u671b\u6709\u754c\u5e8f\u5217\u4f18\u5316\uff08PBSO\uff09\u65b9\u6cd5\u3002PBSO \u5728\u5e8f\u5217\u7684\u4e0d\u540c\u4f4d\u7f6e\u5e94\u7528\u4e0d\u540c\u7684\u5956\u52b1\uff0c\u4ee5\u786e\u4fdd\u6a21\u578b\u4e0d\u4ec5\u80fd\u8fdb\u884c\u51c6\u786e\u7684\u81ea\u52a8\u5f62\u5f0f\u5316\uff0c\u8fd8\u80fd\u8fdb\u884c\u6b63\u786e\u7684\u8bed\u4e49\u9a8c\u8bc1\uff0c\u4ece\u800c\u907f\u514d\u4e86\u53ef\u80fd\u524a\u5f31\u53cd\u601d\u76ee\u7684\u7684\u8868\u9762\u5316\u6279\u8bc4\u3002\u6b64\u5916\uff0c\u4e3a\u4e86\u786e\u4fdd\u8bc4\u4f30\u7684\u53ef\u9760\u6027\uff0c\u8fd8\u5f15\u5165\u4e86\u4e00\u4e2a\u540d\u4e3a ConsistencyCheck \u7684\u65b0\u57fa\u51c6\uff0c\u8be5\u57fa\u51c6\u5305\u542b 859 \u4e2a\u7531\u4e13\u5bb6\u6807\u6ce8\u7684\u9879\u76ee\u3002", "result": "\u5728\u56db\u4e2a\u81ea\u52a8\u5f62\u5f0f\u5316\u57fa\u51c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cReForm \u65b9\u6cd5\u7684\u5e73\u5747\u6027\u80fd\u6bd4\u6700\u5f3a\u7684\u57fa\u7ebf\u65b9\u6cd5\u63d0\u9ad8\u4e86 17.2 \u4e2a\u767e\u5206\u70b9\u3002ConsistencyCheck \u57fa\u51c6\u7684\u8bc4\u4f30\u7ed3\u679c\u4e0d\u4ec5\u9a8c\u8bc1\u4e86 LLMs \u4f5c\u4e3a\u88c1\u5224\u7684\u6709\u6548\u6027\uff0c\u8fd8\u63ed\u793a\u4e86\u81ea\u52a8\u5f62\u5f0f\u5316\u4efb\u52a1\u672c\u8eab\u7684\u56fa\u6709\u96be\u5ea6\uff0c\u8868\u660e\u5373\u4f7f\u662f\u4eba\u7c7b\u4e13\u5bb6\u5728\u5904\u7406\u7684 38.5% \u7684\u6848\u4f8b\u4e2d\u4e5f\u4f1a\u4ea7\u751f\u8bed\u4e49\u9519\u8bef\u3002", "conclusion": "ReForm \u65b9\u6cd5\u901a\u8fc7\u5f15\u5165\u53cd\u601d\u548c\u8fed\u4ee3\u4f18\u5316\u673a\u5236\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u81ea\u52a8\u5f62\u5f0f\u5316\u4efb\u52a1\u7684\u6027\u80fd\uff0c\u89e3\u51b3\u4e86\u73b0\u6709 LLMs \u5728\u8bed\u4e49\u4fdd\u771f\u5ea6\u65b9\u9762\u7684\u4e0d\u8db3\u3002PBSO \u8bad\u7ec3\u7b56\u7565\u548c ConsistencyCheck \u57fa\u51c6\u7684\u63d0\u51fa\uff0c\u4e3a\u81ea\u52a8\u5f62\u5f0f\u5316\u548c\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u548c\u5de5\u5177\u3002\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u81ea\u52a8\u5f62\u5f0f\u5316\u4efb\u52a1\u7684\u6311\u6218\u6027\uff0c\u5373\u4f7f\u5bf9\u4eba\u7c7b\u4e13\u5bb6\u4e5f\u662f\u5982\u6b64\uff0c\u5e76\u4e3a\u672a\u6765\u5f00\u53d1\u66f4\u5f3a\u5927\u7684\u5f62\u5f0f\u5316\u63a8\u7406\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2510.24605", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24605", "abs": "https://arxiv.org/abs/2510.24605", "authors": ["Yicun Yang", "Cong Wang", "Shaobo Wang", "Zichen Wen", "Biqing Qi", "Hanlin Xu", "Linfeng Zhang"], "title": "Diffusion LLM with Native Variable Generation Lengths: Let [EOS] Lead the Way", "comment": null, "summary": "Diffusion-based large language models (dLLMs) have exhibited substantial\npotential for parallel text generation, which may enable more efficient\ngeneration compared to autoregressive models. However, current dLLMs suffer\nfrom fixed generation lengths, which indicates the generation lengths of dLLMs\nhave to be determined before decoding as a hyper-parameter, leading to issues\nin efficiency and flexibility. To solve these problems, in this work, we\npropose to train a diffusion LLM with native variable generation lengths,\nabbreviated as dLLM-Var. Concretely, we aim to train a model to accurately\npredict the [EOS] token in the generated text, which makes a dLLM be able to\nnatively infer in a block diffusion manner, while still maintaining the ability\nof global bi-directional (full) attention and high parallelism. Experiments on\nstandard benchmarks demonstrate that our method achieves a 30.1x speedup over\ntraditional dLLM inference paradigms and a 2.4x speedup relative to\nautoregressive models such as Qwen and Llama. Our method achieves higher\naccuracy and faster inference, elevating dLLMs beyond mere academic novelty and\nsupporting their practical use in real-world applications. Codes and models\nhave been released.", "AI": {"tldr": "\u63d0\u51fa\u4e86dLLM-Var\uff0c\u4e00\u79cd\u80fd\u591f\u539f\u751f\u652f\u6301\u53ef\u53d8\u6587\u672c\u751f\u6210\u957f\u5ea6\u7684\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709dLLM\u56fa\u5b9a\u751f\u6210\u957f\u5ea6\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u6548\u7387\u548c\u7075\u6d3b\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6269\u6563\u7684LLM\uff08dLLM\uff09\u5728\u6587\u672c\u751f\u6210\u65b9\u9762\u867d\u7136\u5177\u6709\u5e76\u884c\u6f5c\u529b\uff0c\u4f46\u5b58\u5728\u751f\u6210\u957f\u5ea6\u56fa\u5b9a\u7684\u95ee\u9898\uff0c\u9700\u8981\u5728\u89e3\u7801\u524d\u9884\u8bbe\u957f\u5ea6\uff0c\u8fd9\u5728\u6548\u7387\u548c\u7075\u6d3b\u6027\u4e0a\u5b58\u5728\u4e0d\u8db3\uff0c\u9650\u5236\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u63a8\u5e7f\u3002", "method": "\u63d0\u51fadLLM-Var\u6a21\u578b\uff0c\u5176\u6838\u5fc3\u5728\u4e8e\u8bad\u7ec3\u6a21\u578b\u80fd\u591f\u51c6\u786e\u9884\u6d4b[EOS]\uff08End-of-Sequence\uff09\u6807\u8bb0\u3002\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\uff0cdLLM\u80fd\u591f\u5728\u5757\u6269\u6563\uff08block diffusion\uff09\u7684\u6a21\u5f0f\u4e0b\u8fdb\u884c\u539f\u751f\u63a8\u7406\uff0c\u540c\u65f6\u4fdd\u7559\u5168\u5c40\u53cc\u5411\uff08full\uff09\u6ce8\u610f\u529b\u548c\u9ad8\u5e76\u884c\u6027\u7684\u4f18\u52bf\u3002", "result": "\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cdLLM-Var\u76f8\u6bd4\u4f20\u7edf\u7684dLLM\u63a8\u7406\u65b9\u6cd5\u5b9e\u73b0\u4e8630.1\u500d\u7684\u52a0\u901f\uff0c\u76f8\u6bd4Qwen\u548cLlama\u7b49\u81ea\u56de\u5f52\u6a21\u578b\u4e5f\u67092.4\u500d\u7684\u52a0\u901f\u3002\u8be5\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u63a8\u7406\u901f\u5ea6\u4e0a\u5747\u6709\u63d0\u5347\u3002", "conclusion": "dLLM-Var\u6210\u529f\u89e3\u51b3\u4e86\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u957f\u5ea6\u56fa\u5b9a\u7684\u5173\u952e\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u751f\u6210\u6548\u7387\u548c\u7075\u6d3b\u6027\uff0c\u4f7f\u5176\u8d85\u8d8a\u4e86\u5355\u7eaf\u7684\u5b66\u672f\u7814\u7a76\u4ef7\u503c\uff0c\u4e3a\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u90e8\u7f72dLLM\u63d0\u4f9b\u4e86\u53ef\u884c\u6027\u3002\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5176\u5728\u51c6\u786e\u6027\u548c\u901f\u5ea6\u4e0a\u7684\u4f18\u52bf\u3002"}}
{"id": "2510.24606", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24606", "abs": "https://arxiv.org/abs/2510.24606", "authors": ["Siheng Xiong", "Joe Zou", "Faramarz Fekri", "Yae Jee Cho"], "title": "Long-Context Modeling with Dynamic Hierarchical Sparse Attention for On-Device LLMs", "comment": "Accepted to NeurIPS 2025 Workshop on Efficient Reasoning", "summary": "The quadratic cost of attention hinders the scalability of long-context LLMs,\nespecially in resource-constrained settings. Existing static sparse methods\nsuch as sliding windows or global tokens utilizes the sparsity of attention to\nreduce the cost of attention, but poorly adapts to the content-dependent\nvariations in attention due to their staticity. While previous work has\nproposed several dynamic approaches to improve flexibility, they still depend\non predefined templates or heuristic mechanisms. Such strategies reduce\ngenerality and prune tokens that remain contextually important, limiting their\naccuracy across diverse tasks. To tackle these bottlenecks of existing methods\nfor long-context modeling, we introduce Dynamic Hierarchical Sparse Attention\n(DHSA), a data-driven framework that dynamically predicts attention sparsity\nonline without retraining. Our proposed DHSA adaptively segments sequences into\nvariable-length chunks, then computes chunk representations by aggregating the\ntoken embeddings within each chunk. To avoid the bias introduced by varying\nchunk lengths, we apply length-normalized aggregation that scales the averaged\nembeddings by the square root of the chunk size. Finally, DHSA upsamples the\nchunk-level similarity scores to token level similarities to calculate\nimportance scores that determine which token-level interactions should be\npreserved. Our experiments on Gemma2 with Needle-in-a-Haystack Test and\nLongBench show that DHSA matches dense attention in accuracy, while reducing\nprefill latency by 20-60% and peak memory usage by 35%. Compared to other\nrepresentative baselines such as block sparse attention, DHSA achieves\nconsistently higher accuracy (6-18% relative gains) with comparable or lower\ncost, offering an efficient and adaptable solution for long-context on-device\nLLMs.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u52a8\u6001\u5206\u5c42\u7a00\u758f\u6ce8\u610f\u529b\uff08DHSA\uff09\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u957f\u4e0a\u4e0b\u6587\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e2d\u4e8c\u6b21\u6ce8\u610f\u529b\u6210\u672c\u5e26\u6765\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898\u3002DHSA\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u7684\u65b9\u5f0f\u52a8\u6001\u9884\u6d4b\u6ce8\u610f\u529b\u7a00\u758f\u6027\uff0c\u5c06\u5e8f\u5217\u81ea\u9002\u5e94\u5730\u5206\u6bb5\uff0c\u5e76\u8fdb\u884c\u957f\u5ea6\u5f52\u4e00\u5316\u805a\u5408\uff0c\u6700\u7ec8\u5c06\u5757\u7ea7\u76f8\u4f3c\u5ea6\u5206\u6570\u4e0a\u91c7\u6837\u5230\u4ee4\u724c\u7ea7\uff0c\u4ee5\u786e\u5b9a\u4fdd\u7559\u54ea\u4e9b\u4ee4\u724c\u4ea4\u4e92\u3002\u5b9e\u9a8c\u8868\u660e\uff0cDHSA\u5728Gemma2\u6a21\u578b\u4e0a\uff0c\u4e0e\u5bc6\u96c6\u6ce8\u610f\u529b\u76f8\u5f53\uff0c\u540c\u65f6\u5c06\u9884\u586b\u5145\u5ef6\u8fdf\u964d\u4f4e\u4e8620-60%\uff0c\u5cf0\u503c\u5185\u5b58\u4f7f\u7528\u91cf\u51cf\u5c11\u4e8635%\uff0c\u5e76\u4e14\u5728\u51c6\u786e\u6027\u65b9\u9762\u4f18\u4e8e\u5176\u4ed6\u7a00\u758f\u6ce8\u610f\u529b\u57fa\u7ebf\u3002", "motivation": "\u957f\u4e0a\u4e0b\u6587\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u9762\u4e34\u7740\u4e8c\u6b21\u6ce8\u610f\u529b\u6210\u672c\u5e26\u6765\u7684\u53ef\u6269\u5c55\u6027\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u8d44\u6e90\u53d7\u9650\u7684\u73af\u5883\u4e0b\u3002\u73b0\u6709\u7684\u9759\u6001\u7a00\u758f\u65b9\u6cd5\uff08\u5982\u6ed1\u52a8\u7a97\u53e3\u3001\u5168\u5c40\u4ee4\u724c\uff09\u867d\u7136\u5229\u7528\u4e86\u6ce8\u610f\u529b\u7a00\u758f\u6027\uff0c\u4f46\u5176\u9759\u6001\u6027\u5bfc\u81f4\u5b83\u4eec\u96be\u4ee5\u9002\u5e94\u5185\u5bb9\u4f9d\u8d56\u7684\u6ce8\u610f\u529b\u53d8\u5316\u3002\u4e4b\u524d\u63d0\u51fa\u7684\u52a8\u6001\u65b9\u6cd5\u867d\u7136\u66f4\u7075\u6d3b\uff0c\u4f46\u4f9d\u8d56\u9884\u5b9a\u4e49\u7684\u6a21\u677f\u6216\u542f\u53d1\u5f0f\u673a\u5236\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u7684\u901a\u7528\u6027\uff0c\u5e76\u53ef\u80fd\u88c1\u526a\u6389\u91cd\u8981\u7684\u4e0a\u4e0b\u6587\u4ee4\u724c\uff0c\u4ece\u800c\u5f71\u54cd\u8de8\u4efb\u52a1\u7684\u51c6\u786e\u6027\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u7684\u52a8\u673a\u662f\u5f00\u53d1\u4e00\u79cd\u66f4\u901a\u7528\u3001\u66f4\u9ad8\u6548\u4e14\u9002\u5e94\u6027\u5f3a\u7684\u957f\u4e0a\u4e0b\u6587\u5efa\u6a21\u65b9\u6cd5\u3002", "method": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u52a8\u6001\u5206\u5c42\u7a00\u758f\u6ce8\u610f\u529b\uff08DHSA\uff09\u7684\u6846\u67b6\u3002DHSA\u9996\u5148\u5c06\u8f93\u5165\u5e8f\u5217\u81ea\u9002\u5e94\u5730\u5206\u5272\u6210\u4e0d\u540c\u957f\u5ea6\u7684\u5757\u3002\u7136\u540e\uff0c\u5b83\u901a\u8fc7\u805a\u5408\u6bcf\u4e2a\u5757\u5185\u7684\u4ee4\u724c\u5d4c\u5165\u6765\u8ba1\u7b97\u5757\u8868\u793a\uff0c\u5e76\u91c7\u7528\u957f\u5ea6\u5f52\u4e00\u5316\u805a\u5408\uff0c\u5c06\u5e73\u5747\u5d4c\u5165\u6309\u5757\u5927\u5c0f\u7684\u5e73\u65b9\u6839\u8fdb\u884c\u7f29\u653e\uff0c\u4ee5\u907f\u514d\u56e0\u5757\u957f\u5ea6\u53d8\u5316\u800c\u5f15\u5165\u7684\u504f\u5dee\u3002\u6700\u540e\uff0cDHSA\u5c06\u5757\u7ea7\u76f8\u4f3c\u5ea6\u5206\u6570\u4e0a\u91c7\u6837\u5230\u4ee4\u724c\u7ea7\u76f8\u4f3c\u5ea6\uff0c\u4ee5\u8ba1\u7b97\u91cd\u8981\u6027\u5206\u6570\uff0c\u5e76\u636e\u6b64\u786e\u5b9a\u4fdd\u7559\u54ea\u4e9b\u4ee4\u724c\u95f4\u7684\u4ea4\u4e92\u3002\u8be5\u6846\u67b6\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u5728\u7ebf\u52a8\u6001\u9884\u6d4b\u6ce8\u610f\u529b\u7a00\u758f\u6027\u3002\u5b9e\u9a8c\u5728Gemma2\u6a21\u578b\u4e0a\u8fdb\u884c\uff0c\u5e76\u4f7f\u7528\u4e86Needle-in-a-Haystack Test\u548cLongBench\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cDHSA\u5728Gemma2\u6a21\u578b\u4e0a\u8fbe\u5230\u4e86\u4e0e\u5bc6\u96c6\u6ce8\u610f\u529b\u76f8\u5f53\u7684\u51c6\u786e\u6027\u3002\u5728\u6027\u80fd\u65b9\u9762\uff0cDHSA\u5c06\u9884\u586b\u5145\u5ef6\u8fdf\u964d\u4f4e\u4e8620-60%\uff0c\u5e76\u5c06\u5cf0\u503c\u5185\u5b58\u4f7f\u7528\u91cf\u51cf\u5c11\u4e8635%\u3002\u4e0e\u5757\u7a00\u758f\u6ce8\u610f\u529b\u7b49\u4ee3\u8868\u6027\u57fa\u7ebf\u76f8\u6bd4\uff0cDHSA\u5728\u6210\u672c\u76f8\u5f53\u6216\u66f4\u4f4e\u7684\u60c5\u51b5\u4e0b\uff0c\u5b9e\u73b0\u4e86\u6301\u7eed\u66f4\u9ad8\u7684\u51c6\u786e\u6027\uff0c\u76f8\u5bf9\u63d0\u9ad8\u4e866-18%\u3002", "conclusion": "DHSA\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684\u957f\u4e0a\u4e0b\u6587LLMs\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u9002\u5e94\u6027\u5f3a\u7684\u89e3\u51b3\u65b9\u6848\u3002\u5b83\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u7684\u52a8\u6001\u7a00\u758f\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5728\u4fdd\u6301\u9ad8\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\u548c\u5185\u5b58\u4f7f\u7528\u91cf\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63a2\u7d22DHSA\u5728\u66f4\u591a\u6a21\u578b\u548c\u4efb\u52a1\u4e0a\u7684\u5e94\u7528\uff0c\u4ee5\u53ca\u4f18\u5316\u5176\u52a8\u6001\u7a00\u758f\u6027\u9884\u6d4b\u7684\u7b97\u6cd5\u3002"}}
{"id": "2510.24619", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7"], "pdf": "https://arxiv.org/pdf/2510.24619", "abs": "https://arxiv.org/abs/2510.24619", "authors": ["Snegha A", "Sayambhu Sen", "Piyush Singh Pasi", "Abhishek Singhania", "Preethi Jyothi"], "title": "Zero-Shot Cross-Lingual Transfer using Prefix-Based Adaptation", "comment": "12 Pages", "summary": "With the release of new large language models (LLMs) like Llama and Mistral,\nzero-shot cross-lingual transfer has become increasingly feasible due to their\nmultilingual pretraining and strong generalization capabilities. However,\nadapting these decoder-only LLMs to new tasks across languages remains\nchallenging. While parameter-efficient fine-tuning (PeFT) techniques like\nLow-Rank Adaptation (LoRA) are widely used, prefix-based techniques such as\nsoft prompt tuning, prefix tuning, and Llama Adapter are less explored,\nespecially for zero-shot transfer in decoder-only models. We present a\ncomprehensive study of three prefix-based methods for zero-shot cross-lingual\ntransfer from English to 35+ high- and low-resource languages. Our analysis\nfurther explores transfer across linguistic families and scripts, as well as\nthe impact of scaling model sizes from 1B to 24B. With Llama 3.1 8B, prefix\nmethods outperform LoRA-baselines by up to 6% on the Belebele benchmark.\nSimilar improvements were observed with Mistral v0.3 7B as well. Despite using\nonly 1.23M learning parameters with prefix tuning, we achieve consistent\nimprovements across diverse benchmarks. These findings highlight the potential\nof prefix-based techniques as an effective and scalable alternative to LoRA,\nparticularly in low-resource multilingual settings.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u96f6\u6837\u672c\u8de8\u8bed\u8a00\u8fc1\u79fb\u65b9\u9762\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u9488\u5bf9\u7279\u5b9a\u4efb\u52a1\u7684\u8c03\u6574\u4ecd\u5177\u6311\u6218\u6027\u3002\u672c\u7814\u7a76\u5168\u9762\u8bc4\u4f30\u4e86\u4e09\u79cd\u57fa\u4e8e\u524d\u7f00\u7684\u65b9\u6cd5\uff08\u8f6f\u63d0\u793a\u8c03\u4f18\u3001\u524d\u7f00\u8c03\u4f18\u548cLlama Adapter\uff09\u572835+\u79cd\u8bed\u8a00\u4e0a\u7684\u96f6\u6837\u672c\u8de8\u8bed\u8a00\u8fc1\u79fb\u80fd\u529b\uff0c\u5e76\u4e0eLoRA\u7b49\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff08PeFT\uff09\u6280\u672f\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5728Llama 3.1 8B\u548cMistral v0.3 7B\u6a21\u578b\u4e0a\uff0c\u57fa\u4e8e\u524d\u7f00\u7684\u65b9\u6cd5\u5728Belebele\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8eLoRA\uff0c\u5373\u4f7f\u4ec5\u4f7f\u7528\u5c11\u91cf\u53ef\u5b66\u4e60\u53c2\u6570\uff08\u5982\u524d\u7f00\u8c03\u4f18\u76841.23M\uff09\u4e5f\u80fd\u5b9e\u73b0\u6027\u80fd\u63d0\u5347\u3002\u7814\u7a76\u8fd8\u63a2\u8ba8\u4e86\u8de8\u8bed\u8a00\u7cfb\u3001\u8de8\u811a\u672c\u8fc1\u79fb\u4ee5\u53ca\u6a21\u578b\u89c4\u6a21\u7684\u5f71\u54cd\uff0c\u8868\u660e\u57fa\u4e8e\u524d\u7f00\u7684\u65b9\u6cd5\u5728\u4f4e\u8d44\u6e90\u591a\u8bed\u8a00\u573a\u666f\u4e0b\u662fLoRA\u7684\u6709\u6548\u4e14\u53ef\u6269\u5c55\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "motivation": "\u5c3d\u7ba1Llama\u548cMistral\u7b49\u65b0\u578b\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u53d1\u5e03\u4f7f\u5f97\u96f6\u6837\u672c\u8de8\u8bed\u8a00\u8fc1\u79fb\u53d8\u5f97\u66f4\u52a0\u53ef\u884c\uff0c\u4f46\u9488\u5bf9\u8fd9\u4e9b\u6a21\u578b\u5728\u8de8\u8bed\u8a00\u4efb\u52a1\u4e0a\u7684\u8c03\u6574\u4ecd\u7136\u9762\u4e34\u6311\u6218\u3002\u7279\u522b\u662f\u5bf9\u4e8e\u4ec5\u89e3\u7801\u5668\u7684LLMs\uff0c\u867d\u7136LoRA\u7b49\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff08PeFT\uff09\u6280\u672f\u88ab\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u8f6f\u63d0\u793a\u8c03\u4f18\u3001\u524d\u7f00\u8c03\u4f18\u548cLlama Adapter\u7b49\u57fa\u4e8e\u524d\u7f00\u7684\u6280\u672f\u5728\u96f6\u6837\u672c\u8fc1\u79fb\u573a\u666f\u4e0b\u7684\u7814\u7a76\u5c1a\u4e0d\u5145\u5206\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u6df1\u5165\u7814\u7a76\u8fd9\u4e9b\u57fa\u4e8e\u524d\u7f00\u7684\u65b9\u6cd5\u5728\u8de8\u8bed\u8a00\u8fc1\u79fb\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\uff0c\u5e76\u4e0e\u73b0\u6709\u4e3b\u6d41\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\uff0c\u7279\u522b\u662f\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u73af\u5883\u4e0b\u3002", "method": "\u672c\u7814\u7a76\u5bf9\u4e09\u79cd\u57fa\u4e8e\u524d\u7f00\u7684\u65b9\u6cd5\uff08\u8f6f\u63d0\u793a\u8c03\u4f18\u3001\u524d\u7f00\u8c03\u4f18\u548cLlama Adapter\uff09\u8fdb\u884c\u4e86\u5168\u9762\u7684\u8bc4\u4f30\uff0c\u7528\u4e8e\u8bc4\u4f30LLMs\u4ece\u82f1\u8bed\u523035\u79cd\u4ee5\u4e0a\u9ad8\u8d44\u6e90\u548c\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u96f6\u6837\u672c\u8de8\u8bed\u8a00\u8fc1\u79fb\u80fd\u529b\u3002\u7814\u7a76\u4f7f\u7528\u4e86Llama 3.1 8B\u548cMistral v0.3 7B\u6a21\u578b\uff0c\u5e76\u5728Belebele\u57fa\u51c6\u6d4b\u8bd5\u4ee5\u53ca\u5176\u4ed6\u591a\u6837\u5316\u57fa\u51c6\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u63a2\u7d22\u4e86\u6a21\u578b\u5728\u8de8\u4e0d\u540c\u8bed\u8a00\u7cfb\u548c\u6587\u5b57\uff08scripts\uff09\u7684\u8fc1\u79fb\u6548\u679c\uff0c\u5e76\u5206\u6790\u4e86\u6a21\u578b\u89c4\u6a21\uff08\u4ece1B\u523024B\uff09\u5bf9\u8fc1\u79fb\u6027\u80fd\u7684\u5f71\u54cd\u3002\u5b9e\u9a8c\u4e2d\uff0c\u57fa\u4e8e\u524d\u7f00\u7684\u65b9\u6cd5\u4ec5\u4f7f\u7528\u4e86\u5c11\u91cf\u53ef\u5b66\u4e60\u53c2\u6570\uff08\u4f8b\u5982\uff0c\u524d\u7f00\u8c03\u4f18\u4f7f\u75281.23M\u53c2\u6570\uff09\uff0c\u5e76\u4e0eLoRA\u7b49\u57fa\u7ebf\u65b9\u6cd5\u8fdb\u884c\u4e86\u6027\u80fd\u5bf9\u6bd4\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5728Llama 3.1 8B\u6a21\u578b\u4e0a\uff0c\u57fa\u4e8e\u524d\u7f00\u7684\u65b9\u6cd5\u5728Belebele\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u6027\u80fd\u6bd4LoRA\u57fa\u7ebf\u9ad8\u51fa6%\u3002\u7c7b\u4f3c\u5730\uff0c\u5728Mistral v0.3 7B\u6a21\u578b\u4e0a\u4e5f\u89c2\u5bdf\u5230\u4e86\u7c7b\u4f3c\u7684\u6027\u80fd\u63d0\u5347\u3002\u5373\u4f7f\u5728\u524d\u7f00\u8c03\u4f18\u4e2d\u4ec5\u4f7f\u75281.23M\u7684\u53ef\u5b66\u4e60\u53c2\u6570\uff0c\u7814\u7a76\u4e5f\u89c2\u5bdf\u5230\u4e86\u5728\u591a\u6837\u5316\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6301\u7eed\u7684\u6027\u80fd\u6539\u8fdb\u3002\u8fd9\u4e9b\u7ed3\u679c\u8868\u660e\uff0c\u57fa\u4e8e\u524d\u7f00\u7684\u6280\u672f\u5728\u4f5c\u4e3aLoRA\u7684\u6709\u6548\u66ff\u4ee3\u65b9\u6848\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u5c24\u5176\u662f\u5728\u4f4e\u8d44\u6e90\u591a\u8bed\u8a00\u5e94\u7528\u573a\u666f\u4e0b\u3002", "conclusion": "\u672c\u7814\u7a76\u5168\u9762\u8bc4\u4f30\u4e86\u4e09\u79cd\u57fa\u4e8e\u524d\u7f00\u7684\u65b9\u6cd5\u5728LLMs\u96f6\u6837\u672c\u8de8\u8bed\u8a00\u8fc1\u79fb\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u5c06\u5176\u4e0eLoRA\u7b49\u4e3b\u6d41\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u6280\u672f\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u57fa\u4e8e\u524d\u7f00\u7684\u65b9\u6cd5\uff0c\u5373\u4f7f\u5728\u53c2\u6570\u91cf\u5f88\u5c11\u7684\u60c5\u51b5\u4e0b\uff0c\u4e5f\u80fd\u5728\u591a\u79cd\u8bed\u8a00\u548c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e0e\u751a\u81f3\u4f18\u4e8eLoRA\u7684\u6027\u80fd\u3002\u8fd9\u8868\u660e\u57fa\u4e8e\u524d\u7f00\u7684\u6280\u672f\u662f\u4e00\u79cd\u5728\u4f4e\u8d44\u6e90\u591a\u8bed\u8a00\u8bbe\u7f6e\u4e0b\uff0c\u7279\u522b\u6709\u6f5c\u529b\u4e14\u53ef\u6269\u5c55\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4e3a\u672a\u6765\u7684\u8de8\u8bed\u8a00LLM\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63a2\u7d22\u4e0d\u540c\u524d\u7f00\u914d\u7f6e\u3001\u4e0e\u5176\u4ed6PeFT\u65b9\u6cd5\u7684\u7ed3\u5408\uff0c\u4ee5\u53ca\u5728\u66f4\u591a\u6837\u5316\u7684\u8de8\u8bed\u8a00\u4efb\u52a1\u4e0a\u7684\u5e94\u7528\u3002"}}
{"id": "2510.24626", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24626", "abs": "https://arxiv.org/abs/2510.24626", "authors": ["William Held", "David Hall", "Percy Liang", "Diyi Yang"], "title": "Relative Scaling Laws for LLMs", "comment": null, "summary": "Scaling laws describe how language models improve with additional data,\nparameters, and compute. While widely used, they are typically measured on\naggregate test sets. Aggregate evaluations yield clean trends but average over\nheterogeneous subpopulations, obscuring performance disparities. We introduce\nrelative scaling laws, which track how performance gaps between test\ndistributions evolve with scale rather than focusing solely on absolute error.\nUsing 255 decoder-only Transformers trained under matched-compute (IsoFLOP)\nbudgets from $10^{18}$--$10^{20}$ FLOPs on standard pretraining datasets, we\nfind diverse trajectories: academic domains on MMLU converge toward parity;\nregional English dialects shift depending on population size; and clusters of\nAI risk behaviours split, with capability- and influence-related risks\nincreasing during pretraining while adversarial risks do not. These results\nshow that although scaling improves overall performance, it is not a universal\nequalizer. To support further study, we release all model checkpoints from this\nwork to enable practitioners to measure relative alongside traditional scaling\nlaws, in order to better prioritize robustness challenges in light of the\nbitter lesson.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u201c\u76f8\u5bf9\u7f29\u653e\u5b9a\u5f8b\u201d\uff0c\u7528\u4e8e\u5206\u6790\u8bed\u8a00\u6a21\u578b\u5728\u6269\u5c55\u6570\u636e\u3001\u53c2\u6570\u548c\u8ba1\u7b97\u91cf\u65f6\uff0c\u4e0d\u540c\u6d4b\u8bd5\u5206\u5e03\u4e4b\u95f4\u6027\u80fd\u5dee\u8ddd\u7684\u53d8\u5316\u8d8b\u52bf\uff0c\u800c\u975e\u4ec5\u5173\u6ce8\u6574\u4f53\u8bef\u5dee\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u867d\u7136\u6a21\u578b\u6574\u4f53\u6027\u80fd\u968f\u89c4\u6a21\u63d0\u5347\uff0c\u4f46\u5e76\u975e\u5bf9\u6240\u6709\u5b50\u96c6\u90fd\u516c\u5e73\u3002\u4f8b\u5982\uff0c\u5b66\u672f\u9886\u57df\u5728MMLU\u4e0a\u7684\u8868\u73b0\u8d8b\u4e8e\u4e00\u81f4\uff0c\u4f46\u82f1\u8bed\u65b9\u8a00\u7684\u5dee\u5f02\u4f1a\u968f\u4eba\u53e3\u89c4\u6a21\u53d8\u5316\uff0cAI\u98ce\u9669\u884c\u4e3a\u7684\u96c6\u7fa4\u5219\u51fa\u73b0\u5206\u5316\uff0c\u80fd\u529b\u548c\u5f71\u54cd\u76f8\u5173\u7684\u98ce\u9669\u968f\u9884\u8bad\u7ec3\u589e\u52a0\u800c\u4e0a\u5347\uff0c\u800c\u5bf9\u6297\u6027\u98ce\u9669\u5219\u4e0d\u7136\u3002\u7814\u7a76\u53d1\u5e03\u4e86\u6240\u6709\u6a21\u578b\u68c0\u67e5\u70b9\uff0c\u4ee5\u652f\u6301\u5bf9\u76f8\u5bf9\u7f29\u653e\u5b9a\u5f8b\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\uff0c\u5e76\u66f4\u597d\u5730\u5e94\u5bf9\u6a21\u578b\u9c81\u68d2\u6027\u6311\u6218\u3002", "motivation": "\u4f20\u7edf\u8bed\u8a00\u6a21\u578b\u7f29\u653e\u5b9a\u5f8b\u4e3b\u8981\u5173\u6ce8\u5728\u805a\u5408\u6d4b\u8bd5\u96c6\u4e0a\u7684\u5e73\u5747\u6027\u80fd\u63d0\u5347\uff0c\u4f46\u8fd9\u79cd\u8bc4\u4f30\u65b9\u5f0f\u63a9\u76d6\u4e86\u6a21\u578b\u5728\u4e0d\u540c\u5b50\u7fa4\u4f53\u6216\u5206\u5e03\u4e0a\u7684\u6027\u80fd\u5dee\u5f02\u3002\u7406\u89e3\u8fd9\u4e9b\u5dee\u5f02\u5982\u4f55\u968f\u6a21\u578b\u89c4\u6a21\u53d8\u5316\u81f3\u5173\u91cd\u8981\uff0c\u5c24\u5176\u662f\u5728AI\u5b89\u5168\u548c\u516c\u5e73\u6027\u65e5\u76ca\u53d7\u5230\u5173\u6ce8\u7684\u80cc\u666f\u4e0b\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u201c\u76f8\u5bf9\u7f29\u653e\u5b9a\u5f8b\u201d\uff0c\u5373\u6a21\u578b\u5728\u4e0d\u540c\u6d4b\u8bd5\u5206\u5e03\u95f4\u7684\u6027\u80fd\u5dee\u8ddd\u5982\u4f55\u968f\u8ba1\u7b97\u91cf\u3001\u6570\u636e\u91cf\u548c\u53c2\u6570\u91cf\u7b49\u56e0\u7d20\u7684\u589e\u52a0\u800c\u6f14\u53d8\uff0c\u4ece\u800c\u66f4\u5168\u9762\u5730\u7406\u89e3\u6a21\u578b\u7684\u6269\u5c55\u884c\u4e3a\uff0c\u5e76\u8bc6\u522b\u6f5c\u5728\u7684\u98ce\u9669\u548c\u4e0d\u5e73\u7b49\u6027\u3002", "method": "\u7814\u7a76\u8bad\u7ec3\u4e86255\u4e2a\u4ec5\u89e3\u7801\u5668\u7684Transformer\u6a21\u578b\uff0c\u5e76\u91c7\u7528\u5339\u914d\u8ba1\u7b97\u9884\u7b97\uff08IsoFLOP\uff09\u7684\u65b9\u6cd5\uff0c\u5c06\u8ba1\u7b97\u91cf\u4ece$10^{18}$\u5230$10^{20}$ FLOPs\u3002\u6a21\u578b\u5728\u6807\u51c6\u7684\u9884\u8bad\u7ec3\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\u3002\u901a\u8fc7\u5bf9\u6bd4\u6a21\u578b\u5728\u4e0d\u540c\u6d4b\u8bd5\u5206\u5e03\u4e0a\u7684\u6027\u80fd\u8868\u73b0\uff0c\u5206\u6790\u4e86\u6027\u80fd\u5dee\u8ddd\u968f\u6a21\u578b\u89c4\u6a21\u53d8\u5316\u7684\u8f68\u8ff9\uff0c\u5e76\u5f15\u5165\u4e86\u201c\u76f8\u5bf9\u7f29\u653e\u5b9a\u5f8b\u201d\u7684\u6982\u5ff5\u6765\u91cf\u5316\u8fd9\u79cd\u53d8\u5316\u3002\u7814\u7a76\u5173\u6ce8\u4e86\u5b66\u672f\u9886\u57df\uff08\u5982MMLU\uff09\u3001\u5730\u57df\u82f1\u8bed\u65b9\u8a00\u4ee5\u53caAI\u98ce\u9669\u884c\u4e3a\uff08\u5982\u80fd\u529b\u3001\u5f71\u54cd\u548c\u5bf9\u6297\u6027\u98ce\u9669\uff09\u7b49\u591a\u4e2a\u7ef4\u5ea6\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u8bed\u8a00\u6a21\u578b\u5728\u6269\u5c55\u8fc7\u7a0b\u4e2d\uff0c\u4e0d\u540c\u6d4b\u8bd5\u5206\u5e03\u95f4\u7684\u6027\u80fd\u5dee\u8ddd\u5448\u73b0\u51fa\u591a\u6837\u5316\u7684\u6f14\u53d8\u8f68\u8ff9\u3002\u5177\u4f53\u6765\u8bf4\uff1a1. \u5728MMLU\u57fa\u51c6\u6d4b\u8bd5\u7684\u5b66\u672f\u9886\u57df\uff0c\u6a21\u578b\u6027\u80fd\u5dee\u8ddd\u8d8b\u4e8e\u6536\u655b\uff0c\u8868\u73b0\u51fa\u4e00\u5b9a\u7a0b\u5ea6\u7684\u516c\u5e73\u6027\u30022. \u5728\u82f1\u8bed\u65b9\u8a00\u6d4b\u8bd5\u4e2d\uff0c\u6a21\u578b\u6027\u80fd\u5dee\u8ddd\u968f\u76ee\u6807\u4eba\u7fa4\u89c4\u6a21\u7684\u53d8\u5316\u800c\u53d8\u5316\uff0c\u663e\u793a\u51fa\u53d7\u6570\u636e\u5206\u5e03\u5f71\u54cd\u7684\u73b0\u8c61\u30023. \u5728AI\u98ce\u9669\u884c\u4e3a\u8bc4\u4f30\u4e2d\uff0c\u6a21\u578b\u5728\u80fd\u529b\u548c\u5f71\u54cd\u65b9\u9762\u7684\u98ce\u9669\u968f\u9884\u8bad\u7ec3\u7684\u589e\u52a0\u800c\u4e0a\u5347\uff0c\u4f46\u5bf9\u6297\u6027\u98ce\u9669\u5e76\u672a\u8868\u73b0\u51fa\u7c7b\u4f3c\u7684\u589e\u957f\u8d8b\u52bf\u3002\u603b\u4f53\u800c\u8a00\uff0c\u6269\u5c55\u867d\u7136\u63d0\u5347\u4e86\u6a21\u578b\u7684\u6574\u4f53\u6027\u80fd\uff0c\u4f46\u5e76\u672a\u5b9e\u73b0\u666e\u904d\u7684\u6027\u80fd\u5747\u8861\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u201c\u76f8\u5bf9\u7f29\u653e\u5b9a\u5f8b\u201d\u4e3a\u7406\u89e3\u8bed\u8a00\u6a21\u578b\u6269\u5c55\u884c\u4e3a\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\uff0c\u63ed\u793a\u4e86\u6a21\u578b\u5728\u4e0d\u540c\u5206\u5e03\u4e0a\u7684\u6027\u80fd\u5dee\u8ddd\u6f14\u53d8\u89c4\u5f8b\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u6a21\u578b\u89c4\u6a21\u7684\u589e\u957f\u5e76\u975e\u4e07\u80fd\u7684\u201c\u516c\u5e73\u5316\u201d\u624b\u6bb5\uff0c\u5728\u5e26\u6765\u6574\u4f53\u6027\u80fd\u63d0\u5347\u7684\u540c\u65f6\uff0c\u4e5f\u53ef\u80fd\u52a0\u5267\u6216\u6539\u53d8\u5728\u7279\u5b9a\u5b50\u7fa4\u4f53\u6216\u98ce\u9669\u7ef4\u5ea6\u4e0a\u7684\u6027\u80fd\u5dee\u5f02\u3002\u7814\u7a76\u53d1\u5e03\u4e86\u6a21\u578b\u68c0\u67e5\u70b9\uff0c\u65e8\u5728\u9f13\u52b1\u793e\u533a\u8fdb\u4e00\u6b65\u7814\u7a76\u76f8\u5bf9\u7f29\u653e\u5b9a\u5f8b\uff0c\u4ee5\u4fbf\u66f4\u597d\u5730\u8bc6\u522b\u548c\u89e3\u51b3\u6a21\u578b\u9c81\u68d2\u6027\u65b9\u9762\u7684\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u201c\u82e6\u6da9\u6559\u8bad\u201d\uff08bitter lesson\uff09\u7684\u6307\u5bfc\u4e0b\uff0c\u66f4\u4f18\u5148\u5730\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002"}}
{"id": "2510.24628", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24628", "abs": "https://arxiv.org/abs/2510.24628", "authors": ["Anh Ngo", "Nicolas Rollet", "Catherine Pelachaud", "Chloe Clavel"], "title": "\"Mm, Wat?\" Detecting Other-initiated Repair Requests in Dialogue", "comment": "9 pages", "summary": "Maintaining mutual understanding is a key component in human-human\nconversation to avoid conversation breakdowns, in which repair, particularly\nOther-Initiated Repair (OIR, when one speaker signals trouble and prompts the\nother to resolve), plays a vital role. However, Conversational Agents (CAs)\nstill fail to recognize user repair initiation, leading to breakdowns or\ndisengagement. This work proposes a multimodal model to automatically detect\nrepair initiation in Dutch dialogues by integrating linguistic and prosodic\nfeatures grounded in Conversation Analysis. The results show that prosodic cues\ncomplement linguistic features and significantly improve the results of\npretrained text and audio embeddings, offering insights into how different\nfeatures interact. Future directions include incorporating visual cues,\nexploring multilingual and cross-context corpora to assess the robustness and\ngeneralizability.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u8bed\u8a00\u548c\u97f5\u5f8b\u7279\u5f81\u7684\u591a\u6a21\u6001\u6a21\u578b\uff0c\u7528\u4e8e\u81ea\u52a8\u68c0\u6d4b\u8377\u5170\u8bed\u5bf9\u8bdd\u4e2d\u7684\u4fee\u590d\u542f\u52a8\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5bf9\u8bdd\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u5411\u3002", "motivation": "\u5f53\u524d\u5bf9\u8bdd\u7cfb\u7edf\u5728\u8bc6\u522b\u7528\u6237\u53d1\u8d77\u7684\u4fee\u590d\uff08OIR\uff09\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u5bb9\u6613\u5bfc\u81f4\u5bf9\u8bdd\u4e2d\u65ad\u6216\u7528\u6237\u6d41\u5931\u3002\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u63d0\u5347\u5bf9\u8bdd\u7cfb\u7edf\u7684\u7528\u6237\u4f53\u9a8c\u3002", "method": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6a21\u6001\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u6574\u5408\u4e86\u57fa\u4e8e\u5bf9\u8bdd\u5206\u6790\u7684\u8bed\u8a00\u7279\u5f81\u548c\u97f5\u5f8b\u7279\u5f81\uff0c\u5e76\u5229\u7528\u9884\u8bad\u7ec3\u7684\u6587\u672c\u548c\u97f3\u9891\u5d4c\u5165\u6280\u672f\u6765\u81ea\u52a8\u68c0\u6d4b\u8377\u5170\u8bed\u5bf9\u8bdd\u4e2d\u7684\u4fee\u590d\u542f\u52a8\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u97f5\u5f8b\u7ebf\u7d22\u80fd\u591f\u6709\u6548\u8865\u5145\u8bed\u8a00\u7279\u5f81\uff0c\u5e76\u663e\u8457\u63d0\u5347\u9884\u8bad\u7ec3\u6587\u672c\u548c\u97f3\u9891\u5d4c\u5165\u7684\u6027\u80fd\u3002\u8fd9\u63ed\u793a\u4e86\u4e0d\u540c\u7279\u5f81\u4e4b\u95f4\u7684\u4ea4\u4e92\u4f5c\u7528\u3002", "conclusion": "\u672c\u7814\u7a76\u6210\u529f\u5f00\u53d1\u4e86\u4e00\u79cd\u591a\u6a21\u6001\u6a21\u578b\uff0c\u80fd\u591f\u6709\u6548\u68c0\u6d4b\u5bf9\u8bdd\u4e2d\u7684\u4fee\u590d\u542f\u52a8\uff0c\u4e3a\u63d0\u9ad8\u5bf9\u8bdd\u7cfb\u7edf\u7684\u667a\u80fd\u6027\u548c\u7528\u6237\u4f53\u9a8c\u63d0\u4f9b\u4e86\u91cd\u8981\u652f\u6301\u3002\u672a\u6765\u7684\u5de5\u4f5c\u5c06\u8003\u8651\u52a0\u5165\u89c6\u89c9\u7ebf\u7d22\uff0c\u5e76\u63a2\u7d22\u591a\u8bed\u8a00\u548c\u8de8\u8bed\u6599\u5e93\u7684\u5e94\u7528\uff0c\u4ee5\u8bc4\u4f30\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2510.24636", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24636", "abs": "https://arxiv.org/abs/2510.24636", "authors": ["Ziyou Hu", "Zhengliang Shi", "Minghang Zhu", "Haitao Li", "Teng Sun", "Pengjie Ren", "Suzan Verberne", "Zhaochun Ren"], "title": "OpenReward: Learning to Reward Long-form Agentic Tasks via Reinforcement Learning", "comment": null, "summary": "Reward models (RMs) have become essential for aligning large language models\n(LLMs), serving as scalable proxies for human evaluation in both training and\ninference. However, existing RMs struggle on knowledge-intensive and long-form\ntasks, where evaluating correctness requires grounding beyond the model's\ninternal knowledge. This limitation hinders them from reliably discriminating\nsubtle quality differences, especially when external evidence is necessary. To\naddress this, we introduce OpenRM, a tool-augmented long-form reward model that\nsystematically judges open-ended responses by invoking external tools to gather\nrelevant evidence. We train OpenRM with Group Relative Policy Optimization\n(GRPO) on over 27K synthesized pairwise examples generated through a\ncontrollable data synthesis framework. The training objective jointly\nsupervises intermediate tool usage and final outcome accuracy, incentivizing\nour reward model to learn effective evidence-based judgment strategies.\nExtensive experiments on three newly-collected datasets and two widely-used\nbenchmarks demonstrate that OpenRM substantially outperforms existing reward\nmodeling approaches. As a further step, we integrate OpenRM into both\ninference-time response selection and training-time data selection. This yields\nconsistent gains in downstream LLM alignment tasks, highlighting the potential\nof tool-augmented reward models for scaling reliable long-form evaluation.", "AI": {"tldr": "\u73b0\u6709\u5956\u52b1\u6a21\u578b(RM)\u5728\u5904\u7406\u9700\u8981\u5916\u90e8\u77e5\u8bc6\u9a8c\u8bc1\u7684\u957f\u7bc7\u5e45\u3001\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u65f6\u5b58\u5728\u5c40\u9650\u6027\u3002\u672c\u6587\u63d0\u51fa\u4e86OpenRM\uff0c\u4e00\u4e2a\u7ed3\u5408\u5de5\u5177\u68c0\u7d22\u5916\u90e8\u8bc1\u636e\u7684\u5956\u52b1\u6a21\u578b\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u5de5\u5177\u4f7f\u7528\u548c\u7ed3\u679c\u51c6\u786e\u6027\u6765\u63d0\u5347\u8bc4\u4f30\u80fd\u529b\u3002\u5b9e\u9a8c\u8bc1\u660eOpenRM\u5728\u957f\u7bc7\u5e45\u8bc4\u4f30\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u80fd\u5728\u4e0b\u6e38LLM\u5bf9\u9f50\u4efb\u52a1\u4e2d\u5e26\u6765\u6301\u7eed\u6536\u76ca\u3002", "motivation": "\u73b0\u6709\u5956\u52b1\u6a21\u578b\u96be\u4ee5\u53ef\u9760\u5730\u8bc4\u4f30\u9700\u8981\u5916\u90e8\u77e5\u8bc6\u7684\u957f\u7bc7\u5e45\u3001\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u7684\u54cd\u5e94\u8d28\u91cf\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u5728LLM\u5bf9\u9f50\u4e2d\u7684\u5e94\u7528\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u5916\u90e8\u8bc1\u636e\u6765\u533a\u5206\u7ec6\u5fae\u8d28\u91cf\u5dee\u5f02\u65f6\u3002", "method": "\u672c\u6587\u63d0\u51faOpenRM\uff0c\u4e00\u4e2a\u5de5\u5177\u589e\u5f3a\u7684\u957f\u7bc7\u5e45\u5956\u52b1\u6a21\u578b\u3002\u5b83\u901a\u8fc7\u8c03\u7528\u5916\u90e8\u5de5\u5177\u6765\u6536\u96c6\u8bc1\u636e\uff0c\u5e76\u4f7f\u7528\u7fa4\u4f53\u76f8\u5bf9\u7b56\u7565\u4f18\u5316(GRPO)\u8fdb\u884c\u8bad\u7ec3\uff0c\u8bad\u7ec3\u6570\u636e\u5305\u542b27K+\u5408\u6210\u7684\u6210\u5bf9\u6837\u672c\u3002\u8bad\u7ec3\u76ee\u6807\u540c\u65f6\u76d1\u7763\u4e2d\u95f4\u7684\u5de5\u5177\u4f7f\u7528\u548c\u6700\u7ec8\u7ed3\u679c\u7684\u51c6\u786e\u6027\u3002", "result": "\u5728\u4e09\u4e2a\u65b0\u6536\u96c6\u7684\u6570\u636e\u96c6\u548c\u4e24\u4e2a\u5e38\u7528\u57fa\u51c6\u7684\u5b9e\u9a8c\u8868\u660e\uff0cOpenRM\u5728\u957f\u7bc7\u5e45\u8bc4\u4f30\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u5956\u52b1\u5efa\u6a21\u65b9\u6cd5\u3002\u5c06OpenRM\u96c6\u6210\u5230\u63a8\u7406\u65f6\u54cd\u5e94\u9009\u62e9\u548c\u8bad\u7ec3\u65f6\u6570\u636e\u9009\u62e9\u4e2d\uff0c\u80fd\u5728\u4e0b\u6e38LLM\u5bf9\u9f50\u4efb\u52a1\u4e2d\u5e26\u6765\u6301\u7eed\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "OpenRM\u901a\u8fc7\u5f15\u5165\u5de5\u5177\u589e\u5f3a\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u5956\u52b1\u6a21\u578b\u5728\u957f\u7bc7\u5e45\u3001\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u8bc4\u4f30\u4e2d\u7684\u4e0d\u8db3\uff0c\u8bc1\u660e\u4e86\u5de5\u5177\u589e\u5f3a\u5956\u52b1\u6a21\u578b\u5728\u6269\u5c55\u53ef\u9760\u957f\u7bc7\u5e45\u8bc4\u4f30\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2510.24647", "categories": ["cs.CL", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2510.24647", "abs": "https://arxiv.org/abs/2510.24647", "authors": ["Hugo Rydel-Johnston", "Alex Kafkas"], "title": "Quantifying the Effects of Word Length, Frequency, and Predictability on Dyslexia", "comment": null, "summary": "We ask where, and under what conditions, dyslexic reading costs arise in a\nlarge-scale naturalistic reading dataset. Using eye-tracking aligned to\nword-level features (word length, frequency, and predictability), we model how\neach feature influences dyslexic time costs. We find that all three features\nrobustly change reading times in both typical and dyslexic readers, and that\ndyslexic readers show stronger sensitivities to each, especially\npredictability. Counterfactual manipulations of these features substantially\nnarrow the dyslexic-control gap by about one third, with predictability showing\nthe strongest effect, followed by length and frequency. These patterns align\nwith dyslexia theories that posit heightened demands on linguistic working\nmemory and phonological encoding, and they motivate further work on lexical\ncomplexity and parafoveal preview benefits to explain the remaining gap. In\nshort, we quantify when extra dyslexic costs arise, how large they are, and\noffer actionable guidance for interventions and computational models for\ndyslexics.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.24652", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2510.24652", "abs": "https://arxiv.org/abs/2510.24652", "authors": ["Jiawei Zhou", "Lei Chen"], "title": "Optimizing Retrieval for RAG via Reinforced Contrastive Learning", "comment": null, "summary": "As retrieval-augmented generation (RAG) becomes increasingly widespread, the\nrole of information retrieval (IR) is shifting from retrieving information for\nhuman users to retrieving contextual knowledge for artificial intelligence (AI)\nsystems, where relevance becomes difficult to define or annotate beforehand. To\naddress this challenge, we propose R3, a Retrieval framework optimized for RAG\nthrough trialand-feedback Reinforced contrastive learning. Unlike prior\napproaches that rely on annotated or synthetic data for supervised fine-tuning,\nR3 enables the retriever to dynamically explore and optimize relevance within\nthe RAG environment. During training, the retrieved results interact with the\nenvironment to produce contrastive signals that automatically guide the\nretriever's self-improvement. Extensive experiments across diverse tasks\ndemonstrate that R3 improves RAG performance by 5.2% over the original\nretriever and surpasses state-of-the-art retrievers by 4.9%, while achieving\ncomparable results to LLM-augmented retrieval and RAG systems built on\npost-trained or instruction-tuned LLMs. It is both efficient and practical,\nrequiring only 4 GPUs and completing training within a single day.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.24668", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24668", "abs": "https://arxiv.org/abs/2510.24668", "authors": ["Mingyi Deng", "Lijun Huang", "Yani Fan", "Jiayi Zhang", "Fashen Ren", "Jinyi Bai", "Fuzhen Yang", "Dayi Miao", "Zhaoyang Yu", "Yifan Wu", "Yanfei Zhang", "Fengwei Teng", "Yingjia Wan", "Song Hu", "Yude Li", "Xin Jin", "Conghao Hu", "Haoyu Li", "Qirui Fu", "Tai Zhong", "Xinyu Wang", "Xiangru Tang", "Nan Tang", "Chenglin Wu", "Yuyu Luo"], "title": "InteractComp: Evaluating Search Agents With Ambiguous Queries", "comment": null, "summary": "Language agents have demonstrated remarkable potential in web search and\ninformation retrieval. However, these search agents assume user queries are\ncomplete and unambiguous, an assumption that diverges from reality where users\nbegin with incomplete queries requiring clarification through interaction. Yet\nmost agents lack interactive mechanisms during the search process, and existing\nbenchmarks cannot assess this capability. To address this gap, we introduce\nInteractComp, a benchmark designed to evaluate whether search agents can\nrecognize query ambiguity and actively interact to resolve it during search.\nFollowing the principle of easy to verify, interact to disambiguate, we\nconstruct 210 expert-curated questions across 9 domains through a\ntarget-distractor methodology that creates genuine ambiguity resolvable only\nthrough interaction. Evaluation of 17 models reveals striking failure: the best\nmodel achieves only 13.73% accuracy despite 71.50% with complete context,\nexposing systematic overconfidence rather than reasoning deficits. Forced\ninteraction produces dramatic gains, demonstrating latent capability current\nstrategies fail to engage. Longitudinal analysis shows interaction capabilities\nstagnated over 15 months while search performance improved seven-fold,\nrevealing a critical blind spot. This stagnation, coupled with the immediate\nfeedback inherent to search tasks, makes InteractComp a valuable resource for\nboth evaluating and training interaction capabilities in search agents. The\ncode is available at https://github.com/FoundationAgents/InteractComp.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.24654", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24654", "abs": "https://arxiv.org/abs/2510.24654", "authors": ["Pengcheng Qiu", "Chaoyi Wu", "Junwei Liu", "Qiaoyu Zheng", "Yusheng Liao", "Haowen Wang", "Yun Yue", "Qianrui Fan", "Shuai Zhen", "Jian Wang", "Jinjie Gu", "Yanfeng Wang", "Ya Zhang", "Weidi Xie"], "title": "Evolving Diagnostic Agents in a Virtual Clinical Environment", "comment": null, "summary": "In this paper, we present a framework for training large language models\n(LLMs) as diagnostic agents with reinforcement learning, enabling them to\nmanage multi-turn diagnostic processes, adaptively select examinations, and\ncommit to final diagnoses. Unlike instruction-tuned models trained on static\ncase summaries, our method acquires diagnostic strategies through interactive\nexploration and outcome-based feedback. Our contributions are fourfold: (i) We\npresent DiagGym, a diagnostics world model trained with electronic health\nrecords that emits examination outcomes conditioned on patient history and\nrecommended examination, serving as a virtual clinical environment for\nrealistic diagnosis training and evaluation; (ii) We train DiagAgent via\nend-to-end, multi-turn reinforcement learning to learn diagnostic policies that\noptimize both information yield and diagnostic accuracy; (iii) We introduce\nDiagBench, a diagnostic benchmark comprising 750 cases with physician-validated\nexamination recommendations and 99 cases annotated with 973 physician-written\nrubrics on diagnosis process; (iv) we demonstrate superior performance across\ndiverse diagnostic settings. DiagAgent significantly outperforms 10\nstate-of-the-art LLMs, including DeepSeek-v3 and GPT-4o, as well as two\nprompt-engineered agents. In single-turn settings, DiagAgent achieves 9.34%\nhigher diagnostic accuracy and 44.03% improvement in examination recommendation\nhit ratio. In end-to-end settings, it delivers 15.12% increase in diagnostic\naccuracy and 23.09% boost in examination recommendation F1 score. In\nrubric-based evaluation, it surpasses the next-best model, Claude-sonnet-4, by\n7.1% in weighted rubric score. These findings indicate that learning policies\nin interactive clinical environments confers dynamic and clinically meaningful\ndiagnostic management abilities unattainable through passive training alone.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.24677", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24677", "abs": "https://arxiv.org/abs/2510.24677", "authors": ["Xun Liang", "Huayi Lai", "Hanyu Wang", "Wentao Zhang", "Linfeng Zhang", "Yanfang Chen", "Feiyu Xiong", "Zhiyu Li"], "title": "Dissecting Role Cognition in Medical LLMs via Neuronal Ablation", "comment": "15 pages, 9 figures", "summary": "Large language models (LLMs) have gained significant traction in medical\ndecision support systems, particularly in the\n  context of medical question answering and role-playing simulations. A common\npractice, Prompt-Based Role Playing (PBRP),\n  instructs models to adopt different clinical roles (e.g., medical students,\nresidents, attending physicians) to simulate varied\n  professional behaviors. However, the impact of such role prompts on model\nreasoning capabilities remains unclear. This\n  study introduces the RP-Neuron-Activated Evaluation Framework(RPNA) to\nevaluate whether role prompts induce distinct,\n  role-specific cognitive processes in LLMs or merely modify linguistic style.\nWe test this framework on three medical QA\n  datasets, employing neuron ablation and representation analysis techniques to\nassess changes in reasoning pathways. Our\n  results demonstrate that role prompts do not significantly enhance the\nmedical reasoning abilities of LLMs. Instead, they\n  primarily affect surface-level linguistic features, with no evidence of\ndistinct reasoning pathways or cognitive differentiation\n  across clinical roles. Despite superficial stylistic changes, the core\ndecision-making mechanisms of LLMs remain uniform\n  across roles, indicating that current PBRP methods fail to replicate the\ncognitive complexity found in real-world medical\n  practice. This highlights the limitations of role-playing in medical AI and\nemphasizes the need for models that simulate genuine\n  cognitive processes rather than linguistic imitation.We have released the\nrelated code in the following repository:https:\n  //github.com/IAAR-Shanghai/RolePlay_LLMDoctor", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.24664", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24664", "abs": "https://arxiv.org/abs/2510.24664", "authors": ["Parker Riley", "Daniel Deutsch", "Mara Finkelstein", "Colten DiIanni", "Juraj Juraska", "Markus Freitag"], "title": "MQM Re-Annotation: A Technique for Collaborative Evaluation of Machine Translation", "comment": null, "summary": "Human evaluation of machine translation is in an arms race with translation\nmodel quality: as our models get better, our evaluation methods need to be\nimproved to ensure that quality gains are not lost in evaluation noise. To this\nend, we experiment with a two-stage version of the current state-of-the-art\ntranslation evaluation paradigm (MQM), which we call MQM re-annotation. In this\nsetup, an MQM annotator reviews and edits a set of pre-existing MQM\nannotations, that may have come from themselves, another human annotator, or an\nautomatic MQM annotation system. We demonstrate that rater behavior in\nre-annotation aligns with our goals, and that re-annotation results in\nhigher-quality annotations, mostly due to finding errors that were missed\nduring the first pass.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.24694", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24694", "abs": "https://arxiv.org/abs/2510.24694", "authors": ["Yida Zhao", "Kuan Li", "Xixi Wu", "Liwen Zhang", "Dingchu Zhang", "Baixuan Li", "Maojia Song", "Zhuo Chen", "Chenxi Wang", "Xinyu Wang", "Kewei Tu", "Pengjun Xie", "Jingren Zhou", "Yong Jiang"], "title": "Repurposing Synthetic Data for Fine-grained Search Agent Supervision", "comment": null, "summary": "LLM-based search agents are increasingly trained on entity-centric synthetic\ndata to solve complex, knowledge-intensive tasks. However, prevailing training\nmethods like Group Relative Policy Optimization (GRPO) discard this rich entity\ninformation, relying instead on sparse, outcome-based rewards. This critical\nlimitation renders them unable to distinguish informative \"near-miss\"\nsamples-those with substantially correct reasoning but a flawed final\nanswer-from complete failures, thus discarding valuable learning signals. We\naddress this by leveraging the very entities discarded during training. Our\nempirical analysis reveals a strong positive correlation between the number of\nground-truth entities identified during an agent's reasoning process and final\nanswer accuracy. Building on this insight, we introduce Entity-aware Group\nRelative Policy Optimization (E-GRPO), a novel framework that formulates a\ndense entity-aware reward function. E-GRPO assigns partial rewards to incorrect\nsamples proportional to their entity match rate, enabling the model to\neffectively learn from these \"near-misses\". Experiments on diverse\nquestion-answering (QA) and deep research benchmarks show that E-GRPO\nconsistently and significantly outperforms the GRPO baseline. Furthermore, our\nanalysis reveals that E-GRPO not only achieves superior accuracy but also\ninduces more efficient reasoning policies that require fewer tool calls,\ndemonstrating a more effective and sample-efficient approach to aligning search\nagents.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.24698", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24698", "abs": "https://arxiv.org/abs/2510.24698", "authors": ["Baixuan Li", "Dingchu Zhang", "Jialong Wu", "Wenbiao Yin", "Zhengwei Tao", "Yida Zhao", "Liwen Zhang", "Haiyang Shen", "Runnan Fang", "Pengjun Xie", "Jingren Zhou", "Yong Jiang"], "title": "ParallelMuse: Agentic Parallel Thinking for Deep Information Seeking", "comment": null, "summary": "Parallel thinking expands exploration breadth, complementing the deep\nexploration of information-seeking (IS) agents to further enhance\nproblem-solving capability. However, conventional parallel thinking faces two\nkey challenges in this setting: inefficiency from repeatedly rolling out from\nscratch, and difficulty in integrating long-horizon reasoning trajectories\nduring answer generation, as limited context capacity prevents full\nconsideration of the reasoning process. To address these issues, we propose\nParallelMuse, a two-stage paradigm designed for deep IS agents. The first\nstage, Functionality-Specified Partial Rollout, partitions generated sequences\ninto functional regions and performs uncertainty-guided path reuse and\nbranching to enhance exploration efficiency. The second stage, Compressed\nReasoning Aggregation, exploits reasoning redundancy to losslessly compress\ninformation relevant to answer derivation and synthesize a coherent final\nanswer. Experiments across multiple open-source agents and benchmarks\ndemonstrate up to 62% performance improvement with a 10--30% reduction in\nexploratory token consumption.", "AI": {"tldr": "\u5e76\u884c\u601d\u8003\u901a\u8fc7\u6269\u5c55\u63a2\u7d22\u5e7f\u5ea6\u6765\u589e\u5f3a\u4fe1\u606f\u5bfb\u6c42\uff08IS\uff09\u667a\u80fd\u4f53\u7684\u89e3\u51b3\u95ee\u9898\u80fd\u529b\u3002\u7136\u800c\uff0c\u4f20\u7edf\u5e76\u884c\u601d\u8003\u5b58\u5728\u91cd\u590d\u4ece\u5934\u5f00\u59cb\u63a8\u51fa\u548c\u6574\u5408\u957f\u65f6\u63a8\u7406\u8f68\u8ff9\u7684\u56f0\u96be\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e86ParallelMuse\uff0c\u4e00\u4e2a\u4e24\u9636\u6bb5\u8303\u5f0f\u3002\u7b2c\u4e00\u9636\u6bb5\uff0c\u529f\u80fd\u6307\u5b9a\u90e8\u5206\u63a8\u51fa\uff0c\u901a\u8fc7\u4e0d\u786e\u5b9a\u6027\u5f15\u5bfc\u7684\u8def\u5f84\u91cd\u7528\u548c\u5206\u652f\u6765\u63d0\u9ad8\u63a2\u7d22\u6548\u7387\u3002\u7b2c\u4e8c\u9636\u6bb5\uff0c\u538b\u7f29\u63a8\u7406\u805a\u5408\uff0c\u5229\u7528\u63a8\u7406\u5197\u4f59\u6765\u65e0\u635f\u538b\u7f29\u4e0e\u7b54\u6848\u63a8\u5bfc\u76f8\u5173\u7684\u4fe1\u606f\uff0c\u5e76\u5408\u6210\u8fde\u8d2f\u7684\u6700\u7ec8\u7b54\u6848\u3002\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u5f00\u6e90\u667a\u80fd\u4f53\u548c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c55\u793a\u4e86\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u51cf\u5c11\u4e86\u63a2\u7d22\u6027\u4ee3\u5e01\u6d88\u8017\u3002", "motivation": "\u5f53\u524d\u7684\u4fe1\u606f\u5bfb\u6c42\uff08IS\uff09\u667a\u80fd\u4f53\u5728\u89e3\u51b3\u95ee\u9898\u65f6\uff0c\u867d\u7136\u80fd\u591f\u8fdb\u884c\u6df1\u5ea6\u63a2\u7d22\uff0c\u4f46\u7f3a\u4e4f\u5e7f\u5ea6\u7684\u63a2\u7d22\u80fd\u529b\u3002\u5e76\u884c\u601d\u8003\u867d\u7136\u53ef\u4ee5\u6269\u5c55\u63a2\u7d22\u7684\u5e7f\u5ea6\uff0c\u4f46\u9762\u4e34\u6548\u7387\u4f4e\u4e0b\uff08\u91cd\u590d\u4ece\u5934\u5f00\u59cb\u63a8\u51fa\uff09\u548c\u96be\u4ee5\u6574\u5408\u957f\u65f6\u63a8\u7406\u8f68\u8ff9\uff08\u7531\u4e8e\u6709\u9650\u7684\u4e0a\u4e0b\u6587\u5bb9\u91cf\uff09\u7684\u6311\u6218\u3002\u8fd9\u4e9b\u95ee\u9898\u9650\u5236\u4e86IS\u667a\u80fd\u4f53\u7684\u6574\u4f53\u95ee\u9898\u89e3\u51b3\u80fd\u529b\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aParallelMuse\u7684\u4e24\u9636\u6bb5\u8303\u5f0f\u6765\u89e3\u51b3\u4e0a\u8ff0\u6311\u6218\u3002\n\u7b2c\u4e00\u9636\u6bb5\uff1a\u529f\u80fd\u6307\u5b9a\u90e8\u5206\u63a8\u51fa\uff08Functionality-Specified Partial Rollout\uff09\uff1a\u8be5\u9636\u6bb5\u5c06\u751f\u6210\u7684\u5e8f\u5217\u5212\u5206\u4e3a\u4e0d\u540c\u7684\u529f\u80fd\u533a\u57df\uff0c\u5e76\u5229\u7528\u4e0d\u786e\u5b9a\u6027\u5f15\u5bfc\u7684\u8def\u5f84\u91cd\u7528\u548c\u5206\u652f\u7b56\u7565\u6765\u63d0\u9ad8\u63a2\u7d22\u6548\u7387\u3002\n\u7b2c\u4e8c\u9636\u6bb5\uff1a\u538b\u7f29\u63a8\u7406\u805a\u5408\uff08Compressed Reasoning Aggregation\uff09\uff1a\u8be5\u9636\u6bb5\u5229\u7528\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u5197\u4f59\u4fe1\u606f\uff0c\u5bf9\u4e0e\u7b54\u6848\u63a8\u5bfc\u76f8\u5173\u7684\u4fe1\u606f\u8fdb\u884c\u65e0\u635f\u538b\u7f29\uff0c\u5e76\u6700\u7ec8\u5408\u6210\u4e00\u4e2a\u8fde\u8d2f\u7684\u7b54\u6848\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cParallelMuse\u5728\u591a\u4e2a\u5f00\u6e90\u667a\u80fd\u4f53\u548c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6027\u80fd\u63d0\u5347\u6700\u9ad8\u53ef\u8fbe62%\uff0c\u540c\u65f6\u63a2\u7d22\u6027\u4ee3\u5e01\u6d88\u8017\u964d\u4f4e\u4e8610%--30%\u3002", "conclusion": "ParallelMuse\u901a\u8fc7\u5176\u4e24\u9636\u6bb5\u8303\u5f0f\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u5e76\u884c\u601d\u8003\u5728IS\u667a\u80fd\u4f53\u4e2d\u9047\u5230\u7684\u6548\u7387\u548c\u957f\u65f6\u63a8\u7406\u6574\u5408\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u5e76\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\u3002\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63a2\u7d22\u66f4\u4f18\u5316\u7684\u538b\u7f29\u7b56\u7565\u548c\u8de8\u9886\u57df\u5e94\u7528\u7684\u6f5c\u529b\u3002"}}
{"id": "2510.24699", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24699", "abs": "https://arxiv.org/abs/2510.24699", "authors": ["Rui Ye", "Zhongwang Zhang", "Kuan Li", "Huifeng Yin", "Zhengwei Tao", "Yida Zhao", "Liangcai Su", "Liwen Zhang", "Zile Qiao", "Xinyu Wang", "Pengjun Xie", "Fei Huang", "Siheng Chen", "Jingren Zhou", "Yong Jiang"], "title": "AgentFold: Long-Horizon Web Agents with Proactive Context Management", "comment": "26 pages, 9 figures", "summary": "LLM-based web agents show immense promise for information seeking, yet their\neffectiveness on long-horizon tasks is hindered by a fundamental trade-off in\ncontext management. Prevailing ReAct-based agents suffer from context\nsaturation as they accumulate noisy, raw histories, while methods that fixedly\nsummarize the full history at each step risk the irreversible loss of critical\ndetails. Addressing these, we introduce AgentFold, a novel agent paradigm\ncentered on proactive context management, inspired by the human cognitive\nprocess of retrospective consolidation. AgentFold treats its context as a\ndynamic cognitive workspace to be actively sculpted, rather than a passive log\nto be filled. At each step, it learns to execute a `folding' operation, which\nmanages its historical trajectory at multiple scales: it can perform granular\ncondensations to preserve vital, fine-grained details, or deep consolidations\nto abstract away entire multi-step sub-tasks. The results on prominent\nbenchmarks are striking: with simple supervised fine-tuning (without continual\npre-training or RL), our AgentFold-30B-A3B agent achieves 36.2% on BrowseComp\nand 47.3% on BrowseComp-ZH. Notably, this performance not only surpasses or\nmatches open-source models of a dramatically larger scale, such as the\nDeepSeek-V3.1-671B-A37B, but also surpasses leading proprietary agents like\nOpenAI's o4-mini.", "AI": {"tldr": "LLM\u9a71\u52a8\u7684\u7f51\u9875\u667a\u80fd\u4f53\u5728\u957f\u7a0b\u4efb\u52a1\u4e2d\u9762\u4e34\u4e0a\u4e0b\u6587\u7ba1\u7406\u74f6\u9888\uff0c\u5bb9\u6613\u56e0\u5386\u53f2\u8bb0\u5f55\u8fc7\u591a\u800c\u9971\u548c\u6216\u56e0\u8fc7\u5ea6\u603b\u7ed3\u4e22\u5931\u7ec6\u8282\u3002\u672c\u6587\u63d0\u51fa\u4e86AgentFold\uff0c\u4e00\u79cd\u53d7\u4eba\u7c7b\u56de\u987e\u6027\u6574\u5408\u542f\u53d1\u7684\u667a\u80fd\u4f53\u8303\u5f0f\uff0c\u901a\u8fc7\u5b66\u4e60\u6267\u884c\u201c\u6298\u53e0\u201d\u64cd\u4f5c\u6765\u4e3b\u52a8\u7ba1\u7406\u591a\u5c3a\u5ea6\u7684\u4e0a\u4e0b\u6587\u5386\u53f2\uff0c\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u538b\u7f29\u6216\u591a\u6b65\u5b50\u4efb\u52a1\u62bd\u8c61\u3002\u5728BrowseComp\u548cBrowseComp-ZH\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAgentFold-30B-A3B\u5728\u65e0\u9700\u6301\u7eed\u9884\u8bad\u7ec3\u6216\u5f3a\u5316\u5b66\u4e60\u7684\u60c5\u51b5\u4e0b\uff0c\u53d6\u5f97\u4e8636.2%\u548c47.3%\u7684\u6027\u80fd\uff0c\u8d85\u8d8a\u4e86\u66f4\u5927\u89c4\u6a21\u7684\u5f00\u6e90\u6a21\u578b\u548c\u9886\u5148\u7684\u95ed\u6e90\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8eLLM\u7684\u7f51\u9875\u667a\u80fd\u4f53\u867d\u7136\u5728\u4fe1\u606f\u68c0\u7d22\u65b9\u9762\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u5728\u5904\u7406\u957f\u7a0b\u4efb\u52a1\u65f6\uff0c\u4e0a\u4e0b\u6587\u7ba1\u7406\u65b9\u9762\u7684\u6839\u672c\u6027\u6743\u8861\u9650\u5236\u4e86\u5176\u6548\u7387\u3002\u57fa\u4e8eReAct\u7684\u667a\u80fd\u4f53\u5bb9\u6613\u56e0\u79ef\u7d2f\u4e86\u8fc7\u591a\u7684\u566a\u58f0\u539f\u59cb\u5386\u53f2\u8bb0\u5f55\u800c\u5bfc\u81f4\u4e0a\u4e0b\u6587\u9971\u548c\uff1b\u800c\u56fa\u5b9a\u5728\u6bcf\u4e00\u6b65\u603b\u7ed3\u6574\u4e2a\u5386\u53f2\u8bb0\u5f55\u7684\u65b9\u6cd5\u5219\u53ef\u80fd\u4e0d\u53ef\u9006\u5730\u4e22\u5931\u5173\u952e\u7ec6\u8282\u3002", "method": "\u672c\u6587\u5f15\u5165\u4e86AgentFold\uff0c\u4e00\u79cd\u65b0\u9896\u7684\u667a\u80fd\u4f53\u8303\u5f0f\uff0c\u5176\u6838\u5fc3\u5728\u4e8e\u4e3b\u52a8\u7684\u4e0a\u4e0b\u6587\u7ba1\u7406\uff0c\u5e76\u501f\u9274\u4e86\u4eba\u7c7b\u56de\u987e\u6027\u6574\u5408\u7684\u8ba4\u77e5\u8fc7\u7a0b\u3002AgentFold\u5c06\u4e0a\u4e0b\u6587\u89c6\u4e3a\u4e00\u4e2a\u52a8\u6001\u7684\u8ba4\u77e5\u5de5\u4f5c\u7a7a\u95f4\uff0c\u800c\u975e\u88ab\u52a8\u586b\u5145\u7684\u65e5\u5fd7\u3002\u5728\u6bcf\u4e00\u6b65\uff0c\u5b83\u5b66\u4e60\u6267\u884c\u4e00\u79cd\u201c\u6298\u53e0\u201d\u64cd\u4f5c\uff0c\u8be5\u64cd\u4f5c\u80fd\u591f\u7ba1\u7406\u5176\u5728\u591a\u4e2a\u5c3a\u5ea6\u4e0a\u7684\u5386\u53f2\u8f68\u8ff9\uff1a\u5b83\u53ef\u4ee5\u8fdb\u884c\u7ec6\u7c92\u5ea6\u7684\u538b\u7f29\u4ee5\u4fdd\u7559\u91cd\u8981\u7684\u7ec6\u5fae\u7ec6\u8282\uff0c\u6216\u8005\u8fdb\u884c\u6df1\u5ea6\u6574\u5408\u4ee5\u62bd\u8c61\u6574\u4e2a\u591a\u6b65\u5b50\u4efb\u52a1\u3002", "result": "\u5728\u8457\u540d\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u53d6\u5f97\u7684\u6210\u679c\u975e\u5e38\u663e\u8457\uff1a\u901a\u8fc7\u7b80\u5355\u7684\u76d1\u7763\u5fae\u8c03\uff08\u65e0\u9700\u6301\u7eed\u9884\u8bad\u7ec3\u6216\u5f3a\u5316\u5b66\u4e60\uff09\uff0cAgentFold-30B-A3B\u667a\u80fd\u4f53\u5728BrowseComp\u4e0a\u8fbe\u5230\u4e8636.2%\u7684\u6027\u80fd\uff0c\u5728BrowseComp-ZH\u4e0a\u8fbe\u5230\u4e8647.3%\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u8fd9\u4e00\u6027\u80fd\u4e0d\u4ec5\u8d85\u8d8a\u6216\u5ab2\u7f8e\u4e86\u89c4\u6a21\u5927\u5f97\u591a\u7684\u5f00\u6e90\u6a21\u578b\uff08\u5982DeepSeek-V3.1-671B-A37B\uff09\uff0c\u800c\u4e14\u8fd8\u8d85\u8d8a\u4e86\u9886\u5148\u7684\u95ed\u6e90\u6a21\u578b\uff08\u5982OpenAI\u7684o4-mini\uff09\u3002", "conclusion": "AgentFold\u901a\u8fc7\u5f15\u5165\u53d7\u4eba\u7c7b\u8ba4\u77e5\u542f\u53d1\u7684\u201c\u6298\u53e0\u201d\u64cd\u4f5c\uff0c\u6709\u6548\u89e3\u51b3\u4e86LLM\u7f51\u9875\u667a\u80fd\u4f53\u5728\u957f\u7a0b\u4efb\u52a1\u4e2d\u7684\u4e0a\u4e0b\u6587\u7ba1\u7406\u96be\u9898\uff0c\u5b9e\u73b0\u4e86\u5728\u4e0d\u727a\u7272\u5173\u952e\u4fe1\u606f\u7684\u524d\u63d0\u4e0b\u9ad8\u6548\u5730\u5904\u7406\u548c\u538b\u7f29\u5386\u53f2\u8bb0\u5f55\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cAgentFold\u5728\u6027\u80fd\u4e0a\u53d6\u5f97\u4e86\u7a81\u7834\u6027\u8fdb\u5c55\uff0c\u5c24\u5176\u662f\u5728\u4e0e\u73b0\u6709\u6a21\u578b\u8fdb\u884c\u6bd4\u8f83\u65f6\uff0c\u5176\u5c55\u73b0\u51fa\u7684\u9ad8\u6548\u6027\u548c\u4f18\u8d8a\u6027\u4e0d\u5bb9\u5ffd\u89c6\u3002\u5c3d\u7ba1\u53d6\u5f97\u4e86\u663e\u8457\u6210\u679c\uff0c\u4f46\u4ecd\u6709\u8fdb\u4e00\u6b65\u63a2\u7d22\u7684\u7a7a\u95f4\uff0c\u4f8b\u5982\u5728\u66f4\u5e7f\u6cdb\u7684\u4efb\u52a1\u548c\u66f4\u590d\u6742\u7684\u573a\u666f\u4e0b\u9a8c\u8bc1\u5176\u9c81\u68d2\u6027\uff0c\u4ee5\u53ca\u7814\u7a76\u66f4\u5148\u8fdb\u7684\u201c\u6298\u53e0\u201d\u7b56\u7565\u548c\u591a\u6a21\u6001\u4fe1\u606f\u6574\u5408\u80fd\u529b\u3002"}}
{"id": "2510.24684", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24684", "abs": "https://arxiv.org/abs/2510.24684", "authors": ["Bo Liu", "Chuanyang Jin", "Seungone Kim", "Weizhe Yuan", "Wenting Zhao", "Ilia Kulikov", "Xian Li", "Sainbayar Sukhbaatar", "Jack Lanchantin", "Jason Weston"], "title": "SPICE: Self-Play In Corpus Environments Improves Reasoning", "comment": null, "summary": "Self-improving systems require environmental interaction for continuous\nadaptation. We introduce SPICE (Self-Play In Corpus Environments), a\nreinforcement learning framework where a single model acts in two roles: a\nChallenger that mines documents from a large corpus to generate diverse\nreasoning tasks, and a Reasoner that solves them. Through adversarial dynamics,\nthe Challenger creates an automatic curriculum at the frontier of the\nReasoner's capability, while corpus grounding provides the rich,\nnear-inexhaustible external signal necessary for sustained improvement. Unlike\nexisting ungrounded self-play methods that offer more limited benefits, SPICE\nachieves consistent gains across mathematical (+8.9%) and general reasoning\n(+9.8%) benchmarks on multiple model families. Our analysis reveals how\ndocument grounding is a key ingredient in SPICE to continuously generate its\nown increasingly challenging goals and achieve them, enabling sustained\nself-improvement.", "AI": {"tldr": "SPICE\u662f\u4e00\u4e2a\u5305\u542b\u201c\u6311\u6218\u8005\u201d\u548c\u201c\u63a8\u7406\u5668\u201d\u4e24\u79cd\u89d2\u8272\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5176\u4e2d\u201c\u6311\u6218\u8005\u201d\u8d1f\u8d23\u4ece\u6587\u6863\u8bed\u6599\u5e93\u4e2d\u751f\u6210\u591a\u6837\u5316\u7684\u63a8\u7406\u4efb\u52a1\uff0c\u201c\u63a8\u7406\u5668\u201d\u8d1f\u8d23\u89e3\u51b3\u8fd9\u4e9b\u4efb\u52a1\u3002\u901a\u8fc7\u5bf9\u6297\u6027\u8bad\u7ec3\uff0cSPICE\u80fd\u591f\u52a8\u6001\u751f\u6210\u7b26\u5408\u201c\u63a8\u7406\u5668\u201d\u80fd\u529b\u8fb9\u754c\u7684\u4efb\u52a1\uff0c\u5e76\u5229\u7528\u8bed\u6599\u5e93\u7684\u4e30\u5bcc\u4fe1\u53f7\u5b9e\u73b0\u6301\u7eed\u6539\u8fdb\uff0c\u5728\u6570\u5b66\u548c\u901a\u7528\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5747\u53d6\u5f97\u4e86\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u6539\u8fdb\u7cfb\u7edf\u9700\u8981\u4e0e\u73af\u5883\u8fdb\u884c\u4ea4\u4e92\u4ee5\u5b9e\u73b0\u6301\u7eed\u9002\u5e94\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u81ea\u5bf9\u6297\u65b9\u6cd5\u7f3a\u4e4f\u4e0e\u5916\u90e8\u4e16\u754c\u7684\u8054\u7cfb\uff0c\u5176\u6539\u8fdb\u6548\u679c\u6709\u9650\u3002\u672c\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u63a2\u7d22\u4e00\u79cd\u80fd\u591f\u5229\u7528\u5916\u90e8\u4fe1\u53f7\u8fdb\u884c\u6301\u7eed\u81ea\u6211\u6539\u8fdb\u7684\u65b9\u6cd5\uff0c\u5e76\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "method": "SPICE\uff08Self-Play In Corpus Environments\uff09\u6846\u67b6\u5305\u542b\u4e24\u4e2a\u89d2\u8272\uff1a\u6311\u6218\u8005\u548c\u63a8\u7406\u5668\u3002\u6311\u6218\u8005\u4ece\u5927\u578b\u6587\u6863\u8bed\u6599\u5e93\u4e2d\u6316\u6398\u4fe1\u606f\uff0c\u751f\u6210\u591a\u6837\u5316\u7684\u63a8\u7406\u4efb\u52a1\uff1b\u63a8\u7406\u5668\u5219\u8d1f\u8d23\u89e3\u51b3\u8fd9\u4e9b\u4efb\u52a1\u3002\u901a\u8fc7\u5bf9\u6297\u6027\u8bad\u7ec3\uff0c\u6311\u6218\u8005\u80fd\u591f\u751f\u6210\u5904\u4e8e\u63a8\u7406\u5668\u80fd\u529b\u8fb9\u754c\u4e0a\u7684\u4efb\u52a1\uff0c\u4ece\u800c\u5f62\u6210\u4e00\u4e2a\u81ea\u52a8\u8bfe\u7a0b\u3002\u540c\u65f6\uff0c\u8bed\u6599\u5e93\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u5916\u90e8\u4fe1\u53f7\uff0c\u652f\u6301\u63a8\u7406\u5668\u7684\u6301\u7eed\u6539\u8fdb\u3002", "result": "SPICE\u5728\u6570\u5b66\u63a8\u7406\u548c\u901a\u7528\u63a8\u7406\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5747\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5206\u522b\u8fbe\u5230\u4e86+8.9%\u548c+9.8%\u3002\u8fd9\u4e9b\u6539\u8fdb\u5728\u591a\u4e2a\u6a21\u578b\u5bb6\u65cf\u4e2d\u5f97\u5230\u4e86\u9a8c\u8bc1\u3002\u5b9e\u9a8c\u5206\u6790\u8868\u660e\uff0c\u6587\u6863\u57fa\u7840\u662fSPICE\u80fd\u591f\u6301\u7eed\u751f\u6210\u66f4\u5177\u6311\u6218\u6027\u7684\u76ee\u6807\u5e76\u5b9e\u73b0\u5b83\u4eec\uff0c\u4ece\u800c\u5b9e\u73b0\u6301\u7eed\u81ea\u6211\u6539\u8fdb\u7684\u5173\u952e\u56e0\u7d20\u3002", "conclusion": "SPICE\u6846\u67b6\u901a\u8fc7\u5c06\u81ea\u5bf9\u6297\u4e0e\u6587\u6863\u8bed\u6599\u5e93\u76f8\u7ed3\u5408\uff0c\u6709\u6548\u5730\u89e3\u51b3\u4e86\u73b0\u6709\u81ea\u6539\u8fdb\u7cfb\u7edf\u5728\u6301\u7eed\u9002\u5e94\u548c\u6539\u8fdb\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002\u8be5\u65b9\u6cd5\u80fd\u591f\u52a8\u6001\u751f\u6210\u5177\u6709\u6311\u6218\u6027\u7684\u76ee\u6807\uff0c\u5e76\u5229\u7528\u4e30\u5bcc\u7684\u5916\u90e8\u4fe1\u53f7\u5b9e\u73b0\u6301\u7eed\u7684\u6027\u80fd\u63d0\u5347\u3002\u7814\u7a76\u7ed3\u679c\u8bc1\u660e\u4e86\u6587\u6863\u57fa\u7840\u5728\u9a71\u52a8\u81ea\u4e3b\u5b66\u4e60\u548c\u6301\u7eed\u6539\u8fdb\u4e2d\u7684\u91cd\u8981\u4f5c\u7528\uff0c\u4e3a\u5f00\u53d1\u66f4\u5f3a\u5927\u7684\u81ea\u6539\u8fdb\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63a2\u7d22SPICE\u5728\u66f4\u5e7f\u6cdb\u9886\u57df\u7684\u5e94\u7528\u4ee5\u53ca\u4f18\u5316\u5176\u8bad\u7ec3\u8fc7\u7a0b\u3002"}}
{"id": "2510.24695", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24695", "abs": "https://arxiv.org/abs/2510.24695", "authors": ["Xuanzhong Chen", "Zile Qiao", "Guoxin Chen", "Liangcai Su", "Zhen Zhang", "Xinyu Wang", "Pengjun Xie", "Fei Huang", "Jingren Zhou", "Yong Jiang"], "title": "AgentFrontier: Expanding the Capability Frontier of LLM Agents with ZPD-Guided Data Synthesis", "comment": "https://tongyi-agent.github.io/blog/introducing-tongyi-deep-research/", "summary": "Training large language model agents on tasks at the frontier of their\ncapabilities is key to unlocking advanced reasoning. We introduce a data\nsynthesis approach inspired by the educational theory of the Zone of Proximal\nDevelopment (ZPD), which defines this frontier as tasks an LLM cannot solve\nalone but can master with guidance. To operationalize this, we present the\nAgentFrontier Engine, an automated pipeline that synthesizes high-quality,\nmultidisciplinary data situated precisely within the LLM's ZPD. This engine\nsupports both continued pre-training with knowledge-intensive data and targeted\npost-training on complex reasoning tasks. From the same framework, we derive\nthe ZPD Exam, a dynamic and automated benchmark designed to evaluate agent\ncapabilities on these frontier tasks. We train AgentFrontier-30B-A3B model on\nour synthesized data, which achieves state-of-the-art results on demanding\nbenchmarks like Humanity's Last Exam, even surpassing some leading proprietary\nagents. Our work demonstrates that a ZPD-guided approach to data synthesis\noffers a scalable and effective path toward building more capable LLM agents.", "AI": {"tldr": "\u901a\u8fc7\u5f15\u5165\u201c\u8fd1\u90bb\u53d1\u5c55\u533a\u201d\uff08ZPD\uff09\u7406\u8bba\uff0c\u6211\u4eec\u5f00\u53d1\u4e86\u201cAgentFrontier Engine\u201d\u6765\u5408\u6210LLM\u80fd\u529b\u8fb9\u754c\u4e0a\u7684\u6570\u636e\uff0c\u7528\u4e8e\u6a21\u578b\u7684\u6301\u7eed\u9884\u8bad\u7ec3\u548c\u63a8\u7406\u4efb\u52a1\u540e\u8bad\u7ec3\u3002\u57fa\u4e8e\u6b64\u5f15\u64ce\u8bad\u7ec3\u7684AgentFrontier-30B-A3B\u6a21\u578b\u5728Humanity's Last Exam\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6210\u679c\uff0c\u8bc1\u660e\u4e86ZPD\u6307\u5bfc\u7684\u6570\u636e\u5408\u6210\u662f\u63d0\u5347LLM\u80fd\u529b\u7684\u6709\u6548\u9014\u5f84\u3002", "motivation": "\u5f53\u524d\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u667a\u80fd\u4f53\u4ee5\u5e94\u5bf9\u524d\u6cbf\u4efb\u52a1\u662f\u63d0\u5347\u5176\u9ad8\u7ea7\u63a8\u7406\u80fd\u529b\u7684\u5173\u952e\u3002\u7136\u800c\uff0c\u5982\u4f55\u7cbe\u786e\u5b9a\u4e49\u548c\u89e6\u53caLLM\u80fd\u529b\u7684\u6700\u524d\u6cbf\uff0c\u5e76\u4e3a\u5176\u63d0\u4f9b\u6709\u6548\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u662f\u4e00\u4e2a\u6838\u5fc3\u6311\u6218\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53d7\u201c\u8fd1\u90bb\u53d1\u5c55\u533a\u201d\uff08ZPD\uff09\u6559\u80b2\u7406\u8bba\u542f\u53d1\u7684\u201cAgentFrontier Engine\u201d\u6570\u636e\u5408\u6210\u65b9\u6cd5\u3002\u8be5\u5f15\u64ce\u80fd\u591f\u81ea\u52a8\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u8de8\u5b66\u79d1\u7684\u6570\u636e\uff0c\u8fd9\u4e9b\u6570\u636e\u7cbe\u786e\u5730\u4f4d\u4e8eLLM\u80fd\u529b\u7684\u6700\u524d\u6cbf\uff0c\u5373LLM\u5355\u72ec\u65e0\u6cd5\u89e3\u51b3\u4f46\u901a\u8fc7\u6307\u5bfc\u53ef\u4ee5\u638c\u63e1\u7684\u4efb\u52a1\u3002\u8be5\u5f15\u64ce\u652f\u6301\u4e24\u79cd\u8bad\u7ec3\u8303\u5f0f\uff1a1\uff09\u4f7f\u7528\u77e5\u8bc6\u5bc6\u96c6\u578b\u6570\u636e\u8fdb\u884c\u6301\u7eed\u9884\u8bad\u7ec3\uff1b2\uff09\u9488\u5bf9\u590d\u6742\u63a8\u7406\u4efb\u52a1\u8fdb\u884c\u5b9a\u5411\u7684\u540e\u8bad\u7ec3\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u4ece\u540c\u4e00\u6846\u67b6\u4e2d\u884d\u751f\u51fa\u201cZPD Exam\u201d\uff0c\u8fd9\u662f\u4e00\u4e2a\u52a8\u6001\u7684\u3001\u81ea\u52a8\u5316\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u667a\u80fd\u4f53\u5728\u8fd9\u4e9b\u524d\u6cbf\u4efb\u52a1\u4e0a\u7684\u80fd\u529b\u3002", "result": "\u4f7f\u7528AgentFrontier Engine\u5408\u6210\u7684\u6570\u636e\u8bad\u7ec3\u7684AgentFrontier-30B-A3B\u6a21\u578b\uff0c\u5728\u4e00\u4e9b\u9ad8\u8981\u6c42\u7684\u57fa\u51c6\u6d4b\u8bd5\uff08\u5982Humanity's Last Exam\uff09\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\uff08state-of-the-art\uff09\u7684\u6210\u679c\uff0c\u751a\u81f3\u5728\u67d0\u4e9b\u65b9\u9762\u8d85\u8d8a\u4e86\u4e00\u4e9b\u9886\u5148\u7684\u5546\u4e1a\u6a21\u578b\u3002", "conclusion": "\u7814\u7a76\u8bc1\u660e\uff0c\u91c7\u7528ZPD\u7406\u8bba\u6307\u5bfc\u7684\u6570\u636e\u5408\u6210\u65b9\u6cd5\uff0c\u4e3a\u6784\u5efa\u66f4\u5f3a\u5927\u7684LLM\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u4e00\u6761\u53ef\u6269\u5c55\u4e14\u6709\u6548\u7684\u524d\u8fdb\u8def\u5f84\u3002\u8fd9\u79cd\u65b9\u6cd5\u80fd\u591f\u7cbe\u786e\u5730\u5b9a\u4f4dLLM\u7684\u80fd\u529b\u8fb9\u754c\uff0c\u5e76\u751f\u6210\u9488\u5bf9\u6027\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u4ece\u800c\u663e\u8457\u63d0\u5347\u6a21\u578b\u7684\u63a8\u7406\u548c\u89e3\u51b3\u590d\u6742\u95ee\u9898\u7684\u80fd\u529b\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63a2\u7d22ZPD\u5728\u4e0d\u540c\u7c7b\u578b\u4efb\u52a1\u548c\u6a21\u578b\u4e0a\u7684\u5e94\u7528\uff0c\u4ee5\u53ca\u4f18\u5316\u6570\u636e\u5408\u6210\u7684\u6548\u7387\u548c\u591a\u6837\u6027\u3002"}}
{"id": "2510.24706", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.24706", "abs": "https://arxiv.org/abs/2510.24706", "authors": ["Shuqing Li", "Jiayi Yan", "Chenyu Niu", "Jen-tse Huang", "Yun Peng", "Wenxuan Wang", "Yepang Liu", "Michael R. Lyu"], "title": "ComboBench: Can LLMs Manipulate Physical Devices to Play Virtual Reality Games?", "comment": null, "summary": "Virtual Reality (VR) games require players to translate high-level semantic\nactions into precise device manipulations using controllers and head-mounted\ndisplays (HMDs). While humans intuitively perform this translation based on\ncommon sense and embodied understanding, whether Large Language Models (LLMs)\ncan effectively replicate this ability remains underexplored. This paper\nintroduces a benchmark, ComboBench, evaluating LLMs' capability to translate\nsemantic actions into VR device manipulation sequences across 262 scenarios\nfrom four popular VR games: Half-Life: Alyx, Into the Radius, Moss: Book II,\nand Vivecraft. We evaluate seven LLMs, including GPT-3.5, GPT-4, GPT-4o,\nGemini-1.5-Pro, LLaMA-3-8B, Mixtral-8x7B, and GLM-4-Flash, compared against\nannotated ground truth and human performance. Our results reveal that while\ntop-performing models like Gemini-1.5-Pro demonstrate strong task decomposition\ncapabilities, they still struggle with procedural reasoning and spatial\nunderstanding compared to humans. Performance varies significantly across\ngames, suggesting sensitivity to interaction complexity. Few-shot examples\nsubstantially improve performance, indicating potential for targeted\nenhancement of LLMs' VR manipulation capabilities. We release all materials at\nhttps://sites.google.com/view/combobench.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aComboBench\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u865a\u62df\u73b0\u5b9e\uff08VR\uff09\u6e38\u620f\u4e2d\u5c06\u8bed\u4e49\u52a8\u4f5c\u8f6c\u5316\u4e3a\u8bbe\u5907\u64cd\u63a7\u5e8f\u5217\u7684\u80fd\u529b\u3002\u7814\u7a76\u8bc4\u4f30\u4e86\u4e03\u79cd\u4e3b\u6d41LLM\uff0c\u5e76\u4e0e\u4eba\u7c7b\u8868\u73b0\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5c3d\u7ba1\u9876\u5c16LLM\uff08\u5982Gemini-1.5-Pro\uff09\u5728\u4efb\u52a1\u5206\u89e3\u65b9\u9762\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u5728\u7a0b\u5e8f\u63a8\u7406\u548c\u7a7a\u95f4\u7406\u89e3\u65b9\u9762\u4ecd\u4e0d\u53ca\u4eba\u7c7b\u3002\u6e38\u620f\u95f4\u7684\u8868\u73b0\u5dee\u5f02\u7a81\u663e\u4e86\u4ea4\u4e92\u590d\u6742\u6027\u5bf9LLM\u80fd\u529b\u7684\u5f71\u54cd\u3002\u5c11\u91cf\u793a\u4f8b\uff08few-shot examples\uff09\u80fd\u663e\u8457\u63d0\u5347LLM\u7684\u8868\u73b0\uff0c\u9884\u793a\u4e86\u901a\u8fc7\u9488\u5bf9\u6027\u8bad\u7ec3\u6765\u589e\u5f3aLLM\u5728VR\u64cd\u63a7\u80fd\u529b\u7684\u53ef\u80fd\u6027\u3002", "motivation": "\u5f53\u524d\uff0c\u865a\u62df\u73b0\u5b9e\uff08VR\uff09\u6e38\u620f\u9700\u8981\u73a9\u5bb6\u5c06\u9ad8\u7ea7\u7684\u8bed\u4e49\u52a8\u4f5c\u8f6c\u5316\u4e3a\u7cbe\u786e\u7684\u8bbe\u5907\u64cd\u63a7\uff08\u5982\u63a7\u5236\u5668\u548c\u5934\u6234\u5f0f\u663e\u793a\u5668\uff09\u3002\u867d\u7136\u4eba\u7c7b\u80fd\u591f\u51ed\u501f\u5e38\u8bc6\u548c\u5177\u8eab\u7406\u89e3\u76f4\u89c2\u5730\u5b8c\u6210\u8fd9\u79cd\u8f6c\u6362\uff0c\u4f46\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u662f\u5426\u80fd\u6709\u6548\u590d\u5236\u8fd9\u79cd\u80fd\u529b\u4ecd\u662f\u672a\u88ab\u5145\u5206\u63a2\u7d22\u7684\u9886\u57df\u3002\u672c\u7814\u7a76\u65e8\u5728\u5f25\u5408\u8fd9\u4e00\u8ba4\u77e5\u5dee\u8ddd\uff0c\u63a2\u7a76LLM\u5728\u7406\u89e3\u548c\u6267\u884cVR\u4ea4\u4e92\u65b9\u9762\u7684\u6f5c\u529b\u3002", "method": "\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u4e2a\u540d\u4e3aComboBench\u7684\u65b0\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8be5\u6d4b\u8bd5\u5305\u542b\u6765\u81ea\u56db\u6b3e\u70ed\u95e8VR\u6e38\u620f\uff08Half-Life: Alyx, Into the Radius, Moss: Book II, and Vivecraft\uff09\u7684262\u4e2a\u4e0d\u540c\u573a\u666f\u3002ComboBench\u7528\u4e8e\u8bc4\u4f30LLM\u5c06\u8bed\u4e49\u52a8\u4f5c\u8f6c\u5316\u4e3aVR\u8bbe\u5907\u64cd\u63a7\u5e8f\u5217\u7684\u80fd\u529b\u3002\u7814\u7a76\u4eba\u5458\u5bf9\u4e03\u79cd\u4e0d\u540c\u7684LLM\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u5305\u62ecGPT-3.5, GPT-4, GPT-4o, Gemini-1.5-Pro, LLaMA-3-8B, Mixtral-8x7B, \u548c GLM-4-Flash\u3002\u6a21\u578b\u8868\u73b0\u4e0e\u7ecf\u8fc7\u6807\u6ce8\u7684\u771f\u5b9e\u6570\u636e\uff08ground truth\uff09\u4ee5\u53ca\u4eba\u7c7b\u7684\u5b9e\u9645\u64cd\u4f5c\u8868\u73b0\u8fdb\u884c\u4e86\u5bf9\u6bd4\u5206\u6790\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0c\u5728\u6240\u6d4b\u8bd5\u7684LLM\u4e2d\uff0cGemini-1.5-Pro\u7b49\u8868\u73b0\u6700\u4f73\u7684\u6a21\u578b\u5728\u4efb\u52a1\u5206\u89e3\u80fd\u529b\u4e0a\u5c55\u73b0\u51fa\u8f83\u5f3a\u7684\u6f5c\u529b\u3002\u7136\u800c\uff0c\u4e0e\u4eba\u7c7b\u73a9\u5bb6\u76f8\u6bd4\uff0c\u8fd9\u4e9b\u6a21\u578b\u5728\u7a0b\u5e8f\u63a8\u7406\u548c\u7a7a\u95f4\u7406\u89e3\u65b9\u9762\u4ecd\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002\u4e0d\u540cVR\u6e38\u620f\u7684\u8868\u73b0\u5dee\u5f02\u5f88\u5927\uff0c\u8868\u660eLLM\u7684\u80fd\u529b\u5bf9\u4ea4\u4e92\u7684\u590d\u6742\u6027\u975e\u5e38\u654f\u611f\u3002\u6b64\u5916\uff0c\u7814\u7a76\u53d1\u73b0\uff0c\u901a\u8fc7\u63d0\u4f9b\u5c11\u91cf\u793a\u4f8b\uff08few-shot examples\uff09\u8fdb\u884c\u8bad\u7ec3\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347LLM\u5728VR\u64cd\u63a7\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u8fd9\u4e3a\u540e\u7eed\u7684\u6027\u80fd\u4f18\u5316\u63d0\u4f9b\u4e86\u65b9\u5411\u3002", "conclusion": "\u672c\u7814\u7a76\u901a\u8fc7ComboBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u9996\u6b21\u7cfb\u7edf\u6027\u5730\u8bc4\u4f30\u4e86LLM\u5728VR\u6e38\u620f\u64cd\u63a7\u65b9\u9762\u7684\u80fd\u529b\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5c3d\u7ba1\u5148\u8fdb\u7684LLM\u5728\u67d0\u4e9b\u65b9\u9762\uff08\u5982\u4efb\u52a1\u5206\u89e3\uff09\u5df2\u5177\u5907\u4e00\u5b9a\u6f5c\u529b\uff0c\u4f46\u5b83\u4eec\u5728\u6a21\u4eff\u4eba\u7c7b\u5728VR\u73af\u5883\u4e2d\u8fdb\u884c\u76f4\u89c2\u3001\u8fde\u8d2f\u7684\u64cd\u4f5c\u65b9\u9762\u4ecd\u663e\u4e0d\u8db3\uff0c\u5c24\u5176\u662f\u5728\u7a0b\u5e8f\u63a8\u7406\u548c\u7a7a\u95f4\u7406\u89e3\u80fd\u529b\u4e0a\u3002\u6e38\u620f\u4ea4\u4e92\u590d\u6742\u6027\u5bf9LLM\u7684\u8868\u73b0\u6709\u663e\u8457\u5f71\u54cd\u3002\u5c11\u91cf\u793a\u4f8b\u5b66\u4e60\u662f\u63d0\u5347LLM\u5728VR\u64cd\u63a7\u4efb\u52a1\u4e0a\u8868\u73b0\u7684\u6709\u6548\u9014\u5f84\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u96c6\u4e2d\u4e8e\u5f00\u53d1\u66f4\u590d\u6742\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4ee5\u53ca\u63a2\u7d22\u80fd\u591f\u63d0\u5347LLM\u5728VR\u573a\u666f\u4e0b\u7a0b\u5e8f\u63a8\u7406\u548c\u7a7a\u95f4\u7406\u89e3\u80fd\u529b\u7684\u8bad\u7ec3\u65b9\u6cd5\uff0c\u6700\u7ec8\u76ee\u6807\u662f\u4f7fLLM\u80fd\u591f\u66f4\u81ea\u7136\u3001\u66f4\u6709\u6548\u5730\u4e0eVR\u73af\u5883\u8fdb\u884c\u4ea4\u4e92\u3002\u672c\u7814\u7a76\u6210\u679c\u5df2\u5728 https://sites.google.com/view/combobench \u516c\u5f00\u3002"}}
{"id": "2404.02039", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2404.02039", "abs": "https://arxiv.org/abs/2404.02039", "authors": ["Sihao Hu", "Tiansheng Huang", "Gaowen Liu", "Ramana Rao Kompella", "Fatih Ilhan", "Selim Furkan Tekin", "Yichang Xu", "Zachary Yahn", "Ling Liu"], "title": "A Survey on Large Language Model-Based Game Agents", "comment": null, "summary": "Game environments provide rich, controllable settings that stimulate many\naspects of real-world complexity. As such, game agents offer a valuable testbed\nfor exploring capabilities relevant to Artificial General Intelligence.\nRecently, the emergence of Large Language Models (LLMs) provides new\nopportunities to endow these agents with generalizable reasoning, memory, and\nadaptability in complex game environments. This survey offers an up-to-date\nreview of LLM-based game agents (LLMGAs) through a unified reference\narchitecture. At the single-agent level, we synthesize existing studies around\nthree core components: memory, reasoning, and perception-action interfaces,\nwhich jointly characterize how language enables agents to perceive, think, and\nact. At the multi-agent level, we outline how communication protocols and\norganizational models support coordination, role differentiation, and\nlarge-scale social behaviors. To contextualize these designs, we introduce a\nchallenge-centered taxonomy linking six major game genres to their dominant\nagent requirements, from low-latency control in action games to open-ended goal\nformation in sandbox worlds. A curated list of related papers is available at\nhttps://github.com/git-disl/awesome-LLM-game-agent-papers", "AI": {"tldr": "\u672c\u7bc7\u8bba\u6587\u5168\u9762\u56de\u987e\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u6e38\u620f\u667a\u80fd\u4f53\uff08LLMGA\uff09\u7684\u7814\u7a76\u73b0\u72b6\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u53c2\u8003\u67b6\u6784\uff0c\u5e76\u4ece\u5355\u667a\u80fd\u4f53\u548c\u591a\u667a\u80fd\u4f53\u4e24\u4e2a\u5c42\u9762\u8fdb\u884c\u4e86\u6df1\u5165\u5206\u6790\u3002\u5728\u5355\u667a\u80fd\u4f53\u5c42\u9762\uff0c\u7814\u7a76\u805a\u7126\u4e8eLLM\u5982\u4f55\u8d4b\u80fd\u667a\u80fd\u4f53\u7684\u8bb0\u5fc6\u3001\u63a8\u7406\u548c\u611f\u77e5-\u884c\u52a8\u63a5\u53e3\uff0c\u5b9e\u73b0\u66f4\u5f3a\u7684\u6cdb\u5316\u3001\u8bb0\u5fc6\u548c\u9002\u5e94\u80fd\u529b\u3002\u5728\u591a\u667a\u80fd\u4f53\u5c42\u9762\uff0c\u5219\u63a2\u8ba8\u4e86\u901a\u4fe1\u534f\u8bae\u548c\u7ec4\u7ec7\u6a21\u578b\u5728\u652f\u6301\u534f\u8c03\u3001\u89d2\u8272\u5206\u5316\u548c\u5927\u89c4\u6a21\u793e\u4f1a\u884c\u4e3a\u4e2d\u7684\u4f5c\u7528\u3002\u8bba\u6587\u8fd8\u5f15\u5165\u4e86\u4e00\u4e2a\u4ee5\u6311\u6218\u4e3a\u4e2d\u5fc3\u7684\u5206\u7c7b\u6cd5\uff0c\u5c06\u516d\u79cd\u4e3b\u8981\u6e38\u620f\u7c7b\u578b\u4e0e\u5176\u5bf9\u667a\u80fd\u4f53\u7684\u9700\u6c42\u76f8\u5339\u914d\uff0c\u4e3aLLMGA\u7684\u8bbe\u8ba1\u548c\u8bc4\u4f30\u63d0\u4f9b\u4e86\u4f9d\u636e\u3002", "motivation": "\u6e38\u620f\u73af\u5883\u56e0\u5176\u4e30\u5bcc\u6027\u3001\u53ef\u63a7\u6027\u4ee5\u53ca\u5bf9\u73b0\u5b9e\u4e16\u754c\u590d\u6742\u6027\u7684\u6a21\u62df\u80fd\u529b\uff0c\u6210\u4e3a\u6d4b\u8bd5\u4eba\u5de5\u667a\u80fd\u901a\u7528\u667a\u80fd\uff08AGI\uff09\u76f8\u5173\u80fd\u529b\u7684\u6709\u4ef7\u503c\u7684\u5e73\u53f0\u3002\u7279\u522b\u662f\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u51fa\u73b0\uff0c\u4e3a\u589e\u5f3a\u6e38\u620f\u667a\u80fd\u4f53\u5728\u590d\u6742\u6e38\u620f\u73af\u5883\u4e2d\u7684\u6cdb\u5316\u63a8\u7406\u3001\u8bb0\u5fc6\u548c\u9002\u5e94\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u7684\u673a\u9047\u3002\u672c\u7814\u7a76\u65e8\u5728\u7cfb\u7edf\u6027\u5730\u68b3\u7406\u548c\u603b\u7ed3\u5f53\u524dLLM\u5728\u6e38\u620f\u667a\u80fd\u4f53\u9886\u57df\u7684\u7814\u7a76\u8fdb\u5c55\uff0c\u4e3a\u8be5\u9886\u57df\u7684\u7814\u7a76\u8005\u63d0\u4f9b\u4e00\u4e2a\u5168\u9762\u7684\u89c6\u89d2\u548c\u53c2\u8003\u6846\u67b6\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u6587\u732e\u7efc\u8ff0\u7684\u65b9\u6cd5\uff0c\u56de\u987e\u4e86\u73b0\u6709\u5173\u4e8eLLM\u5728\u6e38\u620f\u667a\u80fd\u4f53\u65b9\u9762\u7684\u7814\u7a76\u3002\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u53c2\u8003\u67b6\u6784\uff0c\u5c06LLMGA\u5728\u5355\u667a\u80fd\u4f53\u548c\u591a\u667a\u80fd\u4f53\u4e24\u4e2a\u5c42\u9762\u7684\u7814\u7a76\u8fdb\u884c\u6574\u5408\u3002\u5728\u5355\u667a\u80fd\u4f53\u5c42\u9762\uff0c\u7814\u7a76\u56f4\u7ed5\u8bb0\u5fc6\u3001\u63a8\u7406\u548c\u611f\u77e5-\u884c\u52a8\u63a5\u53e3\u8fd9\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\u8fdb\u884c\u5206\u6790\uff0c\u63a2\u8ba8\u8bed\u8a00\u6a21\u578b\u5982\u4f55\u5b9e\u73b0\u667a\u80fd\u4f53\u7684\u611f\u77e5\u3001\u601d\u8003\u548c\u884c\u52a8\u3002\u5728\u591a\u667a\u80fd\u4f53\u5c42\u9762\uff0c\u7814\u7a76\u5173\u6ce8\u901a\u4fe1\u534f\u8bae\u548c\u7ec4\u7ec7\u6a21\u578b\u5728\u652f\u6301\u667a\u80fd\u4f53\u95f4\u7684\u534f\u8c03\u3001\u89d2\u8272\u5206\u5316\u548c\u5927\u89c4\u6a21\u793e\u4f1a\u884c\u4e3a\u65b9\u9762\u7684\u4f5c\u7528\u3002\u6b64\u5916\uff0c\u8bba\u6587\u8fd8\u6784\u5efa\u4e86\u4e00\u4e2a\u4ee5\u6311\u6218\u4e3a\u4e2d\u5fc3\u7684\u5206\u7c7b\u6cd5\uff0c\u5c06\u516d\u79cd\u4e3b\u8981\u6e38\u620f\u7c7b\u578b\uff08\u5982\u52a8\u4f5c\u6e38\u620f\u3001\u6c99\u76d2\u6e38\u620f\u7b49\uff09\u4e0e\u5b83\u4eec\u5bf9\u667a\u80fd\u4f53\u7684\u9700\u6c42\u8fdb\u884c\u5173\u8054\uff0c\u4ee5\u9610\u8ff0\u4e0d\u540c\u6e38\u620f\u573a\u666f\u5bf9LLMGA\u8bbe\u8ba1\u7684\u5f71\u54cd\u3002", "result": "\u672c\u7814\u7a76\u5bf9LLM\u5728\u6e38\u620f\u667a\u80fd\u4f53\u9886\u57df\u7684\u5e94\u7528\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u68b3\u7406\u3002\u7814\u7a76\u8868\u660e\uff0cLLM\u5728\u589e\u5f3a\u6e38\u620f\u667a\u80fd\u4f53\u7684\u8bb0\u5fc6\u80fd\u529b\u3001\u63a8\u7406\u80fd\u529b\u4ee5\u53ca\u611f\u77e5-\u884c\u52a8\u63a5\u53e3\u65b9\u9762\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\u3002\u901a\u8fc7\u6574\u5408LLM\uff0c\u667a\u80fd\u4f53\u80fd\u591f\u66f4\u597d\u5730\u7406\u89e3\u6e38\u620f\u72b6\u6001\u3001\u8fdb\u884c\u66f4\u590d\u6742\u7684\u51b3\u7b56\uff0c\u5e76\u4e0e\u6e38\u620f\u73af\u5883\u8fdb\u884c\u66f4\u81ea\u7136\u7684\u4ea4\u4e92\u3002\u5728\u591a\u667a\u80fd\u4f53\u573a\u666f\u4e0b\uff0cLLM\u80fd\u591f\u4fc3\u8fdb\u667a\u80fd\u4f53\u4e4b\u95f4\u7684\u6709\u6548\u6c9f\u901a\u548c\u534f\u4f5c\uff0c\u5b9e\u73b0\u66f4\u9ad8\u7ea7\u7684\u793e\u4f1a\u884c\u4e3a\u3002\u8bba\u6587\u63d0\u51fa\u7684\u6311\u6218\u4e2d\u5fc3\u5206\u7c7b\u6cd5\uff0c\u6e05\u6670\u5730\u5c55\u793a\u4e86\u4e0d\u540c\u6e38\u620f\u7c7b\u578b\u5bf9LLMGA\u63d0\u51fa\u7684\u5177\u4f53\u8981\u6c42\uff0c\u4e3a\u672a\u6765\u7684\u7814\u7a76\u548c\u5f00\u53d1\u6307\u660e\u4e86\u65b9\u5411\u3002", "conclusion": "\u672c\u7bc7\u7efc\u8ff0\u4e3aLLM\u5728\u6e38\u620f\u667a\u80fd\u4f53\u9886\u57df\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7ed3\u6784\u5316\u7684\u89c6\u89d2\u3002\u901a\u8fc7\u63d0\u51fa\u7684\u7edf\u4e00\u53c2\u8003\u67b6\u6784\u548c\u6311\u6218\u4e2d\u5fc3\u5206\u7c7b\u6cd5\uff0c\u7814\u7a76\u8005\u53ef\u4ee5\u66f4\u597d\u5730\u7406\u89e3LLMGA\u7684\u8bbe\u8ba1\u539f\u7406\u3001\u73b0\u6709\u7814\u7a76\u6210\u679c\u4ee5\u53ca\u672a\u6765\u7684\u53d1\u5c55\u65b9\u5411\u3002LLM\u4e3a\u6784\u5efa\u66f4\u5f3a\u5927\u3001\u66f4\u901a\u7528\u7684\u6e38\u620f\u667a\u80fd\u4f53\u63d0\u4f9b\u4e86\u524d\u6240\u672a\u6709\u7684\u673a\u4f1a\uff0c\u4f46\u4ecd\u6709\u8bb8\u591a\u6311\u6218\u9700\u8981\u514b\u670d\uff0c\u4f8b\u5982\u63d0\u9ad8LLM\u5728\u5b9e\u65f6\u6027\u8981\u6c42\u9ad8\u7684\u6e38\u620f\u4e2d\u7684\u8868\u73b0\u3001\u589e\u5f3a\u5176\u957f\u671f\u89c4\u5212\u80fd\u529b\u4ee5\u53ca\u63a2\u7d22\u66f4\u9ad8\u6548\u7684\u8bad\u7ec3\u65b9\u6cd5\u7b49\u3002\u672a\u6765\u7684\u5de5\u4f5c\u5c06\u96c6\u4e2d\u5728\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\uff0c\u8fdb\u4e00\u6b65\u63a8\u52a8LLM\u5728\u590d\u6742\u6e38\u620f\u73af\u5883\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2410.11133", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2410.11133", "abs": "https://arxiv.org/abs/2410.11133", "authors": ["Sean Lamont", "Christian Walder", "Amir Dezfouli", "Paul Montague", "Michael Norrish"], "title": "3D-Prover: Diversity Driven Theorem Proving With Determinantal Point Processes", "comment": null, "summary": "A key challenge in automated formal reasoning is the intractable search\nspace, which grows exponentially with the depth of the proof. This branching is\ncaused by the large number of candidate proof tactics which can be applied to a\ngiven goal. Nonetheless, many of these tactics are semantically similar or lead\nto an execution error, wasting valuable resources in both cases. We address the\nproblem of effectively pruning this search, using only synthetic data generated\nfrom previous proof attempts. We first demonstrate that it is possible to\ngenerate semantically aware tactic representations which capture the effect on\nthe proving environment, likelihood of success, and execution time. We then\npropose a novel filtering mechanism which leverages these representations to\nselect semantically diverse and high quality tactics, using Determinantal Point\nProcesses. Our approach, 3D- Prover, is designed to be general, and to augment\nany underlying tactic generator. We demonstrate the effectiveness of 3D-Prover\non the miniF2F and LeanDojo benchmarks by augmenting popular open source\nproving LLMs. We show that our approach leads to an increase in the overall\nproof rate, as well as a significant improvement in the tactic success rate,\nexecution time and diversity. We make our code available at\nhttps://github.com/sean-lamont/3D-Prover.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a3D-Prover\u7684\u65b0\u65b9\u6cd5\uff0c\u5229\u7528\u5408\u6210\u6570\u636e\u901a\u8fc7\u751f\u6210\u8bed\u4e49\u611f\u77e5\u7b56\u7565\u8868\u793a\u6765\u89e3\u51b3\u81ea\u52a8\u5316\u5f62\u5f0f\u63a8\u7406\u4e2d\u7684\u641c\u7d22\u7a7a\u95f4\u7206\u70b8\u95ee\u9898\u3002\u901a\u8fc7\u4f7f\u7528\u51b3\u5fc3\u70b9\u8fc7\u7a0b\u6765\u9009\u62e9\u591a\u6837\u5316\u548c\u9ad8\u8d28\u91cf\u7684\u7b56\u7565\uff0c3D-Prover\u663e\u8457\u63d0\u9ad8\u4e86miniF2F\u548cLeanDojo\u57fa\u51c6\u4e0a\u7684\u8bc1\u660e\u7387\u3001\u7b56\u7565\u6210\u529f\u7387\u3001\u6267\u884c\u65f6\u95f4\u548c\u591a\u6837\u6027\u3002", "motivation": "\u81ea\u52a8\u5316\u5f62\u5f0f\u63a8\u7406\u9762\u4e34\u641c\u7d22\u7a7a\u95f4\u5de8\u5927\u7684\u6311\u6218\uff0c\u8fd9\u4f1a\u968f\u7740\u8bc1\u660e\u6df1\u5ea6\u7684\u589e\u52a0\u5448\u6307\u6570\u7ea7\u589e\u957f\uff0c\u56e0\u4e3a\u53ef\u80fd\u5e94\u7528\u7684\u5019\u9009\u8bc1\u660e\u7b56\u7565\u6570\u91cf\u5e9e\u5927\u3002\u8bb8\u591a\u7b56\u7565\u5728\u8bed\u4e49\u4e0a\u76f8\u4f3c\u6216\u4f1a\u5bfc\u81f4\u6267\u884c\u9519\u8bef\uff0c\u4ece\u800c\u6d6a\u8d39\u5b9d\u8d35\u7684\u8ba1\u7b97\u8d44\u6e90\u3002\u89e3\u51b3\u641c\u7d22\u7a7a\u95f4\u7206\u70b8\u95ee\u9898\u5e76\u6709\u6548\u4fee\u526a\u4e0d\u5fc5\u8981\u7684\u7b56\u7565\u81f3\u5173\u91cd\u8981\u3002", "method": "\u8be5\u7814\u7a76\u9996\u5148\u751f\u6210\u80fd\u591f\u6355\u83b7\u5bf9\u8bc1\u660e\u73af\u5883\u7684\u5f71\u54cd\u3001\u6210\u529f\u53ef\u80fd\u6027\u548c\u6267\u884c\u65f6\u95f4\u7684\u8bed\u4e49\u611f\u77e5\u7b56\u7565\u8868\u793a\u3002\u7136\u540e\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u8fc7\u6ee4\u673a\u5236\uff0c\u8be5\u673a\u5236\u5229\u7528\u8fd9\u4e9b\u8868\u793a\uff0c\u5e76\u4f7f\u7528\u51b3\u5fc3\u70b9\u8fc7\u7a0b\u6765\u9009\u62e9\u8bed\u4e49\u4e0a\u591a\u6837\u4e14\u9ad8\u8d28\u91cf\u7684\u7b56\u7565\u3002\u8be5\u65b9\u6cd53D-Prover\u65e8\u5728\u901a\u7528\uff0c\u5e76\u80fd\u589e\u5f3a\u4efb\u4f55\u6f5c\u5728\u7684\u7b56\u7565\u751f\u6210\u5668\u3002", "result": "\u5728miniF2F\u548cLeanDojo\u57fa\u51c6\u4e0a\uff0c\u901a\u8fc7\u589e\u5f3a\u6d41\u884c\u7684\u5f00\u6e90\u8bc1\u660e\u8bed\u8a00\u6a21\u578b\uff0c\u8be5\u65b9\u6cd5\u5728\u6574\u4f53\u8bc1\u660e\u7387\u65b9\u9762\u6709\u6240\u63d0\u9ad8\uff0c\u5e76\u5728\u7b56\u7565\u6210\u529f\u7387\u3001\u6267\u884c\u65f6\u95f4\u548c\u591a\u6837\u6027\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6539\u8fdb\u3002", "conclusion": "3D-Prover\u901a\u8fc7\u5229\u7528\u5408\u6210\u6570\u636e\u548c\u51b3\u5fc3\u70b9\u8fc7\u7a0b\uff0c\u6709\u6548\u5730\u89e3\u51b3\u4e86\u81ea\u52a8\u5316\u5f62\u5f0f\u63a8\u7406\u4e2d\u7684\u641c\u7d22\u7a7a\u95f4\u7206\u70b8\u95ee\u9898\uff0c\u5e76\u5728\u5173\u952e\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c55\u793a\u4e86\u5176\u4f18\u8d8a\u6027\u3002\u8fd9\u9879\u5de5\u4f5c\u4e3a\u63d0\u9ad8\u81ea\u52a8\u5316\u8bc1\u660e\u7cfb\u7edf\u7684\u6548\u7387\u548c\u6027\u80fd\u5f00\u8f9f\u4e86\u65b0\u7684\u9014\u5f84\u3002"}}
{"id": "2411.15737", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2411.15737", "abs": "https://arxiv.org/abs/2411.15737", "authors": ["Jiahao Wang", "Mingyue Cheng", "Qingyang Mao", "Yitong Zhou", "Daoyu Wang", "Qi Liu", "Feiyang Xu", "Xin Li"], "title": "TableTime: Reformulating Time Series Classification as Training-Free Table Understanding with Large Language Models", "comment": null, "summary": "Large language models (LLMs) have demonstrated their effectiveness in\nmultivariate time series classification (MTSC). Effective adaptation of LLMs\nfor MTSC necessitates informative data representations. Existing LLM-based\nmethods directly encode embeddings for time series within the latent space of\nLLMs from scratch to align with semantic space of LLMs. Despite their\neffectiveness, we reveal that these methods conceal three inherent bottlenecks:\n(1) they struggle to encode temporal and channel-specific information in a\nlossless manner, both of which are critical components of multivariate time\nseries; (2) it is much difficult to align the learned representation space with\nthe semantic space of the LLMs; (3) they require task-specific retraining,\nwhich is both computationally expensive and labor-intensive. To bridge these\ngaps, we propose TableTime, which reformulates MTSC as a table understanding\ntask. Specifically, TableTime introduces the following strategies: (1) convert\nmultivariate time series into a tabular form, thus minimizing information loss\nto the greatest extent; (2) represent tabular time series in text format to\nachieve natural alignment with the semantic space of LLMs; (3) design a\nreasoning framework that integrates contextual text information, neighborhood\nassistance, multi-path inference and problem decomposition to enhance the\nreasoning ability of LLMs and realize zero-shot classification. Extensive\nexperiments performed on 10 publicly representative datasets from UEA archive\nverify the superiorities of the TableTime.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTableTime\u7684\u65b0\u65b9\u6cd5\uff0c\u5c06\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\uff08MTSC\uff09\u4efb\u52a1\u91cd\u6784\u4e3a\u8868\u683c\u7406\u89e3\u4efb\u52a1\uff0c\u4ee5\u514b\u670d\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u65b9\u6cd5\u5728\u5904\u7406MTSC\u65f6\u7684\u4fe1\u606f\u4e22\u5931\u3001\u8868\u793a\u7a7a\u95f4\u5bf9\u9f50\u56f0\u96be\u4ee5\u53ca\u9700\u8981\u4efb\u52a1\u7279\u5b9a\u91cd\u8bad\u7b49\u74f6\u9888\u3002TableTime\u901a\u8fc7\u5c06\u65f6\u95f4\u5e8f\u5217\u8f6c\u6362\u4e3a\u8868\u683c\u5f62\u5f0f\u3001\u6587\u672c\u8868\u793a\u4ee5\u53ca\u8bbe\u8ba1\u6574\u5408\u4e86\u4e0a\u4e0b\u6587\u6587\u672c\u4fe1\u606f\u3001\u90bb\u57df\u8f85\u52a9\u3001\u591a\u8def\u5f84\u63a8\u7406\u548c\u95ee\u9898\u5206\u89e3\u7684\u63a8\u7406\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86LLM\u5728MTSC\u4efb\u52a1\u4e0a\u7684\u96f6\u6837\u672c\u5206\u7c7b\u80fd\u529b\uff0c\u5e76\u5728UEA\u6863\u6848\u5e93\u768410\u4e2a\u4ee3\u8868\u6027\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u65b9\u6cd5\u5728\u5904\u7406\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\uff08MTSC\uff09\u65f6\uff0c\u5b58\u5728\u4e09\u4e2a\u4e3b\u8981\u74f6\u9888\uff1a1. \u65e0\u6cd5\u65e0\u635f\u5730\u7f16\u7801\u65f6\u95f4\u5e8f\u5217\u4e2d\u7684\u65f6\u95f4\u4fe1\u606f\u548c\u901a\u9053\u7279\u5b9a\u4fe1\u606f\uff1b2. \u5b66\u4e60\u5230\u7684\u8868\u793a\u7a7a\u95f4\u96be\u4ee5\u4e0eLLM\u7684\u8bed\u4e49\u7a7a\u95f4\u5bf9\u9f50\uff1b3. \u9700\u8981\u8017\u65f6\u8017\u529b\u7684\u4efb\u52a1\u7279\u5b9a\u91cd\u8bad\u3002\u8fd9\u4e9b\u74f6\u9888\u9650\u5236\u4e86LLM\u5728MTSC\u4efb\u52a1\u4e0a\u7684\u6709\u6548\u6027\u548c\u6548\u7387\u3002", "method": "TableTime\u65b9\u6cd5\u5c06MTSC\u4efb\u52a1\u91cd\u6784\u4e3a\u8868\u683c\u7406\u89e3\u4efb\u52a1\u3002\u5177\u4f53\u7b56\u7565\u5305\u62ec\uff1a1. \u5c06\u591a\u5143\u65f6\u95f4\u5e8f\u5217\u8f6c\u6362\u4e3a\u8868\u683c\u5f62\u5f0f\uff0c\u6700\u5927\u7a0b\u5ea6\u5730\u51cf\u5c11\u4fe1\u606f\u635f\u5931\u30022. \u5c06\u8868\u683c\u5f62\u5f0f\u7684\u65f6\u95f4\u5e8f\u5217\u8868\u793a\u4e3a\u6587\u672c\uff0c\u4ee5\u4fbf\u4e0eLLM\u7684\u8bed\u4e49\u7a7a\u95f4\u81ea\u7136\u5bf9\u9f50\u30023. \u8bbe\u8ba1\u4e86\u4e00\u4e2a\u63a8\u7406\u6846\u67b6\uff0c\u6574\u5408\u4e86\u4e0a\u4e0b\u6587\u6587\u672c\u4fe1\u606f\u3001\u90bb\u57df\u8f85\u52a9\u3001\u591a\u8def\u5f84\u63a8\u7406\u548c\u95ee\u9898\u5206\u89e3\uff0c\u4ee5\u589e\u5f3aLLM\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u5b9e\u73b0\u96f6\u6837\u672c\u5206\u7c7b\u3002\u5b9e\u9a8c\u5728UEA\u6863\u6848\u5e93\u768410\u4e2a\u516c\u5f00\u4ee3\u8868\u6027\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u3002", "result": "TableTime\u65b9\u6cd5\u572810\u4e2a\u516c\u5f00\u4ee3\u8868\u6027\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4fe1\u606f\u4e22\u5931\u3001\u7a7a\u95f4\u5bf9\u9f50\u56f0\u96be\u548c\u4efb\u52a1\u91cd\u8bad\u7b49\u95ee\u9898\uff0c\u5e76\u5b9e\u73b0\u4e86\u96f6\u6837\u672c\u5206\u7c7b\u3002", "conclusion": "TableTime\u901a\u8fc7\u5c06MTSC\u8f6c\u5316\u4e3a\u8868\u683c\u7406\u89e3\u4efb\u52a1\uff0c\u6210\u529f\u514b\u670d\u4e86\u73b0\u6709LLM\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u66f4\u6709\u6548\u3001\u66f4\u9ad8\u6548\u7684\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u3002\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\uff0c\u4e3aLLM\u5728MTSC\u9886\u57df\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63a2\u7d22TableTime\u5728\u5904\u7406\u66f4\u590d\u6742\u7684\u65f6\u95f4\u5e8f\u5217\u6a21\u5f0f\u548c\u66f4\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u3002"}}
{"id": "2502.21142", "categories": ["cs.AI", "cs.LG", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2502.21142", "abs": "https://arxiv.org/abs/2502.21142", "authors": ["L\u00e9opold Mayti\u00e9", "Roland Bertin Johannet", "Rufin VanRullen"], "title": "Multimodal Dreaming: A Global Workspace Approach to World Model-Based Reinforcement Learning", "comment": "Under review", "summary": "Humans leverage rich internal models of the world to reason about the future,\nimagine counterfactuals, and adapt flexibly to new situations. In Reinforcement\nLearning (RL), world models aim to capture how the environment evolves in\nresponse to the agent's actions, facilitating planning and generalization.\nHowever, typical world models directly operate on the environment variables\n(e.g. pixels, physical attributes), which can make their training slow and\ncumbersome; instead, it may be advantageous to rely on high-level latent\ndimensions that capture relevant multimodal variables. Global Workspace (GW)\nTheory offers a cognitive framework for multimodal integration and information\nbroadcasting in the brain, and recent studies have begun to introduce efficient\ndeep learning implementations of GW. Here, we evaluate the capabilities of an\nRL system combining GW with a world model. We compare our GW-Dreamer with\nvarious versions of the standard PPO and the original Dreamer algorithms. We\nshow that performing the dreaming process (i.e., mental simulation) inside the\nGW latent space allows for training with fewer environment steps. As an\nadditional emergent property, the resulting model (but not its comparison\nbaselines) displays strong robustness to the absence of one of its observation\nmodalities (images or simulation attributes). We conclude that the combination\nof GW with World Models holds great potential for improving decision-making in\nRL agents.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4e86\u5168\u5c40\u5de5\u4f5c\u7a7a\u95f4\uff08GW\uff09\u7406\u8bba\u548c\u4e16\u754c\u6a21\u578b\uff08World Models\uff09\u7684\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u7cfb\u7edf\uff0c\u79f0\u4e3aGW-Dreamer\u3002\u8be5\u7cfb\u7edf\u5728GW\u7684\u6f5c\u5728\u7a7a\u95f4\u4e2d\u8fdb\u884c\u201c\u68a6\u5883\u201d\u8fc7\u7a0b\uff08\u5373\u5fc3\u667a\u6a21\u62df\uff09\uff0c\u4ece\u800c\u53ef\u4ee5\u7528\u66f4\u5c11\u7684\u73af\u5883\u4ea4\u4e92\u6b65\u6570\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u4e14\u5728\u7f3a\u5c11\u4e00\u79cd\u89c2\u5bdf\u6a21\u6001\uff08\u56fe\u50cf\u6216\u6a21\u62df\u5c5e\u6027\uff09\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\uff0c\u800c\u57fa\u7ebf\u6a21\u578b\u5219\u4e0d\u5177\u5907\u6b64\u7279\u6027\u3002", "motivation": "\u5f53\u524d\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u4e2d\u7684\u4e16\u754c\u6a21\u578b\u901a\u5e38\u76f4\u63a5\u5728\u73af\u5883\u53d8\u91cf\uff08\u5982\u50cf\u7d20\u3001\u7269\u7406\u5c5e\u6027\uff09\u4e0a\u64cd\u4f5c\uff0c\u5bfc\u81f4\u8bad\u7ec3\u7f13\u6162\u4e14\u6548\u7387\u4f4e\u4e0b\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e00\u9650\u5236\uff0c\u672c\u6587\u65e8\u5728\u5229\u7528\u9ad8\u5c42\u6f5c\u5728\u7ef4\u5ea6\u6765\u6355\u6349\u76f8\u5173\u7684\u591a\u6a21\u6001\u53d8\u91cf\uff0c\u4ee5\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\u3002\u5168\u5c40\u5de5\u4f5c\u7a7a\u95f4\uff08GW\uff09\u7406\u8bba\u63d0\u4f9b\u4e86\u4e00\u4e2a\u8ba4\u77e5\u6846\u67b6\uff0c\u7528\u4e8e\u5927\u8111\u4e2d\u7684\u591a\u6a21\u6001\u4fe1\u606f\u6574\u5408\u548c\u5e7f\u64ad\uff0c\u8fd9\u4e3a\u6784\u5efa\u66f4\u9ad8\u6548\u7684\u5b66\u4e60\u7cfb\u7edf\u63d0\u4f9b\u4e86\u542f\u53d1\u3002", "method": "\u672c\u6587\u63d0\u51fa\u7684GW-Dreamer\u7cfb\u7edf\u7ed3\u5408\u4e86\u5168\u5c40\u5de5\u4f5c\u7a7a\u95f4\uff08GW\uff09\u7406\u8bba\u548c\u4e16\u754c\u6a21\u578b\u3002\u8be5\u65b9\u6cd5\u7684\u6838\u5fc3\u5728\u4e8e\uff0c\u5c06\u201c\u68a6\u5883\u201d\u8fc7\u7a0b\uff08\u5fc3\u667a\u6a21\u62df\uff09\u7f6e\u4e8eGW\u7684\u6f5c\u5728\u7a7a\u95f4\u4e2d\u8fdb\u884c\u3002\u7814\u7a76\u4eba\u5458\u5c06GW-Dreamer\u4e0e\u6807\u51c6\u7684PPO\u7b97\u6cd5\u548c\u539f\u59cb\u7684Dreamer\u7b97\u6cd5\u8fdb\u884c\u4e86\u6bd4\u8f83\uff0c\u8bc4\u4f30\u5176\u5728\u8bad\u7ec3\u6548\u7387\u548c\u9c81\u68d2\u6027\u65b9\u9762\u7684\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728GW\u6f5c\u5728\u7a7a\u95f4\u4e2d\u6267\u884c\u68a6\u5883\u8fc7\u7a0b\u7684GW-Dreamer\u7cfb\u7edf\uff0c\u80fd\u591f\u4ee5\u66f4\u5c11\u7684\u73af\u5883\u4ea4\u4e92\u6b65\u6570\u5b8c\u6210\u8bad\u7ec3\u3002\u6b64\u5916\uff0cGW-Dreamer\u5c55\u73b0\u51fa\u4e00\u79cd\u65b0\u5174\u7684\u9c81\u68d2\u6027\u4f18\u52bf\uff0c\u5373\u4f7f\u5728\u7f3a\u5c11\u4e00\u79cd\u89c2\u5bdf\u6a21\u6001\uff08\u56fe\u50cf\u6216\u6a21\u62df\u5c5e\u6027\uff09\u7684\u60c5\u51b5\u4e0b\uff0c\u5176\u6027\u80fd\u4e5f\u8868\u73b0\u51fa\u8272\uff0c\u800c\u5bf9\u6bd4\u7684\u57fa\u7ebf\u6a21\u578b\u5219\u4e0d\u5177\u5907\u8fd9\u79cd\u9c81\u68d2\u6027\u3002", "conclusion": "\u672c\u6587\u7684\u7ed3\u8bba\u662f\uff0c\u5c06\u5168\u5c40\u5de5\u4f5c\u7a7a\u95f4\uff08GW\uff09\u7406\u8bba\u4e0e\u4e16\u754c\u6a21\u578b\u76f8\u7ed3\u5408\uff0c\u4e3a\u63d0\u5347RL\u667a\u80fd\u4f53\u7684\u51b3\u7b56\u80fd\u529b\u5e26\u6765\u4e86\u5de8\u5927\u7684\u6f5c\u529b\u3002GW-Dreamer\u7cfb\u7edf\u5728\u8bad\u7ec3\u6548\u7387\u548c\u5bf9\u89c2\u5bdf\u6a21\u6001\u7f3a\u5931\u7684\u9c81\u68d2\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u9884\u793a\u7740\u8be5\u65b9\u5411\u5728\u672a\u6765RL\u7814\u7a76\u4e2d\u7684\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2505.17323", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2505.17323", "abs": "https://arxiv.org/abs/2505.17323", "authors": ["Ruaridh Mon-Williams", "Max Taylor-Davies", "Elizabeth Mieczkowski", "Natalia Velez", "Neil R. Bramley", "Yanwei Wang", "Thomas L. Griffiths", "Christopher G. Lucas"], "title": "Partner Modelling Emerges in Recurrent Agents (But Only When It Matters)", "comment": null, "summary": "Humans are remarkably adept at collaboration, able to infer the strengths and\nweaknesses of new partners in order to work successfully towards shared goals.\nTo build AI systems with this capability, we must first understand its building\nblocks: does such flexibility require explicit, dedicated mechanisms for\nmodelling others -- or can it emerge spontaneously from the pressures of\nopen-ended cooperative interaction? To investigate this question, we train\nsimple model-free RNN agents to collaborate with a population of diverse\npartners. Using the `Overcooked-AI' environment, we collect data from thousands\nof collaborative teams, and analyse agents' internal hidden states. Despite a\nlack of additional architectural features, inductive biases, or auxiliary\nobjectives, the agents nevertheless develop structured internal representations\nof their partners' task abilities, enabling rapid adaptation and generalisation\nto novel collaborators. We investigated these internal models through probing\ntechniques, and large-scale behavioural analysis. Notably, we find that\nstructured partner modelling emerges when agents can influence partner\nbehaviour by controlling task allocation. Our results show that partner\nmodelling can arise spontaneously in model-free agents -- but only under\nenvironmental conditions that impose the right kind of social pressure.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bad\u7ec3\u7b80\u5355\u7684\u65e0\u6a21\u578bRNN\u667a\u80fd\u4f53\u4e0e\u591a\u6837\u5316\u7684\u4f19\u4f34\u8fdb\u884c\u534f\u4f5c\uff0c\u53d1\u73b0\u5728\u7f3a\u4e4f\u989d\u5916\u67b6\u6784\u3001\u5f52\u7eb3\u504f\u7f6e\u6216\u8f85\u52a9\u76ee\u6807\u7684\u60c5\u51b5\u4e0b\uff0c\u667a\u80fd\u4f53\u80fd\u81ea\u53d1\u5730\u53d1\u5c55\u51fa\u5bf9\u5176\u4f19\u4f34\u4efb\u52a1\u80fd\u529b\u7684\u7ed3\u6784\u5316\u5185\u90e8\u8868\u5f81\uff0c\u4ece\u800c\u5b9e\u73b0\u5bf9\u65b0\u4f19\u4f34\u7684\u5feb\u901f\u9002\u5e94\u548c\u6cdb\u5316\u3002\u8fd9\u79cd\u4f19\u4f34\u5efa\u6a21\u7684\u51fa\u73b0\u4e0e\u73af\u5883\u6761\u4ef6\u6709\u5173\uff0c\u7279\u522b\u662f\u5f53\u667a\u80fd\u4f53\u80fd\u591f\u901a\u8fc7\u63a7\u5236\u4efb\u52a1\u5206\u914d\u6765\u5f71\u54cd\u4f19\u4f34\u884c\u4e3a\u65f6\u3002", "motivation": "\u4e3a\u4e86\u6784\u5efa\u5177\u5907\u4eba\u7c7b\u534f\u4f5c\u80fd\u529b\u7684AI\u7cfb\u7edf\uff0c\u7814\u7a76\u8005\u65e8\u5728\u63a2\u7a76\u8fd9\u79cd\u7075\u6d3b\u6027\u662f\u9700\u8981\u663e\u5f0f\u7684\u4f19\u4f34\u5efa\u6a21\u673a\u5236\uff0c\u8fd8\u662f\u53ef\u4ee5\u81ea\u53d1\u5730\u4ece\u5f00\u653e\u5f0f\u5408\u4f5c\u4e92\u52a8\u4e2d\u6d8c\u73b0\u3002\u7406\u89e3\u8fd9\u4e00\u70b9\u5bf9\u4e8e\u5f00\u53d1\u66f4\u5f3a\u5927\u7684AI\u534f\u4f5c\u81f3\u5173\u91cd\u8981\u3002", "method": "\u7814\u7a76\u8005\u4f7f\u7528`Overcooked-AI`\u73af\u5883\uff0c\u8bad\u7ec3\u4e86\u7b80\u5355\u7684\u65e0\u6a21\u578bRNN\u667a\u80fd\u4f53\u4e0e\u4e00\u4e2a\u7531\u591a\u6837\u5316\u4f19\u4f34\u7ec4\u6210\u7684\u7fa4\u4f53\u8fdb\u884c\u534f\u4f5c\u3002\u901a\u8fc7\u6536\u96c6\u6570\u5343\u4e2a\u534f\u4f5c\u56e2\u961f\u7684\u6570\u636e\uff0c\u5e76\u5206\u6790\u667a\u80fd\u4f53\u7684\u5185\u90e8\u9690\u85cf\u72b6\u6001\uff0c\u6765\u63a2\u7a76\u4f19\u4f34\u5efa\u6a21\u7684\u51fa\u73b0\u3002\u7814\u7a76\u4e2d\u8fd0\u7528\u4e86\u63a2\u6d4b\u6280\u672f\u548c\u5927\u89c4\u6a21\u884c\u4e3a\u5206\u6790\u6765\u8c03\u67e5\u667a\u80fd\u4f53\u7684\u5185\u90e8\u6a21\u578b\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u5373\u4f7f\u667a\u80fd\u4f53\u6ca1\u6709\u989d\u5916\u7684\u67b6\u6784\u7279\u5f81\u3001\u5f52\u7eb3\u504f\u7f6e\u6216\u8f85\u52a9\u76ee\u6807\uff0c\u5b83\u4eec\u4e5f\u80fd\u53d1\u5c55\u51fa\u5bf9\u4f19\u4f34\u4efb\u52a1\u80fd\u529b\u7684\u7ed3\u6784\u5316\u5185\u90e8\u8868\u5f81\uff0c\u4ece\u800c\u80fd\u591f\u5feb\u901f\u9002\u5e94\u5e76\u6cdb\u5316\u5230\u65b0\u7684\u5408\u4f5c\u8005\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5f53\u667a\u80fd\u4f53\u53ef\u4ee5\u901a\u8fc7\u63a7\u5236\u4efb\u52a1\u5206\u914d\u6765\u5f71\u54cd\u4f19\u4f34\u884c\u4e3a\u65f6\uff0c\u7ed3\u6784\u5316\u7684\u4f19\u4f34\u5efa\u6a21\u5c31\u4f1a\u51fa\u73b0\u3002", "conclusion": "\u672c\u7814\u7a76\u8bc1\u660e\u4e86\u5728\u6a21\u578b\u65e0\u5173\u7684\u667a\u80fd\u4f53\u4e2d\uff0c\u4f19\u4f34\u5efa\u6a21\u53ef\u4ee5\u81ea\u53d1\u6d8c\u73b0\uff0c\u4f46\u524d\u63d0\u662f\u73af\u5883\u6761\u4ef6\u65bd\u52a0\u4e86\u9002\u5f53\u7684\u793e\u4f1a\u538b\u529b\u3002\u8fd9\u8868\u660e\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u534f\u4f5c\u73af\u5883\uff0c\u53ef\u4ee5\u57f9\u517b\u51fa\u66f4\u667a\u80fd\u3001\u66f4\u5177\u9002\u5e94\u6027\u7684AI\u5408\u4f5c\u8005\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63a2\u7d22\u4e0d\u540c\u73af\u5883\u56e0\u7d20\u5bf9\u4f19\u4f34\u5efa\u6a21\u6d8c\u73b0\u7684\u5f71\u54cd\uff0c\u4ee5\u53ca\u5c06\u5176\u5e94\u7528\u4e8e\u66f4\u590d\u6742\u7684\u534f\u4f5c\u4efb\u52a1\u3002"}}
{"id": "2510.24707", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24707", "abs": "https://arxiv.org/abs/2510.24707", "authors": ["Juraj Juraska", "Tobias Domhan", "Mara Finkelstein", "Tetsuji Nakagawa", "Geza Kovacs", "Daniel Deutsch", "Pidong Wang", "Markus Freitag"], "title": "MetricX-25 and GemSpanEval: Google Translate Submissions to the WMT25 Evaluation Shared Task", "comment": "Accepted to WMT25", "summary": "In this paper, we present our submissions to the unified WMT25 Translation\nEvaluation Shared Task. For the Quality Score Prediction subtask, we create a\nnew generation of MetricX with improvements in the input format and the\ntraining protocol, while for the Error Span Detection subtask we develop a new\nmodel, GemSpanEval, trained to predict error spans along with their severities\nand categories. Both systems are based on the state-of-the-art multilingual\nopen-weights model Gemma 3, fine-tuned on publicly available WMT data. We\ndemonstrate that MetricX-25, adapting Gemma 3 to an encoder-only architecture\nwith a regression head on top, can be trained to effectively predict both MQM\nand ESA quality scores, and significantly outperforms its predecessor. Our\ndecoder-only GemSpanEval model, on the other hand, we show to be competitive in\nerror span detection with xCOMET, a strong encoder-only sequence-tagging\nbaseline. With error span detection formulated as a generative task, we\ninstruct the model to also output the context for each predicted error span,\nthus ensuring that error spans are identified unambiguously.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4f5c\u8005\u4e3aWMT25\u7ffb\u8bd1\u8bc4\u4f30\u5171\u4eab\u4efb\u52a1\u63d0\u4ea4\u7684\u4e24\u4e2a\u7cfb\u7edf\uff1aMetricX-25\u548cGemSpanEval\u3002MetricX-25\u662f\u4e3a\u8d28\u91cf\u5206\u6570\u9884\u6d4b\u5b50\u4efb\u52a1\u8bbe\u8ba1\u7684\uff0c\u5b83\u6539\u8fdb\u4e86\u8f93\u5165\u683c\u5f0f\u548c\u8bad\u7ec3\u534f\u8bae\uff0c\u5e76\u57fa\u4e8eGemma 3\u6a21\u578b\uff0c\u5728MQM\u548cESA\u8d28\u91cf\u5206\u6570\u9884\u6d4b\u65b9\u9762\u8868\u73b0\u4f18\u4e8e\u524d\u4ee3\u3002GemSpanEval\u662f\u4e3a\u9519\u8bef\u8de8\u5ea6\u68c0\u6d4b\u5b50\u4efb\u52a1\u8bbe\u8ba1\u7684\uff0c\u540c\u6837\u57fa\u4e8eGemma 3\uff0c\u80fd\u591f\u9884\u6d4b\u9519\u8bef\u8de8\u5ea6\u53ca\u5176\u4e25\u91cd\u7a0b\u5ea6\u548c\u7c7b\u522b\uff0c\u5e76\u4e14\u901a\u8fc7\u5c06\u5176\u89c6\u4e3a\u751f\u6210\u4efb\u52a1\u6765\u786e\u4fdd\u9519\u8bef\u8de8\u5ea6\u7684\u660e\u786e\u6027\uff0c\u5728\u9519\u8bef\u8de8\u5ea6\u68c0\u6d4b\u65b9\u9762\u4e0exCOMET\u76f8\u5f53\u3002", "motivation": "\u5f53\u524d\u7684\u673a\u5668\u7ffb\u8bd1\u8bc4\u4f30\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u65b9\u9762\u4ecd\u6709\u4e0d\u8db3\uff0c\u5c24\u5176\u662f\u5728\u9884\u6d4b\u7ffb\u8bd1\u8d28\u91cf\u5206\u6570\u548c\u7cbe\u786e\u5b9a\u4f4d\u9519\u8bef\u65b9\u9762\u3002\u73b0\u6709\u7684\u6307\u6807\u53ef\u80fd\u65e0\u6cd5\u5b8c\u5168\u6355\u6349\u4eba\u7c7b\u5bf9\u7ffb\u8bd1\u8d28\u91cf\u7684\u7ec6\u5fae\u5224\u65ad\uff0c\u800c\u9519\u8bef\u5b9a\u4f4d\u5219\u66f4\u52a0\u56f0\u96be\u3002\u56e0\u6b64\uff0c\u9700\u8981\u66f4\u5148\u8fdb\u7684\u8bc4\u4f30\u65b9\u6cd5\u6765\u63d0\u9ad8\u673a\u5668\u7ffb\u8bd1\u8d28\u91cf\u8bc4\u4f30\u7684\u51c6\u786e\u6027\u548c\u7ec6\u7c92\u5ea6\u3002", "method": "1. **\u8d28\u91cf\u5206\u6570\u9884\u6d4b (MetricX-25):** \u4f7f\u7528Gemma 3\u6a21\u578b\uff0c\u91c7\u7528\u7f16\u7801\u5668-only\u67b6\u6784\uff0c\u5e76\u5728\u5176\u9876\u90e8\u6dfb\u52a0\u56de\u5f52\u5934\u3002\u901a\u8fc7\u6539\u8fdb\u8f93\u5165\u683c\u5f0f\u548c\u8bad\u7ec3\u534f\u8bae\uff0c\u5728\u516c\u5f00\u53ef\u7528\u7684WMT\u6570\u636e\u4e0a\u8fdb\u884c\u5fae\u8c03\uff0c\u4ee5\u9884\u6d4bMQM\u548cESA\u8d28\u91cf\u5206\u6570\u3002\n2. **\u9519\u8bef\u8de8\u5ea6\u68c0\u6d4b (GemSpanEval):** \u4f7f\u7528Gemma 3\u6a21\u578b\uff0c\u91c7\u7528\u89e3\u7801\u5668-only\u67b6\u6784\u3002\u5c06\u9519\u8bef\u8de8\u5ea6\u68c0\u6d4b\u89c6\u4e3a\u4e00\u4e2a\u751f\u6210\u4efb\u52a1\uff0c\u6a21\u578b\u88ab\u6307\u793a\u8f93\u51fa\u6bcf\u4e2a\u9884\u6d4b\u9519\u8bef\u8de8\u5ea6\u7684\u4e0a\u4e0b\u6587\uff0c\u4ee5\u786e\u4fdd\u5176\u660e\u786e\u6027\u3002\u6a21\u578b\u540c\u65f6\u9884\u6d4b\u9519\u8bef\u8de8\u5ea6\u7684\u4e25\u91cd\u7a0b\u5ea6\u548c\u7c7b\u522b\u3002", "result": "1. **MetricX-25:** \u5728MQM\u548cESA\u8d28\u91cf\u5206\u6570\u9884\u6d4b\u4efb\u52a1\u4e0a\uff0cMetricX-25\u663e\u8457\u4f18\u4e8e\u5176\u524d\u4ee3\u4ea7\u54c1\uff0c\u8868\u660e\u6539\u8fdb\u7684\u8f93\u5165\u683c\u5f0f\u548c\u8bad\u7ec3\u534f\u8bae\u6709\u6548\u63d0\u9ad8\u4e86\u9884\u6d4b\u6027\u80fd\u3002\n2. **GemSpanEval:** \u5728\u9519\u8bef\u8de8\u5ea6\u68c0\u6d4b\u4efb\u52a1\u4e0a\uff0cGemSpanEval\u8868\u73b0\u51fa\u4e0e\u5f3a\u5927\u7684\u7f16\u7801\u5668-only\u57fa\u7ebf\u6a21\u578bxCOMET\u76f8\u5f53\u7684\u7ade\u4e89\u529b\u3002\u901a\u8fc7\u751f\u6210\u4efb\u52a1\u7684 formulation\uff0cGemSpanEval\u80fd\u591f\u660e\u786e\u5730\u8bc6\u522b\u9519\u8bef\u8de8\u5ea6\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684MetricX-25\u548cGemSpanEval\u7cfb\u7edf\u5728WMT25\u7ffb\u8bd1\u8bc4\u4f30\u5171\u4eab\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u6709\u7ade\u4e89\u529b\u7684\u7ed3\u679c\u3002MetricX-25\u5728\u8d28\u91cf\u5206\u6570\u9884\u6d4b\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u6b65\uff0c\u800cGemSpanEval\u901a\u8fc7\u521b\u65b0\u7684\u751f\u6210\u4efb\u52a1\u65b9\u6cd5\u5728\u9519\u8bef\u8de8\u5ea6\u68c0\u6d4b\u65b9\u9762\u5c55\u73b0\u4e86\u6f5c\u529b\u3002\u8fd9\u4e9b\u57fa\u4e8e\u5148\u8fdb\u7684Gemma 3\u591a\u8bed\u8a00\u6a21\u578b\u7684\u7cfb\u7edf\uff0c\u4e3a\u673a\u5668\u7ffb\u8bd1\u8d28\u91cf\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5c24\u5176\u662f\u5728\u7ec6\u7c92\u5ea6\u9519\u8bef\u5206\u6790\u65b9\u9762\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63a2\u7d22\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u548c\u5728\u66f4\u591a\u8bed\u8a00\u5bf9\u4e0a\u7684\u5e94\u7528\u3002"}}
{"id": "2506.23464", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.23464", "abs": "https://arxiv.org/abs/2506.23464", "authors": ["Sahil Tripathi", "Md Tabrez Nafis", "Imran Hussain", "Jiechao Gao"], "title": "The Confidence Paradox: Can LLM Know When It's Wrong", "comment": "Accepted at the 14th IJCNLP & 4th AACL 2025 (Main)", "summary": "Document Visual Question Answering (DocVQA) models often produce\noverconfident or ethically misaligned responses, especially under uncertainty.\nExisting models like LayoutLMv3, UDOP, and DONUT focus on accuracy but lack\nethical calibration. We propose HonestVQA, a model-agnostic, self-supervised\nframework that aligns model confidence with correctness using weighted loss and\ncontrastive learning. We introduce two new metrics Honesty Score (H-Score) and\nEthical Confidence Index (ECI)-to evaluate ethical alignment. HonestVQA\nimproves accuracy and F1 by up to 4.3% across SpDocVQA, InfographicsVQA, and\nSROIE datasets, while reducing overconfidence. It also generalizes well across\ndomains, achieving 78.9% accuracy and 76.1% F1-score.", "AI": {"tldr": "\u6587\u6863\u89c6\u89c9\u95ee\u7b54\uff08DocVQA\uff09\u6a21\u578b\u5e38\u5728\u4e0d\u786e\u5b9a\u65f6\u7ed9\u51fa\u8fc7\u4e8e\u81ea\u4fe1\u6216\u4e0d\u7b26\u5408\u4f26\u7406\u7684\u56de\u7b54\u3002\u4e3a\u89e3\u51b3\u6b64\u95ee\u9898\uff0c\u672c\u7814\u7a76\u63d0\u51fa\u4e86HonestVQA\uff0c\u4e00\u4e2a\u6a21\u578b\u65e0\u5173\u7684\u81ea\u76d1\u7763\u6846\u67b6\uff0c\u901a\u8fc7\u52a0\u6743\u635f\u5931\u548c\u5bf9\u6bd4\u5b66\u4e60\u6765\u6821\u51c6\u6a21\u578b\u7f6e\u4fe1\u5ea6\u4e0e\u6b63\u786e\u6027\u3002\u7814\u7a76\u8fd8\u5f15\u5165\u4e86H-Score\u548cECI\u4e24\u4e2a\u65b0\u6307\u6807\u6765\u8bc4\u4f30\u4f26\u7406\u5bf9\u9f50\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cHonestVQA\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u63d0\u9ad8\u4e86\u51c6\u786e\u7387\u548cF1\u5206\u6570\uff0c\u5e76\u51cf\u5c11\u4e86\u8fc7\u5ea6\u81ea\u4fe1\uff0c\u540c\u65f6\u5728\u4e0d\u540c\u9886\u57df\u5c55\u73b0\u4e86\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684DocVQA\u6a21\u578b\uff08\u5982LayoutLMv3\u3001UDOP\u3001DONUT\uff09\u4e3b\u8981\u5173\u6ce8\u51c6\u786e\u7387\uff0c\u4f46\u5728\u9762\u5bf9\u4e0d\u786e\u5b9a\u6027\u65f6\uff0c\u5176\u56de\u7b54\u53ef\u80fd\u8fc7\u4e8e\u81ea\u4fe1\u6216\u5b58\u5728\u4f26\u7406\u504f\u5dee\uff0c\u672a\u80fd\u6709\u6548\u6821\u51c6\u6a21\u578b\u7684\u7f6e\u4fe1\u5ea6\u3002\u8fd9\u79cd\u4e0d\u51c6\u786e\u7684\u7f6e\u4fe1\u5ea6\u8bc4\u4f30\u53ef\u80fd\u5bfc\u81f4\u6a21\u578b\u5728\u5173\u952e\u5e94\u7528\u573a\u666f\u4e2d\u505a\u51fa\u9519\u8bef\u7684\u51b3\u7b56\uff0c\u56e0\u6b64\uff0c\u63d0\u5347DocVQA\u6a21\u578b\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u53ef\u9760\u6027\u548c\u4f26\u7406\u5bf9\u9f50\u80fd\u529b\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86HonestVQA\uff0c\u4e00\u4e2a\u6a21\u578b\u65e0\u5173\u7684\u81ea\u76d1\u7763\u6846\u67b6\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u52a0\u6743\u635f\u5931\uff08weighted loss\uff09\u548c\u5bf9\u6bd4\u5b66\u4e60\uff08contrastive learning\uff09\u6765\u4f18\u5316\u6a21\u578b\uff0c\u65e8\u5728\u4f7f\u6a21\u578b\u7684\u7f6e\u4fe1\u5ea6\u4e0e\u5176\u9884\u6d4b\u7684\u6b63\u786e\u6027\u76f8\u5339\u914d\u3002\u5177\u4f53\u800c\u8a00\uff0c\u52a0\u6743\u635f\u5931\u51fd\u6570\u80fd\u591f\u6839\u636e\u9884\u6d4b\u7684\u51c6\u786e\u6027\u8c03\u6574\u6837\u672c\u7684\u91cd\u8981\u6027\uff0c\u800c\u5bf9\u6bd4\u5b66\u4e60\u5219\u5e2e\u52a9\u6a21\u578b\u533a\u5206\u76f8\u4f3c\u4f46\u4e0d\u540c\u7684\u6837\u672c\uff0c\u4ece\u800c\u63d0\u9ad8\u5176\u5bf9\u7ec6\u5fae\u5dee\u522b\u7684\u611f\u77e5\u80fd\u529b\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u5b9a\u4e49\u4e86\u4e24\u4e2a\u65b0\u7684\u8bc4\u4f30\u6307\u6807\uff1aH-Score\uff08Honesty Score\uff09\u548cECI\uff08Ethical Confidence Index\uff09\uff0c\u7528\u4e8e\u91cf\u5316\u6a21\u578b\u7684\u8bda\u5b9e\u5ea6\u548c\u4f26\u7406\u7f6e\u4fe1\u6c34\u5e73\u3002", "result": "\u5728SpDocVQA\u3001InfographicsVQA\u548cSROIE\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cHonestVQA\u76f8\u8f83\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u5728\u51c6\u786e\u7387\u548cF1\u5206\u6570\u4e0a\u63d0\u9ad8\u4e86\u9ad8\u8fbe4.3%\u3002\u540c\u65f6\uff0c\u8be5\u6846\u67b6\u6709\u6548\u964d\u4f4e\u4e86\u6a21\u578b\u7684\u8fc7\u5ea6\u81ea\u4fe1\u95ee\u9898\u3002\u6b64\u5916\uff0cHonestVQA\u5728\u4e0d\u540c\u9886\u57df\u4e5f\u8868\u73b0\u51fa\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5728\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u4e8678.9%\u7684\u51c6\u786e\u7387\u548c76.1%\u7684F1\u5206\u6570\u3002", "conclusion": "HonestVQA\u6846\u67b6\u901a\u8fc7\u521b\u65b0\u7684\u52a0\u6743\u635f\u5931\u548c\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\uff0c\u6210\u529f\u89e3\u51b3\u4e86DocVQA\u6a21\u578b\u5728\u4e0d\u786e\u5b9a\u6027\u4e0b\u7684\u8fc7\u5ea6\u81ea\u4fe1\u548c\u4f26\u7406\u504f\u5dee\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002\u65b0\u63d0\u51fa\u7684H-Score\u548cECI\u6307\u6807\u4e3a\u8bc4\u4f30\u6a21\u578b\u4f26\u7406\u5bf9\u9f50\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002\u8be5\u7814\u7a76\u4e0d\u4ec5\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u800c\u4e14\u5c55\u793a\u4e86\u826f\u597d\u7684\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u6784\u5efa\u66f4\u8d1f\u8d23\u4efb\u7684AI\u7cfb\u7edf\u5960\u5b9a\u4e86\u57fa\u7840\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u63a2\u7d22\u5c06\u6b64\u6846\u67b6\u5e94\u7528\u4e8e\u66f4\u5e7f\u6cdb\u7684VQA\u4efb\u52a1\uff0c\u5e76\u8fdb\u4e00\u6b65\u7814\u7a76\u5176\u5728\u771f\u5b9e\u4e16\u754c\u590d\u6742\u573a\u666f\u4e0b\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2507.03285", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.03285", "abs": "https://arxiv.org/abs/2507.03285", "authors": ["Jianyu Zhang", "L\u00e9on Bottou"], "title": "Memory Mosaics at scale", "comment": "Oral @ NeurIPS 2025", "summary": "Memory Mosaics [Zhang et al., 2025], networks of associative memories, have\ndemonstrated appealing compositional and in-context learning capabilities on\nmedium-scale networks (GPT-2 scale) and synthetic small datasets. This work\nshows that these favorable properties remain when we scale memory mosaics to\nlarge language model sizes (llama-8B scale) and real-world datasets.\n  To this end, we scale memory mosaics to 10B size, we train them on one\ntrillion tokens, we introduce a couple architectural modifications (\"Memory\nMosaics v2\"), we assess their capabilities across three evaluation dimensions:\ntraining-knowledge storage, new-knowledge storage, and in-context learning.\n  Throughout the evaluation, memory mosaics v2 match transformers on the\nlearning of training knowledge (first dimension) and significantly outperforms\ntransformers on carrying out new tasks at inference time (second and third\ndimensions). These improvements cannot be easily replicated by simply\nincreasing the training data for transformers. A memory mosaics v2 trained on\none trillion tokens still perform better on these tasks than a transformer\ntrained on eight trillion tokens.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2404.13397", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2404.13397", "abs": "https://arxiv.org/abs/2404.13397", "authors": ["Sefika Efeoglu", "Adrian Paschke"], "title": "Retrieval-Augmented Generation-based Relation Extraction", "comment": "published at the Semantic Web journal. The last version is available:\n  https://doi.org/10.1177/22104968251385519", "summary": "Information Extraction (IE) is a transformative process that converts\nunstructured text data into a structured format by employing entity and\nrelation extraction (RE) methodologies. The identification of the relation\nbetween a pair of entities plays a crucial role within this framework. Despite\nthe existence of various techniques for relation extraction, their efficacy\nheavily relies on access to labeled data and substantial computational\nresources. In addressing these challenges, Large Language Models (LLMs) emerge\nas promising solutions; however, they might return hallucinating responses due\nto their own training data. To overcome these limitations, Retrieved-Augmented\nGeneration-based Relation Extraction (RAG4RE) in this work is proposed,\noffering a pathway to enhance the performance of relation extraction tasks.\n  This work evaluated the effectiveness of our RAG4RE approach utilizing\ndifferent LLMs. Through the utilization of established benchmarks, such as\nTACRED, TACREV, Re-TACRED, and SemEval RE datasets, our aim is to\ncomprehensively evaluate the efficacy of our RAG4RE approach. In particularly,\nwe leverage prominent LLMs including Flan T5, Llama2, and Mistral in our\ninvestigation. The results of our study demonstrate that our RAG4RE approach\nsurpasses performance of traditional RE approaches based solely on LLMs,\nparticularly evident in the TACRED dataset and its variations. Furthermore, our\napproach exhibits remarkable performance compared to previous RE methodologies\nacross both TACRED and TACREV datasets, underscoring its efficacy and potential\nfor advancing RE tasks in natural language processing.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2508.21730", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.21730", "abs": "https://arxiv.org/abs/2508.21730", "authors": ["Fabrizio Fagiolo", "Nicol\u00f2 Vescera"], "title": "Freeze and Conquer: Reusable Ansatz for Solving the Traveling Salesman Problem", "comment": null, "summary": "In this paper we present a variational algorithm for the Traveling Salesman\nProblem (TSP) that combines (i) a compact encoding of permutations, which\nreduces the qubit requirement too, (ii) an optimize-freeze-reuse strategy:\nwhere the circuit topology (``Ansatz'') is first optimized on a training\ninstance by Simulated Annealing (SA), then ``frozen'' and re-used on novel\ninstances, limited to a rapid re-optimization of only the circuit parameters.\nThis pipeline eliminates costly structural research in testing, making the\nprocedure immediately implementable on NISQ hardware.\n  On a set of $40$ randomly generated symmetric instances that span $4 - 7$\ncities, the resulting Ansatz achieves an average optimal trip sampling\nprobability of $100\\%$ for 4 city cases, $90\\%$ for 5 city cases and $80\\%$ for\n6 city cases. With 7 cities the success rate drops markedly to an average of\n$\\sim 20\\%$, revealing the onset of scalability limitations of the proposed\nmethod.\n  The results show robust generalization ability for moderate problem sizes and\nindicate how freezing the Ansatz can dramatically reduce time-to-solution\nwithout degrading solution quality. The paper also discusses scalability\nlimitations, the impact of ``warm-start'' initialization of parameters, and\nprospects for extension to more complex problems, such as Vehicle Routing and\nJob-Shop Scheduling.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2404.17401", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2404.17401", "abs": "https://arxiv.org/abs/2404.17401", "authors": ["R\u00e9my Decoupes", "Roberto Interdonato", "Mathieu Roche", "Maguelonne Teisseire", "Sarah Valentin"], "title": "Evaluation of Geographical Distortions in Language Models", "comment": "Accepted version. Published in Machine Learning (Springer) 114:263\n  (2025). Open access under a CC BY-NC-ND 4.0 license. DOI:\n  10.1007/s10994-025-06916-9", "summary": "Language models now constitute essential tools for improving efficiency for\nmany professional tasks such as writing, coding, or learning. For this reason,\nit is imperative to identify inherent biases. In the field of Natural Language\nProcessing, five sources of bias are well-identified: data, annotation,\nrepresentation, models, and research design. This study focuses on biases\nrelated to geographical knowledge. We explore the connection between geography\nand language models by highlighting their tendency to misrepresent spatial\ninformation, thus leading to distortions in the representation of geographical\ndistances. This study introduces four indicators to assess these distortions,\nby comparing geographical and semantic distances. Experiments are conducted\nfrom these four indicators with ten widely used language models. Results\nunderscore the critical necessity of inspecting and rectifying spatial biases\nin language models to ensure accurate and equitable representations.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2509.06463", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2509.06463", "abs": "https://arxiv.org/abs/2509.06463", "authors": ["Chengwei Wu", "Li Du", "Hanyu Zhao", "Yiming Ju", "Jiapu Wang", "Tianyu Chen", "Haoyi Zhou"], "title": "Accelerate Scaling of LLM Finetuning via Quantifying the Coverage and Depth of Instruction Set", "comment": null, "summary": "Scaling the amount of data used for supervied fine-tuning(SFT) does not\nguarantee the proportional gains in model performance, highlighting a critical\nneed to understand what makes training samples effective. This work identifies\ntwo fundamental dataset properties that govern SFT scalability:\n\\textbf{semantic coverage}, or the breadth of task domains, and\n\\textbf{information depth}, or the richness of individual examples. We\ndemonstrate that simple proxies for these properties explain the majority of\nvalidation loss variance in our experiments. In this work, we further propose\nthe \\textbf{Information Landscape Approximation (ILA)}, a model-agnostic data\nselection framework that jointly optimizes for these two factors. ILA\nconstructs compact subsets that approximate the informational value of large\ndatasets. Empirical results show that models tuned on ILA-selected data achieve\nfaster and more sustained performance improvements across diverse tasks and\nmodel sizes compared to existing methods, a phenomenon we term\n\\textbf{accelerated scaling}.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2405.07883", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2405.07883", "abs": "https://arxiv.org/abs/2405.07883", "authors": ["Benjamin Minixhofer", "Edoardo Maria Ponti", "Ivan Vuli\u0107"], "title": "Zero-Shot Tokenizer Transfer", "comment": "NeurIPS 2024", "summary": "Language models (LMs) are bound to their tokenizer, which maps raw text to a\nsequence of vocabulary items (tokens). This restricts their flexibility: for\nexample, LMs trained primarily on English may still perform well in other\nnatural and programming languages, but have vastly decreased efficiency due to\ntheir English-centric tokenizer. To mitigate this, we should be able to swap\nthe original LM tokenizer with an arbitrary one, on the fly, without degrading\nperformance. Hence, in this work we define a new problem: Zero-Shot Tokenizer\nTransfer (ZeTT). The challenge at the core of ZeTT is finding embeddings for\nthe tokens in the vocabulary of the new tokenizer. Since prior heuristics for\ninitializing embeddings often perform at chance level in a ZeTT setting, we\npropose a new solution: we train a hypernetwork taking a tokenizer as input and\npredicting the corresponding embeddings. We empirically demonstrate that the\nhypernetwork generalizes to new tokenizers both with encoder (e.g., XLM-R) and\ndecoder LLMs (e.g., Mistral-7B). Our method comes close to the original models'\nperformance in cross-lingual and coding tasks while markedly reducing the\nlength of the tokenized sequence. We also find that the remaining gap can be\nquickly closed by continued training on less than 1B tokens. Finally, we show\nthat a ZeTT hypernetwork trained for a base (L)LM can also be applied to\nfine-tuned variants without extra training. Overall, our results make\nsubstantial strides toward detaching LMs from their tokenizer.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2509.17550", "categories": ["cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.17550", "abs": "https://arxiv.org/abs/2509.17550", "authors": ["Neslihan Kose", "Anthony Rhodes", "Umur Aybars Ciftci", "Ilke Demir"], "title": "Is It Certainly a Deepfake? Reliability Analysis in Detection & Generation Ecosystem", "comment": "Accepted for publication at the ICCV 2025 workshop - STREAM", "summary": "As generative models are advancing in quality and quantity for creating\nsynthetic content, deepfakes begin to cause online mistrust. Deepfake detectors\nare proposed to counter this effect, however, misuse of detectors claiming fake\ncontent as real or vice versa further fuels this misinformation problem. We\npresent the first comprehensive uncertainty analysis of deepfake detectors,\nsystematically investigating how generative artifacts influence prediction\nconfidence. As reflected in detectors' responses, deepfake generators also\ncontribute to this uncertainty as their generative residues vary, so we cross\nthe uncertainty analysis of deepfake detectors and generators. Based on our\nobservations, the uncertainty manifold holds enough consistent information to\nleverage uncertainty for deepfake source detection. Our approach leverages\nBayesian Neural Networks and Monte Carlo dropout to quantify both aleatoric and\nepistemic uncertainties across diverse detector architectures. We evaluate\nuncertainty on two datasets with nine generators, with four blind and two\nbiological detectors, compare different uncertainty methods, explore region-\nand pixel-based uncertainty, and conduct ablation studies. We conduct and\nanalyze binary real/fake, multi-class real/fake, source detection, and\nleave-one-out experiments between the generator/detector combinations to share\ntheir generalization capability, model calibration, uncertainty, and robustness\nagainst adversarial attacks. We further introduce uncertainty maps that\nlocalize prediction confidence at the pixel level, revealing distinct patterns\ncorrelated with generator-specific artifacts. Our analysis provides critical\ninsights for deploying reliable deepfake detection systems and establishes\nuncertainty quantification as a fundamental requirement for trustworthy\nsynthetic media detection.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2409.11390", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2409.11390", "abs": "https://arxiv.org/abs/2409.11390", "authors": ["Rebecca M. M. Hicke", "Yuri Bizzoni", "Pascale Feldkamp", "Ross Deans Kristensen-McLachlan"], "title": "Says Who? Effective Zero-Shot Annotation of Focalization", "comment": "Accepted at CHR 2025", "summary": "Focalization describes the way in which access to narrative information is\nrestricted or controlled based on the knowledge available to knowledge of the\nnarrator. It is encoded via a wide range of lexico-grammatical features and is\nsubject to reader interpretation. Even trained annotators frequently disagree\non correct labels, suggesting this task is both qualitatively and\ncomputationally challenging. In this work, we test how well five contemporary\nlarge language model (LLM) families and two baselines perform when annotating\nshort literary excerpts for focalization. Despite the challenging nature of the\ntask, we find that LLMs show comparable performance to trained human\nannotators, with GPT-4o achieving an average F1 of 84.79%. Further, we\ndemonstrate that the log probabilities output by GPT-family models frequently\nreflect the difficulty of annotating particular excerpts. Finally, we provide a\ncase study analyzing sixteen Stephen King novels, demonstrating the usefulness\nof this approach for computational literary studies and the insights gleaned\nfrom examining focalization at scale.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u6587\u5b66\u6587\u672c\u4e2d\u201c\u7126\u70b9\u5316\u201d\u73b0\u8c61\u6807\u6ce8\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002\u7814\u7a76\u53d1\u73b0\uff0cLLM\uff0c\u7279\u522b\u662fGPT-4o\uff0c\u5728\u7126\u70b9\u5316\u6807\u6ce8\u4e0a\u7684\u8868\u73b0\u53ef\u4e0e\u53d7\u8fc7\u8bad\u7ec3\u7684\u4eba\u7c7b\u6807\u6ce8\u8005\u76f8\u5ab2\u7f8e\uff0cGPT-4o\u7684\u5e73\u5747F1\u5f97\u5206\u4e3a84.79%\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u8868\u660eLLM\u7684\u5bf9\u6570\u6982\u7387\u80fd\u591f\u53cd\u6620\u6807\u6ce8\u7684\u96be\u5ea6\uff0c\u5e76\u901a\u8fc7\u5bf9\u65af\u8482\u82ac\u00b7\u91d1\u5c0f\u8bf4\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u5728\u8ba1\u7b97\u6587\u5b66\u7814\u7a76\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "motivation": "\u7126\u70b9\u5316\u662f\u6587\u5b66\u53d9\u4e8b\u4e2d\u4e00\u4e2a\u590d\u6742\u4e14\u4e3b\u89c2\u7684\u73b0\u8c61\uff0c\u6307\u7684\u662f\u53d9\u4e8b\u4fe1\u606f\u5982\u4f55\u6839\u636e\u53d9\u8ff0\u8005\u7684\u77e5\u8bc6\u8fdb\u884c\u9650\u5236\u6216\u63a7\u5236\u3002\u7531\u4e8e\u5176\u7f16\u7801\u6d89\u53ca\u5e7f\u6cdb\u7684\u8bcd\u6c47\u8bed\u6cd5\u7279\u5f81\u4e14\u6613\u4e8e\u8bfb\u8005\u89e3\u91ca\uff0c\u5373\u4f7f\u662f\u8bad\u7ec3\u6709\u7d20\u7684\u6807\u6ce8\u8005\u5728\u6807\u6ce8\u65f6\u4e5f\u5e38\u5e38\u51fa\u73b0\u5206\u6b67\uff0c\u8fd9\u4f7f\u5f97\u7126\u70b9\u5316\u6210\u4e3a\u4e00\u9879\u5728\u5b9a\u6027\u7814\u7a76\u548c\u8ba1\u7b97\u5904\u7406\u4e0a\u90fd\u6781\u5177\u6311\u6218\u6027\u7684\u4efb\u52a1\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5f53\u524d\u5148\u8fdb\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u81ea\u52a8\u6807\u6ce8\u7126\u70b9\u5316\u73b0\u8c61\u65b9\u9762\u7684\u80fd\u529b\uff0c\u4ee5\u671f\u4e3a\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\u63d0\u4f9b\u65b0\u7684\u8ba1\u7b97\u89c6\u89d2\uff0c\u5e76\u63a8\u52a8\u8ba1\u7b97\u6587\u5b66\u7814\u7a76\u7684\u53d1\u5c55\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u4e86\u591a\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5bb6\u65cf\u548c\u57fa\u7ebf\u6a21\u578b\u6765\u6d4b\u8bd5\u5b83\u4eec\u5728\u6807\u6ce8\u6587\u5b66\u6587\u672c\u4e2d\u7126\u70b9\u5316\u73b0\u8c61\u7684\u80fd\u529b\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u7814\u7a76\u6d4b\u8bd5\u4e86\u4e94\u79cd\u4e3b\u6d41LLM\u5bb6\u65cf\u548c\u4e24\u79cd\u57fa\u7ebf\u6a21\u578b\u7684\u6027\u80fd\u3002\u5b9e\u9a8c\u8bbe\u8ba1\u5305\u62ec\u4f7f\u7528\u8fd9\u4e9b\u6a21\u578b\u5bf9\u7b80\u77ed\u7684\u6587\u5b66\u9009\u6bb5\u8fdb\u884c\u7126\u70b9\u5316\u6807\u6ce8\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u5229\u7528GPT\u7cfb\u5217\u6a21\u578b\u8f93\u51fa\u7684\u5bf9\u6570\u6982\u7387\u6765\u8bc4\u4f30\u6a21\u578b\u5bf9\u6807\u6ce8\u96be\u5ea6\u7684\u611f\u77e5\u80fd\u529b\u3002\u6700\u540e\uff0c\u901a\u8fc7\u5bf9\u5341\u516d\u90e8\u65af\u8482\u82ac\u00b7\u91d1\u5c0f\u8bf4\u7684\u6848\u4f8b\u5206\u6790\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u5b9e\u9645\u6587\u5b66\u7814\u7a76\u4e2d\u7684\u5e94\u7528\u6548\u679c\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0c\u5c3d\u7ba1\u7126\u70b9\u5316\u6807\u6ce8\u4efb\u52a1\u5177\u6709\u6311\u6218\u6027\uff0c\u4f46LLM\u5728\u51c6\u786e\u6027\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5176\u6027\u80fd\u4e0e\u8bad\u7ec3\u6709\u7d20\u7684\u4eba\u7c7b\u6807\u6ce8\u8005\u76f8\u5f53\u3002\u5176\u4e2d\uff0cGPT-4o\u6a21\u578b\u53d6\u5f97\u4e86\u5e73\u574784.79%\u7684F1\u5f97\u5206\uff0c\u8868\u73b0\u5c24\u4e3a\u7a81\u51fa\u3002\u7814\u7a76\u8fd8\u53d1\u73b0\uff0cGPT\u7cfb\u5217\u6a21\u578b\u4ea7\u751f\u7684\u5bf9\u6570\u6982\u7387\u80fd\u591f\u6709\u6548\u53cd\u6620\u51fa\u7279\u5b9a\u6587\u672c\u7247\u6bb5\u5728\u6807\u6ce8\u4e0a\u7684\u96be\u6613\u7a0b\u5ea6\u3002\u5728\u5bf9\u65af\u8482\u82ac\u00b7\u91d1\u5c0f\u8bf4\u7684\u6848\u4f8b\u7814\u7a76\u4e2d\uff0c\u8be5\u65b9\u6cd5\u6210\u529f\u5c55\u793a\u4e86\u5176\u5728\u89c4\u6a21\u5316\u5206\u6790\u7126\u70b9\u5316\u73b0\u8c61\u65b9\u9762\u7684\u5b9e\u7528\u6027\uff0c\u5e76\u63ed\u793a\u4e86\u76f8\u5173\u6587\u5b66\u89c1\u89e3\u3002", "conclusion": "\u672c\u7814\u7a76\u6210\u529f\u8bc1\u660e\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u7684\u8ba1\u7b97\u6587\u5b66\u4efb\u52a1\uff0c\u5982\u7126\u70b9\u5316\u6807\u6ce8\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u5176\u8868\u73b0\u8db3\u4ee5\u5ab2\u7f8e\u4eba\u7c7b\u4e13\u5bb6\u3002GPT-4o\u7b49\u6a21\u578b\u4e0d\u4ec5\u80fd\u51c6\u786e\u6807\u6ce8\u7126\u70b9\u5316\uff0c\u5176\u6982\u7387\u8f93\u51fa\u8fd8\u80fd\u6307\u793a\u6807\u6ce8\u96be\u5ea6\uff0c\u4e3a\u6df1\u5165\u7684\u8ba1\u7b97\u6587\u5b66\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u5de5\u5177\u3002\u901a\u8fc7\u5bf9\u65af\u8482\u82ac\u00b7\u91d1\u5c0f\u8bf4\u7684\u89c4\u6a21\u5316\u5206\u6790\uff0c\u8bc1\u5b9e\u4e86\u8be5\u65b9\u6cd5\u5728\u53d1\u73b0\u6587\u5b66\u6a21\u5f0f\u548c\u83b7\u5f97\u65b0\u89c1\u89e3\u65b9\u9762\u7684\u6709\u6548\u6027\u3002\u5c3d\u7ba1\u5982\u6b64\uff0c\u672a\u6765\u7684\u7814\u7a76\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63a2\u7d22\u6a21\u578b\u5728\u5904\u7406\u66f4\u957f\u6587\u672c\u3001\u66f4\u591a\u6837\u5316\u6587\u5b66\u98ce\u683c\u4ee5\u53ca\u63d0\u9ad8\u6807\u6ce8\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u7684\u80fd\u529b\u3002"}}
{"id": "2509.23143", "categories": ["cs.AI", "cs.LG", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2509.23143", "abs": "https://arxiv.org/abs/2509.23143", "authors": ["Charles L. Wang"], "title": "MathBode: Understanding LLM Reasoning with Dynamical Systems", "comment": null, "summary": "This paper presents MathBode, a dynamic diagnostic for mathematical reasoning\nin large language models (LLMs). Instead of one-shot accuracy, MathBode treats\neach parametric problem as a system: we drive a single parameter sinusoidally\nand fit first-harmonic responses of model outputs and exact solutions. This\nyields interpretable, frequency-resolved metrics -- gain (amplitude tracking)\nand phase (lag) -- that form Bode-style fingerprints. Across five closed-form\nfamilies (linear solve, ratio/saturation, compound interest, 2x2 linear\nsystems, similar triangles), the diagnostic surfaces systematic low-pass\nbehavior and growing phase lag that accuracy alone obscures. We compare several\nmodels against a symbolic baseline that calibrates the instrument ($G \\approx\n1$, $\\phi \\approx 0$). Results separate frontier from mid-tier models on\ndynamics, providing a compact, reproducible protocol that complements standard\nbenchmarks with actionable measurements of reasoning fidelity and consistency.\nWe open-source the dataset and code to enable further research and adoption.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86MathBode\uff0c\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u6570\u5b66\u63a8\u7406\u80fd\u529b\u7684\u52a8\u6001\u8bca\u65ad\u5de5\u5177\u3002\u4e0e\u4f20\u7edf\u7684\u5355\u6b21\u51c6\u786e\u7387\u8bc4\u4f30\u4e0d\u540c\uff0cMathBode\u5c06\u53c2\u6570\u5316\u95ee\u9898\u89c6\u4e3a\u4e00\u4e2a\u7cfb\u7edf\uff0c\u901a\u8fc7\u5bf9\u5355\u4e2a\u53c2\u6570\u8fdb\u884c\u6b63\u5f26\u9a71\u52a8\uff0c\u5e76\u62df\u5408\u6a21\u578b\u8f93\u51fa\u548c\u7cbe\u786e\u89e3\u7684\u4e00\u9636\u8c10\u6ce2\u54cd\u5e94\uff0c\u4ece\u800c\u5f97\u5230\u53ef\u89e3\u91ca\u7684\u3001\u9891\u7387\u76f8\u5173\u7684\u589e\u76ca\uff08\u5e45\u5ea6\u8ddf\u8e2a\uff09\u548c\u76f8\u4f4d\uff08\u6ede\u540e\uff09\u6307\u6807\uff0c\u5f62\u6210\u7c7b\u4f3cBode\u56fe\u7684\u201c\u6307\u7eb9\u201d\u3002\u8be5\u65b9\u6cd5\u63ed\u793a\u4e86LLM\u5728\u5904\u7406\u6570\u5b66\u95ee\u9898\u65f6\u666e\u904d\u5b58\u5728\u7684\u4f4e\u901a\u6ee4\u6ce2\u884c\u4e3a\u548c\u4e0d\u65ad\u589e\u52a0\u7684\u76f8\u4f4d\u6ede\u540e\uff0c\u8fd9\u4e9b\u52a8\u6001\u7279\u6027\u662f\u4ec5\u51ed\u51c6\u786e\u7387\u65e0\u6cd5\u6355\u6349\u7684\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0cMathBode\u80fd\u591f\u6709\u6548\u5730\u533a\u5206\u4e0d\u540c\u6a21\u578b\u5728\u52a8\u6001\u63a8\u7406\u80fd\u529b\u4e0a\u7684\u5dee\u5f02\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u7d27\u51d1\u3001\u53ef\u590d\u73b0\u7684\u8bc4\u4f30\u534f\u8bae\uff0c\u4ee5\u8865\u5145\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u63a8\u7406\u4fdd\u771f\u5ea6\u548c\u4e00\u81f4\u6027\u5ea6\u91cf\u3002\u7814\u7a76\u4eba\u5458\u5df2\u5f00\u6e90\u6570\u636e\u96c6\u548c\u4ee3\u7801\u4ee5\u4fc3\u8fdb\u672a\u6765\u7814\u7a76\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8bc4\u4f30\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u6700\u7ec8\u7684\u51c6\u786e\u7387\uff0c\u5ffd\u7565\u4e86\u6a21\u578b\u5728\u5904\u7406\u6570\u5b66\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u52a8\u6001\u7279\u6027\u3002\u8fd9\u79cd\u7247\u9762\u7684\u8bc4\u4f30\u65b9\u5f0f\u65e0\u6cd5\u63ed\u793a\u6a21\u578b\u63a8\u7406\u8fc7\u7a0b\u4e2d\u53ef\u80fd\u5b58\u5728\u7684\u7cfb\u7edf\u6027\u95ee\u9898\uff0c\u4f8b\u5982\u5bf9\u8f93\u5165\u53d8\u5316\u7684\u54cd\u5e94\u901f\u5ea6\u3001\u4fe1\u606f\u4f20\u9012\u7684\u5ef6\u8fdf\u7b49\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u5f00\u53d1\u4e00\u79cd\u80fd\u591f\u6df1\u5165\u63a2\u7a76LLM\u6570\u5b66\u63a8\u7406\u52a8\u6001\u884c\u4e3a\u7684\u8bca\u65ad\u5de5\u5177\uff0c\u4ee5\u66f4\u5168\u9762\u5730\u7406\u89e3\u548c\u6539\u8fdb\u6a21\u578b\u7684\u6027\u80fd\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMathBode\u7684\u52a8\u6001\u8bca\u65ad\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u5c06\u6570\u5b66\u95ee\u9898\u89c6\u4e3a\u4e00\u4e2a\u52a8\u6001\u7cfb\u7edf\uff0c\u901a\u8fc7\u5bf9\u8f93\u5165\u53c2\u6570\u8fdb\u884c\u6b63\u5f26\u4fe1\u53f7\u7684\u5468\u671f\u6027\u6270\u52a8\uff0c\u5e76\u5206\u6790\u6a21\u578b\u8f93\u51fa\u5bf9\u8fd9\u79cd\u6270\u52a8\u7684\u54cd\u5e94\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u7814\u7a76\u4eba\u5458\u6d4b\u91cf\u6a21\u578b\u8f93\u51fa\u7684\u4e00\u9636\u8c10\u6ce2\u54cd\u5e94\uff0c\u5305\u62ec\u589e\u76ca\uff08\u5e45\u5ea6\u8ddf\u8e2a\u80fd\u529b\uff09\u548c\u76f8\u4f4d\uff08\u54cd\u5e94\u6ede\u540e\uff09\uff0c\u4ee5\u6b64\u6765\u91cf\u5316\u6a21\u578b\u7684\u52a8\u6001\u884c\u4e3a\u3002\u901a\u8fc7\u5728\u4e0d\u540c\u53c2\u6570\u548c\u95ee\u9898\u7c7b\u578b\u4e0a\u8fdb\u884c\u6d4b\u8bd5\uff0cMathBode\u751f\u6210\u4e86\u7c7b\u4f3cBode\u56fe\u7684\u201c\u6307\u7eb9\u201d\uff0c\u7528\u4e8e\u8868\u5f81\u6a21\u578b\u7684\u63a8\u7406\u52a8\u6001\u3002\u7814\u7a76\u4eba\u5458\u4f7f\u7528\u4e86\u4e00\u4e2a\u7b26\u53f7\u57fa\u7ebf\u6a21\u578b\u6765\u6821\u51c6\u8be5\u8bca\u65ad\u5de5\u5177\u3002", "result": "\u901a\u8fc7\u5728\u4e94\u79cd\u4e0d\u540c\u7c7b\u578b\u7684\u5c01\u95ed\u5f62\u5f0f\u95ee\u9898\uff08\u7ebf\u6027\u6c42\u89e3\u3001\u6bd4\u4f8b/\u9971\u548c\u3001\u590d\u5229\u30012x2\u7ebf\u6027\u65b9\u7a0b\u7ec4\u3001\u76f8\u4f3c\u4e09\u89d2\u5f62\uff09\u4e0a\u7684\u5b9e\u9a8c\uff0cMathBode\u8bca\u65ad\u5de5\u5177\u63ed\u793a\u4e86LLM\u666e\u904d\u5b58\u5728\u7684\u4f4e\u901a\u6ee4\u6ce2\u884c\u4e3a\uff0c\u5373\u6a21\u578b\u5bf9\u5feb\u901f\u53d8\u5316\u7684\u8f93\u5165\u54cd\u5e94\u8f83\u6162\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u89c2\u5bdf\u5230\u6a21\u578b\u8f93\u51fa\u5b58\u5728\u4e0d\u65ad\u589e\u52a0\u7684\u76f8\u4f4d\u6ede\u540e\uff0c\u8868\u660e\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u6216\u591a\u6b65\u63a8\u7406\u65f6\uff0c\u5176\u8f93\u51fa\u4f1a\u843d\u540e\u4e8e\u7cbe\u786e\u89e3\u3002MathBode\u80fd\u591f\u533a\u5206\u4e0d\u540c\u6a21\u578b\u5728\u52a8\u6001\u63a8\u7406\u80fd\u529b\u4e0a\u7684\u5dee\u5f02\uff0c\u5c06\u524d\u6cbf\u6a21\u578b\u4e0e\u4e2d\u7b49\u6c34\u5e73\u6a21\u578b\u533a\u5206\u5f00\u6765\u3002\u76f8\u6bd4\u4e8e\u4f20\u7edf\u7684\u51c6\u786e\u7387\u6307\u6807\uff0c\u8fd9\u79cd\u52a8\u6001\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u7ec6\u81f4\u3001\u66f4\u5177\u4fe1\u606f\u91cf\u7684\u6a21\u578b\u6027\u80fd\u6d1e\u5bdf\u3002", "conclusion": "MathBode\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u52a8\u6001\u8bca\u65ad\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\uff0c\u5176\u6838\u5fc3\u8d21\u732e\u5728\u4e8e\u5f15\u5165\u4e86\u589e\u76ca\u548c\u76f8\u4f4d\u7684\u6982\u5ff5\u6765\u91cf\u5316\u6a21\u578b\u7684\u52a8\u6001\u54cd\u5e94\u7279\u6027\u3002\u8be5\u65b9\u6cd5\u63ed\u793a\u4e86LLM\u5728\u6570\u5b66\u63a8\u7406\u4e2d\u666e\u904d\u5b58\u5728\u7684\u4f4e\u901a\u6ee4\u6ce2\u548c\u76f8\u4f4d\u6ede\u540e\u73b0\u8c61\uff0c\u8fd9\u662f\u4f20\u7edf\u9759\u6001\u8bc4\u4f30\u65b9\u6cd5\u6240\u65e0\u6cd5\u5bdf\u89c9\u7684\u3002MathBode\u7684\u8bc4\u4f30\u7ed3\u679c\u80fd\u591f\u6709\u6548\u5730\u533a\u5206\u4e0d\u540c\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5e76\u4e3a\u6539\u8fdbLLM\u7684\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u53ef\u64cd\u4f5c\u7684\u89c1\u89e3\u3002\u867d\u7136\u8be5\u7814\u7a76\u5728\u591a\u4e2a\u95ee\u9898\u7c7b\u578b\u4e0a\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u4f46\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u6269\u5c55\u5230\u66f4\u5e7f\u6cdb\u7684\u6570\u5b66\u9886\u57df\uff0c\u5e76\u8fdb\u4e00\u6b65\u63a2\u7d22\u8fd9\u4e9b\u52a8\u6001\u7279\u6027\u4e0e\u6a21\u578b\u67b6\u6784\u3001\u8bad\u7ec3\u6570\u636e\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u8be5\u65b9\u6cd5\u5177\u6709\u666e\u9002\u6027\uff0c\u5e76\u4e14\u5df2\u5f00\u6e90\uff0c\u6709\u671b\u63a8\u52a8LLM\u6570\u5b66\u63a8\u7406\u7814\u7a76\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2410.20445", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2410.20445", "abs": "https://arxiv.org/abs/2410.20445", "authors": ["Yuwei Du", "Jie Feng", "Jie Zhao", "Yong Li"], "title": "TrajAgent: An LLM-Agent Framework for Trajectory Modeling via Large-and-Small Model Collaboration", "comment": "Accepted by NeurIPS 2025,\n  https://github.com/tsinghua-fib-lab/TrajAgent", "summary": "Trajectory modeling, which includes research on trajectory data pattern\nmining and future prediction, has widespread applications in areas such as life\nservices, urban transportation, and public administration. Numerous methods\nhave been proposed to address specific problems within trajectory modeling.\nHowever, the heterogeneity of data and the diversity of trajectory tasks make\neffective and reliable trajectory modeling an important yet highly challenging\nendeavor, even for domain experts. In this paper, we propose TrajAgent, an\nagent framework powered by large language models, designed to facilitate robust\nand efficient trajectory modeling through automation modeling. This framework\nleverages and optimizes diverse specialized models to address various\ntrajectory modeling tasks across different datasets effectively. In TrajAgent,\nwe first develop UniEnv, an execution environment with a unified data and model\ninterface, to support the execution and training of various models. Building on\nUniEnv, we introduce an agentic workflow designed for automatic trajectory\nmodeling across various trajectory tasks and data. Furthermore, we introduce\ncollaborative learning schema between LLM-based agents and small speciallized\nmodels, to enhance the performance of the whole framework effectively.\nExtensive experiments on five tasks using four real-world datasets demonstrate\nthe effectiveness of TrajAgent in automated trajectory modeling, achieving a\nperformance improvement of 2.38%-69.91% over baseline methods. The codes and\ndata can be accessed via https://github.com/tsinghua-fib-lab/TrajAgent.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTrajAgent\u7684\u6846\u67b6\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u81ea\u52a8\u5316\u8f68\u8ff9\u5efa\u6a21\u8fc7\u7a0b\u3002TrajAgent\u901a\u8fc7\u7edf\u4e00\u7684\u73af\u5883\uff08UniEnv\uff09\u6574\u5408\u591a\u79cd\u4e13\u4e1a\u6a21\u578b\uff0c\u5e76\u5f15\u5165LLM\u4e0e\u4e13\u4e1a\u6a21\u578b\u4e4b\u95f4\u7684\u534f\u4f5c\u5b66\u4e60\u673a\u5236\uff0c\u4ee5\u5e94\u5bf9\u6570\u636e\u5f02\u6784\u6027\u548c\u4efb\u52a1\u591a\u6837\u6027\u5e26\u6765\u7684\u6311\u6218\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cTrajAgent\u5728\u4e94\u4e2a\u4efb\u52a1\u548c\u56db\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u6027\u80fd\u63d0\u5347\u5e45\u5ea6\u4e3a2.38%-69.91%\u3002", "motivation": "\u8f68\u8ff9\u5efa\u6a21\u5728\u751f\u6d3b\u670d\u52a1\u3001\u57ce\u5e02\u4ea4\u901a\u548c\u516c\u5171\u7ba1\u7406\u7b49\u9886\u57df\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u6570\u636e\u5f02\u6784\u6027\u548c\u4efb\u52a1\u591a\u6837\u6027\u4f7f\u5f97\u6709\u6548\u7684\u8f68\u8ff9\u5efa\u6a21\u6210\u4e3a\u4e00\u9879\u91cd\u8981\u4e14\u6781\u5177\u6311\u6218\u6027\u7684\u4efb\u52a1\uff0c\u5373\u4f7f\u5bf9\u9886\u57df\u4e13\u5bb6\u4e5f\u662f\u5982\u6b64\u3002\u73b0\u6709\u7684\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u5f3a\u5927\u3001\u66f4\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7814\u7a76\u63d0\u51fa\u4e86TrajAgent\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u3002\u6838\u5fc3\u7ec4\u4ef6\u5305\u62ec\uff1a1. UniEnv\uff1a\u4e00\u4e2a\u63d0\u4f9b\u7edf\u4e00\u6570\u636e\u548c\u6a21\u578b\u63a5\u53e3\u7684\u6267\u884c\u73af\u5883\uff0c\u652f\u6301\u6a21\u578b\u6267\u884c\u548c\u8bad\u7ec3\u30022. Agentic Workflow\uff1a\u4e00\u4e2a\u4e3a\u81ea\u52a8\u5316\u8f68\u8ff9\u5efa\u6a21\u8bbe\u8ba1\u7684\u6d41\u7a0b\uff0c\u80fd\u591f\u5904\u7406\u5404\u79cd\u8f68\u8ff9\u4efb\u52a1\u548c\u6570\u636e\u30023. LLM-based Agents\u4e0eSpecialized Models\u7684\u534f\u4f5c\u5b66\u4e60\uff1a\u901a\u8fc7\u8fd9\u79cd\u673a\u5236\uff0c\u6846\u67b6\u80fd\u591f\u6709\u6548\u63d0\u5347\u6574\u4f53\u6027\u80fd\u3002\u5b9e\u9a8c\u5728\u4e94\u4e2a\u4efb\u52a1\u548c\u56db\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\uff0c\u4ee5\u9a8c\u8bc1TrajAgent\u7684\u6709\u6548\u6027\u3002", "result": "TrajAgent\u5728\u4e94\u4e2a\u8f68\u8ff9\u5efa\u6a21\u4efb\u52a1\u548c\u56db\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5176\u5728\u81ea\u52a8\u5316\u8f68\u8ff9\u5efa\u6a21\u65b9\u9762\u7684\u6709\u6548\u6027\u3002\u4e0e\u57fa\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0cTrajAgent\u7684\u6027\u80fd\u63d0\u5347\u5e45\u5ea6\u8fbe\u5230\u4e862.38%-69.91%\uff0c\u663e\u793a\u51fa\u663e\u8457\u7684\u4f18\u52bf\u3002", "conclusion": "TrajAgent\u6846\u67b6\u901a\u8fc7\u5229\u7528LLM\u548c\u521b\u65b0\u7684\u534f\u4f5c\u5b66\u4e60\u673a\u5236\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u81ea\u52a8\u5316\u8f68\u8ff9\u5efa\u6a21\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6570\u636e\u5f02\u6784\u6027\u548c\u4efb\u52a1\u591a\u6837\u6027\u5e26\u6765\u7684\u6311\u6218\u3002\u8be5\u6846\u67b6\u5728\u591a\u4e2a\u4efb\u52a1\u548c\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u4e3a\u8f68\u8ff9\u5efa\u6a21\u9886\u57df\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f3a\u5927\u4e14\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002\u672a\u6765\u7814\u7a76\u53ef\u8fdb\u4e00\u6b65\u63a2\u7d22\u8be5\u6846\u67b6\u5728\u66f4\u5e7f\u6cdb\u5e94\u7528\u573a\u666f\u4e2d\u7684\u6f5c\u529b\u4ee5\u53ca\u4e0e\u5176\u4ed6\u5148\u8fdb\u6a21\u578b\u7684\u878d\u5408\u3002"}}
{"id": "2509.26080", "categories": ["cs.AI", "stat.AP"], "pdf": "https://arxiv.org/pdf/2509.26080", "abs": "https://arxiv.org/abs/2509.26080", "authors": ["Emma Rose Madden"], "title": "Evaluating the Use of Large Language Models as Synthetic Social Agents in Social Science Research", "comment": null, "summary": "Large Language Models (LLMs) are being increasingly used as synthetic agents\nin social science, in applications ranging from augmenting survey responses to\npowering multi-agent simulations. This paper outlines cautions that should be\ntaken when interpreting LLM outputs and proposes a pragmatic reframing for the\nsocial sciences in which LLMs are used as high-capacity pattern matchers for\nquasi-predictive interpolation under explicit scope conditions and not as\nsubstitutes for probabilistic inference. Practical guardrails such as\nindependent draws, preregistered human baselines, reliability-aware validation,\nand subgroup calibration, are introduced so that researchers may engage in\nuseful prototyping and forecasting while avoiding category errors.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5efa\u8bae\u5728\u793e\u4f1a\u79d1\u5b66\u4e2d\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u65f6\u8981\u8c28\u614e\uff0c\u5c06\u5176\u89c6\u4e3a\u9ad8\u5bb9\u91cf\u6a21\u5f0f\u5339\u914d\u5668\uff0c\u7528\u4e8e\u51c6\u9884\u6d4b\u63d2\u503c\uff0c\u800c\u4e0d\u662f\u6982\u7387\u63a8\u7406\u7684\u66ff\u4ee3\u54c1\uff0c\u5e76\u63d0\u51fa\u4e86\u5b9e\u7528\u7684\u62a4\u680f\u63aa\u65bd\uff0c\u5982\u72ec\u7acb\u62bd\u6837\u3001\u9884\u6ce8\u518c\u7684\u4eba\u7c7b\u57fa\u7ebf\u3001\u53ef\u9760\u6027\u611f\u77e5\u9a8c\u8bc1\u548c\u5b50\u7fa4\u6821\u51c6\uff0c\u4ee5\u907f\u514d\u8303\u7574\u9519\u8bef\uff0c\u5b9e\u73b0\u6709\u7528\u7684\u539f\u578b\u8bbe\u8ba1\u548c\u9884\u6d4b\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u793e\u4f1a\u79d1\u5b66\u4e2d\u7684\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f8b\u5982\u5728\u589e\u5f3a\u8c03\u67e5\u54cd\u5e94\u548c\u9a71\u52a8\u591a\u4e3b\u4f53\u6a21\u62df\u65b9\u9762\uff0c\u7814\u7a76\u8005\u4eec\u9700\u8981\u7406\u89e3\u5982\u4f55\u6b63\u786e\u89e3\u91caLLM\u7684\u8f93\u51fa\u3002\u5ffd\u89c6LLM\u7684\u5c40\u9650\u6027\u53ef\u80fd\u5bfc\u81f4\u9519\u8bef\u7684\u7ed3\u8bba\uff0c\u56e0\u6b64\uff0c\u4e3aLLM\u5728\u793e\u4f1a\u79d1\u5b66\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u6e05\u6670\u7684\u6307\u5bfc\u548c\u5b9e\u8df5\u6846\u67b6\u81f3\u5173\u91cd\u8981\uff0c\u4ee5\u786e\u4fdd\u7814\u7a76\u7684\u4e25\u8c28\u6027\u548c\u6709\u6548\u6027\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u52a1\u5b9e\u7684\u91cd\u6784\u6846\u67b6\uff0c\u5efa\u8bae\u5728\u793e\u4f1a\u79d1\u5b66\u4e2d\u4f7f\u7528LLMs\u65f6\uff0c\u5e94\u5c06\u5176\u89c6\u4e3a\u9ad8\u5bb9\u91cf\u6a21\u5f0f\u5339\u914d\u5668\uff0c\u7528\u4e8e\u5728\u660e\u786e\u7684\u8303\u56f4\u6761\u4ef6\u4e0b\u8fdb\u884c\u51c6\u9884\u6d4b\u63d2\u503c\u3002\u7814\u7a76\u8005\u5e94\u907f\u514d\u5c06LLMs\u89c6\u4e3a\u6982\u7387\u63a8\u7406\u7684\u66ff\u4ee3\u54c1\u3002\u6b64\u5916\uff0c\u8bba\u6587\u8fd8\u5f15\u5165\u4e86\u5b9e\u7528\u7684\u62a4\u680f\u63aa\u65bd\uff0c\u5305\u62ec\u72ec\u7acb\u62bd\u6837\u3001\u9884\u6ce8\u518c\u7684\u4eba\u7c7b\u57fa\u7ebf\u3001\u53ef\u9760\u6027\u611f\u77e5\u9a8c\u8bc1\u548c\u5b50\u7fa4\u6821\u51c6\u3002", "result": "\u901a\u8fc7\u91c7\u7528\u6240\u63d0\u51fa\u7684\u6846\u67b6\u548c\u62a4\u680f\u63aa\u65bd\uff0c\u7814\u7a76\u8005\u53ef\u4ee5\u5728\u793e\u4f1a\u79d1\u5b66\u9886\u57df\u8fdb\u884c\u6709\u7528\u7684\u539f\u578b\u8bbe\u8ba1\u548c\u9884\u6d4b\u3002\u8fd9\u4e9b\u63aa\u65bd\u6709\u52a9\u4e8e\u907f\u514d\u5c06LLMs\u89c6\u4e3a\u80fd\u591f\u8fdb\u884c\u6982\u7387\u63a8\u7406\u7684\u5b9e\u4f53\uff0c\u4ece\u800c\u9632\u6b62\u8303\u7574\u9519\u8bef\uff0c\u5e76\u63d0\u9ad8\u7814\u7a76\u7ed3\u679c\u7684\u53ef\u9760\u6027\u3002", "conclusion": "\u5728\u793e\u4f1a\u79d1\u5b66\u7814\u7a76\u4e2d\uff0c\u5e94\u8c28\u614e\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\uff0c\u5e76\u5c06\u5176\u5b9a\u4f4d\u4e3a\u7528\u4e8e\u51c6\u9884\u6d4b\u63d2\u503c\u7684\u6a21\u5f0f\u5339\u914d\u5de5\u5177\uff0c\u800c\u975e\u6982\u7387\u63a8\u7406\u7684\u66ff\u4ee3\u54c1\u3002\u901a\u8fc7\u5b9e\u65bd\u72ec\u7acb\u62bd\u6837\u3001\u9884\u6ce8\u518c\u7684\u4eba\u7c7b\u57fa\u7ebf\u3001\u53ef\u9760\u6027\u611f\u77e5\u9a8c\u8bc1\u548c\u5b50\u7fa4\u6821\u51c6\u7b49\u62a4\u680f\u63aa\u65bd\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u5229\u7528LLMs\u8fdb\u884c\u539f\u578b\u8bbe\u8ba1\u548c\u9884\u6d4b\uff0c\u540c\u65f6\u907f\u514d\u6f5c\u5728\u7684\u8bef\u7528\u548c\u9519\u8bef\u89e3\u91ca\uff0c\u786e\u4fdd\u7814\u7a76\u7684\u51c6\u786e\u6027\u548c\u6709\u6548\u6027\u3002\u672a\u6765\u7684\u7814\u7a76\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63a2\u7d22\u8fd9\u4e9b\u62a4\u680f\u63aa\u65bd\u5728\u4e0d\u540c\u793e\u4f1a\u79d1\u5b66\u573a\u666f\u4e0b\u7684\u5177\u4f53\u5e94\u7528\u548c\u4f18\u5316\u3002"}}
{"id": "2411.19477", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2411.19477", "abs": "https://arxiv.org/abs/2411.19477", "authors": ["Yanxi Chen", "Xuchen Pan", "Yaliang Li", "Bolin Ding", "Jingren Zhou"], "title": "Provable Scaling Laws for the Test-Time Compute of Large Language Models", "comment": "NeurIPS 2025 camera-ready version", "summary": "We propose two simple, principled and practical algorithms that enjoy\nprovable scaling laws for the test-time compute of large language models\n(LLMs). The first one is a two-stage knockout-style algorithm: given an input\nproblem, it first generates multiple candidate solutions, and then aggregate\nthem via a knockout tournament for the final output. Assuming that the LLM can\ngenerate a correct solution with non-zero probability and do better than a\nrandom guess in comparing a pair of correct and incorrect solutions, we prove\ntheoretically that the failure probability of this algorithm decays to zero\nexponentially or by a power law (depending on the specific way of scaling) as\nits test-time compute grows. The second one is a two-stage league-style\nalgorithm, where each candidate is evaluated by its average win rate against\nmultiple opponents, rather than eliminated upon loss to a single opponent.\nUnder analogous but more robust assumptions, we prove that its failure\nprobability also decays to zero exponentially with more test-time compute. Both\nalgorithms require a black-box LLM and nothing else (e.g., no verifier or\nreward model) for a minimalistic implementation, which makes them appealing for\npractical applications and easy to adapt for different tasks. Through extensive\nexperiments with diverse models and datasets, we validate the proposed theories\nand demonstrate the outstanding scaling properties of both algorithms.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u7528\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u7b80\u5355\u3001\u6709\u539f\u5219\u4e14\u5b9e\u7528\u7684\u7b97\u6cd5\uff0c\u5b83\u4eec\u5177\u6709\u53ef\u8bc1\u660e\u7684\u6d4b\u8bd5\u65f6\u95f4\u8ba1\u7b97\u6269\u5c55\u5b9a\u5f8b\u3002\u7b2c\u4e00\u79cd\u662f\u4e24\u9636\u6bb5\u6dd8\u6c70\u8d5b\u7b97\u6cd5\uff1a\u4e3a\u7ed9\u5b9a\u8f93\u5165\u751f\u6210\u591a\u4e2a\u5019\u9009\u89e3\u51b3\u65b9\u6848\uff0c\u7136\u540e\u901a\u8fc7\u6dd8\u6c70\u8d5b\u8fdb\u884c\u805a\u5408\u3002\u7b2c\u4e8c\u79cd\u662f\u4e24\u9636\u6bb5\u8054\u8d5b\u7b97\u6cd5\uff1a\u6bcf\u4e2a\u5019\u9009\u65b9\u6848\u901a\u8fc7\u4e0e\u591a\u4e2a\u5bf9\u624b\u7684\u5e73\u5747\u80dc\u7387\u8fdb\u884c\u8bc4\u4f30\u3002\u8fd9\u4e24\u79cd\u7b97\u6cd5\u90fd\u53ea\u9700\u8981\u4e00\u4e2a\u9ed1\u76d2LLM\uff0c\u65e0\u9700\u5176\u4ed6\u5de5\u5177\uff0c\u6613\u4e8e\u5b9e\u73b0\u548c\u9002\u5e94\u4e0d\u540c\u4efb\u52a1\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u5e76\u5c55\u793a\u4e86\u7b97\u6cd5\u7684\u4f18\u8d8a\u6269\u5c55\u6027\u80fd\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5904\u7406\u590d\u6742\u4efb\u52a1\u65f6\uff0c\u5176\u6d4b\u8bd5\u65f6\u95f4\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\uff0c\u9650\u5236\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u3002\u5982\u4f55\u5728\u5927\u89c4\u6a21\u8ba1\u7b97\u4e0b\uff0c\u4fdd\u8bc1LLM\u7684\u8f93\u51fa\u8d28\u91cf\u5e76\u964d\u4f4e\u9519\u8bef\u7387\uff0c\u662f\u4e00\u4e2a\u91cd\u8981\u7684\u7814\u7a76\u95ee\u9898\u3002\u672c\u6587\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u80fd\u591f\u6709\u6548\u964d\u4f4eLLM\u6d4b\u8bd5\u9519\u8bef\u7387\uff0c\u5e76\u5177\u6709\u53ef\u8bc1\u660e\u7684\u6269\u5c55\u89c4\u5f8b\u7684\u7b97\u6cd5\uff0c\u4ee5\u89e3\u51b3\u8ba1\u7b97\u6210\u672c\u4e0e\u6a21\u578b\u6027\u80fd\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u7b97\u6cd5\uff1a\n1. **\u4e24\u9636\u6bb5\u6dd8\u6c70\u8d5b\u7b97\u6cd5**\uff1a\u9996\u5148\u751f\u6210\u591a\u4e2a\u5019\u9009\u89e3\u51b3\u65b9\u6848\uff0c\u7136\u540e\u901a\u8fc7\u7c7b\u4f3c\u6dd8\u6c70\u8d5b\u7684\u673a\u5236\u8fdb\u884c\u4e24\u4e24\u6bd4\u8f83\u548c\u6dd8\u6c70\uff0c\u6700\u7ec8\u9009\u51fa\u6700\u4f18\u89e3\u3002\n2. **\u4e24\u9636\u6bb5\u8054\u8d5b\u7b97\u6cd5**\uff1a\u540c\u6837\u751f\u6210\u591a\u4e2a\u5019\u9009\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u6bcf\u4e2a\u65b9\u6848\u4f1a\u4e0e\u5176\u4ed6\u591a\u4e2a\u65b9\u6848\u8fdb\u884c\u591a\u8f6e\u6bd4\u8f83\uff08\u7c7b\u4f3c\u8054\u8d5b\uff09\uff0c\u6839\u636e\u5e73\u5747\u80dc\u7387\u8fdb\u884c\u6392\u540d\uff0c\u9009\u62e9\u80dc\u7387\u6700\u9ad8\u7684\u65b9\u6848\u3002\n\n\u8fd9\u4e24\u79cd\u7b97\u6cd5\u90fd\u5047\u8bbeLLM\u80fd\u591f\u4ee5\u975e\u96f6\u6982\u7387\u751f\u6210\u6b63\u786e\u7b54\u6848\uff0c\u5e76\u4e14\u5728\u6bd4\u8f83\u4e24\u4e2a\u89e3\u51b3\u65b9\u6848\u65f6\u4f18\u4e8e\u968f\u673a\u731c\u6d4b\u3002\u7b97\u6cd5\u7684\u5b9e\u73b0\u4ec5\u9700\u4e00\u4e2a\u9ed1\u76d2LLM\uff0c\u65e0\u9700\u989d\u5916\u7684\u9a8c\u8bc1\u5668\u6216\u5956\u52b1\u6a21\u578b\u3002\u901a\u8fc7\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0c\u5728\u4e0d\u540c\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u7684\u6709\u6548\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u4e24\u79cd\u7b97\u6cd5\u5728\u589e\u52a0\u6d4b\u8bd5\u65f6\u95f4\u8ba1\u7b97\u91cf\u65f6\uff0c\u9519\u8bef\u7387\u80fd\u591f\u4ee5\u6307\u6570\u7ea7\u6216\u5e42\u5f8b\u7ea7\uff08\u53d6\u51b3\u4e8e\u5177\u4f53\u6269\u5c55\u65b9\u5f0f\uff09\u7684\u901f\u5ea6\u8870\u51cf\u3002\u8fd9\u8bc1\u660e\u4e86\u7b97\u6cd5\u5177\u6709\u4f18\u8d8a\u7684\u53ef\u6269\u5c55\u6027\u3002\u7b97\u6cd5\u7684\u5b9e\u73b0\u7b80\u5355\uff0c\u5e76\u4e14\u5728\u5404\u79cd\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e0a\u90fd\u8868\u73b0\u51fa\u4e86\u826f\u597d\u7684\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u7406\u8bba\u5206\u6790\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u4e24\u79cd\u65b0\u9896\u7684LLM\u7b97\u6cd5\uff08\u6dd8\u6c70\u8d5b\u548c\u8054\u8d5b\uff09\u80fd\u591f\u6709\u6548\u964d\u4f4e\u6d4b\u8bd5\u65f6\u95f4\u9519\u8bef\u7387\uff0c\u5e76\u5177\u6709\u53ef\u8bc1\u660e\u7684\u6269\u5c55\u89c4\u5f8b\u3002\u8fd9\u4e9b\u7b97\u6cd5\u4ec5\u4f9d\u8d56\u4e8e\u9ed1\u76d2LLM\uff0c\u6613\u4e8e\u5b9e\u73b0\u548c\u5e94\u7528\u3002\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u548c\u4f18\u8d8a\u7684\u53ef\u6269\u5c55\u6027\uff0c\u4e3a\u5728\u8ba1\u7b97\u8d44\u6e90\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u63d0\u5347LLM\u6027\u80fd\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u63a2\u7d22\u66f4\u590d\u6742\u7684\u6bd4\u8f83\u673a\u5236\u548c\u6269\u5c55\u7b56\u7565\u3002"}}
{"id": "2412.12679", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2412.12679", "abs": "https://arxiv.org/abs/2412.12679", "authors": ["Yupei Li", "Manuel Milling", "Lucia Specia", "Bj\u00f6rn W. Schuller"], "title": "Discourse Features Enhance Detection of Document-Level Machine-Generated Content", "comment": "Accepted by IJCNN 2025", "summary": "The availability of high-quality APIs for Large Language Models (LLMs) has\nfacilitated the widespread creation of Machine-Generated Content (MGC), posing\nchallenges such as academic plagiarism and the spread of misinformation.\nExisting MGC detectors often focus solely on surface-level information,\noverlooking implicit and structural features. This makes them susceptible to\ndeception by surface-level sentence patterns, particularly for longer texts and\nin texts that have been subsequently paraphrased. To overcome these challenges,\nwe introduce novel methodologies and datasets. Besides the publicly available\ndataset Plagbench, we developed the paraphrased Long-Form Question and Answer\n(paraLFQA) and paraphrased Writing Prompts (paraWP) datasets using GPT and\nDIPPER, a discourse paraphrasing tool, by extending artifacts from their\noriginal versions. To better capture the structure of longer texts at document\nlevel, we propose DTransformer, a model that integrates discourse analysis\nthrough PDTB preprocessing to encode structural features. It results in\nsubstantial performance gains across both datasets - 15.5% absolute improvement\non paraLFQA, 4% absolute improvement on paraWP, and 1.5% absolute improvemene\non M4 compared to SOTA approaches. The data and code are available at:\nhttps://github.com/myxp-lyp/Discourse-Features-Enhance-Detection-of-Document-Level-Machine-Generated-Content.git.", "AI": {"tldr": "\u9274\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09API\u7684\u666e\u53ca\uff0c\u673a\u5668\u751f\u6210\u5185\u5bb9\uff08MGC\uff09\u7684\u6fc0\u589e\u5e26\u6765\u4e86\u5b66\u672f\u527d\u7a83\u548c\u865a\u5047\u4fe1\u606f\u4f20\u64ad\u7b49\u6311\u6218\u3002\u73b0\u6709MGC\u68c0\u6d4b\u5668\u4e3b\u8981\u5173\u6ce8\u8868\u9762\u4fe1\u606f\uff0c\u5ffd\u7565\u4e86\u9690\u5f0f\u548c\u7ed3\u6784\u5316\u7279\u5f81\uff0c\u5bb9\u6613\u88ab\u8868\u9762\u53e5\u5b50\u6a21\u5f0f\u6b3a\u9a97\uff0c\u5c24\u5176\u662f\u5728\u957f\u6587\u672c\u548c\u7ecf\u8fc7\u91ca\u4e49\u7684\u6587\u672c\u4e2d\u3002\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u65b0\u7684\u65b9\u6cd5\u548c\u6570\u636e\u96c6\uff0c\u5305\u62ec\u91ca\u4e49\u540e\u7684\u957f\u95ee\u7b54\uff08paraLFQA\uff09\u548c\u91ca\u4e49\u540e\u7684\u5199\u4f5c\u63d0\u793a\uff08paraWP\uff09\u6570\u636e\u96c6\uff0c\u5e76\u5f15\u5165\u4e86DTransformer\u6a21\u578b\u3002\u8be5\u6a21\u578b\u901a\u8fc7\u7ed3\u5408\u8bdd\u8bed\u5206\u6790\u548cPDTB\u9884\u5904\u7406\u6765\u7f16\u7801\u957f\u6587\u672c\u7684\u7ed3\u6784\u7279\u5f81\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cDTransformer\u5728paraLFQA\u3001paraWP\u548cM4\u6570\u636e\u96c6\u4e0a\u5206\u522b\u53d6\u5f97\u4e8615.5%\u30014%\u548c1.5%\u7684\u7edd\u5bf9\u6027\u80fd\u63d0\u5347\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09API\u7684\u5e7f\u6cdb\u53ef\u7528\u6027\u5bfc\u81f4\u4e86\u673a\u5668\u751f\u6210\u5185\u5bb9\uff08MGC\uff09\u7684\u6fc0\u589e\uff0c\u8fd9\u5e26\u6765\u4e86\u4e25\u91cd\u7684\u6311\u6218\uff0c\u4f8b\u5982\u5b66\u672f\u527d\u7a83\u548c\u865a\u5047\u4fe1\u606f\u7684\u4f20\u64ad\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684MGC\u68c0\u6d4b\u65b9\u6cd5\u5f80\u5f80\u53ea\u5173\u6ce8\u6587\u672c\u7684\u8868\u9762\u7279\u5f81\uff0c\u5ffd\u7565\u4e86\u6df1\u5c42\u7684\u9690\u5f0f\u548c\u7ed3\u6784\u5316\u4fe1\u606f\u3002\u8fd9\u79cd\u65b9\u6cd5\u4f7f\u5f97\u5b83\u4eec\u5bb9\u6613\u88ab\u8868\u9762\u4e0a\u7684\u53e5\u5b50\u6a21\u5f0f\u6240\u6b3a\u9a97\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u957f\u6587\u672c\u6216\u7ecf\u8fc7\u91ca\u4e49\u7684\u6587\u672c\u65f6\uff0c\u68c0\u6d4b\u6548\u679c\u5927\u6253\u6298\u6263\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u5f00\u53d1\u66f4\u5f3a\u5927\u7684MGC\u68c0\u6d4b\u65b9\u6cd5\uff0c\u4ee5\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e24\u79cd\u65b0\u7684\u6570\u636e\u96c6\uff1a\u91ca\u4e49\u540e\u7684\u957f\u95ee\u7b54\uff08paraLFQA\uff09\u548c\u91ca\u4e49\u540e\u7684\u5199\u4f5c\u63d0\u793a\uff08paraWP\uff09\u3002\u8fd9\u4e9b\u6570\u636e\u96c6\u662f\u901a\u8fc7\u5bf9\u73b0\u6709\u6570\u636e\u96c6\u8fdb\u884c\u6269\u5c55\u548c\u91ca\u4e49\u800c\u521b\u5efa\u7684\uff0c\u4f7f\u7528\u4e86GPT\u548cDIPPER\uff08\u4e00\u79cd\u8bdd\u8bed\u91ca\u4e49\u5de5\u5177\uff09\u3002\u6b64\u5916\uff0c\u4e3a\u4e86\u66f4\u597d\u5730\u6355\u6349\u957f\u6587\u672c\u5728\u6587\u6863\u5c42\u9762\u7684\u7ed3\u6784\uff0c\u7814\u7a76\u8005\u4eec\u63d0\u51fa\u4e86DTransformer\u6a21\u578b\u3002\u8be5\u6a21\u578b\u7684\u6838\u5fc3\u5728\u4e8e\u6574\u5408\u8bdd\u8bed\u5206\u6790\uff0c\u5e76\u5229\u7528PDTB\uff08Penn Discourse Treebank\uff09\u9884\u5904\u7406\u6765\u7f16\u7801\u6587\u672c\u7684\u7ed3\u6784\u7279\u5f81\u3002\u8fd9\u79cd\u65b9\u6cd5\u65e8\u5728\u8d85\u8d8a\u8868\u9762\u7279\u5f81\u7684\u9650\u5236\uff0c\u66f4\u6df1\u5165\u5730\u7406\u89e3\u6587\u672c\u7684\u5185\u5728\u7ed3\u6784\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\uff0cDTransformer\u6a21\u578b\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002\u5177\u4f53\u800c\u8a00\uff0c\u5728paraLFQA\u6570\u636e\u96c6\u4e0a\uff0c\u6027\u80fd\u63d0\u5347\u4e8615.5%\uff1b\u5728paraWP\u6570\u636e\u96c6\u4e0a\uff0c\u6027\u80fd\u63d0\u5347\u4e864%\uff1b\u5728M4\u6570\u636e\u96c6\u4e0a\uff0c\u6027\u80fd\u4e5f\u63d0\u5347\u4e861.5%\u3002\u8fd9\u4e9b\u6539\u8fdb\u76f8\u5bf9\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\uff08SOTA\uff09\u7684\u65b9\u6cd5\u6765\u8bf4\u662f\u76f8\u5f53\u53ef\u89c2\u7684\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u6a21\u578b\u5728\u68c0\u6d4b\u6587\u6863\u7ea7\u673a\u5668\u751f\u6210\u5185\u5bb9\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u6210\u529f\u5f00\u53d1\u4e86\u65b0\u7684\u6570\u636e\u96c6\uff08paraLFQA\u548cparaWP\uff09\u548c\u4e00\u79cd\u540d\u4e3aDTransformer\u7684\u65b0\u6a21\u578b\uff0c\u901a\u8fc7\u6574\u5408\u8bdd\u8bed\u5206\u6790\u548cPDTB\u9884\u5904\u7406\u6765\u6355\u6349\u957f\u6587\u672c\u7684\u7ed3\u6784\u7279\u5f81\uff0c\u4ece\u800c\u6709\u6548\u63d0\u5347\u4e86\u673a\u5668\u751f\u6210\u5185\u5bb9\uff08MGC\uff09\u7684\u68c0\u6d4b\u6027\u80fd\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cDTransformer\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u5747\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002\u8fd9\u9879\u5de5\u4f5c\u4e3a\u89e3\u51b3MGC\u5e26\u6765\u7684\u5b66\u672f\u527d\u7a83\u548c\u865a\u5047\u4fe1\u606f\u4f20\u64ad\u7b49\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63a2\u7d22\u66f4\u590d\u6742\u7684\u8bdd\u8bed\u7ed3\u6784\u7279\u5f81\uff0c\u5e76\u9488\u5bf9\u4e0d\u540c\u7c7b\u578b\u7684MGC\u8fdb\u884c\u6a21\u578b\u4f18\u5316\u3002"}}
{"id": "2510.16724", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.16724", "abs": "https://arxiv.org/abs/2510.16724", "authors": ["Minhua Lin", "Zongyu Wu", "Zhichao Xu", "Hui Liu", "Xianfeng Tang", "Qi He", "Charu Aggarwal", "Hui Liu", "Xiang Zhang", "Suhang Wang"], "title": "A Comprehensive Survey on Reinforcement Learning-based Agentic Search: Foundations, Roles, Optimizations, Evaluations, and Applications", "comment": "38 pages, 4 figures, 7 tables", "summary": "The advent of large language models (LLMs) has transformed information access\nand reasoning through open-ended natural language interaction. However, LLMs\nremain limited by static knowledge, factual hallucinations, and the inability\nto retrieve real-time or domain-specific information. Retrieval-Augmented\nGeneration (RAG) mitigates these issues by grounding model outputs in external\nevidence, but traditional RAG pipelines are often single turn and heuristic,\nlacking adaptive control over retrieval and reasoning. Recent advances in\nagentic search address these limitations by enabling LLMs to plan, retrieve,\nand reflect through multi-step interaction with search environments. Within\nthis paradigm, reinforcement learning (RL) offers a powerful mechanism for\nadaptive and self-improving search behavior. This survey provides the first\ncomprehensive overview of \\emph{RL-based agentic search}, organizing the\nemerging field along three complementary dimensions: (i) What RL is for\n(functional roles), (ii) How RL is used (optimization strategies), and (iii)\nWhere RL is applied (scope of optimization). We summarize representative\nmethods, evaluation protocols, and applications, and discuss open challenges\nand future directions toward building reliable and scalable RL driven agentic\nsearch systems. We hope this survey will inspire future research on the\nintegration of RL and agentic search. Our repository is available at\nhttps://github.com/ventr1c/Awesome-RL-based-Agentic-Search-Papers.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4fe1\u606f\u83b7\u53d6\u548c\u63a8\u7406\u65b9\u9762\u53d6\u5f97\u4e86\u5de8\u5927\u8fdb\u5c55\uff0c\u4f46\u5b83\u4eec\u53d7\u9650\u4e8e\u9759\u6001\u77e5\u8bc6\u3001\u4e8b\u5b9e\u9519\u8bef\u4ee5\u53ca\u65e0\u6cd5\u83b7\u53d6\u5b9e\u65f6\u6216\u9886\u57df\u7279\u5b9a\u4fe1\u606f\u3002\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u901a\u8fc7\u5f15\u5165\u5916\u90e8\u8bc1\u636e\u6765\u7f13\u89e3\u8fd9\u4e9b\u95ee\u9898\uff0c\u4f46\u4f20\u7edfRAG\u6d41\u7a0b\u901a\u5e38\u662f\u5355\u8f6e\u4e14\u542f\u53d1\u5f0f\u7684\uff0c\u7f3a\u4e4f\u5bf9\u68c0\u7d22\u548c\u63a8\u7406\u7684\u81ea\u9002\u5e94\u63a7\u5236\u3002\u57fa\u4e8e\u667a\u80fd\u4f53\u641c\u7d22\u7684\u6700\u65b0\u8fdb\u5c55\u901a\u8fc7\u5b9e\u73b0LLMs\u5728\u641c\u7d22\u73af\u5883\u4e2d\u8fdb\u884c\u591a\u6b65\u4ea4\u4e92\u7684\u89c4\u5212\u3001\u68c0\u7d22\u548c\u53cd\u601d\uff0c\u6765\u89e3\u51b3\u8fd9\u4e9b\u5c40\u9650\u6027\u3002\u8be5\u8c03\u67e5\u5168\u9762\u6982\u8ff0\u4e86\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u7684\u667a\u80fd\u4f53\u641c\u7d22\uff0c\u5e76\u4ece\u4e09\u4e2a\u7ef4\u5ea6\u7ec4\u7ec7\u4e86\u8be5\u65b0\u5174\u9886\u57df\uff1a\uff08i\uff09RL\u7684\u529f\u80fd\u89d2\u8272\uff0c\uff08ii\uff09RL\u7684\u4f18\u5316\u7b56\u7565\uff0c\u4ee5\u53ca\uff08iii\uff09RL\u7684\u5e94\u7528\u8303\u56f4\u3002\u6587\u7ae0\u603b\u7ed3\u4e86\u4ee3\u8868\u6027\u7684\u65b9\u6cd5\u3001\u8bc4\u4f30\u534f\u8bae\u548c\u5e94\u7528\uff0c\u5e76\u8ba8\u8bba\u4e86\u5728\u6784\u5efa\u53ef\u9760\u548c\u53ef\u6269\u5c55\u7684RL\u9a71\u52a8\u7684\u667a\u80fd\u4f53\u641c\u7d22\u7cfb\u7edf\u65b9\u9762\u7684\u5f00\u653e\u6027\u6311\u6218\u548c\u672a\u6765\u65b9\u5411\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4fe1\u606f\u8bbf\u95ee\u548c\u63a8\u7406\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u6210\u5c31\uff0c\u4f46\u5b83\u4eec\u4ecd\u7136\u9762\u4e34\u7740\u77e5\u8bc6\u9759\u6001\u3001\u4e8b\u5b9e\u5e7b\u89c9\u4ee5\u53ca\u65e0\u6cd5\u68c0\u7d22\u5b9e\u65f6\u6216\u7279\u5b9a\u9886\u57df\u4fe1\u606f\u7b49\u6311\u6218\u3002\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u901a\u8fc7\u6574\u5408\u5916\u90e8\u77e5\u8bc6\u6765\u90e8\u5206\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u7136\u800c\uff0c\u4f20\u7edf\u7684RAG\u65b9\u6cd5\u5f80\u5f80\u662f\u5355\u8f6e\u4e14\u57fa\u4e8e\u542f\u53d1\u5f0f\u7684\uff0c\u7f3a\u4e4f\u5bf9\u68c0\u7d22\u548c\u63a8\u7406\u8fc7\u7a0b\u7684\u81ea\u9002\u5e94\u63a7\u5236\u80fd\u529b\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u63a2\u7d22\u66f4\u5148\u8fdb\u7684\u65b9\u6cd5\u6765\u589e\u5f3aLLMs\u7684\u77e5\u8bc6\u83b7\u53d6\u548c\u63a8\u7406\u80fd\u529b\uff0c\u4f7f\u5176\u80fd\u591f\u66f4\u6709\u6548\u5730\u5229\u7528\u5916\u90e8\u4fe1\u606f\u5e76\u8fdb\u884c\u81ea\u9002\u5e94\u7684\u641c\u7d22\u3002", "method": "\u672c\u8c03\u67e5\u5168\u9762\u6982\u8ff0\u4e86\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u7684\u667a\u80fd\u4f53\u641c\u7d22\uff08Agentic Search\uff09\u3002\u8be5\u7814\u7a76\u5c06\u65b0\u5174\u7684RL\u9a71\u52a8\u7684\u667a\u80fd\u4f53\u641c\u7d22\u9886\u57df\uff0c\u6cbf\u7740\u4e09\u4e2a\u4e92\u8865\u7684\u7ef4\u5ea6\u8fdb\u884c\u7ec4\u7ec7\uff1a1. RL\u7684\u529f\u80fd\u89d2\u8272\uff08\u5373RL\u88ab\u7528\u4e8e\u89e3\u51b3\u4ec0\u4e48\u95ee\u9898\uff09\uff1b2. RL\u7684\u4f18\u5316\u7b56\u7565\uff08\u5373\u5982\u4f55\u5229\u7528RL\u6765\u4f18\u5316\u641c\u7d22\u8fc7\u7a0b\uff09\uff1b3. RL\u7684\u5e94\u7528\u8303\u56f4\uff08\u5373RL\u5728\u641c\u7d22\u8fc7\u7a0b\u7684\u54ea\u4e9b\u90e8\u5206\u88ab\u5e94\u7528\uff09\u3002\u7814\u7a76\u4eba\u5458\u603b\u7ed3\u4e86\u8be5\u9886\u57df\u5185\u5177\u6709\u4ee3\u8868\u6027\u7684\u65b9\u6cd5\u3001\u8bc4\u4f30\u534f\u8bae\u548c\u5e94\u7528\u5b9e\u4f8b\uff0c\u5e76\u63a2\u8ba8\u4e86\u5728\u6784\u5efa\u53ef\u9760\u548c\u53ef\u6269\u5c55\u7684RL\u9a71\u52a8\u7684\u667a\u80fd\u4f53\u641c\u7d22\u7cfb\u7edf\u65b9\u9762\u6240\u9762\u4e34\u7684\u6311\u6218\u548c\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u3002", "result": "\u8be5\u8c03\u67e5\u7cfb\u7edf\u5730\u68b3\u7406\u4e86\u57fa\u4e8eRL\u7684\u667a\u80fd\u4f53\u641c\u7d22\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u5e76\u4ece\u529f\u80fd\u89d2\u8272\u3001\u4f18\u5316\u7b56\u7565\u548c\u5e94\u7528\u8303\u56f4\u4e09\u4e2a\u7ef4\u5ea6\u5bf9\u5176\u8fdb\u884c\u4e86\u5206\u7c7b\u548c\u7ec4\u7ec7\u3002\u6587\u7ae0\u603b\u7ed3\u4e86\u8be5\u9886\u57df\u5185\u7684\u4ee3\u8868\u6027\u65b9\u6cd5\u3001\u8bc4\u4f30\u534f\u8bae\u548c\u5b9e\u9645\u5e94\u7528\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u89c6\u89d2\u6765\u7406\u89e3\u8be5\u9886\u57df\u3002\u901a\u8fc7\u5bf9\u73b0\u6709\u7814\u7a76\u7684\u603b\u7ed3\u548c\u5206\u6790\uff0c\u8be5\u8c03\u67e5\u63ed\u793a\u4e86RL\u5728\u63d0\u5347\u667a\u80fd\u4f53\u641c\u7d22\u80fd\u529b\u65b9\u9762\u7684\u5de8\u5927\u6f5c\u529b\uff0c\u540c\u65f6\u4e5f\u6307\u51fa\u4e86\u5f53\u524d\u5b58\u5728\u7684\u6311\u6218\uff0c\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9d\u8d35\u7684\u53c2\u8003\u3002", "conclusion": "\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u7684\u667a\u80fd\u4f53\u641c\u7d22\u662f\u589e\u5f3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4fe1\u606f\u83b7\u53d6\u548c\u63a8\u7406\u80fd\u529b\u7684\u4e00\u4e2a\u6709\u524d\u9014\u7684\u65b9\u5411\u3002\u901a\u8fc7\u5c06RL\u7684\u81ea\u9002\u5e94\u548c\u81ea\u6539\u8fdb\u80fd\u529b\u5e94\u7528\u4e8e\u667a\u80fd\u4f53\u641c\u7d22\u7684\u89c4\u5212\u3001\u68c0\u7d22\u548c\u53cd\u601d\u8fc7\u7a0b\uff0c\u53ef\u4ee5\u514b\u670d\u4f20\u7edfRAG\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002\u672c\u8c03\u67e5\u5168\u9762\u6982\u8ff0\u4e86\u8be5\u9886\u57df\uff0c\u5e76\u4ece\u529f\u80fd\u89d2\u8272\u3001\u4f18\u5316\u7b56\u7565\u548c\u5e94\u7528\u8303\u56f4\u4e09\u4e2a\u7ef4\u5ea6\u8fdb\u884c\u4e86\u7ec4\u7ec7\uff0c\u603b\u7ed3\u4e86\u73b0\u6709\u65b9\u6cd5\u548c\u5e94\u7528\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u3002\u8be5\u9886\u57df\u7684\u672a\u6765\u53d1\u5c55\u5c06\u96c6\u4e2d\u5728\u6784\u5efa\u66f4\u53ef\u9760\u3001\u66f4\u53ef\u6269\u5c55\u7684RL\u9a71\u52a8\u7684\u667a\u80fd\u4f53\u641c\u7d22\u7cfb\u7edf\uff0c\u4ee5\u5e94\u5bf9\u65e5\u76ca\u589e\u957f\u7684\u4fe1\u606f\u9700\u6c42\u548c\u590d\u6742\u6027\u3002"}}
{"id": "2412.15189", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2412.15189", "abs": "https://arxiv.org/abs/2412.15189", "authors": ["Daniel Russo", "Stefano Menini", "Jacopo Staiano", "Marco Guerini"], "title": "Face the Facts! Evaluating RAG-based Fact-checking Pipelines in Realistic Settings", "comment": "Code and data at https://github.com/drusso98/face-the-facts -\n  Accepted for publication at INLG 2025", "summary": "Natural Language Processing and Generation systems have recently shown the\npotential to complement and streamline the costly and time-consuming job of\nprofessional fact-checkers. In this work, we lift several constraints of\ncurrent state-of-the-art pipelines for automated fact-checking based on the\nRetrieval-Augmented Generation (RAG) paradigm. Our goal is to benchmark, under\nmore realistic scenarios, RAG-based methods for the generation of verdicts -\ni.e., short texts discussing the veracity of a claim - evaluating them on\nstylistically complex claims and heterogeneous, yet reliable, knowledge bases.\nOur findings show a complex landscape, where, for example, LLM-based retrievers\noutperform other retrieval techniques, though they still struggle with\nheterogeneous knowledge bases; larger models excel in verdict faithfulness,\nwhile smaller models provide better context adherence, with human evaluations\nfavouring zero-shot and one-shot approaches for informativeness, and fine-tuned\nmodels for emotional alignment.", "AI": {"tldr": "\u672c\u7814\u7a76\u65e8\u5728\u66f4\u771f\u5b9e\u5730\u8bc4\u4f30\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7684\u81ea\u52a8\u4e8b\u5b9e\u6838\u67e5\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u751f\u6210\u5224\u65ad\uff08\u5373\u8ba8\u8bba\u58f0\u660e\u771f\u5b9e\u6027\u7684\u7b80\u77ed\u6587\u672c\uff09\u65b9\u9762\u3002\u7814\u7a76\u8005\u653e\u5bbd\u4e86\u73b0\u6709RAG\u6d41\u6c34\u7ebf\u7684\u4e00\u4e9b\u9650\u5236\uff0c\u5e76\u5728\u98ce\u683c\u590d\u6742\u58f0\u660e\u548c\u5f02\u6784\u4f46\u53ef\u9760\u7684\u77e5\u8bc6\u5e93\u4e0a\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u68c0\u7d22\u5668\u4f18\u4e8e\u5176\u4ed6\u68c0\u7d22\u6280\u672f\uff0c\u4f46\u5728\u5904\u7406\u5f02\u6784\u77e5\u8bc6\u5e93\u65f6\u4ecd\u5b58\u5728\u56f0\u96be\uff1b\u8f83\u5927\u7684\u6a21\u578b\u5728\u5224\u65ad\u5fe0\u5b9e\u5ea6\u65b9\u9762\u8868\u73b0\u66f4\u597d\uff0c\u800c\u8f83\u5c0f\u7684\u6a21\u578b\u5728\u4e0a\u4e0b\u6587\u9075\u5faa\u65b9\u9762\u8868\u73b0\u66f4\u4f73\uff1b\u4eba\u7c7b\u8bc4\u4f30\u663e\u793a\uff0c\u96f6\u6837\u672c\u548c\u5355\u6837\u672c\u65b9\u6cd5\u5728\u4fe1\u606f\u91cf\u65b9\u9762\u8868\u73b0\u66f4\u597d\uff0c\u800c\u5fae\u8c03\u6a21\u578b\u5728\u60c5\u611f\u4e00\u81f4\u6027\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u4e8b\u5b9e\u6838\u67e5\u5de5\u4f5c\u6210\u672c\u9ad8\u6602\u4e14\u8017\u65f6\uff0c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u548c\u751f\u6210\u7cfb\u7edf\uff08\u5982RAG\uff09\u6709\u6f5c\u529b\u8f85\u52a9\u8fd9\u4e00\u5de5\u4f5c\u3002\u7136\u800c\uff0c\u5f53\u524d\u57fa\u4e8eRAG\u7684\u81ea\u52a8\u4e8b\u5b9e\u6838\u67e5\u65b9\u6cd5\u5728\u66f4\u73b0\u5b9e\u7684\u573a\u666f\u4e0b\uff08\u5982\u98ce\u683c\u590d\u6742\u7684\u58f0\u660e\u548c\u5f02\u6784\u77e5\u8bc6\u5e93\uff09\u7684\u8bc4\u4f30\u4ecd\u6709\u5f85\u6df1\u5165\u7814\u7a76\u3002\u672c\u7814\u7a76\u65e8\u5728\u5f25\u8865\u8fd9\u4e00\u4e0d\u8db3\uff0c\u901a\u8fc7\u5728\u66f4\u8d34\u8fd1\u5b9e\u9645\u7684\u573a\u666f\u4e0b\u5bf9RAG\u65b9\u6cd5\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4e3a\u6539\u8fdb\u81ea\u52a8\u4e8b\u5b9e\u6838\u67e5\u7cfb\u7edf\u63d0\u4f9b\u6307\u5bfc\u3002", "method": "\u672c\u7814\u7a76\u653e\u5bbd\u4e86\u73b0\u6709\u57fa\u4e8eRAG\u7684\u81ea\u52a8\u4e8b\u5b9e\u6838\u67e5\u6d41\u6c34\u7ebf\u7684\u4e00\u4e9b\u9650\u5236\uff0c\u5e76\u5728\u98ce\u683c\u590d\u6742\u7684\u58f0\u660e\u548c\u5f02\u6784\u4f46\u53ef\u9760\u7684\u77e5\u8bc6\u5e93\u4e0a\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\u3002\u7814\u7a76\u8bc4\u4f30\u4e86\u4e0d\u540c\u68c0\u7d22\u6280\u672f\uff08\u5305\u62ec\u57fa\u4e8eLLM\u7684\u68c0\u7d22\u5668\uff09\u548c\u4e0d\u540c\u6a21\u578b\u89c4\u6a21\uff08\u5927\u6a21\u578b\u548c\u5c0f\u6a21\u578b\uff09\u5728\u751f\u6210\u5224\u65ad\u65b9\u9762\u7684\u8868\u73b0\u3002\u540c\u65f6\uff0c\u4e5f\u5bf9\u6bd4\u4e86\u96f6\u6837\u672c\u3001\u5355\u6837\u672c\u548c\u5fae\u8c03\u6a21\u578b\u5728\u4fe1\u606f\u91cf\u548c\u60c5\u611f\u4e00\u81f4\u6027\u65b9\u9762\u7684\u4eba\u7c7b\u8bc4\u4f30\u7ed3\u679c\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u57fa\u4e8eLLM\u7684\u68c0\u7d22\u5668\u5728\u68c0\u7d22\u65b9\u9762\u4f18\u4e8e\u5176\u4ed6\u6280\u672f\uff0c\u4f46\u5728\u5904\u7406\u5f02\u6784\u77e5\u8bc6\u5e93\u65f6\u4ecd\u9047\u5230\u6311\u6218\u3002\u5728\u751f\u6210\u5224\u65ad\u65b9\u9762\uff0c\u8f83\u5927\u7684\u6a21\u578b\u5728\u5fe0\u5b9e\u5ea6\uff08\u5224\u65ad\u5185\u5bb9\u4e0e\u4e8b\u5b9e\u7684\u4e00\u81f4\u6027\uff09\u4e0a\u8868\u73b0\u66f4\u4f18\uff0c\u800c\u8f83\u5c0f\u7684\u6a21\u578b\u5728\u4e0a\u4e0b\u6587\u9075\u5faa\uff08\u5224\u65ad\u662f\u5426\u8d34\u5408\u539f\u59cb\u58f0\u660e\u7684\u8bed\u5883\uff09\u4e0a\u8868\u73b0\u66f4\u597d\u3002\u4eba\u7c7b\u8bc4\u4f30\u663e\u793a\uff0c\u96f6\u6837\u672c\u548c\u5355\u6837\u672c\u65b9\u6cd5\u5728\u63d0\u4f9b\u4fe1\u606f\u65b9\u9762\u66f4\u53d7\u9752\u7750\uff0c\u800c\u5fae\u8c03\u6a21\u578b\u5219\u5728\u60c5\u611f\u4e00\u81f4\u6027\u65b9\u9762\u8868\u73b0\u66f4\u4f73\u3002", "conclusion": "\u672c\u7814\u7a76\u63ed\u793a\u4e86\u5728\u66f4\u73b0\u5b9e\u7684\u573a\u666f\u4e0b\u8bc4\u4f30RAG\u57fa\u4e8b\u5b9e\u6838\u67e5\u65b9\u6cd5\u7684\u590d\u6742\u6027\u3002\u867d\u7136LLM\u68c0\u7d22\u5668\u548c\u5927\u578b\u6a21\u578b\u5728\u67d0\u4e9b\u65b9\u9762\u8868\u73b0\u51fa\u4f18\u52bf\uff0c\u4f46\u5728\u5904\u7406\u5f02\u6784\u77e5\u8bc6\u5e93\u548c\u5e73\u8861\u5224\u65ad\u5fe0\u5b9e\u5ea6\u4e0e\u4e0a\u4e0b\u6587\u9075\u5faa\u65b9\u9762\u4ecd\u9700\u6539\u8fdb\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63a2\u7d22\u5982\u4f55\u4f18\u5316\u68c0\u7d22\u7b56\u7565\u4ee5\u9002\u5e94\u5f02\u6784\u77e5\u8bc6\u5e93\uff0c\u4ee5\u53ca\u5982\u4f55\u5728\u4e0d\u540c\u5e94\u7528\u573a\u666f\u4e0b\u5e73\u8861\u6a21\u578b\u5927\u5c0f\u3001\u5fe0\u5b9e\u5ea6\u548c\u4e0a\u4e0b\u6587\u9075\u5faa\uff0c\u5e76\u4f18\u5316\u96f6\u6837\u672c/\u5355\u6837\u672c\u4e0e\u5fae\u8c03\u65b9\u6cd5\u7684\u9009\u62e9\uff0c\u4ee5\u6ee1\u8db3\u4e0d\u540c\u7684\u8bc4\u4f30\u6807\u51c6\uff08\u5982\u4fe1\u606f\u91cf\u548c\u60c5\u611f\u4e00\u81f4\u6027\uff09\u3002"}}
{"id": "2504.06560", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2504.06560", "abs": "https://arxiv.org/abs/2504.06560", "authors": ["Lanrui Wang", "Mingyu Zheng", "Hongyin Tang", "Zheng Lin", "Yanan Cao", "Jingang Wang", "Xunliang Cai", "Weiping Wang"], "title": "NeedleInATable: Exploring Long-Context Capability of Large Language Models towards Long-Structured Tables", "comment": "Accepted by NeurIPS 2025", "summary": "Processing structured tabular data, particularly large and lengthy tables,\nconstitutes a fundamental yet challenging task for large language models\n(LLMs). However, existing long-context benchmarks like Needle-in-a-Haystack\nprimarily focus on unstructured text, neglecting the challenge of diverse\nstructured tables. Meanwhile, previous tabular benchmarks mainly consider\ndownstream tasks that require high-level reasoning abilities, and overlook\nmodels' underlying fine-grained perception of individual table cells, which is\ncrucial for practical and robust LLM-based table applications. To address this\ngap, we introduce \\textsc{NeedleInATable} (NIAT), a new long-context tabular\nbenchmark that treats each table cell as a ``needle'' and requires models to\nextract the target cell based on cell locations or lookup questions. Our\ncomprehensive evaluation of various LLMs and multimodal LLMs reveals a\nsubstantial performance gap between popular downstream tabular tasks and the\nsimpler NIAT task, suggesting that they may rely on dataset-specific\ncorrelations or shortcuts to obtain better benchmark results but lack truly\nrobust long-context understanding towards structured tables. Furthermore, we\ndemonstrate that using synthesized NIAT training data can effectively improve\nperformance on both NIAT task and downstream tabular tasks, which validates the\nimportance of NIAT capability for LLMs' genuine table understanding ability.", "AI": {"tldr": "\u9488\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5904\u7406\u7ed3\u6784\u5316\u8868\u683c\u6570\u636e\u65b9\u9762\u7684\u6311\u6218\uff0c\u7279\u522b\u662f\u957f\u4e0a\u4e0b\u6587\u8868\u683c\uff0c\u73b0\u6709\u7684\u957f\u4e0a\u4e0b\u6587\u57fa\u51c6\u6d4b\u8bd5\uff08\u5982 Needle-in-a-Haystack\uff09\u4e3b\u8981\u5173\u6ce8\u975e\u7ed3\u6784\u5316\u6587\u672c\uff0c\u5ffd\u7565\u4e86\u8868\u683c\u6570\u636e\u7684\u591a\u6837\u6027\u3002\u540c\u65f6\uff0c\u4ee5\u5f80\u7684\u8868\u683c\u57fa\u51c6\u6d4b\u8bd5\u4fa7\u91cd\u4e8e\u9700\u8981\u9ad8\u7ea7\u63a8\u7406\u80fd\u529b\u7684\u4e0b\u6e38\u4efb\u52a1\uff0c\u5ffd\u89c6\u4e86\u6a21\u578b\u5bf9\u5355\u4e2a\u8868\u683c\u5355\u5143\u683c\u7684\u7ec6\u7c92\u5ea6\u611f\u77e5\u80fd\u529b\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u7814\u7a76\u8005\u63d0\u51fa\u4e86 NeedleInATable (NIAT) \u57fa\u51c6\u6d4b\u8bd5\uff0c\u5c06\u6bcf\u4e2a\u8868\u683c\u5355\u5143\u683c\u89c6\u4e3a\u201c\u9488\u201d\uff0c\u8981\u6c42\u6a21\u578b\u6839\u636e\u5355\u5143\u683c\u4f4d\u7f6e\u6216\u67e5\u627e\u95ee\u9898\u63d0\u53d6\u76ee\u6807\u5355\u5143\u683c\u3002\u901a\u8fc7\u5bf9\u591a\u79cd LLMs \u548c\u591a\u6a21\u6001 LLMs \u7684\u8bc4\u4f30\uff0c\u53d1\u73b0\u5b83\u4eec\u5728 NIAT \u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u4e0e\u6d41\u884c\u7684\u4e0b\u6e38\u8868\u683c\u4efb\u52a1\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u8868\u660e\u73b0\u6709\u6a21\u578b\u53ef\u80fd\u4f9d\u8d56\u6570\u636e\u96c6\u7279\u5b9a\u7684\u5173\u8054\u6216\u6377\u5f84\u6765\u83b7\u5f97\u9ad8\u5206\uff0c\u800c\u975e\u771f\u6b63\u5177\u5907\u5bf9\u7ed3\u6784\u5316\u8868\u683c\u7684\u9c81\u68d2\u957f\u4e0a\u4e0b\u6587\u7406\u89e3\u80fd\u529b\u3002\u6b64\u5916\uff0c\u4f7f\u7528\u5408\u6210\u7684 NIAT \u8bad\u7ec3\u6570\u636e\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u6a21\u578b\u5728 NIAT \u4efb\u52a1\u548c\u4e0b\u6e38\u8868\u683c\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u9a8c\u8bc1\u4e86 NIAT \u80fd\u529b\u5bf9\u4e8e LLMs \u7406\u89e3\u8868\u683c\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u957f\u4e0a\u4e0b\u6587\u57fa\u51c6\u6d4b\u8bd5\uff08\u5982 Needle-in-a-Haystack\uff09\u4e3b\u8981\u5173\u6ce8\u975e\u7ed3\u6784\u5316\u6587\u672c\uff0c\u5ffd\u7565\u4e86\u5927\u578b\u3001\u957f\u683c\u5f0f\u7ed3\u6784\u5316\u8868\u683c\u7684\u5904\u7406\u8fd9\u4e00\u5173\u952e\u6311\u6218\u3002\u73b0\u6709\u7684\u8868\u683c\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u4fa7\u91cd\u4e8e\u9700\u8981\u9ad8\u7ea7\u63a8\u7406\u80fd\u529b\u7684\u4e0b\u6e38\u4efb\u52a1\uff0c\u800c\u5ffd\u89c6\u4e86\u6a21\u578b\u5bf9\u8868\u683c\u5355\u5143\u683c\u7684\u7ec6\u7c92\u5ea6\u611f\u77e5\u80fd\u529b\uff0c\u8fd9\u79cd\u80fd\u529b\u5bf9\u4e8e\u5b9e\u9645\u548c\u9c81\u68d2\u7684 LLM \u8868\u683c\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u4e13\u95e8\u8bc4\u4f30 LLM \u5728\u957f\u4e0a\u4e0b\u6587\u8868\u683c\u573a\u666f\u4e0b\u7ec6\u7c92\u5ea6\u7406\u89e3\u80fd\u529b\u7684\u65b0\u57fa\u51c6\u3002", "method": "\u63d0\u51fa NeedleInATable (NIAT) \u8fd9\u4e00\u65b0\u7684\u957f\u4e0a\u4e0b\u6587\u8868\u683c\u57fa\u51c6\u6d4b\u8bd5\u3002NIAT \u5c06\u8868\u683c\u4e2d\u7684\u6bcf\u4e2a\u5355\u5143\u683c\u89c6\u4e3a\u201c\u9488\u201d\uff0c\u8981\u6c42\u6a21\u578b\u6839\u636e\u5355\u5143\u683c\u7684\u4f4d\u7f6e\u6216\u57fa\u4e8e\u5355\u5143\u683c\u5185\u5bb9\u7684\u67e5\u8be2\u6765\u63d0\u53d6\u76ee\u6807\u5355\u5143\u683c\u3002\u5bf9\u591a\u79cd LLMs \u548c\u591a\u6a21\u6001 LLMs \u8fdb\u884c\u4e86\u5168\u9762\u8bc4\u4f30\u3002\u7814\u7a76\u4e86\u4f7f\u7528\u5408\u6210 NIAT \u8bad\u7ec3\u6570\u636e\u6765\u63d0\u9ad8\u6a21\u578b\u5728 NIAT \u4efb\u52a1\u548c\u4e0b\u6e38\u8868\u683c\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0c\u5728 NIAT \u4efb\u52a1\u4e0a\u7684\u6a21\u578b\u6027\u80fd\u4e0e\u6d41\u884c\u7684\u4e0b\u6e38\u8868\u683c\u4efb\u52a1\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u7684\u6027\u80fd\u5dee\u8ddd\u3002\u8fd9\u8868\u660e\uff0c\u8bb8\u591a LLMs \u5728\u5904\u7406\u4e0b\u6e38\u8868\u683c\u4efb\u52a1\u65f6\u53ef\u80fd\u4f9d\u8d56\u4e8e\u6570\u636e\u96c6\u7279\u5b9a\u7684\u5173\u8054\u6216\u201c\u6377\u5f84\u201d\uff0c\u800c\u975e\u771f\u6b63\u5177\u5907\u5bf9\u7ed3\u6784\u5316\u957f\u4e0a\u4e0b\u6587\u8868\u683c\u7684\u9c81\u68d2\u7406\u89e3\u80fd\u529b\u3002\u7814\u7a76\u8fd8\u53d1\u73b0\uff0c\u4f7f\u7528\u5408\u6210\u7684 NIAT \u8bad\u7ec3\u6570\u636e\u80fd\u591f\u6709\u6548\u63d0\u5347\u6a21\u578b\u5728 NIAT \u4efb\u52a1\u548c\u4e0b\u6e38\u8868\u683c\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u8bc1\u660e\u4e86 NIAT \u80fd\u529b\u5bf9\u4e8e LLMs \u771f\u6b63\u7406\u89e3\u8868\u683c\u7684\u91cd\u8981\u6027\u3002", "conclusion": "NIAT \u57fa\u51c6\u6d4b\u8bd5\u63ed\u793a\u4e86\u5f53\u524d LLMs \u5728\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u7ed3\u6784\u5316\u8868\u683c\u65b9\u9762\u7684\u663e\u8457\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5b83\u4eec\u5bf9\u7ec6\u7c92\u5ea6\u5355\u5143\u683c\u7684\u611f\u77e5\u80fd\u529b\u3002\u73b0\u6709\u7684\u4e0b\u6e38\u8868\u683c\u4efb\u52a1\u8bc4\u4f30\u53ef\u80fd\u65e0\u6cd5\u5145\u5206\u53cd\u6620\u6a21\u578b\u5728\u771f\u5b9e\u4e16\u754c\u8868\u683c\u5e94\u7528\u4e2d\u7684\u9c81\u68d2\u6027\u3002\u901a\u8fc7\u5408\u6210 NIAT \u8bad\u7ec3\u6570\u636e\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u6a21\u578b\u5728\u8fd9\u65b9\u9762\u7684\u80fd\u529b\uff0c\u5f3a\u8c03\u4e86\u4e13\u95e8\u8bad\u7ec3\u6a21\u578b\u8fdb\u884c\u7ec6\u7c92\u5ea6\u8868\u683c\u7406\u89e3\u7684\u5fc5\u8981\u6027\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u7ee7\u7eed\u6269\u5c55 NIAT \u7684\u89c4\u6a21\u548c\u591a\u6837\u6027\uff0c\u5e76\u63a2\u7d22\u66f4\u5148\u8fdb\u7684\u6a21\u578b\u67b6\u6784\u548c\u8bad\u7ec3\u7b56\u7565\u6765\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\u3002"}}
{"id": "2504.19467", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2504.19467", "abs": "https://arxiv.org/abs/2504.19467", "authors": ["Jiageng Wu", "Bowen Gu", "Ren Zhou", "Kevin Xie", "Doug Snyder", "Yixing Jiang", "Valentina Carducci", "Richard Wyss", "Rishi J Desai", "Emily Alsentzer", "Leo Anthony Celi", "Adam Rodman", "Sebastian Schneeweiss", "Jonathan H. Chen", "Santiago Romero-Brufau", "Kueiyu Joshua Lin", "Jie Yang"], "title": "BRIDGE: Benchmarking Large Language Models for Understanding Real-world Clinical Practice Text", "comment": null, "summary": "Large language models (LLMs) hold great promise for medical applications and\nare evolving rapidly, with new models being released at an accelerated pace.\nHowever, benchmarking on large-scale real-world data such as electronic health\nrecords (EHRs) is critical, as clinical decisions are directly informed by\nthese sources, yet current evaluations remain limited. Most existing benchmarks\nrely on medical exam-style questions or PubMed-derived text, failing to capture\nthe complexity of real-world clinical data. Others focus narrowly on specific\napplication scenarios, limiting their generalizability across broader clinical\nuse. To address this gap, we present BRIDGE, a comprehensive multilingual\nbenchmark comprising 87 tasks sourced from real-world clinical data sources\nacross nine languages. It covers eight major task types spanning the entire\ncontinuum of patient care across six clinical stages and 20 representative\napplications, including triage and referral, consultation, information\nextraction, diagnosis, prognosis, and billing coding, and involves 14 clinical\nspecialties. We systematically evaluated 95 LLMs (including DeepSeek-R1,\nGPT-4o, Gemini series, and Qwen3 series) under various inference strategies.\nOur results reveal substantial performance variation across model sizes,\nlanguages, natural language processing tasks, and clinical specialties.\nNotably, we demonstrate that open-source LLMs can achieve performance\ncomparable to proprietary models, while medically fine-tuned LLMs based on\nolder architectures often underperform versus updated general-purpose models.\nThe BRIDGE and its corresponding leaderboard serve as a foundational resource\nand a unique reference for the development and evaluation of new LLMs in\nreal-world clinical text understanding.\n  The BRIDGE leaderboard:\nhttps://huggingface.co/spaces/YLab-Open/BRIDGE-Medical-Leaderboard", "AI": {"tldr": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u533b\u7597\u9886\u57df\u7684\u5e94\u7528\u524d\u666f\u5e7f\u9614\uff0c\u4f46\u5bf9\u5176\u5728\u771f\u5b9e\u4e16\u754c\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHRs\uff09\u7b49\u5927\u89c4\u6a21\u4e34\u5e8a\u6570\u636e\u4e0a\u7684\u8bc4\u4f30\u4ecd\u7136\u6709\u9650\u3002\u73b0\u6709\u7684\u57fa\u51c6\u6d4b\u8bd5\u672a\u80fd\u5145\u5206\u53cd\u6620\u4e34\u5e8a\u51b3\u7b56\u7684\u590d\u6742\u6027\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u63d0\u51fa\u4e86BRIDGE\uff0c\u4e00\u4e2a\u5305\u542b87\u4e2a\u4efb\u52a1\u3001\u8986\u76d69\u79cd\u8bed\u8a00\u30018\u79cd\u4efb\u52a1\u7c7b\u578b\u30016\u4e2a\u4e34\u5e8a\u9636\u6bb5\u300120\u4e2a\u5e94\u7528\u573a\u666f\u548c14\u4e2a\u4e34\u5e8a\u4e13\u4e1a\u7684\u7efc\u5408\u6027\u591a\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u3002\u6211\u4eec\u8bc4\u4f30\u4e8695\u4e2aLLMs\uff0c\u7ed3\u679c\u663e\u793a\u6a21\u578b\u5728\u4e0d\u540c\u89c4\u6a21\u3001\u8bed\u8a00\u3001\u4efb\u52a1\u548c\u4e34\u5e8a\u4e13\u4e1a\u4e0a\u7684\u8868\u73b0\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u5f00\u6e90\u6a21\u578b\u53ef\u4ee5\u5ab2\u7f8e\u95ed\u6e90\u6a21\u578b\uff0c\u800c\u57fa\u4e8e\u65e7\u67b6\u6784\u7684\u533b\u5b66\u5fae\u8c03\u6a21\u578b\u6709\u65f6\u4e0d\u5982\u66f4\u65b0\u7684\u901a\u7528\u6a21\u578b\u3002BRIDGE\u53ca\u5176\u6392\u884c\u699c\u5c06\u4e3a\u5f00\u53d1\u548c\u8bc4\u4f30\u4e34\u5e8a\u6587\u672c\u7406\u89e3LLMs\u63d0\u4f9b\u91cd\u8981\u8d44\u6e90\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u533b\u7597\u9886\u57df\u7684\u5e94\u7528\u6f5c\u529b\u5de8\u5927\uff0c\u4f46\u5f53\u524d\u7684\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\u3002\u5927\u591a\u6570\u73b0\u6709\u7684\u57fa\u51c6\u6d4b\u8bd5\u4f9d\u8d56\u4e8e\u533b\u5b66\u8003\u8bd5\u98ce\u683c\u7684\u95ee\u9898\u6216\u4ecePubMed\u63d0\u53d6\u7684\u6587\u672c\uff0c\u672a\u80fd\u6355\u6349\u771f\u5b9e\u4e16\u754c\u4e34\u5e8a\u6570\u636e\uff08\u5982\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55EHRs\uff09\u7684\u590d\u6742\u6027\u548c\u591a\u6837\u6027\u3002\u6b64\u5916\uff0c\u4e00\u4e9b\u8bc4\u4f30\u4ec5\u9650\u4e8e\u7279\u5b9a\u5e94\u7528\u573a\u666f\uff0c\u7f3a\u4e4f\u5e7f\u6cdb\u7684\u4e34\u5e8a\u9002\u7528\u6027\u3002\u56e0\u6b64\uff0c\u8feb\u5207\u9700\u8981\u4e00\u4e2a\u5168\u9762\u3001\u5927\u89c4\u6a21\u7684\u57fa\u51c6\u6d4b\u8bd5\u6765\u51c6\u786e\u8bc4\u4f30LLMs\u5728\u771f\u5b9e\u4e34\u5e8a\u73af\u5883\u4e2d\u7684\u8868\u73b0\uff0c\u4ee5\u6307\u5bfc\u6a21\u578b\u7684\u5f00\u53d1\u548c\u4f18\u5316\u3002", "method": "\u6211\u4eec\u6784\u5efa\u4e86\u4e00\u4e2a\u540d\u4e3aBRIDGE \u7684\u591a\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5b83\u5305\u542b 87 \u4e2a\u4efb\u52a1\uff0c\u8fd9\u4e9b\u4efb\u52a1\u6765\u6e90\u4e8e\u771f\u5b9e\u4e16\u754c\u7684\u4e34\u5e8a\u6570\u636e\uff0c\u8986\u76d6\u4e5d\u79cd\u8bed\u8a00\u3002\u8be5\u57fa\u51c6\u6d4b\u8bd5\u6db5\u76d6\u4e86\u516b\u79cd\u4e3b\u8981\u7684\u4efb\u52a1\u7c7b\u578b\uff0c\u5305\u62ec\u5206\u8bca\u8f6c\u8bca\u3001\u54a8\u8be2\u3001\u4fe1\u606f\u63d0\u53d6\u3001\u8bca\u65ad\u3001\u9884\u540e\u548c\u8ba1\u8d39\u7f16\u7801\u7b49\uff0c\u8fd9\u4e9b\u4efb\u52a1\u8d2f\u7a7f\u4e86\u60a3\u8005\u62a4\u7406\u7684\u5168\u8fc7\u7a0b\uff0c\u6d89\u53ca\u516d\u4e2a\u4e34\u5e8a\u9636\u6bb5\u548c\u4e8c\u5341\u4e2a\u4ee3\u8868\u6027\u5e94\u7528\u3002\u6b64\u5916\uff0c\u57fa\u51c6\u6d4b\u8bd5\u8fd8\u8986\u76d6\u4e86\u5341\u56db\u4e2a\u4e34\u5e8a\u4e13\u4e1a\u3002\u6211\u4eec\u5728\u6b64\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7cfb\u7edf\u6027\u5730\u8bc4\u4f30\u4e86\u5305\u62ec DeepSeek-R1\u3001GPT-4o\u3001Gemini \u7cfb\u5217\u548c Qwen3 \u7cfb\u5217\u5728\u5185\u7684 95 \u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5e76\u91c7\u7528\u4e86\u591a\u79cd\u63a8\u7406\u7b56\u7565\u3002", "result": "\u5728\u5bf9 95 \u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8bc4\u4f30\u4e2d\uff0c\u6211\u4eec\u89c2\u5bdf\u5230\u6a21\u578b\u5728\u4e0d\u540c\u5c3a\u5bf8\u3001\u8bed\u8a00\u3001\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u4ee5\u53ca\u4e34\u5e8a\u4e13\u4e1a\u4e0a\u7684\u8868\u73b0\u5b58\u5728\u663e\u8457\u7684\u6027\u80fd\u5dee\u5f02\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u4e00\u4e9b\u5f00\u6e90 LLMs \u5728\u6027\u80fd\u4e0a\u53ef\u4ee5\u4e0e\u95ed\u6e90\u6a21\u578b\u76f8\u5ab2\u7f8e\u3002\u6709\u8da3\u7684\u662f\uff0c\u6211\u4eec\u53d1\u73b0\u57fa\u4e8e\u8f83\u65e7\u6a21\u578b\u67b6\u6784\u3001\u7ecf\u8fc7\u533b\u5b66\u9886\u57df\u4e13\u95e8\u5fae\u8c03\u7684\u6a21\u578b\uff0c\u5176\u6027\u80fd\u5f80\u5f80\u4e0d\u5982\u66f4\u65b0\u7684\u901a\u7528\u6a21\u578b\u3002", "conclusion": "BRIDGE \u57fa\u51c6\u6d4b\u8bd5\u7684\u6784\u5efa\u548c\u8bc4\u4f30\u7ed3\u679c\u4e3a\u7406\u89e3\u548c\u6539\u8fdb\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u771f\u5b9e\u4e34\u5e8a\u6587\u672c\u5904\u7406\u80fd\u529b\u65b9\u9762\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u89c1\u89e3\u3002\u8be5\u57fa\u51c6\u6d4b\u8bd5\u53ca\u5176\u5728\u7ebf\u6392\u884c\u699c\uff08https://huggingface.co/spaces/YLab-Open/BRIDGE-Medical-Leaderboard\uff09\u4e3a\u5f00\u53d1\u548c\u8bc4\u4f30\u65b0\u5174\u7684\u4e34\u5e8a\u6587\u672c\u7406\u89e3 LLMs \u63d0\u4f9b\u4e86\u4e00\u4e2a\u57fa\u7840\u6027\u8d44\u6e90\u548c\u72ec\u7279\u7684\u53c2\u8003\u70b9\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u5229\u7528 BRIDGE \u6765\u63a8\u52a8 LLMs \u5728\u5b9e\u9645\u533b\u7597\u5e94\u7528\u4e2d\u7684\u53d1\u5c55\u3002"}}
{"id": "2505.14617", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2505.14617", "abs": "https://arxiv.org/abs/2505.14617", "authors": ["Sahar Abdelnabi", "Ahmed Salem"], "title": "The Hawthorne Effect in Reasoning Models: Evaluating and Steering Test Awareness", "comment": "NeurIPS 2025 (Spotlight). Code is available at:\n  https://github.com/microsoft/Test_Awareness_Steering", "summary": "Reasoning-focused LLMs sometimes alter their behavior when they detect that\nthey are being evaluated, which can lead them to optimize for test-passing\nperformance or to comply more readily with harmful prompts if real-world\nconsequences appear absent. We present the first quantitative study of how such\n\"test awareness\" impacts model behavior, particularly its performance on\nsafety-related tasks. We introduce a white-box probing framework that (i)\nlinearly identifies awareness-related activations and (ii) steers models toward\nor away from test awareness while monitoring downstream performance. We apply\nour method to different state-of-the-art open-weight reasoning LLMs across both\nrealistic and hypothetical tasks (denoting tests or simulations). Our results\ndemonstrate that test awareness significantly impacts safety alignment (such as\ncompliance with harmful requests and conforming to stereotypes) with effects\nvarying in both magnitude and direction across models. By providing control\nover this latent effect, our work aims to provide a stress-test mechanism and\nincrease trust in how we perform safety evaluations.", "AI": {"tldr": "\u7814\u7a76\u9996\u6b21\u91cf\u5316\u4e86\u201c\u6d4b\u8bd5\u610f\u8bc6\u201d\u5bf9LLM\u5b89\u5168\u5bf9\u9f50\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u767d\u76d2\u63a2\u6d4b\u6846\u67b6\uff0c\u53ef\u4ee5\u901a\u8fc7\u63a7\u5236\u6a21\u578b\u5bf9\u6d4b\u8bd5\u7684\u610f\u8bc6\u6765\u7f13\u89e3\u8d1f\u9762\u5f71\u54cd\uff0c\u63d0\u9ad8\u6a21\u578b\u8bc4\u4f30\u7684\u53ef\u9760\u6027\u3002", "motivation": "LLM\u5728\u88ab\u8bc4\u4f30\u65f6\u53ef\u80fd\u6539\u53d8\u884c\u4e3a\uff0c\u4f18\u5316\u6d4b\u8bd5\u8868\u73b0\u6216\u66f4\u5bb9\u6613\u88ab\u8bf1\u5bfc\u4ea7\u751f\u6709\u5bb3\u8f93\u51fa\u3002\u8fd9\u79cd\u201c\u6d4b\u8bd5\u610f\u8bc6\u201d\u5bf9\u6a21\u578b\u5b89\u5168\u5bf9\u9f50\u7684\u5f71\u54cd\u5c1a\u4e0d\u660e\u786e\uff0c\u9700\u8981\u91cf\u5316\u7814\u7a76\u6765\u7406\u89e3\u548c\u63a7\u5236\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u767d\u76d2\u63a2\u6d4b\u6846\u67b6\uff0c\u80fd\u591f\u8bc6\u522b\u4e0e\u6d4b\u8bd5\u610f\u8bc6\u76f8\u5173\u7684\u6fc0\u6d3b\uff0c\u5e76\u5f15\u5bfc\u6a21\u578b\u4ea7\u751f\u6216\u907f\u514d\u6d4b\u8bd5\u610f\u8bc6\u3002\u8be5\u6846\u67b6\u5e94\u7528\u4e8e\u591a\u79cd\u5148\u8fdb\u7684\u5f00\u653e\u6743\u91cd\u63a8\u7406LLM\uff0c\u5e76\u5728\u73b0\u5b9e\u548c\u5047\u8bbe\u4efb\u52a1\u4e2d\u8fdb\u884c\u4e86\u6d4b\u8bd5\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u6d4b\u8bd5\u610f\u8bc6\u663e\u8457\u5f71\u54cd\u6a21\u578b\u7684\u5b89\u5168\u5bf9\u9f50\uff0c\u5305\u62ec\u5bf9\u6709\u5bb3\u8bf7\u6c42\u7684\u670d\u4ece\u548c\u5bf9\u523b\u677f\u5370\u8c61\u7684\u9075\u4ece\u3002\u8fd9\u79cd\u5f71\u54cd\u5728\u4e0d\u540c\u6a21\u578b\u4e0a\u7684\u8868\u73b0\u5404\u5f02\uff0c\u5176\u5f71\u54cd\u7684\u5927\u5c0f\u548c\u65b9\u5411\u4e5f\u5b58\u5728\u5dee\u5f02\u3002", "conclusion": "\u7814\u7a76\u9996\u6b21\u91cf\u5316\u4e86\u201c\u6d4b\u8bd5\u610f\u8bc6\u201d\u5bf9LLM\u5b89\u5168\u5bf9\u9f50\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u79cd\u63a7\u5236\u8be5\u6548\u5e94\u7684\u65b9\u6cd5\u3002\u8fd9\u6709\u52a9\u4e8e\u66f4\u597d\u5730\u8fdb\u884c\u6a21\u578b\u5b89\u5168\u8bc4\u4f30\uff0c\u589e\u5f3a\u8bc4\u4f30\u7684\u53ef\u9760\u6027\uff0c\u5e76\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u65b9\u5411\u3002"}}
{"id": "2505.17100", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2505.17100", "abs": "https://arxiv.org/abs/2505.17100", "authors": ["Haoyan Yang", "Runxue Bao", "Cao Xiao", "Jun Ma", "Parminder Bhatia", "Shangqian Gao", "Taha Kass-Hout"], "title": "Any Large Language Model Can Be a Reliable Judge: Debiasing with a Reasoning-based Bias Detector", "comment": "Accepted at NeurIPS 2025 (Camera-Ready Version)", "summary": "LLM-as-a-Judge has emerged as a promising tool for automatically evaluating\ngenerated outputs, but its reliability is often undermined by potential biases\nin judgment. Existing efforts to mitigate these biases face key limitations:\nin-context learning-based methods fail to address rooted biases due to the\nevaluator's limited capacity for self-reflection, whereas fine-tuning is not\napplicable to all evaluator types, especially closed-source models. To address\nthis challenge, we introduce the Reasoning-based Bias Detector (RBD), which is\na plug-in module that identifies biased evaluations and generates structured\nreasoning to guide evaluator self-correction. Rather than modifying the\nevaluator itself, RBD operates externally and engages in an iterative process\nof bias detection and feedback-driven revision. To support its development, we\ndesign a complete pipeline consisting of biased dataset construction,\nsupervision collection, distilled reasoning-based fine-tuning of RBD, and\nintegration with LLM evaluators. We fine-tune four sizes of RBD models, ranging\nfrom 1.5B to 14B, and observe consistent performance improvements across all\nscales. Experimental results on 4 bias types--verbosity, position, bandwagon,\nand sentiment--evaluated using 8 LLM evaluators demonstrate RBD's strong\neffectiveness. For example, the RBD-8B model improves evaluation accuracy by an\naverage of 18.5% and consistency by 10.9%, and surpasses prompting-based\nbaselines and fine-tuned judges by 12.8% and 17.2%, respectively. These results\nhighlight RBD's effectiveness and scalability. Additional experiments further\ndemonstrate its strong generalization across biases and domains, as well as its\nefficiency.", "AI": {"tldr": "LLM-as-a-Judge\u5728\u8bc4\u4f30\u751f\u6210\u6587\u672c\u65b9\u9762\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u5176\u53ef\u9760\u6027\u53d7\u5230\u504f\u89c1\u7684\u5f71\u54cd\u3002\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aRBD\uff08Reasoning-based Bias Detector\uff09\u7684\u63d2\u4ef6\u6a21\u5757\uff0c\u7528\u4e8e\u8bc6\u522b\u8bc4\u4f30\u4e2d\u7684\u504f\u89c1\u5e76\u63d0\u4f9b\u7ed3\u6784\u5316\u63a8\u7406\u4ee5\u6307\u5bfc\u8bc4\u4f30\u5668\u81ea\u6211\u7ea0\u6b63\u3002RBD\u4f5c\u4e3a\u5916\u90e8\u6a21\u5757\u8fd0\u884c\uff0c\u4e0d\u4fee\u6539\u8bc4\u4f30\u5668\u672c\u8eab\uff0c\u5e76\u901a\u8fc7\u8fed\u4ee3\u8fc7\u7a0b\u68c0\u6d4b\u504f\u89c1\u5e76\u8fdb\u884c\u53cd\u9988\u9a71\u52a8\u7684\u4fee\u8ba2\u3002\u7814\u7a76\u8fd8\u6784\u5efa\u4e86\u4e00\u4e2a\u5b8c\u6574\u7684\u6d41\u6c34\u7ebf\uff0c\u5305\u62ec\u504f\u89c1\u6570\u636e\u96c6\u7684\u6784\u5efa\u3001\u76d1\u7763\u6570\u636e\u7684\u6536\u96c6\u3001RBD\u7684\u84b8\u998f\u63a8\u7406\u5f0f\u5fae\u8c03\u4ee5\u53ca\u4e0eLLM\u8bc4\u4f30\u5668\u7684\u96c6\u6210\u3002\u5728\u56db\u79cd\u504f\u89c1\u7c7b\u578b\uff08\u5197\u957f\u3001\u4f4d\u7f6e\u3001\u4ece\u4f17\u548c\u60c5\u611f\uff09\u4ee5\u53ca\u516b\u79cdLLM\u8bc4\u4f30\u5668\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cRBD\u80fd\u6709\u6548\u63d0\u5347\u8bc4\u4f30\u51c6\u786e\u6027\u548c\u4e00\u81f4\u6027\uff0c\u5e76\u4e14\u4f18\u4e8e\u57fa\u4e8e\u63d0\u793a\u7684\u65b9\u6cd5\u548c\u5fae\u8c03\u7684\u8bc4\u4f30\u5668\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4f5c\u4e3a\u8bc4\u4f30\u5de5\u5177\uff08LLM-as-a-Judge\uff09\u5728\u81ea\u52a8\u8bc4\u4f30\u751f\u6210\u6587\u672c\u65b9\u9762\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u5176\u8bc4\u4f30\u7ed3\u679c\u7684\u53ef\u9760\u6027\u5e38\u5e38\u53d7\u5230\u5185\u5728\u504f\u89c1\u7684\u4e25\u91cd\u5f71\u54cd\u3002\u73b0\u6709\u7684\u7f13\u89e3\u504f\u89c1\u7684\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff1a\u57fa\u4e8e\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08in-context learning\uff09\u7684\u65b9\u6cd5\u7531\u4e8e\u8bc4\u4f30\u5668\u6709\u9650\u7684\u81ea\u6211\u53cd\u601d\u80fd\u529b\uff0c\u65e0\u6cd5\u89e3\u51b3\u6839\u6df1\u8482\u56fa\u7684\u504f\u89c1\uff1b\u800c\u6a21\u578b\u5fae\u8c03\uff08fine-tuning\uff09\u7684\u65b9\u6cd5\u53c8\u65e0\u6cd5\u5e94\u7528\u4e8e\u6240\u6709\u7c7b\u578b\u7684\u8bc4\u4f30\u5668\uff0c\u7279\u522b\u662f\u90a3\u4e9b\u65e0\u6cd5\u8bbf\u95ee\u5176\u5185\u90e8\u53c2\u6570\u7684\u95ed\u6e90\u6a21\u578b\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u6709\u6548\u4e14\u5e7f\u6cdb\u5730\u89e3\u51b3LLM\u8bc4\u4f30\u4e2d\u7684\u504f\u89c1\u95ee\u9898\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aRBD\uff08Reasoning-based Bias Detector\uff09\u7684\u63d2\u4ef6\u6a21\u5757\u3002RBD\u4f5c\u4e3a\u4e00\u4e2a\u5916\u90e8\u7ec4\u4ef6\uff0c\u80fd\u591f\u8bc6\u522bLLM\u8bc4\u4f30\u4e2d\u7684\u504f\u89c1\uff0c\u5e76\u751f\u6210\u7ed3\u6784\u5316\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u4ee5\u6307\u5bfc\u8bc4\u4f30\u5668\u8fdb\u884c\u81ea\u6211\u7ea0\u6b63\uff0c\u800c\u65e0\u9700\u4fee\u6539\u8bc4\u4f30\u5668\u672c\u8eab\u3002RBD\u901a\u8fc7\u4e00\u4e2a\u8fed\u4ee3\u8fc7\u7a0b\u6765\u8fd0\u4f5c\uff1a\u9996\u5148\u68c0\u6d4b\u8bc4\u4f30\u4e2d\u7684\u504f\u89c1\uff0c\u7136\u540e\u6839\u636e\u68c0\u6d4b\u5230\u7684\u504f\u89c1\u751f\u6210\u53cd\u9988\uff0c\u9a71\u52a8\u8bc4\u4f30\u5668\u8fdb\u884c\u4fee\u8ba2\u3002\u4e3a\u4e86\u652f\u6301RBD\u7684\u5f00\u53d1\uff0c\u7814\u7a76\u4eba\u5458\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u5b8c\u6574\u7684\u6d41\u6c34\u7ebf\uff0c\u5305\u62ec\uff1a1\uff09\u6784\u5efa\u5305\u542b\u5404\u79cd\u504f\u89c1\u7c7b\u578b\u7684\u8bc4\u4f30\u6570\u636e\u96c6\uff1b2\uff09\u6536\u96c6\u7528\u4e8e\u76d1\u7763RBD\u7684\u6807\u6ce8\u6570\u636e\uff1b3\uff09\u5bf9RBD\u8fdb\u884c\u84b8\u998f\u63a8\u7406\u5f0f\u5fae\u8c03\uff1b4\uff09\u5c06RBD\u96c6\u6210\u5230\u73b0\u6709\u7684LLM\u8bc4\u4f30\u6d41\u7a0b\u4e2d\u3002\u7814\u7a76\u4eba\u5458\u5fae\u8c03\u4e86\u56db\u79cd\u4e0d\u540c\u89c4\u6a21\uff081.5B\u523014B\u53c2\u6570\uff09\u7684RBD\u6a21\u578b\uff0c\u5e76\u5728\u56db\u79cd\u504f\u89c1\u7c7b\u578b\uff08\u5197\u957f\u3001\u4f4d\u7f6e\u3001\u4ece\u4f17\u548c\u60c5\u611f\uff09\u4e0a\uff0c\u4f7f\u7528\u516b\u79cd\u4e0d\u540c\u7684LLM\u8bc4\u4f30\u5668\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cRBD\u5728\u6d88\u9664LLM\u8bc4\u4f30\u504f\u89c1\u65b9\u9762\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6709\u6548\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002\u65e0\u8bba\u6a21\u578b\u89c4\u6a21\u5982\u4f55\uff0cRBD\u7684\u6027\u80fd\u5747\u968f\u7740\u6a21\u578b\u589e\u5927\u800c\u6301\u7eed\u63d0\u5347\u3002\u5728\u6240\u6709\u56db\u79cd\u504f\u89c1\u7c7b\u578b\u548c\u516b\u79cdLLM\u8bc4\u4f30\u5668\u4e0a\uff0cRBD\u6a21\u578b\u663e\u8457\u63d0\u9ad8\u4e86\u8bc4\u4f30\u7684\u51c6\u786e\u6027\u548c\u4e00\u81f4\u6027\u3002\u5177\u4f53\u800c\u8a00\uff0cRBD-8B\u6a21\u578b\u5e73\u5747\u5c06\u8bc4\u4f30\u51c6\u786e\u7387\u63d0\u9ad8\u4e8618.5%\uff0c\u4e00\u81f4\u6027\u63d0\u9ad8\u4e8610.9%\u3002\u4e0e\u4ec5\u4f7f\u7528\u63d0\u793a\uff08prompting\uff09\u7684\u65b9\u6cd5\u76f8\u6bd4\uff0cRBD\u7684\u8bc4\u4f30\u51c6\u786e\u7387\u5e73\u5747\u9ad8\u51fa12.8%\uff1b\u800c\u4e0e\u7ecf\u8fc7\u5fae\u8c03\u7684\u8bc4\u4f30\u5668\u76f8\u6bd4\uff0cRBD\u7684\u8bc4\u4f30\u51c6\u786e\u7387\u5e73\u5747\u9ad8\u51fa17.2%\u3002\u6b64\u5916\uff0c\u989d\u5916\u7684\u5b9e\u9a8c\u8bc1\u660e\u4e86RBD\u5728\u4e0d\u540c\u504f\u89c1\u7c7b\u578b\u548c\u4e0d\u540c\u9886\u57df\u4e4b\u95f4\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u4e14\u5728\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u4e5f\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u672c\u7814\u7a76\u6210\u529f\u5f00\u53d1\u5e76\u9a8c\u8bc1\u4e86\u4e00\u79cd\u540d\u4e3aRBD\u7684\u65b0\u578b\u63d2\u4ef6\u6a21\u5757\uff0c\u5b83\u80fd\u591f\u6709\u6548\u5730\u8bc6\u522b\u548c\u51cf\u8f7bLLM\u8bc4\u4f30\u4e2d\u7684\u504f\u89c1\uff0c\u540c\u65f6\u4fdd\u6301\u8bc4\u4f30\u5668\uff08\u5305\u62ec\u95ed\u6e90\u6a21\u578b\uff09\u7684\u5b8c\u6574\u6027\u3002RBD\u901a\u8fc7\u751f\u6210\u7ed3\u6784\u5316\u63a8\u7406\u6765\u6307\u5bfc\u8bc4\u4f30\u5668\u7684\u81ea\u6211\u4fee\u6b63\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u7075\u6d3b\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\u4e86RBD\u5728\u63d0\u9ad8\u8bc4\u4f30\u51c6\u786e\u6027\u548c\u4e00\u81f4\u6027\u65b9\u9762\u7684\u663e\u8457\u4f18\u52bf\uff0c\u5e76\u4e14\u5176\u6cdb\u5316\u80fd\u529b\u548c\u6548\u7387\u4e5f\u5f97\u5230\u4e86\u9a8c\u8bc1\u3002\u5c3d\u7ba1RBD\u5728\u591a\u4e2a\u7ef4\u5ea6\u4e0a\u53d6\u5f97\u4e86\u4f18\u5f02\u7684\u8868\u73b0\uff0c\u4f46\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63a2\u7d22\u66f4\u5e7f\u6cdb\u7684\u504f\u89c1\u7c7b\u578b\u3001\u66f4\u590d\u6742\u7684\u8bc4\u4f30\u573a\u666f\uff0c\u4ee5\u53ca\u4f18\u5316RBD\u7684\u8ba1\u7b97\u6548\u7387\u548c\u96c6\u6210\u65b9\u5f0f\u3002"}}
{"id": "2506.00481", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.00481", "abs": "https://arxiv.org/abs/2506.00481", "authors": ["Junseo Kim", "Jongwook Han", "Dongmin Choi", "Jongwook Yoon", "Eun-Ju Lee", "Yohan Jo"], "title": "PVP: An Image Dataset for Personalized Visual Persuasion with Persuasion Strategies, Viewer Characteristics, and Persuasiveness Ratings", "comment": "ACL 2025 Main. Code and dataset are released at:\n  https://github.com/holi-lab/PVP_Personalized_Visual_Persuasion", "summary": "Visual persuasion, which uses visual elements to influence cognition and\nbehaviors, is crucial in fields such as advertising and political\ncommunication. With recent advancements in artificial intelligence, there is\ngrowing potential to develop persuasive systems that automatically generate\npersuasive images tailored to individuals. However, a significant bottleneck in\nthis area is the lack of comprehensive datasets that connect the persuasiveness\nof images with the personal information about those who evaluated the images.\nTo address this gap and facilitate technological advancements in personalized\nvisual persuasion, we release the Personalized Visual Persuasion (PVP) dataset,\ncomprising 28,454 persuasive images across 596 messages and 9 persuasion\nstrategies. Importantly, the PVP dataset provides persuasiveness scores of\nimages evaluated by 2,521 human annotators, along with their demographic and\npsychological characteristics (personality traits and values). We demonstrate\nthe utility of our dataset by developing a persuasive image generator and an\nautomated evaluator, and establish benchmark baselines. Our experiments reveal\nthat incorporating psychological characteristics enhances the generation and\nevaluation of persuasive images, providing valuable insights for personalized\nvisual persuasion.", "AI": {"tldr": "\u8be5\u7814\u7a76\u53d1\u5e03\u4e86\u4e00\u4e2a\u540d\u4e3aPVP\uff08Personalized Visual Persuasion\uff09\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u8be5\u6570\u636e\u96c6\u5305\u542b28,454\u5f20\u5177\u6709\u8bf4\u670d\u529b\u7684\u56fe\u50cf\uff0c\u6db5\u76d6596\u6761\u4fe1\u606f\u548c9\u79cd\u8bf4\u670d\u7b56\u7565\u3002\u6570\u636e\u96c6\u8bb0\u5f55\u4e862,521\u540d\u4eba\u7c7b\u6807\u6ce8\u8005\u5bf9\u56fe\u50cf\u8bf4\u670d\u529b\u7684\u8bc4\u5206\uff0c\u4ee5\u53ca\u4ed6\u4eec\u7684\u4e2a\u4eba\u4fe1\u606f\uff08\u4eba\u53e3\u7edf\u8ba1\u5b66\u7279\u5f81\u3001\u6027\u683c\u7279\u8d28\u548c\u4ef7\u503c\u89c2\uff09\u3002\u7814\u7a76\u4eba\u5458\u5229\u7528\u8be5\u6570\u636e\u96c6\u5f00\u53d1\u4e86\u4e00\u4e2a\u81ea\u52a8\u751f\u6210\u8bf4\u670d\u6027\u56fe\u50cf\u7684\u7cfb\u7edf\u548c\u4e00\u4e2a\u81ea\u52a8\u8bc4\u4f30\u7cfb\u7edf\uff0c\u5e76\u5efa\u7acb\u4e86\u57fa\u51c6\u6a21\u578b\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u7ed3\u5408\u7528\u6237\u7684\u5fc3\u7406\u7279\u5f81\u53ef\u4ee5\u63d0\u5347\u8bf4\u670d\u6027\u56fe\u50cf\u751f\u6210\u548c\u8bc4\u4f30\u7684\u6548\u679c\uff0c\u4e3a\u4e2a\u6027\u5316\u89c6\u89c9\u8bf4\u670d\u9886\u57df\u63d0\u4f9b\u4e86\u5b9d\u8d35\u89c1\u89e3\u3002", "motivation": "\u5e7f\u544a\u548c\u653f\u6cbb\u5ba3\u4f20\u7b49\u9886\u57df\u5e7f\u6cdb\u5e94\u7528\u89c6\u89c9\u8bf4\u670d\u6280\u672f\u3002\u7136\u800c\uff0c\u76ee\u524d\u7f3a\u4e4f\u5c06\u56fe\u50cf\u8bf4\u670d\u529b\u4e0e\u8bc4\u4f30\u8005\u4e2a\u4eba\u4fe1\u606f\u8054\u7cfb\u8d77\u6765\u7684\u6570\u636e\u96c6\uff0c\u8fd9\u963b\u788d\u4e86\u80fd\u591f\u81ea\u52a8\u4e3a\u4e2a\u4f53\u751f\u6210\u5b9a\u5236\u5316\u8bf4\u670d\u56fe\u50cf\u7684AI\u7cfb\u7edf\u7684\u53d1\u5c55\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u672c\u7814\u7a76\u65e8\u5728\u521b\u5efa\u4e00\u4e2a\u5168\u9762\u7684\u6570\u636e\u96c6\uff0c\u4ee5\u4fc3\u8fdb\u4e2a\u6027\u5316\u89c6\u89c9\u8bf4\u670d\u6280\u672f\u7684\u7814\u7a76\u548c\u5e94\u7528\u3002", "method": "\u7814\u7a76\u4eba\u5458\u6784\u5efa\u4e86\u4e00\u4e2a\u540d\u4e3aPVP\uff08Personalized Visual Persuasion\uff09\u7684\u6570\u636e\u96c6\uff0c\u5176\u4e2d\u5305\u542b28,454\u5f20\u56fe\u50cf\uff0c\u8fd9\u4e9b\u56fe\u50cf\u4e0e596\u6761\u4e0d\u540c\u7684\u4fe1\u606f\u4ee5\u53ca9\u79cd\u4e0d\u540c\u7684\u8bf4\u670d\u7b56\u7565\u76f8\u5173\u8054\u30022,521\u540d\u4eba\u7c7b\u6807\u6ce8\u8005\u5bf9\u8fd9\u4e9b\u56fe\u50cf\u7684\u8bf4\u670d\u529b\u8fdb\u884c\u4e86\u8bc4\u5206\uff0c\u540c\u65f6\u8fd8\u6536\u96c6\u4e86\u4ed6\u4eec\u7684\u4e2a\u4eba\u4fe1\u606f\uff0c\u5305\u62ec\u4eba\u53e3\u7edf\u8ba1\u5b66\u7279\u5f81\u3001\u6027\u683c\u7279\u8d28\u548c\u4ef7\u503c\u89c2\u3002\u5728\u6b64\u57fa\u7840\u4e0a\uff0c\u7814\u7a76\u4eba\u5458\u5f00\u53d1\u4e86\u4e00\u4e2a\u81ea\u52a8\u751f\u6210\u8bf4\u670d\u6027\u56fe\u50cf\u7684\u6a21\u578b\u548c\u4e00\u4e2a\u81ea\u52a8\u8bc4\u4f30\u8bf4\u670d\u6027\u56fe\u50cf\u7684\u6a21\u578b\uff0c\u5e76\u4f7f\u7528PVP\u6570\u636e\u96c6\u5bf9\u8fd9\u4e9b\u6a21\u578b\u8fdb\u884c\u4e86\u8bad\u7ec3\u548c\u8bc4\u4f30\uff0c\u5efa\u7acb\u4e86\u57fa\u51c6\u6027\u80fd\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\uff0c\u7814\u7a76\u53d1\u73b0\u5c06\u7528\u6237\u7684\u5fc3\u7406\u7279\u5f81\uff08\u5982\u6027\u683c\u7279\u8d28\u548c\u4ef7\u503c\u89c2\uff09\u878d\u5165\u5230\u8bf4\u670d\u6027\u56fe\u50cf\u7684\u751f\u6210\u548c\u8bc4\u4f30\u8fc7\u7a0b\u4e2d\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u6a21\u578b\u7684\u6027\u80fd\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u5229\u7528\u5fc3\u7406\u7279\u5f81\u7684\u6a21\u578b\u5728\u751f\u6210\u66f4\u5177\u8bf4\u670d\u529b\u7684\u56fe\u50cf\u4ee5\u53ca\u66f4\u51c6\u786e\u5730\u8bc4\u4f30\u56fe\u50cf\u8bf4\u670d\u529b\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002\u7814\u7a76\u4eba\u5458\u5efa\u7acb\u4e86\u76f8\u5e94\u7684\u57fa\u51c6\u6a21\u578b\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u4e86\u53c2\u8003\u3002", "conclusion": "\u672c\u7814\u7a76\u6210\u529f\u6784\u5efa\u5e76\u53d1\u5e03\u4e86PVP\u6570\u636e\u96c6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6570\u636e\u96c6\u7684\u4e0d\u8db3\uff0c\u4e3a\u4e2a\u6027\u5316\u89c6\u89c9\u8bf4\u670d\u9886\u57df\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u5173\u952e\u8d44\u6e90\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8003\u8651\u7528\u6237\u7684\u5fc3\u7406\u7279\u5f81\u5bf9\u4e8e\u63d0\u5347\u89c6\u89c9\u8bf4\u670d\u7684\u6548\u679c\u81f3\u5173\u91cd\u8981\uff0c\u4e3a\u5f00\u53d1\u66f4\u6709\u6548\u7684\u4e2a\u6027\u5316\u8bf4\u670d\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002\u672a\u6765\u7684\u7814\u7a76\u53ef\u4ee5\u57fa\u4e8e\u6b64\u6570\u636e\u96c6\uff0c\u8fdb\u4e00\u6b65\u63a2\u7d22\u66f4\u590d\u6742\u7684\u4e2a\u6027\u5316\u8bf4\u670d\u673a\u5236\u548c\u6a21\u578b\u3002"}}
{"id": "2506.00789", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.00789", "abs": "https://arxiv.org/abs/2506.00789", "authors": ["Yixiao Zeng", "Tianyu Cao", "Danqing Wang", "Xinran Zhao", "Zimeng Qiu", "Morteza Ziyadi", "Tongshuang Wu", "Lei Li"], "title": "RARE: Retrieval-Aware Robustness Evaluation for Retrieval-Augmented Generation Systems", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) enhances recency and factuality in\nanswers. However, existing evaluations rarely test how well these systems cope\nwith real-world noise, conflicting between internal and external retrieved\ncontexts, or fast-changing facts. We introduce Retrieval-Aware Robustness\nEvaluation (RARE), a unified framework and large-scale benchmark that jointly\nstress-tests query and document perturbations over dynamic, time-sensitive\ncorpora. One of the central features of RARE is a knowledge-graph-driven\nsynthesis pipeline (RARE-Get) that automatically extracts single and multi-hop\nrelations from the customized corpus and generates multi-level question sets\nwithout manual intervention. Leveraging this pipeline, we construct a dataset\n(RARE-Set) spanning 527 expert-level time-sensitive finance, economics, and\npolicy documents and 48295 questions whose distribution evolves as the\nunderlying sources change. To quantify resilience, we formalize\nretrieval-conditioned robustness metrics (RARE-Met) that capture a model's\nability to remain correct or recover when queries, documents, or real-world\nretrieval results are systematically altered. Our findings reveal that RAG\nsystems are unexpectedly sensitive to perturbations. Moreover, they\nconsistently demonstrate lower robustness on multi-hop queries compared to\nsingle-hop queries across all domains.", "AI": {"tldr": "\u73b0\u6709\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7cfb\u7edf\u5728\u5904\u7406\u771f\u5b9e\u4e16\u754c\u4e2d\u7684\u566a\u58f0\u3001\u5185\u90e8\u68c0\u7d22\u4e0e\u5916\u90e8\u4e0a\u4e0b\u6587\u51b2\u7a81\u4ee5\u53ca\u5feb\u901f\u53d8\u5316\u7684\u4e8b\u5b9e\u65f6\uff0c\u9c81\u68d2\u6027\u4e0d\u8db3\u3002\u672c\u6587\u63d0\u51fa\u4e86\u68c0\u7d22\u611f\u77e5\u9c81\u68d2\u6027\u8bc4\u4f30\uff08RARE\uff09\u6846\u67b6\u548c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4ee5\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\u3002RARE\u5229\u7528\u77e5\u8bc6\u56fe\u8c31\u9a71\u52a8\u7684\u5408\u6210\u7ba1\u9053\uff08RARE-Get\uff09\u81ea\u52a8\u751f\u6210\u591a\u5c42\u6b21\u7684\u95ee\u9898\u96c6\uff0c\u5e76\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b527\u7bc7\u91d1\u878d\u3001\u7ecf\u6d4e\u548c\u653f\u7b56\u6587\u6863\u53ca48295\u4e2a\u95ee\u9898\u7684RARE-Set\u6570\u636e\u96c6\u3002\u8be5\u6570\u636e\u96c6\u7684\u7279\u70b9\u662f\u4fe1\u606f\u968f\u65f6\u95f4\u52a8\u6001\u53d8\u5316\u3002RARE-Met\u5ea6\u91cf\u6807\u51c6\u7528\u4e8e\u91cf\u5316\u6a21\u578b\u7684\u9c81\u68d2\u6027\uff0c\u53d1\u73b0RAG\u7cfb\u7edf\u5bf9\u6270\u52a8\u975e\u5e38\u654f\u611f\uff0c\u5e76\u4e14\u5728\u591a\u8df3\u67e5\u8be2\u65b9\u9762\u9c81\u68d2\u6027\u4f4e\u4e8e\u5355\u8df3\u67e5\u8be2\u3002", "motivation": "\u73b0\u6709\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6280\u672f\u867d\u7136\u63d0\u9ad8\u4e86\u7b54\u6848\u7684\u65f6\u6548\u6027\u548c\u4e8b\u5b9e\u51c6\u786e\u6027\uff0c\u4f46\u5728\u771f\u5b9e\u4e16\u754c\u7684\u5e94\u7528\u4e2d\u9762\u4e34\u4e25\u5cfb\u6311\u6218\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u8fd9\u4e9b\u7cfb\u7edf\u5728\u5904\u7406\u5e26\u6709\u566a\u58f0\u7684\u6570\u636e\u3001\u533a\u5206\u5185\u90e8\u68c0\u7d22\u4fe1\u606f\u4e0e\u5916\u90e8\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u4ee5\u53ca\u5e94\u5bf9\u5feb\u901f\u53d8\u5316\u7684\u4e8b\u5b9e\u65f6\uff0c\u5176\u9c81\u68d2\u6027\u5f80\u5f80\u4e0d\u8db3\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u8bc4\u4f30\u65b9\u6cd5\u5f88\u5c11\u80fd\u5168\u9762\u5730\u6d4b\u8bd5RAG\u7cfb\u7edf\u5728\u8fd9\u4e9b\u771f\u5b9e\u573a\u666f\u4e0b\u7684\u8868\u73b0\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u5982\u4f55\u6709\u6548\u5730\u8bc4\u4f30\u548c\u63d0\u5347RAG\u7cfb\u7edf\u5728\u590d\u6742\u591a\u53d8\u7684\u771f\u5b9e\u73af\u5883\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u5177\u6709\u91cd\u8981\u7684\u73b0\u5b9e\u610f\u4e49\u548c\u7814\u7a76\u4ef7\u503c\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u68c0\u7d22\u611f\u77e5\u9c81\u68d2\u6027\u8bc4\u4f30\uff08RARE\uff09\u7684\u7edf\u4e00\u6846\u67b6\u548c\u5927\u89c4\u6a21\u57fa\u51c6\u6d4b\u8bd5\u3002\u8be5\u6846\u67b6\u80fd\u591f\u8054\u5408\u6d4b\u8bd5\u67e5\u8be2\u548c\u6587\u6863\u5728\u52a8\u6001\u3001\u65f6\u654f\u6027\u8bed\u6599\u5e93\u4e0a\u7684\u6270\u52a8\u5f71\u54cd\u3002RARE\u6846\u67b6\u7684\u6838\u5fc3\u662f\u4e00\u4e2a\u540d\u4e3aRARE-Get\u7684\u77e5\u8bc6\u56fe\u8c31\u9a71\u52a8\u7684\u5408\u6210\u7ba1\u9053\uff0c\u8be5\u7ba1\u9053\u53ef\u4ee5\u81ea\u52a8\u4ece\u81ea\u5b9a\u4e49\u8bed\u6599\u5e93\u4e2d\u63d0\u53d6\u5355\u8df3\u548c\u591a\u8df3\u5173\u7cfb\uff0c\u5e76\u751f\u6210\u591a\u5c42\u6b21\u7684\u95ee\u9898\u96c6\uff0c\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u3002\u57fa\u4e8e\u6b64\u7ba1\u9053\uff0c\u7814\u7a76\u4eba\u5458\u6784\u5efa\u4e86\u4e00\u4e2a\u540d\u4e3aRARE-Set\u7684\u6570\u636e\u96c6\uff0c\u5176\u4e2d\u5305\u542b527\u7bc7\u4e13\u5bb6\u7ea7\u522b\u7684\u3001\u5173\u4e8e\u91d1\u878d\u3001\u7ecf\u6d4e\u548c\u653f\u7b56\u7684\u3001\u5177\u6709\u65f6\u6548\u6027\u7684\u6587\u6863\uff0c\u4ee5\u53ca48295\u4e2a\u95ee\u9898\u3002\u8be5\u6570\u636e\u96c6\u7684\u7279\u70b9\u662f\uff0c\u968f\u7740\u5e95\u5c42\u6570\u636e\u6e90\u7684\u53d8\u5316\uff0c\u95ee\u9898\u7684\u5206\u5e03\u4e5f\u4f1a\u968f\u4e4b\u6f14\u53d8\u3002\u4e3a\u4e86\u91cf\u5316\u6a21\u578b\u7684\u9c81\u68d2\u6027\uff0c\u7814\u7a76\u4eba\u5458\u5f62\u5f0f\u5316\u4e86\u68c0\u7d22\u6761\u4ef6\u9c81\u68d2\u6027\u5ea6\u91cf\uff08RARE-Met\uff09\uff0c\u8be5\u5ea6\u91cf\u80fd\u591f\u6355\u6349\u6a21\u578b\u5728\u67e5\u8be2\u3001\u6587\u6863\u6216\u771f\u5b9e\u68c0\u7d22\u7ed3\u679c\u88ab\u7cfb\u7edf\u6027\u5730\u6539\u53d8\u65f6\uff0c\u4fdd\u6301\u6b63\u786e\u6216\u6062\u590d\u6b63\u786e\u7684\u80fd\u529b\u3002", "result": "\u901a\u8fc7RARE\u6846\u67b6\u8fdb\u884c\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u5f53\u524d\u7684RAG\u7cfb\u7edf\u5bf9\u6270\u52a8\u8868\u73b0\u51fa\u51fa\u4e4e\u610f\u6599\u7684\u654f\u611f\u6027\u3002\u5177\u4f53\u800c\u8a00\uff0c\u5728\u6240\u6709\u6d4b\u8bd5\u7684\u9886\u57df\u4e2d\uff0cRAG\u7cfb\u7edf\u5728\u9762\u5bf9\u67e5\u8be2\u3001\u6587\u6863\u6216\u68c0\u7d22\u7ed3\u679c\u7684\u7cfb\u7edf\u6027\u6539\u53d8\u65f6\uff0c\u5176\u56de\u7b54\u7684\u51c6\u786e\u6027\u4f1a\u663e\u8457\u4e0b\u964d\u3002\u6b64\u5916\uff0c\u8bc4\u4f30\u7ed3\u679c\u8fd8\u8868\u660e\uff0c\u4e0e\u5355\u8df3\u67e5\u8be2\u76f8\u6bd4\uff0cRAG\u7cfb\u7edf\u5728\u5904\u7406\u591a\u8df3\u67e5\u8be2\u65f6\uff0c\u5176\u9c81\u68d2\u6027 consistently \u8f83\u4f4e\u3002\u8fd9\u610f\u5473\u7740RAG\u7cfb\u7edf\u5728\u9700\u8981\u6574\u5408\u591a\u6b65\u63a8\u7406\u6216\u5173\u8054\u591a\u4e2a\u4fe1\u606f\u7247\u6bb5\u65f6\uff0c\u66f4\u5bb9\u6613\u53d7\u5230\u566a\u58f0\u548c\u53d8\u5316\u7684\u5f71\u54cd\u800c\u4ea7\u751f\u9519\u8bef\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684RARE\u6846\u67b6\u548cRARE-Set\u6570\u636e\u96c6\u4e3a\u8bc4\u4f30RAG\u7cfb\u7edf\u5728\u771f\u5b9e\u4e16\u754c\u52a8\u6001\u3001\u65f6\u654f\u6027\u73af\u5883\u4e0b\u7684\u9c81\u68d2\u6027\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u5de5\u5177\u3002\u7814\u7a76\u7ed3\u679c\u63ed\u793a\u4e86\u5f53\u524dRAG\u7cfb\u7edf\u5728\u9762\u5bf9\u6570\u636e\u6270\u52a8\u548c\u590d\u6742\u67e5\u8be2\uff08\u5982\u591a\u8df3\u67e5\u8be2\uff09\u65f6\u7684\u8106\u5f31\u6027\uff0c\u5f3a\u8c03\u4e86\u63d0\u9ad8RAG\u7cfb\u7edf\u9c81\u68d2\u6027\u7684\u7d27\u8feb\u6027\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u96c6\u4e2d\u4e8e\u5f00\u53d1\u66f4\u5177\u9c81\u68d2\u6027\u7684RAG\u6a21\u578b\u67b6\u6784\u3001\u4f18\u5316\u68c0\u7d22\u7b56\u7565\u4ee5\u66f4\u597d\u5730\u5904\u7406\u566a\u58f0\u548c\u4e0d\u786e\u5b9a\u6027\uff0c\u4ee5\u53ca\u8fdb\u4e00\u6b65\u6269\u5c55RARE\u57fa\u51c6\u6d4b\u8bd5\u4ee5\u8986\u76d6\u66f4\u5e7f\u6cdb\u7684\u9886\u57df\u548c\u66f4\u590d\u6742\u7684\u8bc4\u4f30\u573a\u666f\u3002"}}
{"id": "2506.01381", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.01381", "abs": "https://arxiv.org/abs/2506.01381", "authors": ["Yilong Lai", "Jialong Wu", "Zhenglin Wang", "Deyu Zhou"], "title": "AdaRewriter: Unleashing the Power of Prompting-based Conversational Query Reformulation via Test-Time Adaptation", "comment": "Accepted by EMNLP 2025", "summary": "Prompting-based conversational query reformulation has emerged as a powerful\napproach for conversational search, refining ambiguous user queries into\nstandalone search queries. Best-of-N reformulation over the generated\ncandidates via prompting shows impressive potential scaling capability.\nHowever, both the previous tuning methods (training time) and adaptation\napproaches (test time) can not fully unleash their benefits. In this paper, we\npropose AdaRewriter, a novel framework for query reformulation using an\noutcome-supervised reward model via test-time adaptation. By training a\nlightweight reward model with contrastive ranking loss, AdaRewriter selects the\nmost promising reformulation during inference. Notably, it can operate\neffectively in black-box systems, including commercial LLM APIs. Experiments on\nfive conversational search datasets show that AdaRewriter significantly\noutperforms the existing methods across most settings, demonstrating the\npotential of test-time adaptation for conversational query reformulation.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAdaRewriter\u7684\u65b0\u578b\u6846\u67b6\uff0c\u7528\u4e8e\u901a\u8fc7\u6d4b\u8bd5\u65f6\u9002\u5e94\uff08test-time adaptation\uff09\u6765\u4f18\u5316\u57fa\u4e8e\u63d0\u793a\u7684\u5bf9\u8bdd\u67e5\u8be2\u91cd\u6784\uff0c\u5e76\u4f7f\u7528\u7ed3\u679c\u76d1\u7763\u7684\u5956\u52b1\u6a21\u578b\u6765\u9009\u62e9\u6700\u4f73\u91cd\u6784\u7ed3\u679c\uff0c\u8be5\u65b9\u6cd5\u5728\u9ed1\u76d2\u7cfb\u7edf\u4e2d\u4e5f\u80fd\u6709\u6548\u8fd0\u884c\uff0c\u5e76\u5728\u4e94\u4e2a\u5bf9\u8bdd\u641c\u7d22\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u63d0\u793a\u7684\u5bf9\u8bdd\u67e5\u8be2\u91cd\u6784\u65b9\u6cd5\u5728\u5229\u7528\u6700\u4f73\u5019\u9009\u91cd\u6784\uff08Best-of-N reformulation\uff09\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u65e0\u8bba\u662f\u901a\u8fc7\u8bad\u7ec3\u65f6\u8c03\u6574\u8fd8\u662f\u6d4b\u8bd5\u65f6\u9002\u5e94\uff0c\u90fd\u672a\u80fd\u5145\u5206\u53d1\u6325\u5176\u6f5c\u529b\u3002\u8fd9\u963b\u788d\u4e86\u5728\u5bf9\u8bdd\u641c\u7d22\u4e2d\u6709\u6548\u6539\u8fdb\u6a21\u7cca\u7528\u6237\u67e5\u8be2\u5e76\u751f\u6210\u72ec\u7acb\u641c\u7d22\u67e5\u8be2\u7684\u80fd\u529b\u3002", "method": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86AdaRewriter\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5229\u7528\u7ed3\u679c\u76d1\u7763\u7684\u5956\u52b1\u6a21\u578b\u8fdb\u884c\u6d4b\u8bd5\u65f6\u9002\u5e94\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u5b83\u901a\u8fc7\u5bf9\u6bd4\u635f\u5931\u51fd\u6570\u8bad\u7ec3\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u5956\u52b1\u6a21\u578b\uff0c\u5e76\u5728\u63a8\u7406\u65f6\u5229\u7528\u8be5\u6a21\u578b\u9009\u62e9\u6700\u6709\u5e0c\u671b\u7684\u91cd\u6784\u7ed3\u679c\u3002AdaRewriter\u80fd\u591f\u6709\u6548\u5904\u7406\u9ed1\u76d2\u7cfb\u7edf\uff0c\u5305\u62ec\u5546\u4e1a\u5927\u578b\u8bed\u8a00\u6a21\u578bAPI\u3002", "result": "\u5728\u4e94\u4e2a\u5bf9\u8bdd\u641c\u7d22\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cAdaRewrewriter\u5728\u5927\u591a\u6570\u8bbe\u7f6e\u4e0b\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002\u8fd9\u8bc1\u660e\u4e86\u6d4b\u8bd5\u65f6\u9002\u5e94\u5728\u5bf9\u8bdd\u67e5\u8be2\u91cd\u6784\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "AdaRewriter\u901a\u8fc7\u5f15\u5165\u6d4b\u8bd5\u65f6\u9002\u5e94\u548c\u7ed3\u679c\u76d1\u7763\u7684\u5956\u52b1\u6a21\u578b\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709\u5bf9\u8bdd\u67e5\u8be2\u91cd\u6784\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u4f18\u8d8a\u7684\u6027\u80fd\u3002\u8be5\u7814\u7a76\u5f3a\u8c03\u4e86\u6d4b\u8bd5\u65f6\u9002\u5e94\u5728\u63d0\u5347\u5bf9\u8bdd\u641c\u7d22\u80fd\u529b\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u5e76\u4e3a\u672a\u6765\u7684\u7814\u7a76\u6307\u660e\u4e86\u65b9\u5411\u3002"}}
{"id": "2506.06964", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.06964", "abs": "https://arxiv.org/abs/2506.06964", "authors": ["Subhojyoti Mukherjee", "Viet Dac Lai", "Raghavendra Addanki", "Ryan Rossi", "Seunghyun Yoon", "Trung Bui", "Anup Rao", "Jayakumar Subramanian", "Branislav Kveton"], "title": "Offline RL by Reward-Weighted Fine-Tuning for Conversation Optimization", "comment": "Accepted at NeurIPS 2025 (main conference)", "summary": "Offline reinforcement learning (RL) is a variant of RL where the policy is\nlearned from a previously collected dataset of trajectories and rewards. In our\nwork, we propose a practical approach to offline RL with large language models\n(LLMs). We recast the problem as reward-weighted fine-tuning, which can be\nsolved using similar techniques to supervised fine-tuning (SFT). To showcase\nthe value of our approach, we apply it to learning short-horizon\nquestion-answering policies of a fixed length, where the agent reasons about\npotential answers or asks clarifying questions. Our work stands in a stark\ncontrast to state-of-the-art methods in this domain, based on SFT and direct\npreference optimization, which have additional hyper-parameters and do not\ndirectly optimize for rewards. We compare to them empirically, and report major\ngains in both optimized rewards and language quality.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8fdb\u884c\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u7684\u5b9e\u7528\u65b9\u6cd5\uff0c\u5c06\u95ee\u9898\u8f6c\u5316\u4e3a\u5956\u52b1\u52a0\u6743\u5fae\u8c03\uff0c\u5e76\u5728\u77ed\u65f6\u95ee\u7b54\u7b56\u7565\u5b66\u4e60\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u4f20\u7edf\u7684\u79bb\u7ebfRL\u65b9\u6cd5\u5728\u5904\u7406\u5927\u89c4\u6a21\u6570\u636e\u96c6\u548c\u590d\u6742\u4efb\u52a1\u65f6\u9762\u4e34\u6311\u6218\u3002\u800c\u73b0\u6709\u7684\u57fa\u4e8eSFT\u548cDPO\u7684\u65b9\u6cd5\u867d\u7136\u5728\u95ee\u7b54\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5e76\u672a\u76f4\u63a5\u4f18\u5316\u5956\u52b1\uff0c\u4e14\u5b58\u5728\u989d\u5916\u7684\u8d85\u53c2\u6570\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u4e00\u79cd\u66f4\u76f4\u63a5\u3001\u66f4\u9ad8\u6548\u7684\u79bb\u7ebfRL\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u9488\u5bf9\u77ed\u65f6\u95ee\u7b54\u7b56\u7565\u7684\u5b66\u4e60\uff0c\u4ee5\u514b\u670d\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u79bb\u7ebfRL\u95ee\u9898\u91cd\u6784\u4e3a\u5956\u52b1\u52a0\u6743\u5fae\u8c03\uff08reward-weighted fine-tuning\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u53ef\u4ee5\u5229\u7528\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u7684\u6280\u672f\u8fdb\u884c\u6c42\u89e3\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u7814\u7a76\u4eba\u5458\u5c06LLMs\u5e94\u7528\u4e8e\u5b66\u4e60\u56fa\u5b9a\u957f\u5ea6\u7684\u77ed\u65f6\u95ee\u7b54\u7b56\u7565\uff0c\u901a\u8fc7\u4f18\u5316\u5956\u52b1\u4fe1\u53f7\u6765\u6307\u5bfc\u6a21\u578b\u7684\u5b66\u4e60\u8fc7\u7a0b\u3002\u5b9e\u9a8c\u4e2d\uff0c\u5c06\u8be5\u65b9\u6cd5\u4e0e\u57fa\u4e8eSFT\u548cDPO\u7684\u5f53\u524d\u6700\u4f18\u65b9\u6cd5\u8fdb\u884c\u4e86\u5bf9\u6bd4\u3002", "result": "\u4e0e\u57fa\u4e8eSFT\u548cDPO\u7684\u5f53\u524d\u6700\u4f18\u65b9\u6cd5\u76f8\u6bd4\uff0c\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u4f18\u5316\u7684\u5956\u52b1\u548c\u8bed\u8a00\u8d28\u91cf\u65b9\u9762\u5747\u53d6\u5f97\u4e86\u663e\u8457\u7684\u63d0\u5347\u3002\u8fd9\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u77ed\u65f6\u95ee\u7b54\u7b56\u7565\u5b66\u4e60\u4efb\u52a1\u4e2d\uff0c\u80fd\u591f\u66f4\u6709\u6548\u5730\u5229\u7528\u79bb\u7ebf\u6570\u636e\u8fdb\u884c\u5b66\u4e60\uff0c\u5e76\u751f\u6210\u66f4\u9ad8\u8d28\u91cf\u7684\u56de\u7b54\u3002", "conclusion": "\u672c\u6587\u6210\u529f\u5730\u5c06LLMs\u5e94\u7528\u4e8e\u79bb\u7ebfRL\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u5956\u52b1\u52a0\u6743\u5fae\u8c03\u65b9\u6cd5\uff0c\u5728\u77ed\u65f6\u95ee\u7b54\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u4f18\u4e8e\u73b0\u6709SOTA\u65b9\u6cd5\u7684\u6027\u80fd\u3002\u8be5\u65b9\u6cd5\u4e3a\u79bb\u7ebfRL\u5728LLM\u9886\u57df\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\uff0c\u5e76\u4e3a\u672a\u6765\u5728\u8be5\u9886\u57df\u7684\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002\u7136\u800c\uff0c\u8be5\u65b9\u6cd5\u5728\u66f4\u957f\u671f\u7684\u4efb\u52a1\u548c\u66f4\u590d\u6742\u7684RL\u95ee\u9898\u4e0a\u7684\u6709\u6548\u6027\u4ecd\u9700\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u3002"}}
{"id": "2506.09349", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.09349", "abs": "https://arxiv.org/abs/2506.09349", "authors": ["Chao-Hong Tan", "Qian Chen", "Wen Wang", "Chong Deng", "Qinglin Zhang", "Luyao Cheng", "Hai Yu", "Xin Zhang", "Xiang Lv", "Tianyu Zhao", "Chong Zhang", "Yukun Ma", "Yafeng Chen", "Hui Wang", "Jiaqing Liu", "Xiangang Li", "Jieping Ye"], "title": "DrVoice: Parallel Speech-Text Voice Conversation Model via Dual-Resolution Speech Representations", "comment": "Work in progress", "summary": "Recent studies on end-to-end (E2E) speech generation with large language\nmodels (LLMs) have attracted significant community attention, with multiple\nworks extending text-based LLMs to generate discrete speech tokens. Existing\nE2E approaches primarily fall into two categories: (1) Methods that generate\ndiscrete speech tokens independently without incorporating them into the LLM's\nautoregressive process, resulting in text generation being unaware of\nconcurrent speech synthesis. (2) Models that generate interleaved or parallel\nspeech-text tokens through joint autoregressive modeling, enabling mutual\nmodality awareness during generation. This paper presents DrVoice, a parallel\nspeech-text voice conversation model based on joint autoregressive modeling,\nfeaturing dual-resolution speech representations. Notably, while current\nmethods utilize mainly 12.5Hz input audio representation, our proposed\ndual-resolution mechanism reduces the input frequency for the LLM to 5Hz,\nsignificantly reducing computational cost and alleviating the frequency\ndiscrepancy between speech and text tokens and in turn better exploiting LLMs'\ncapabilities. Experimental results demonstrate that DRVOICE-7B establishes new\nstate-of-the-art (SOTA) on OpenAudioBench and Big Bench Audio benchmarks, while\nachieving performance comparable to the SOTA on VoiceBench and UltraEval-Audio\nbenchmarks, making it a leading open-source speech foundation model in ~7B\nmodels.", "AI": {"tldr": "DrVoice\u662f\u4e00\u4e2a\u57fa\u4e8e\u8054\u5408\u81ea\u56de\u5f52\u5efa\u6a21\u7684\u5e76\u884c\u8bed\u97f3-\u6587\u672c\u5bf9\u8bdd\u6a21\u578b\uff0c\u91c7\u7528\u53cc\u5206\u8fa8\u7387\u8bed\u97f3\u8868\u793a\u3002\u8be5\u6a21\u578b\u5c06LLM\u7684\u8f93\u5165\u97f3\u9891\u9891\u7387\u4ece12.5Hz\u964d\u4f4e\u52305Hz\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\uff0c\u5e76\u89e3\u51b3\u4e86\u8bed\u97f3\u548c\u6587\u672c\u4ee4\u724c\u4e4b\u95f4\u7684\u9891\u7387\u5dee\u5f02\uff0c\u4ece\u800c\u66f4\u597d\u5730\u5229\u7528\u4e86LLM\u7684\u80fd\u529b\u3002DrVoice-7B\u5728OpenAudioBench\u548cBig Bench Audio\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u521b\u4e0b\u65b0\u7eaa\u5f55\uff0c\u5e76\u5728VoiceBench\u548cUltraEval-Audio\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u4e0eSOTA\u76f8\u5f53\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7aef\u5230\u7aef\u8bed\u97f3\u751f\u6210\u6a21\u578b\u5b58\u5728\u4e24\u79cd\u4e3b\u8981\u65b9\u6cd5\uff1a\u4e00\u662f\u72ec\u7acb\u751f\u6210\u79bb\u6563\u8bed\u97f3\u4ee4\u724c\uff0c\u5bfc\u81f4\u6587\u672c\u751f\u6210\u65e0\u6cd5\u611f\u77e5\u8bed\u97f3\u5408\u6210\uff1b\u4e8c\u662f\u901a\u8fc7\u8054\u5408\u81ea\u56de\u5f52\u5efa\u6a21\u751f\u6210\u4ea4\u9519\u6216\u5e76\u884c\u7684\u8bed\u97f3-\u6587\u672c\u4ee4\u724c\uff0c\u5b9e\u73b0\u4e86\u6a21\u6001\u95f4\u7684\u76f8\u4e92\u611f\u77e5\u3002\u7136\u800c\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u5728\u5904\u7406\u8bed\u97f3\u4ee4\u724c\u65f6\u53ef\u80fd\u9762\u4e34\u8ba1\u7b97\u6210\u672c\u9ad8\u548c\u9891\u7387\u5dee\u5f02\u95ee\u9898\u3002", "method": "DrVoice\u91c7\u7528\u8054\u5408\u81ea\u56de\u5f52\u5efa\u6a21\uff0c\u5b9e\u73b0\u4e86\u8bed\u97f3\u548c\u6587\u672c\u4ee4\u724c\u7684\u5e76\u884c\u751f\u6210\uff0c\u5e76\u5f15\u5165\u4e86\u53cc\u5206\u8fa8\u7387\u8bed\u97f3\u8868\u793a\u3002\u901a\u8fc7\u5c06LLM\u7684\u8f93\u5165\u97f3\u9891\u9891\u7387\u4ece\u5e38\u89c1\u768412.5Hz\u964d\u4f4e\u52305Hz\uff0cDrVoice\u6709\u6548\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u5e76\u51cf\u5c0f\u4e86\u8bed\u97f3\u4ee4\u724c\u548c\u6587\u672c\u4ee4\u724c\u4e4b\u95f4\u7684\u9891\u7387\u5dee\u5f02\uff0c\u4ece\u800c\u589e\u5f3a\u4e86LLM\u5bf9\u8bed\u97f3\u4fe1\u606f\u7684\u5229\u7528\u80fd\u529b\u3002\u6a21\u578b\u5b9e\u9a8c\u57fa\u4e8e~7B\u53c2\u6570\u89c4\u6a21\u3002", "result": "DrVoice-7B\u5728OpenAudioBench\u548cBig Bench Audio\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u65b0\u7684SOTA\u6027\u80fd\u3002\u5728VoiceBench\u548cUltraEval-Audio\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5176\u6027\u80fd\u4e0eSOTA\u76f8\u5f53\u3002", "conclusion": "DrVoice\u901a\u8fc7\u5176\u521b\u65b0\u7684\u53cc\u5206\u8fa8\u7387\u8bed\u97f3\u8868\u793a\u548c\u964d\u4f4e\u7684\u8f93\u5165\u9891\u7387\uff0c\u5728\u8bed\u97f3\u751f\u6210\u9886\u57df\u53d6\u5f97\u4e86\u663e\u8457\u7684\u8fdb\u5c55\uff0c\u6210\u4e3a\u4e00\u4e2a\u9886\u5148\u7684\u5f00\u6e90\u8bed\u97f3\u57fa\u7840\u6a21\u578b\u3002\u8be5\u6a21\u578b\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u548c\u6548\u7387\u3002\u672a\u6765\u7684\u7814\u7a76\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63a2\u7d22\u66f4\u4f4e\u7684\u58f0\u97f3\u9891\u7387\u8868\u793a\u6216\u66f4\u590d\u6742\u7684\u6a21\u578b\u7ed3\u6784\uff0c\u4ee5\u671f\u5728\u66f4\u5e7f\u6cdb\u7684\u8bed\u97f3\u4efb\u52a1\u4e2d\u5b9e\u73b0\u66f4\u9ad8\u7684\u6027\u80fd\u3002"}}
{"id": "2506.15355", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.15355", "abs": "https://arxiv.org/abs/2506.15355", "authors": ["Arijit Maji", "Raghvendra Kumar", "Akash Ghosh", "Anushka", "Sriparna Saha"], "title": "SANSKRITI: A Comprehensive Benchmark for Evaluating Language Models' Knowledge of Indian Culture", "comment": "ACL 2025 Findings", "summary": "Language Models (LMs) are indispensable tools shaping modern workflows, but\ntheir global effectiveness depends on understanding local socio-cultural\ncontexts. To address this, we introduce SANSKRITI, a benchmark designed to\nevaluate language models' comprehension of India's rich cultural diversity.\nComprising 21,853 meticulously curated question-answer pairs spanning 28 states\nand 8 union territories, SANSKRITI is the largest dataset for testing Indian\ncultural knowledge. It covers sixteen key attributes of Indian culture: rituals\nand ceremonies, history, tourism, cuisine, dance and music, costume, language,\nart, festivals, religion, medicine, transport, sports, nightlife, and\npersonalities, providing a comprehensive representation of India's cultural\ntapestry. We evaluate SANSKRITI on leading Large Language Models (LLMs), Indic\nLanguage Models (ILMs), and Small Language Models (SLMs), revealing significant\ndisparities in their ability to handle culturally nuanced queries, with many\nmodels struggling in region-specific contexts. By offering an extensive,\nculturally rich, and diverse dataset, SANSKRITI sets a new standard for\nassessing and improving the cultural understanding of LMs.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86SANSKRITI\uff0c\u4e00\u4e2a\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u5bf9\u5370\u5ea6\u6587\u5316\u7406\u89e3\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002\u8be5\u6d4b\u8bd5\u5305\u542b21,853\u4e2a\u95ee\u7b54\u5bf9\uff0c\u6db5\u76d6\u5370\u5ea628\u4e2a\u90a6\u548c8\u4e2a\u8054\u90a6\u5c5e\u5730\u768416\u4e2a\u6587\u5316\u5c5e\u6027\uff0c\u662f\u76ee\u524d\u6700\u5927\u7684\u5370\u5ea6\u6587\u5316\u77e5\u8bc6\u6d4b\u8bd5\u6570\u636e\u96c6\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u3001\u6307\u793a\u6027\u8bed\u8a00\u6a21\u578b\uff08ILMs\uff09\u548c\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08SLMs\uff09\u5728\u5904\u7406\u5177\u6709\u6587\u5316\u7279\u5f02\u6027\u7684\u67e5\u8be2\u65f6\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u8bb8\u591a\u6a21\u578b\u5728\u533a\u57df\u6027\u8bed\u5883\u4e0b\u8868\u73b0\u4e0d\u4f73\u3002SANSKRITI\u7684\u63a8\u51fa\u4e3a\u8bc4\u4f30\u548c\u6539\u8fdb\u8bed\u8a00\u6a21\u578b\u7684\u6587\u5316\u7406\u89e3\u80fd\u529b\u8bbe\u5b9a\u4e86\u65b0\u6807\u51c6\u3002", "motivation": "\u5168\u7403\u8303\u56f4\u5185\u8bed\u8a00\u6a21\u578b\u7684\u6709\u6548\u6027\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u4f9d\u8d56\u4e8e\u5b83\u4eec\u5bf9\u5f53\u5730\u793e\u4f1a\u6587\u5316\u80cc\u666f\u7684\u7406\u89e3\u3002\u7136\u800c\uff0c\u76ee\u524d\u7f3a\u4e4f\u4e13\u95e8\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u5bf9\u5370\u5ea6\u4e30\u5bcc\u6587\u5316\u591a\u6837\u6027\u7406\u89e3\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002\u8fd9\u963b\u788d\u4e86\u5728\u5370\u5ea6\u7b49\u6587\u5316\u591a\u5143\u5316\u5730\u533a\u6709\u6548\u90e8\u7f72\u548c\u5e94\u7528\u8bed\u8a00\u6a21\u578b\u3002", "method": "1. \u6570\u636e\u96c6\u6784\u5efa\uff1a\u521b\u5efa\u4e86\u4e00\u4e2a\u540d\u4e3aSANSKRITI\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b21,853\u4e2a\u7cbe\u5fc3\u7b56\u5212\u7684\u95ee\u7b54\u5bf9\u30022. \u8986\u76d6\u8303\u56f4\uff1a\u8be5\u6570\u636e\u96c6\u6db5\u76d6\u4e86\u5370\u5ea6\u768428\u4e2a\u90a6\u548c8\u4e2a\u8054\u90a6\u5c5e\u5730\uff0c\u5e76\u5173\u6ce8\u4e8616\u4e2a\u5173\u952e\u7684\u5370\u5ea6\u6587\u5316\u5c5e\u6027\uff0c\u5305\u62ec\uff1a\u4eea\u5f0f\u4e0e\u5e86\u5178\u3001\u5386\u53f2\u3001\u65c5\u6e38\u3001\u7f8e\u98df\u3001\u821e\u8e48\u4e0e\u97f3\u4e50\u3001\u670d\u9970\u3001\u8bed\u8a00\u3001\u827a\u672f\u3001\u8282\u65e5\u3001\u5b97\u6559\u3001\u533b\u836f\u3001\u4ea4\u901a\u3001\u4f53\u80b2\u3001\u591c\u751f\u6d3b\u548c\u540d\u4eba\u30023. \u6a21\u578b\u8bc4\u4f30\uff1a\u5728SANSKRITI\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8bc4\u4f30\u4e86\u4e3b\u6d41\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u3001\u6307\u793a\u6027\u8bed\u8a00\u6a21\u578b\uff08ILMs\uff09\u548c\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08SLMs\uff09\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0c\u5728\u5904\u7406\u5177\u6709\u6587\u5316\u7279\u5f02\u6027\u7684\u67e5\u8be2\u65f6\uff0c\u4e0d\u540c\u7c7b\u578b\u7684\u8bed\u8a00\u6a21\u578b\u8868\u73b0\u51fa\u663e\u8457\u7684\u6027\u80fd\u5dee\u8ddd\u3002\u8bb8\u591a\u6a21\u578b\u5728\u7406\u89e3\u548c\u56de\u5e94\u7279\u5b9a\u533a\u57df\u7684\u6587\u5316\u8bed\u5883\u65f6\u9047\u5230\u4e86\u56f0\u96be\uff0c\u8868\u660e\u5b83\u4eec\u5bf9\u5370\u5ea6\u6587\u5316\u591a\u6837\u6027\u7684\u638c\u63e1\u7a0b\u5ea6\u4e0d\u8db3\u3002", "conclusion": "SANSKRITI\u662f\u4e00\u4e2a\u5927\u89c4\u6a21\u3001\u6587\u5316\u4e30\u5bcc\u4e14\u591a\u6837\u5316\u7684\u6570\u636e\u96c6\uff0c\u5b83\u4e3a\u8bc4\u4f30\u548c\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u5bf9\u5370\u5ea6\u6587\u5316\u591a\u6837\u6027\u7684\u7406\u89e3\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u7684\u6807\u51c6\u3002\u8be5\u57fa\u51c6\u6d4b\u8bd5\u7684\u8bc4\u4f30\u7ed3\u679c\u63ed\u793a\u4e86\u73b0\u6709\u6a21\u578b\u5728\u6587\u5316\u654f\u611f\u6027\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u4e3a\u672a\u6765\u8bed\u8a00\u6a21\u578b\u5728\u591a\u5143\u6587\u5316\u73af\u5883\u4e0b\u7684\u7814\u7a76\u548c\u5e94\u7528\u6307\u660e\u4e86\u65b9\u5411\u3002"}}
{"id": "2510.01268", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.01268", "abs": "https://arxiv.org/abs/2510.01268", "authors": ["Hongyi Zhou", "Jin Zhu", "Pingfan Su", "Kai Ye", "Ying Yang", "Shakeel A O B Gavioli-Akilagun", "Chengchun Shi"], "title": "AdaDetectGPT: Adaptive Detection of LLM-Generated Text with Statistical Guarantees", "comment": "Accepted by NeurIPS2025", "summary": "We study the problem of determining whether a piece of text has been authored\nby a human or by a large language model (LLM). Existing state of the art\nlogits-based detectors make use of statistics derived from the log-probability\nof the observed text evaluated using the distribution function of a given\nsource LLM. However, relying solely on log probabilities can be sub-optimal. In\nresponse, we introduce AdaDetectGPT -- a novel classifier that adaptively\nlearns a witness function from training data to enhance the performance of\nlogits-based detectors. We provide statistical guarantees on its true positive\nrate, false positive rate, true negative rate and false negative rate.\nExtensive numerical studies show AdaDetectGPT nearly uniformly improves the\nstate-of-the-art method in various combination of datasets and LLMs, and the\nimprovement can reach up to 37\\%. A python implementation of our method is\navailable at https://github.com/Mamba413/AdaDetectGPT.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a AdaDetectGPT \u7684\u65b0\u578b\u6587\u672c\u5206\u7c7b\u5668\uff0c\u7528\u4e8e\u533a\u5206\u4eba\u7c7b\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u7684\u6587\u672c\u3002\u4e0e\u4ec5\u4f9d\u8d56\u5bf9\u6570\u6982\u7387\u7684\u73b0\u6709\u65b9\u6cd5\u4e0d\u540c\uff0cAdaDetectGPT \u80fd\u591f\u81ea\u9002\u5e94\u5730\u4ece\u8bad\u7ec3\u6570\u636e\u4e2d\u5b66\u4e60\u201c\u89c1\u8bc1\u51fd\u6570\u201d\uff0c\u4ece\u800c\u63d0\u5347\u68c0\u6d4b\u6027\u80fd\uff0c\u5e76\u5728\u5404\u79cd\u6570\u636e\u96c6\u548c LLM \u4e0a\u5b9e\u73b0\u4e86\u9ad8\u8fbe 37% \u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u5f53\u524d\u533a\u5206\u4eba\u7c7b\u6587\u672c\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u6587\u672c\u7684\u4efb\u52a1\u9762\u4e34\u6311\u6218\u3002\u73b0\u6709\u7684\u57fa\u4e8e\u5bf9\u6570\u6982\u7387\u7684\u68c0\u6d4b\u5668\u867d\u7136\u6709\u6548\uff0c\u4f46\u5176\u6027\u80fd\u53ef\u80fd\u53d7\u5230\u9650\u5236\uff0c\u65e0\u6cd5\u5145\u5206\u5229\u7528\u6240\u6709\u53ef\u7528\u4fe1\u606f\uff0c\u56e0\u6b64\u5b58\u5728\u63d0\u5347\u7a7a\u95f4\u3002\u7814\u7a76\u7684\u610f\u4e49\u5728\u4e8e\u63d0\u9ad8\u6587\u672c\u771f\u5b9e\u6027\u7684\u9274\u522b\u80fd\u529b\uff0c\u8fd9\u5bf9\u4fe1\u606f\u4f20\u64ad\u7684\u51c6\u786e\u6027\u548c\u5b89\u5168\u6027\u81f3\u5173\u91cd\u8981\u3002", "method": "\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u79cd\u540d\u4e3a AdaDetectGPT \u7684\u65b0\u578b\u5206\u7c7b\u5668\u3002\u8be5\u65b9\u6cd5\u7684\u6838\u5fc3\u5728\u4e8e\u81ea\u9002\u5e94\u5730\u5b66\u4e60\u4e00\u4e2a\u201c\u89c1\u8bc1\u51fd\u6570\u201d\uff08witness function\uff09\u3002\u8fd9\u4e2a\u51fd\u6570\u4ece\u8bad\u7ec3\u6570\u636e\u4e2d\u63d0\u53d6\uff0c\u65e8\u5728\u589e\u5f3a\u73b0\u6709\u7684\u57fa\u4e8e\u5bf9\u6570\u6982\u7387\u7684\u68c0\u6d4b\u5668\u7684\u6027\u80fd\u3002\u7814\u7a76\u8fd8\u5bf9 AdaDetectGPT \u7684\u771f\u9633\u6027\u7387\u3001\u5047\u9633\u6027\u7387\u3001\u771f\u9634\u6027\u7387\u548c\u5047\u9634\u6027\u7387\u63d0\u4f9b\u4e86\u7edf\u8ba1\u4fdd\u8bc1\u3002\u5b9e\u9a8c\u90e8\u5206\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u6570\u503c\u7814\u7a76\uff0c\u4ee5\u8bc4\u4f30\u5176\u6027\u80fd\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u7684\u6570\u503c\u7814\u7a76\uff0cAdaDetectGPT \u5728\u5404\u79cd\u4e0d\u540c\u7684\u6570\u636e\u96c6\u548c LLM \u7ec4\u5408\u4e0b\uff0c\u90fd\u5c55\u73b0\u51fa\u5bf9\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u7684\u8fd1\u4e4e\u5747\u5300\u7684\u6539\u8fdb\u3002\u6027\u80fd\u63d0\u5347\u5e45\u5ea6\u6700\u9ad8\u53ef\u8fbe 37%\u3002\u8fd9\u8868\u660e AdaDetectGPT \u5728\u63d0\u9ad8 LLM \u751f\u6210\u6587\u672c\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u6210\u6548\u3002", "conclusion": "AdaDetectGPT \u662f\u4e00\u79cd\u6709\u6548\u589e\u5f3a LLM \u751f\u6210\u6587\u672c\u68c0\u6d4b\u5668\u6027\u80fd\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u5b66\u4e60\u89c1\u8bc1\u51fd\u6570\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002\u8be5\u7814\u7a76\u4e0d\u4ec5\u5728\u7406\u8bba\u4e0a\u63d0\u4f9b\u4e86\u6027\u80fd\u4fdd\u8bc1\uff0c\u800c\u4e14\u5728\u5b9e\u8df5\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002\u672a\u6765\u53ef\u5728\u6b64\u57fa\u7840\u4e0a\u8fdb\u4e00\u6b65\u63a2\u7d22\u66f4\u590d\u6742\u7684\u68c0\u6d4b\u673a\u5236\u6216\u5e94\u7528\u4e8e\u66f4\u5e7f\u6cdb\u7684\u6587\u672c\u751f\u6210\u573a\u666f\u3002\u9644\u5e26\u7684 Python \u5b9e\u73b0\u4e5f\u65b9\u4fbf\u4e86\u8be5\u65b9\u6cd5\u7684\u63a8\u5e7f\u548c\u5e94\u7528\u3002"}}
{"id": "2509.21837", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.21837", "abs": "https://arxiv.org/abs/2509.21837", "authors": ["Duncan Soiffer", "Steven Kolawole", "Virginia Smith"], "title": "Semantic Agreement Enables Efficient Open-Ended LLM Cascades", "comment": "2025 Conference on Empirical Methods in Natural Language Processing\n  (EMNLP) Industry Track", "summary": "Cascade systems route computational requests to smaller models when possible\nand defer to larger models only when necessary, offering a promising approach\nto balance cost and quality in LLM deployment. However, they face a fundamental\nchallenge in open-ended text generation: determining output reliability when\ngeneration quality lies on a continuous spectrum, often with multiple valid\nresponses. To address this, we propose semantic agreement -- meaning-level\nconsensus between ensemble outputs -- as a training-free signal for reliable\ndeferral. We show that when diverse model outputs agree semantically, their\nconsensus is a stronger reliability signal than token-level confidence.\nEvaluated from 500M to 70B-parameter models, we find that semantic cascades\nmatch or surpass target-model quality at 40% of the cost and reduce latency by\nup to 60%. Our method requires no model internals, works across black-box APIs,\nand remains robust to model updates, making it a practical baseline for\nreal-world LLM deployment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u8bed\u4e49\u7ea7\u8054\u201d\u7684\u65b0\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u90e8\u7f72\u4e2d\u5e73\u8861\u6210\u672c\u548c\u8d28\u91cf\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u4e00\u79cd\u79f0\u4e3a\u201c\u8bed\u4e49\u5171\u8bc6\u201d\u7684\u8bad\u7ec3\u65e0\u5173\u4fe1\u53f7\u6765\u5224\u65ad\u8f93\u51fa\u7684\u53ef\u9760\u6027\uff0c\u5f53\u4e0d\u540c\u6a21\u578b\u751f\u6210\u7684\u8f93\u5728\u8bed\u4e49\u4e0a\u8fbe\u6210\u4e00\u81f4\u65f6\uff0c\u5c31\u8ba4\u4e3a\u8f93\u51fa\u662f\u53ef\u9760\u7684\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8bed\u4e49\u7ea7\u8054\u5728\u6210\u672c\u964d\u4f4e 40% \u548c\u5ef6\u8fdf\u51cf\u5c11 60% \u7684\u540c\u65f6\uff0c\u80fd\u591f\u8fbe\u5230\u6216\u8d85\u8fc7\u76ee\u6807\u6a21\u578b\u7684\u8d28\u91cf\u3002\u8be5\u65b9\u6cd5\u9002\u7528\u4e8e\u9ed1\u76d2 API\uff0c\u4e14\u4e0d\u4f9d\u8d56\u6a21\u578b\u5185\u90e8\u4fe1\u606f\uff0c\u662f\u4e00\u79cd\u5b9e\u7528\u7684 LLM \u90e8\u7f72\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u73b0\u6709\u7684\u7ea7\u8054\u7cfb\u7edf\u867d\u7136\u53ef\u4ee5\u901a\u8fc7\u5c06\u8ba1\u7b97\u8bf7\u6c42\u8def\u7531\u5230\u66f4\u5c0f\u7684\u6a21\u578b\u6765\u964d\u4f4e\u6210\u672c\uff0c\u4f46\u5728\u5f00\u653e\u5f0f\u6587\u672c\u751f\u6210\u4efb\u52a1\u4e2d\u5b58\u5728\u4e00\u4e2a\u6839\u672c\u6027\u95ee\u9898\uff1a\u5982\u4f55\u786e\u5b9a\u8f93\u51fa\u7684\u53ef\u9760\u6027\uff0c\u56e0\u4e3a\u751f\u6210\u8d28\u91cf\u901a\u5e38\u5904\u4e8e\u4e00\u4e2a\u8fde\u7eed\u7684\u5149\u8c31\u4e0a\uff0c\u5e76\u4e14\u53ef\u80fd\u5b58\u5728\u591a\u4e2a\u6709\u6548\u54cd\u5e94\u3002\u8fd9\u4f7f\u5f97\u5728\u6210\u672c\u548c\u8d28\u91cf\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u53d8\u5f97\u56f0\u96be\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u8bed\u4e49\u5171\u8bc6\u201d\u7684\u8bad\u7ec3\u65e0\u5173\u4fe1\u53f7\uff0c\u7528\u4e8e\u5224\u65ad\u8f93\u51fa\u7684\u53ef\u9760\u6027\u3002\u5f53\u591a\u4e2a\u6a21\u578b\u751f\u6210\u7684\u8f93\u51fa\u5728\u8bed\u4e49\u5c42\u9762\u4e0a\u8fbe\u6210\u4e00\u81f4\u65f6\uff0c\u8fd9\u79cd\u5171\u8bc6\u5c31\u88ab\u89c6\u4e3a\u4e00\u4e2a\u53ef\u9760\u7684\u4fe1\u53f7\u3002\u8be5\u65b9\u6cd5\u4e0d\u4f9d\u8d56\u4e8e\u6a21\u578b\u5185\u90e8\u7684\u4efb\u4f55\u4fe1\u606f\uff0c\u53ef\u4ee5\u76f4\u63a5\u5e94\u7528\u4e8e\u9ed1\u76d2 API\uff0c\u5e76\u4e14\u80fd\u591f\u9002\u5e94\u6a21\u578b\u66f4\u65b0\u3002", "result": "\u5728 5 \u4ebf\u5230 700 \u4ebf\u53c2\u6570\u7684\u6a21\u578b\u4e0a\u8fdb\u884c\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u8bed\u4e49\u7ea7\u8054\u5728\u4fdd\u8bc1\u6a21\u578b\u8d28\u91cf\u7684\u540c\u65f6\uff0c\u6210\u672c\u964d\u4f4e\u4e86 40%\uff0c\u5ef6\u8fdf\u51cf\u5c11\u4e86\u9ad8\u8fbe 60%\u3002", "conclusion": "\u8bed\u4e49\u7ea7\u8054\u901a\u8fc7\u5229\u7528\u201c\u8bed\u4e49\u5171\u8bc6\u201d\u4f5c\u4e3a\u4e00\u79cd\u8bad\u7ec3\u65e0\u5173\u7684\u53ef\u9760\u6027\u4fe1\u53f7\uff0c\u6709\u6548\u5730\u89e3\u51b3\u4e86\u5f00\u653e\u5f0f\u6587\u672c\u751f\u6210\u4e2d\u7ea7\u8054\u7cfb\u7edf\u7684\u6311\u6218\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u8bbf\u95ee\u6a21\u578b\u5185\u90e8\uff0c\u53ef\u7528\u4e8e\u9ed1\u76d2 API\uff0c\u5e76\u5bf9\u6a21\u578b\u66f4\u65b0\u5177\u6709\u9c81\u68d2\u6027\uff0c\u4e3a\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u4e14\u9ad8\u6548\u7684\u57fa\u51c6\u3002"}}
{"id": "2510.03490", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.03490", "abs": "https://arxiv.org/abs/2510.03490", "authors": ["Aneesha Sampath", "Oya Aran", "Emily Mower Provost"], "title": "SEER: The Span-based Emotion Evidence Retrieval Benchmark", "comment": null, "summary": "We introduce the SEER (Span-based Emotion Evidence Retrieval) Benchmark to\ntest Large Language Models' (LLMs) ability to identify the specific spans of\ntext that express emotion. Unlike traditional emotion recognition tasks that\nassign a single label to an entire sentence, SEER targets the underexplored\ntask of emotion evidence detection: pinpointing which exact phrases convey\nemotion. This span-level approach is crucial for applications like empathetic\ndialogue and clinical support, which need to know how emotion is expressed, not\njust what the emotion is. SEER includes two tasks: identifying emotion evidence\nwithin a single sentence, and identifying evidence across a short passage of\nfive consecutive sentences. It contains new annotations for both emotion and\nemotion evidence on 1200 real-world sentences. We evaluate 14 open-source LLMs\nand find that, while some models approach average human performance on\nsingle-sentence inputs, their accuracy degrades in longer passages. Our error\nanalysis reveals key failure modes, including overreliance on emotion keywords\nand false positives in neutral text.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86SEER\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8bc6\u522b\u6587\u672c\u4e2d\u8868\u8fbe\u60c5\u611f\u7684\u5177\u4f53\u6587\u672c\u7247\u6bb5\uff08span\uff09\u7684\u80fd\u529b\u3002\u8be5\u57fa\u51c6\u6d4b\u8bd5\u5305\u542b\u4e24\u4e2a\u4efb\u52a1\uff1a\u5728\u5355\u53e5\u5185\u8bc6\u522b\u60c5\u611f\u8bc1\u636e\uff0c\u4ee5\u53ca\u5728\u5305\u542b\u4e94\u4e2a\u8fde\u7eed\u53e5\u5b50\u7684\u77ed\u6587\u6bb5\u4e2d\u8bc6\u522b\u8bc1\u636e\u3002\u7814\u7a76\u8bc4\u4f30\u4e8614\u4e2a\u5f00\u6e90LLM\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u5355\u53e5\u8f93\u5165\u4e0a\u8868\u73b0\u5c1a\u53ef\uff0c\u4f46\u5728\u5904\u7406\u957f\u6587\u672c\u65f6\u51c6\u786e\u7387\u4e0b\u964d\u3002\u9519\u8bef\u5206\u6790\u63ed\u793a\u4e86\u6a21\u578b\u8fc7\u5ea6\u4f9d\u8d56\u60c5\u611f\u5173\u952e\u8bcd\u548c\u5728\u975e\u60c5\u611f\u6587\u672c\u4e2d\u4ea7\u751f\u8bef\u62a5\u7b49\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u7684\u60c5\u611f\u8bc6\u522b\u4efb\u52a1\u901a\u5e38\u5c06\u5355\u4e00\u6807\u7b7e\u5206\u914d\u7ed9\u6574\u4e2a\u53e5\u5b50\uff0c\u4f46\u672a\u80fd\u6355\u6349\u60c5\u611f\u7684\u5177\u4f53\u8868\u8fbe\u65b9\u5f0f\u3002\u7136\u800c\uff0c\u5728\u9700\u8981\u7406\u89e3\u60c5\u611f\u8868\u8fbe\u7ec6\u8282\u7684\u5e94\u7528\uff08\u5982\u5171\u60c5\u5bf9\u8bdd\u548c\u4e34\u5e8a\u652f\u6301\uff09\u4e2d\uff0c\u8bc6\u522b\u51fa\u4f20\u8fbe\u60c5\u611f\u7684\u786e\u5207\u77ed\u8bed\u81f3\u5173\u91cd\u8981\u3002\u56e0\u6b64\uff0c\u672c\u6587\u65e8\u5728\u89e3\u51b3\u60c5\u611f\u8bc1\u636e\u68c0\u6d4b\u8fd9\u4e00\u672a\u88ab\u5145\u5206\u63a2\u7d22\u7684\u4efb\u52a1\uff0c\u4ee5\u586b\u8865\u73b0\u6709\u7814\u7a76\u7684\u7a7a\u767d\u3002", "method": "\u672c\u6587\u5f15\u5165\u4e86SEER\uff08Span-based Emotion Evidence Retrieval\uff09\u57fa\u51c6\u6d4b\u8bd5\u3002\u8be5\u57fa\u51c6\u6d4b\u8bd5\u5305\u542b\u5bf91200\u4e2a\u771f\u5b9e\u4e16\u754c\u53e5\u5b50\u8fdb\u884c\u7684\u60c5\u611f\u548c\u60c5\u611f\u8bc1\u636e\u7684\u65b0\u6807\u6ce8\u3002SEER\u5305\u542b\u4e24\u4e2a\u5b50\u4efb\u52a1\uff1a1. \u5728\u5355\u53e5\u5185\u90e8\u8bc6\u522b\u60c5\u611f\u8bc1\u636e\uff1b2. \u5728\u5305\u542b\u4e94\u4e2a\u8fde\u7eed\u53e5\u5b50\u7684\u77ed\u6587\u6bb5\u4e2d\u8bc6\u522b\u60c5\u611f\u8bc1\u636e\u3002\u7814\u7a76\u8bc4\u4f30\u4e8614\u4e2a\u5f00\u6e90LLM\u5728SEER\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u5728SEER\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0c\u4e00\u4e9b\u6a21\u578b\u5728\u5355\u53e5\u8f93\u5165\u4e0a\u7684\u8868\u73b0\u63a5\u8fd1\u5e73\u5747\u4eba\u7c7b\u6c34\u5e73\u3002\u7136\u800c\uff0c\u6a21\u578b\u5728\u5904\u7406\u5305\u542b\u4e94\u4e2a\u8fde\u7eed\u53e5\u5b50\u7684\u8f83\u957f\u6587\u672c\u6bb5\u65f6\uff0c\u51c6\u786e\u7387\u660e\u663e\u4e0b\u964d\u3002\u9519\u8bef\u5206\u6790\u8868\u660e\uff0c\u6a21\u578b\u503e\u5411\u4e8e\u8fc7\u5ea6\u4f9d\u8d56\u60c5\u611f\u5173\u952e\u8bcd\uff0c\u5e76\u5728\u4e2d\u6027\u6587\u672c\u4e2d\u4ea7\u751f\u8bef\u62a5\uff0c\u8fd9\u8868\u660e\u6a21\u578b\u5728\u7406\u89e3\u4e0a\u4e0b\u6587\u548c\u7ec6\u5fae\u60c5\u611f\u8868\u8fbe\u65b9\u9762\u4ecd\u5b58\u5728\u6311\u6218\u3002", "conclusion": "SEER\u57fa\u51c6\u6d4b\u8bd5\u7684\u63d0\u51fa\u4e3a\u8bc4\u4f30LLM\u5728\u60c5\u611f\u8bc1\u636e\u68c0\u6d4b\u65b9\u9762\u7684\u80fd\u529b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u5e73\u53f0\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5c3d\u7ba1LLM\u5728\u8bc6\u522b\u5355\u53e5\u4e2d\u7684\u60c5\u611f\u8bc1\u636e\u65b9\u9762\u53d6\u5f97\u4e86\u4e00\u5b9a\u8fdb\u5c55\uff0c\u4f46\u5728\u66f4\u590d\u6742\u7684\u957f\u6587\u672c\u573a\u666f\u4e0b\u4ecd\u9700\u6539\u8fdb\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u96c6\u4e2d\u5728\u5f00\u53d1\u80fd\u591f\u66f4\u597d\u5730\u7406\u89e3\u4e0a\u4e0b\u6587\u3001\u51cf\u5c11\u5bf9\u5173\u952e\u8bcd\u4f9d\u8d56\u5e76\u63d0\u9ad8\u5728\u975e\u60c5\u611f\u6587\u672c\u4e2d\u533a\u5206\u80fd\u529b\u7684\u6a21\u578b\u3002SplashScreen"}}
{"id": "2509.24494", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.24494", "abs": "https://arxiv.org/abs/2509.24494", "authors": ["Hongcheng Wang", "Yinuo Huang", "Sukai Wang", "Guanghui Ren", "Hao Dong"], "title": "GRPO-MA: Multi-Answer Generation in GRPO for Stable and Efficient Chain-of-Thought Training", "comment": "Under review", "summary": "Recent progress, such as DeepSeek-R1, has shown that the GRPO algorithm, a\nReinforcement Learning (RL) approach, can effectively train Chain-of-Thought\n(CoT) reasoning in Large Language Models (LLMs) and Vision-Language Models\n(VLMs). In this paper, we analyze three challenges of GRPO: gradient coupling\nbetween thoughts and answers, sparse reward signals caused by limited parallel\nsampling, and unstable advantage estimation. To mitigate these challenges, we\npropose GRPO-MA, a simple yet theoretically grounded method that leverages\nmulti-answer generation from each thought process, enabling more robust and\nefficient optimization. Theoretically, we show that the variance of thought\nadvantage decreases as the number of answers per thought increases.\nEmpirically, our gradient analysis confirms this effect, showing that GRPO-MA\nreduces gradient spikes compared to GRPO. Experiments on math, code, and\ndiverse multimodal tasks demonstrate that GRPO-MA substantially improves\nperformance and training efficiency. Our ablation studies further reveal that\nincreasing the number of answers per thought consistently enhances model\nperformance.", "AI": {"tldr": "GRPO-MA\u901a\u8fc7\u751f\u6210\u6bcf\u4e2a\u601d\u8003\u8fc7\u7a0b\u7684\u591a\u4e2a\u7b54\u6848\u6765\u89e3\u51b3GRPO\u7b97\u6cd5\u5728\u8bad\u7ec3LLMs\u548cVLMs\u8fdb\u884cCoT\u63a8\u7406\u65f6\u9047\u5230\u7684\u68af\u5ea6\u8026\u5408\u3001\u7a00\u758f\u5956\u52b1\u548c\u4e0d\u7a33\u5b9a\u7684\u4f18\u52bf\u4f30\u8ba1\u95ee\u9898\u3002\u7406\u8bba\u548c\u5b9e\u9a8c\u5747\u8868\u660e\uff0c\u589e\u52a0\u6bcf\u4e2a\u601d\u8003\u8fc7\u7a0b\u7684\u7b54\u6848\u6570\u91cf\u53ef\u4ee5\u51cf\u5c11\u4f18\u52bf\u4f30\u8ba1\u7684\u65b9\u5dee\uff0c\u964d\u4f4e\u68af\u5ea6\u5cf0\u503c\uff0c\u4ece\u800c\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u548c\u6a21\u578b\u5728\u6570\u5b66\u3001\u4ee3\u7801\u53ca\u591a\u6a21\u6001\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "GRPO\u7b97\u6cd5\u5728\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u8fdb\u884c\u601d\u7ef4\u94fe\uff08CoT\uff09\u63a8\u7406\u65b9\u9762\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u5b58\u5728\u68af\u5ea6\u8026\u5408\u3001\u5956\u52b1\u7a00\u758f\u548c\u4f18\u52bf\u4f30\u8ba1\u4e0d\u7a33\u5b9a\u7b49\u6311\u6218\u3002\u8fd9\u4e9b\u6311\u6218\u9650\u5236\u4e86GRPO\u7684\u6709\u6548\u6027\u548c\u6548\u7387\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u7814\u7a76\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u514b\u670d\u8fd9\u4e9b\u9650\u5236\uff0c\u4ee5\u66f4\u6709\u6548\u5730\u8bad\u7ec3CoT\u63a8\u7406\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86GRPO-MA\uff0c\u4e00\u79cd\u5229\u7528\u6bcf\u4e2a\u601d\u8003\u8fc7\u7a0b\u751f\u6210\u591a\u4e2a\u7b54\u6848\u7684\u65b9\u6cd5\uff0c\u6765\u89e3\u51b3GRPO\u9762\u4e34\u7684\u6311\u6218\u3002\u7406\u8bba\u4e0a\uff0c\u8bc1\u660e\u4e86\u589e\u52a0\u6bcf\u4e2a\u601d\u8003\u8fc7\u7a0b\u7684\u7b54\u6848\u6570\u91cf\u53ef\u4ee5\u51cf\u5c0f\u5176\u4f18\u52bf\u4f30\u8ba1\u7684\u65b9\u5dee\u3002\u5b9e\u9a8c\u4e0a\uff0c\u901a\u8fc7\u68af\u5ea6\u5206\u6790\u9a8c\u8bc1\u4e86GRPO-MA\u53ef\u4ee5\u51cf\u5c11\u68af\u5ea6\u5cf0\u503c\u3002\u5728\u6570\u5b66\u3001\u4ee3\u7801\u548c\u591a\u6a21\u6001\u4efb\u52a1\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u5e76\u5c06GRPO-MA\u4e0eGRPO\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002\u6b64\u5916\uff0c\u8fd8\u8fdb\u884c\u4e86\u6d88\u878d\u7814\u7a76\uff0c\u4ee5\u8bc4\u4f30\u589e\u52a0\u6bcf\u4e2a\u601d\u8003\u8fc7\u7a0b\u7684\u7b54\u6848\u6570\u91cf\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cGRPO-MA\u5728\u964d\u4f4e\u68af\u5ea6\u5cf0\u503c\u65b9\u9762\u4f18\u4e8eGRPO\u3002\u5728\u6570\u5b66\u3001\u4ee3\u7801\u548c\u591a\u6a21\u6001\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cGRPO-MA\u80fd\u591f\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u548c\u8bad\u7ec3\u6548\u7387\u3002\u6d88\u878d\u7814\u7a76\u8fdb\u4e00\u6b65\u8bc1\u5b9e\uff0c\u589e\u52a0\u6bcf\u4e2a\u601d\u8003\u8fc7\u7a0b\u7684\u7b54\u6848\u6570\u91cf\u80fd\u591f\u6301\u7eed\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "GRPO-MA\u901a\u8fc7\u751f\u6210\u591a\u7b54\u6848\u6765\u6709\u6548\u89e3\u51b3GRPO\u5728CoT\u63a8\u7406\u8bad\u7ec3\u4e2d\u7684\u6311\u6218\uff0c\u63d0\u9ad8\u4e86\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u6548\u7387\uff0c\u5e76\u5728\u591a\u9879\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u6027\u80fd\u63d0\u5347\u3002\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u5728\u7406\u8bba\u4e0a\u5f97\u5230\u652f\u6301\uff0c\u5728\u5b9e\u8df5\u4e2d\u4e5f\u5f97\u5230\u4e86\u9a8c\u8bc1\u3002\u672a\u6765\u7684\u5de5\u4f5c\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63a2\u7d22\u591a\u7b54\u6848\u751f\u6210\u7b56\u7565\u7684\u4f18\u5316\u548c\u5728\u66f4\u5e7f\u6cdb\u4efb\u52a1\u4e0a\u7684\u5e94\u7528\u3002"}}
{"id": "2510.15545", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15545", "abs": "https://arxiv.org/abs/2510.15545", "authors": ["Sibo Xiao", "Jinyuan Fu", "Zhongle Xie", "Lidan Shou"], "title": "TokenTiming: A Dynamic Alignment Method for Universal Speculative Decoding Model Pairs", "comment": null, "summary": "Accelerating the inference of large language models (LLMs) has been a\ncritical challenge in generative AI. Speculative decoding (SD) substantially\nimproves LLM inference efficiency. However, its utility is limited by a\nfundamental constraint: the draft and target models must share the same\nvocabulary, thus limiting the herd of available draft models and often\nnecessitating the training of a new model from scratch. Inspired by Dynamic\nTime Warping (DTW), a classic algorithm for aligning time series, we propose\nthe algorithm TokenTiming for universal speculative decoding. It operates by\nre-encoding the draft token sequence to get a new target token sequence, and\nthen uses DTW to build a mapping to transfer the probability distributions for\nspeculative sampling. Benefiting from this, our method accommodates mismatched\nvocabularies and works with any off-the-shelf models without retraining and\nmodification. We conduct comprehensive experiments on various tasks,\ndemonstrating 1.57x speedup. This work enables a universal approach for draft\nmodel selection, making SD a more versatile and practical tool for LLM\nacceleration.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTokenTiming\u7684\u901a\u7528\u6295\u673a\u89e3\u7801\u7b97\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u65f6\u95f4\u89c4\u6574\uff08DTW\uff09\u6280\u672f\u89e3\u51b3\u4e86\u73b0\u6709\u6295\u673a\u89e3\u7801\u7b97\u6cd5\u4e2d\u8349\u7a3f\u6a21\u578b\u548c\u76ee\u6807\u6a21\u578b\u5fc5\u987b\u5171\u4eab\u76f8\u540c\u8bcd\u6c47\u7684\u9650\u5236\uff0c\u5b9e\u73b0\u4e861.57\u500d\u7684\u52a0\u901f\uff0c\u5e76\u5141\u8bb8\u4f7f\u7528\u4efb\u4f55\u73b0\u6210\u7684\u6a21\u578b\u800c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6216\u4fee\u6539\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u63a8\u7406\u52a0\u901f\u662f\u751f\u6210\u5f0fAI\u4e2d\u7684\u4e00\u4e2a\u5173\u952e\u6311\u6218\u3002\u6295\u673a\u89e3\u7801\uff08SD\uff09\u662f\u4e00\u79cd\u6709\u6548\u63d0\u5347LLM\u63a8\u7406\u6548\u7387\u7684\u65b9\u6cd5\uff0c\u4f46\u5176\u5e94\u7528\u53d7\u5230\u8349\u7a3f\u6a21\u578b\u548c\u76ee\u6807\u6a21\u578b\u5fc5\u987b\u5171\u4eab\u76f8\u540c\u8bcd\u6c47\u7684\u9650\u5236\uff0c\u8fd9\u4e0d\u4ec5\u9650\u5236\u4e86\u53ef\u7528\u8349\u7a3f\u6a21\u578b\u7684\u9009\u62e9\u8303\u56f4\uff0c\u8fd8\u5e38\u5e38\u9700\u8981\u4ece\u5934\u5f00\u59cb\u8bad\u7ec3\u65b0\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTokenTiming\u7684\u901a\u7528\u6295\u673a\u89e3\u7801\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u501f\u9274\u4e86\u52a8\u6001\u65f6\u95f4\u89c4\u6574\uff08DTW\uff09\u7684\u601d\u60f3\u3002TokenTiming\u901a\u8fc7\u91cd\u65b0\u7f16\u7801\u8349\u7a3f\u6a21\u578b\u7684\u8bcd\u5143\u5e8f\u5217\u6765\u751f\u6210\u65b0\u7684\u76ee\u6807\u8bcd\u5143\u5e8f\u5217\uff0c\u5e76\u5229\u7528DTW\u5efa\u7acb\u6620\u5c04\u5173\u7cfb\uff0c\u4ece\u800c\u5c06\u6982\u7387\u5206\u5e03\u8f6c\u79fb\u4ee5\u8fdb\u884c\u6295\u673a\u91c7\u6837\u3002\u8fd9\u79cd\u65b9\u6cd5\u80fd\u591f\u5904\u7406\u8bcd\u6c47\u4e0d\u5339\u914d\u7684\u95ee\u9898\uff0c\u5e76\u9002\u7528\u4e8e\u4efb\u4f55\u73b0\u6210\u7684\u6a21\u578b\uff0c\u65e0\u9700\u8fdb\u884c\u518d\u8bad\u7ec3\u6216\u4fee\u6539\u3002\u5728\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u79cd\u4efb\u52a1\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u6d4b\u8bd5\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0cTokenTiming\u7b97\u6cd5\u80fd\u591f\u5b9e\u73b01.57\u500d\u7684\u52a0\u901f\u6548\u679c\u3002", "conclusion": "TokenTiming\u7b97\u6cd5\u4e3a\u8349\u7a3f\u6a21\u578b\u7684\u9009\u62e9\u63d0\u4f9b\u4e86\u4e00\u79cd\u901a\u7528\u7684\u65b9\u6cd5\uff0c\u514b\u670d\u4e86\u73b0\u6709\u6295\u673a\u89e3\u7801\u7b97\u6cd5\u7684\u8bcd\u6c47\u9650\u5236\uff0c\u4f7f\u5f97\u6295\u673a\u89e3\u7801\u6210\u4e3a\u4e00\u4e2a\u66f4\u901a\u7528\u3001\u66f4\u5b9e\u7528\u7684LLM\u52a0\u901f\u5de5\u5177\u3002\u8be5\u7814\u7a76\u4e3aLLM\u63a8\u7406\u6548\u7387\u7684\u63d0\u5347\u5f00\u8f9f\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2509.24958", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.24958", "abs": "https://arxiv.org/abs/2509.24958", "authors": ["Linlu Gong", "Ante Wang", "Yunghwei Lai", "Weizhi Ma", "Yang Liu"], "title": "The Dialogue That Heals: A Comprehensive Evaluation of Doctor Agents' Inquiry Capability", "comment": null, "summary": "An effective physician should possess a combination of empathy, expertise,\npatience, and clear communication when treating a patient. Recent advances have\nsuccessfully endowed AI doctors with expert diagnostic skills, particularly the\nability to actively seek information through inquiry. However, other essential\nqualities of a good doctor remain overlooked. To bridge this gap, we present\nMAQuE(Medical Agent Questioning Evaluation), the largest-ever benchmark for the\nautomatic and comprehensive evaluation of medical multi-turn questioning. It\nfeatures 3,000 realistically simulated patient agents that exhibit diverse\nlinguistic patterns, cognitive limitations, emotional responses, and tendencies\nfor passive disclosure. We also introduce a multi-faceted evaluation framework,\ncovering task success, inquiry proficiency, dialogue competence, inquiry\nefficiency, and patient experience. Experiments on different LLMs reveal\nsubstantial challenges across the evaluation aspects. Even state-of-the-art\nmodels show significant room for improvement in their inquiry capabilities.\nThese models are highly sensitive to variations in realistic patient behavior,\nwhich considerably impacts diagnostic accuracy. Furthermore, our fine-grained\nmetrics expose trade-offs between different evaluation perspectives,\nhighlighting the challenge of balancing performance and practicality in\nreal-world clinical settings.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86MAQuE\uff0c\u4e00\u4e2a\u5305\u542b3000\u4e2a\u6a21\u62df\u60a3\u8005\u7684\u533b\u7597\u591a\u8f6e\u95ee\u8bca\u8bc4\u4f30\u57fa\u51c6\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u4e2a\u591a\u7ef4\u5ea6\u8bc4\u4f30\u6846\u67b6\uff0c\u65e8\u5728\u5168\u9762\u8bc4\u4f30AI\u533b\u751f\u7684\u95ee\u8bca\u80fd\u529b\uff0c\u53d1\u73b0\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6a21\u62df\u771f\u5b9e\u60a3\u8005\u4ea4\u4e92\u548c\u8bca\u65ad\u51c6\u786e\u6027\u65b9\u9762\u4ecd\u6709\u663e\u8457\u63d0\u5347\u7a7a\u95f4\uff0c\u5e76\u63ed\u793a\u4e86\u4e0d\u540c\u8bc4\u4f30\u7ef4\u5ea6\u95f4\u7684\u6743\u8861\u3002", "motivation": "\u5c3d\u7ba1AI\u5728\u533b\u5b66\u8bca\u65ad\u65b9\u9762\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u540c\u7406\u5fc3\u3001\u8010\u5fc3\u548c\u6e05\u6670\u6c9f\u901a\u7b49\u533b\u751f\u5e94\u5177\u5907\u7684\u5176\u4ed6\u91cd\u8981\u54c1\u8d28\u4ecd\u88ab\u5ffd\u89c6\u3002\u73b0\u6709AI\u533b\u751f\u5728\u4e3b\u52a8\u83b7\u53d6\u4fe1\u606f\u65b9\u9762\u6709\u6240\u6b20\u7f3a\uff0c\u65e0\u6cd5\u5168\u9762\u6a21\u62df\u4e00\u540d\u4f18\u79c0\u533b\u751f\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u5168\u9762\u8bc4\u4f30AI\u533b\u751f\u5728\u591a\u8f6e\u95ee\u8bca\u4e2d\u8868\u73b0\u7684\u57fa\u51c6\uff0c\u4ee5\u5f25\u8865\u8fd9\u4e00\u5dee\u8ddd\uff0c\u5e76\u63a8\u52a8AI\u5728\u533b\u7597\u9886\u57df\u66f4\u5168\u9762\u3001\u66f4\u4eba\u6027\u5316\u7684\u53d1\u5c55\u3002", "method": "\u7814\u7a76\u8005\u6784\u5efa\u4e86MAQuE\uff08Medical Agent Questioning Evaluation\uff09\u57fa\u51c6\uff0c\u5305\u542b3000\u4e2a\u6a21\u62df\u60a3\u8005\uff0c\u8fd9\u4e9b\u60a3\u8005\u5177\u6709\u591a\u6837\u7684\u8bed\u8a00\u6a21\u5f0f\u3001\u8ba4\u77e5\u5c40\u9650\u3001\u60c5\u7eea\u53cd\u5e94\u548c\u88ab\u52a8\u62ab\u9732\u503e\u5411\u3002\u4ed6\u4eec\u8fd8\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u591a\u65b9\u9762\u8bc4\u4f30\u6846\u67b6\uff0c\u6db5\u76d6\u4efb\u52a1\u6210\u529f\u7387\u3001\u95ee\u8bca\u719f\u7ec3\u5ea6\u3001\u5bf9\u8bdd\u80fd\u529b\u3001\u95ee\u8bca\u6548\u7387\u548c\u60a3\u8005\u4f53\u9a8c\u3002\u5728\u4e0d\u540c\u7684LLM\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u4ee5\u8bc4\u4f30\u5176\u5728\u8fd9\u4e9b\u65b9\u9762\u7684\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5373\u4f7f\u662f\u5148\u8fdb\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u95ee\u8bca\u80fd\u529b\u65b9\u9762\u4e5f\u9762\u4e34\u5de8\u5927\u6311\u6218\u3002\u6a21\u578b\u5728\u5904\u7406\u771f\u5b9e\u60a3\u8005\u884c\u4e3a\u53d8\u5316\u65f6\u8868\u73b0\u51fa\u9ad8\u5ea6\u654f\u611f\u6027\uff0c\u8fd9\u663e\u8457\u5f71\u54cd\u4e86\u8bca\u65ad\u51c6\u786e\u6027\u3002\u7cbe\u7ec6\u5316\u6307\u6807\u7684\u5206\u6790\u8fd8\u63ed\u793a\u4e86\u4e0d\u540c\u8bc4\u4f30\u89c6\u89d2\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u51f8\u663e\u4e86\u5728\u73b0\u5b9e\u4e34\u5e8a\u73af\u5883\u4e2d\u5e73\u8861\u6027\u80fd\u548c\u5b9e\u7528\u6027\u7684\u96be\u5ea6\u3002", "conclusion": "MAQuE\u57fa\u51c6\u548c\u8bc4\u4f30\u6846\u67b6\u4e3a\u5168\u9762\u8bc4\u4f30AI\u533b\u751f\u7684\u591a\u8f6e\u95ee\u8bca\u80fd\u529b\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u73b0\u6709LLM\u5728\u6a21\u62df\u771f\u5b9e\u60a3\u8005\u4ea4\u4e92\u548c\u4fdd\u6301\u8bca\u65ad\u51c6\u786e\u6027\u65b9\u9762\u4ecd\u5b58\u5728\u663e\u8457\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u60a3\u8005\u884c\u4e3a\u7684\u591a\u6837\u6027\u548c\u60c5\u7eea\u65f6\u3002\u672a\u6765\u7684\u7814\u7a76\u9700\u8981\u5173\u6ce8\u5982\u4f55\u63d0\u9ad8AI\u533b\u751f\u5728\u8fd9\u4e9b\u65b9\u9762\u7684\u8868\u73b0\uff0c\u4ee5\u53ca\u5982\u4f55\u5728\u4e0d\u540c\u8bc4\u4f30\u6307\u6807\u4e4b\u95f4\u627e\u5230\u6700\u4f73\u5e73\u8861\u70b9\uff0c\u4ee5\u5b9e\u73b0\u66f4\u53ef\u9760\u3001\u66f4\u4eba\u6027\u5316\u7684AI\u533b\u7597\u52a9\u624b\u3002"}}
{"id": "2510.10114", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.10114", "abs": "https://arxiv.org/abs/2510.10114", "authors": ["Luyao Zhuang", "Shengyuan Chen", "Yilin Xiao", "Huachi Zhou", "Yujing Zhang", "Hao Chen", "Qinggang Zhang", "Xiao Huang"], "title": "LinearRAG: Linear Graph Retrieval Augmented Generation on Large-scale Corpora", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) is widely used to mitigate\nhallucinations of Large Language Models (LLMs) by leveraging external\nknowledge. While effective for simple queries, traditional RAG systems struggle\nwith large-scale, unstructured corpora where information is fragmented. Recent\nadvances incorporate knowledge graphs to capture relational structures,\nenabling more comprehensive retrieval for complex, multi-hop reasoning tasks.\nHowever, existing graph-based RAG (GraphRAG) methods rely on unstable and\ncostly relation extraction for graph construction, often producing noisy graphs\nwith incorrect or inconsistent relations that degrade retrieval quality. In\nthis paper, we revisit the pipeline of existing GraphRAG systems and propose\nLinearRAG (Linear Graph-based Retrieval-Augmented Generation), an efficient\nframework that enables reliable graph construction and precise passage\nretrieval. Specifically, LinearRAG constructs a relation-free hierarchical\ngraph, termed Tri-Graph, using only lightweight entity extraction and semantic\nlinking, avoiding unstable relation modeling. This new paradigm of graph\nconstruction scales linearly with corpus size and incurs no extra token\nconsumption, providing an economical and reliable indexing of the original\npassages. For retrieval, LinearRAG adopts a two-stage strategy: (i) relevant\nentity activation via local semantic bridging, followed by (ii) passage\nretrieval through global importance aggregation. Extensive experiments on four\ndatasets demonstrate that LinearRAG significantly outperforms baseline models.\nOur code and datasets are available at https://github.com/DEEP-PolyU/LinearRAG.", "AI": {"tldr": "LinearRAG\u662f\u4e00\u79cd\u65b0\u7684\u56fe\u589e\u5f3a\u68c0\u7d22\u751f\u6210\uff08GraphRAG\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u5173\u7cfb\u65e0\u5173\u7684\u5c42\u6b21\u56fe\uff08Tri-Graph\uff09\u5e76\u91c7\u7528\u4e24\u9636\u6bb5\u68c0\u7d22\u7b56\u7565\uff0c\u89e3\u51b3\u4e86\u73b0\u6709GraphRAG\u65b9\u6cd5\u5728\u5904\u7406\u5927\u89c4\u6a21\u975e\u7ed3\u6784\u5316\u8bed\u6599\u5e93\u65f6\u9047\u5230\u7684\u56fe\u6784\u5efa\u4e0d\u7a33\u5b9a\u548c\u68c0\u7d22\u8d28\u91cf\u4e0b\u964d\u7684\u95ee\u9898\u3002\u5b9e\u9a8c\u8868\u660e\uff0cLinearRAG\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7cfb\u7edf\u5728\u5904\u7406\u5927\u89c4\u6a21\u3001\u975e\u7ed3\u6784\u5316\u8bed\u6599\u5e93\u65f6\uff0c\u7279\u522b\u662f\u5f53\u4fe1\u606f\u5206\u6563\u65f6\uff0c\u4f1a\u9047\u5230\u56f0\u96be\u3002\u867d\u7136\u77e5\u8bc6\u56fe\u8c31\u53ef\u4ee5\u6355\u6349\u5b9e\u4f53\u95f4\u7684\u5173\u7cfb\u4ee5\u6539\u8fdb\u68c0\u7d22\uff0c\u4f46\u73b0\u6709\u7684\u56fe\u589e\u5f3aRAG\uff08GraphRAG\uff09\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u4e0d\u7a33\u5b9a\u4e14\u6210\u672c\u9ad8\u6602\u7684\u5173\u7cfb\u62bd\u53d6\u6765\u6784\u5efa\u56fe\u8c31\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u56fe\u8c31\u566a\u58f0\u5927\u3001\u5173\u7cfb\u9519\u8bef\uff0c\u4ece\u800c\u964d\u4f4e\u68c0\u7d22\u8d28\u91cf\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u5f00\u53d1\u4e00\u79cd\u66f4\u7a33\u5b9a\u3001\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684GraphRAG\u65b9\u6cd5\u3002", "method": "LinearRAG\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u56fe\u8c31\u6784\u5efa\u65b9\u6cd5\uff0c\u5373\u6784\u5efa\u4e00\u4e2a\u5173\u7cfb\u65e0\u5173\u7684\u5c42\u6b21\u56fe\uff0c\u79f0\u4e3aTri-Graph\u3002\u8be5\u65b9\u6cd5\u4ec5\u4f7f\u7528\u8f7b\u91cf\u7ea7\u7684\u5b9e\u4f53\u63d0\u53d6\u548c\u8bed\u4e49\u94fe\u63a5\uff0c\u907f\u514d\u4e86\u4e0d\u7a33\u5b9a\u7684\u5173\u7cfb\u5efa\u6a21\u3002\u8fd9\u79cd\u56fe\u8c31\u6784\u5efa\u65b9\u6cd5\u53ef\u4ee5\u968f\u8bed\u6599\u5e93\u5927\u5c0f\u7ebf\u6027\u6269\u5c55\uff0c\u5e76\u4e14\u4e0d\u589e\u52a0\u989d\u5916\u7684token\u6d88\u8017\u3002\u5728\u68c0\u7d22\u65b9\u9762\uff0cLinearRAG\u91c7\u7528\u4e24\u9636\u6bb5\u7b56\u7565\uff1a\u9996\u5148\u901a\u8fc7\u5c40\u90e8\u8bed\u4e49\u6865\u63a5\u6fc0\u6d3b\u76f8\u5173\u5b9e\u4f53\uff0c\u7136\u540e\u901a\u8fc7\u5168\u5c40\u91cd\u8981\u6027\u805a\u5408\u8fdb\u884c\u6587\u6863\u68c0\u7d22\u3002", "result": "\u5728\u56db\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cLinearRAG\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u57fa\u7ebf\u6a21\u578b\u3002\u5177\u4f53\u6027\u80fd\u63d0\u5347\u548c\u6307\u6807\u5bf9\u6bd4\u672a\u5728\u6458\u8981\u4e2d\u8be6\u7ec6\u8bf4\u660e\uff0c\u4f46\u5f3a\u8c03\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "conclusion": "LinearRAG\u901a\u8fc7\u6784\u5efa\u5173\u7cfb\u65e0\u5173\u7684Tri-Graph\u548c\u91c7\u7528\u4e24\u9636\u6bb5\u68c0\u7d22\u7b56\u7565\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709GraphRAG\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5b9e\u73b0\u4e86\u7a33\u5b9a\u3001\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u56fe\u8c31\u6784\u5efa\u548c\u7cbe\u786e\u7684\u6587\u6863\u68c0\u7d22\u3002\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u7684\u6027\u80fd\uff0c\u4e3a\u5904\u7406\u5927\u89c4\u6a21\u975e\u7ed3\u6784\u5316\u6570\u636e\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.22830", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.22830", "abs": "https://arxiv.org/abs/2510.22830", "authors": ["Haowei Hua", "Hong Jiao", "Xinyi Wang"], "title": "Exploration of Summarization by Generative Language Models for Automated Scoring of Long Essays", "comment": "19 pages, 5 Tables 7 Figures, Presentation at Artificial Intelligence\n  in Measurement and Education Conference (AIME-Con)", "summary": "BERT and its variants are extensively explored for automated scoring.\nHowever, a limit of 512 tokens for these encoder-based models showed the\ndeficiency in automated scoring of long essays. Thus, this research explores\ngenerative language models for automated scoring of long essays via\nsummarization and prompting. The results revealed great improvement of scoring\naccuracy with QWK increased from 0.822 to 0.8878 for the Learning Agency Lab\nAutomated Essay Scoring 2.0 dataset.", "AI": {"tldr": "BERT\u7b49\u6a21\u578b\u5728\u957f\u6587\u4e66\u81ea\u52a8\u8bc4\u5206\u65b9\u9762\u5b58\u5728512\u4e2a\u8bcd\u5143\u7684\u9650\u5236\uff0c\u672c\u7814\u7a76\u91c7\u7528\u751f\u6210\u5f0f\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u6587\u672c\u6458\u8981\u548c\u63d0\u793a\u6280\u672f\uff0c\u63d0\u9ad8\u4e86\u8bc4\u5206\u51c6\u786e\u7387\uff0cQWK\u4ece0.822\u63d0\u5347\u81f30.8878\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8eBERT\u7b49\u7f16\u7801\u5668\u6a21\u578b\u7684\u81ea\u52a8\u8bc4\u5206\u65b9\u6cd5\u5728\u5904\u7406\u957f\u7bc7\u8bba\u6587\u65f6\u5b58\u5728512\u4e2a\u8bcd\u5143\u7684\u9650\u5236\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u5728\u957f\u6587\u4e66\u8bc4\u5206\u65b9\u9762\u7684\u5e94\u7528\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u957f\u6587\u4e66\u7684\u81ea\u52a8\u8bc4\u5206\u65b9\u6cd5\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u672c\u7814\u7a76\u63a2\u7d22\u4f7f\u7528\u751f\u6210\u5f0f\u8bed\u8a00\u6a21\u578b\uff0c\u7ed3\u5408\u6587\u672c\u6458\u8981\u548c\u63d0\u793a\u6280\u672f\uff0c\u6765\u89e3\u51b3\u957f\u6587\u4e66\u81ea\u52a8\u8bc4\u5206\u7684\u9650\u5236\u3002\u5177\u4f53\u5b9e\u9a8c\u91c7\u7528\u4e86Learning Agency Lab Automated Essay Scoring 2.0\u6570\u636e\u96c6\u3002", "result": "\u901a\u8fc7\u4f7f\u7528\u751f\u6210\u5f0f\u8bed\u8a00\u6a21\u578b\uff0c\u8bc4\u5206\u51c6\u786e\u7387\u5f97\u5230\u663e\u8457\u63d0\u5347\uff0c\u5728Learning Agency Lab Automated Essay Scoring 2.0\u6570\u636e\u96c6\u4e0a\u7684QWK\u8bc4\u5206\u4ece0.822\u63d0\u9ad8\u52300.8878\u3002", "conclusion": "\u751f\u6210\u5f0f\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u6587\u672c\u6458\u8981\u548c\u63d0\u793a\u6280\u672f\uff0c\u80fd\u591f\u6709\u6548\u5730\u514b\u670dBERT\u7b49\u6a21\u578b\u5728\u957f\u6587\u4e66\u81ea\u52a8\u8bc4\u5206\u4e2d\u7684\u8bcd\u5143\u9650\u5236\uff0c\u663e\u8457\u63d0\u9ad8\u8bc4\u5206\u51c6\u786e\u6027\u3002\u672a\u6765\u7684\u7814\u7a76\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63a2\u7d22\u4e0d\u540c\u7684\u751f\u6210\u6a21\u578b\u548c\u63d0\u793a\u7b56\u7565\uff0c\u5e76\u5c1d\u8bd5\u5e94\u7528\u4e8e\u66f4\u591a\u6837\u5316\u7684\u957f\u6587\u4e66\u8bc4\u5206\u4efb\u52a1\u3002"}}
{"id": "2510.23169", "categories": ["cs.CL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.23169", "abs": "https://arxiv.org/abs/2510.23169", "authors": ["Marah Ghoummaid", "Vladimir Tchuiev", "Ofek Glick", "Michal Moshkovitz", "Dotan Di Castro"], "title": "MATCH: Task-Driven Code Evaluation through Contrastive Learning", "comment": null, "summary": "AI-based code generation is increasingly prevalent, with GitHub Copilot\nestimated to generate 46% of the code on GitHub. Accurately evaluating how well\ngenerated code aligns with developer intent remains a critical challenge.\nTraditional evaluation methods, such as unit tests, are often unscalable and\ncostly. Syntactic similarity metrics (e.g., BLEU, ROUGE) fail to capture code\nfunctionality, and metrics like CodeBERTScore require reference code, which is\nnot always available. To address the gap in reference-free evaluation, with few\nalternatives such as ICE-Score, this paper introduces MATCH, a novel\nreference-free metric. MATCH uses Contrastive Learning to generate meaningful\nembeddings for code and natural language task descriptions, enabling similarity\nscoring that reflects how well generated code implements the task. We show that\nMATCH achieves stronger correlations with functional correctness and human\npreference than existing metrics across multiple programming languages.", "AI": {"tldr": "GitHub Copilot\u7b49AI\u5de5\u5177\u751f\u6210\u7684\u4ee3\u7801\u5360\u6bd4\u8f83\u9ad8\uff0c\u4f46\u8bc4\u4f30\u5176\u662f\u5426\u7b26\u5408\u5f00\u53d1\u8005\u610f\u56fe\u4ecd\u662f\u6311\u6218\u3002\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\uff08\u5982\u5355\u5143\u6d4b\u8bd5\u3001BLEU\u3001ROUGE\u3001CodeBERTScore\uff09\u5b58\u5728\u53ef\u6269\u5c55\u6027\u5dee\u3001\u6210\u672c\u9ad8\u3001\u65e0\u6cd5\u6355\u6349\u4ee3\u7801\u529f\u80fd\u6216\u9700\u8981\u53c2\u8003\u4ee3\u7801\u7b49\u95ee\u9898\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMATCH\u7684\u65b0\u578b\u65e0\u53c2\u8003\u4ee3\u7801\u8bc4\u4f30\u6307\u6807\uff0c\u4f7f\u7528\u5bf9\u6bd4\u5b66\u4e60\u751f\u6210\u4ee3\u7801\u548c\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u63cf\u8ff0\u7684\u5d4c\u5165\uff0c\u4ece\u800c\u80fd\u591f\u8bc4\u4f30\u751f\u6210\u4ee3\u7801\u4e0e\u4efb\u52a1\u7684\u5951\u5408\u5ea6\u3002\u7814\u7a76\u8868\u660e\uff0cMATCH\u5728\u591a\u79cd\u7f16\u7a0b\u8bed\u8a00\u4e2d\uff0c\u4e0e\u529f\u80fd\u6b63\u786e\u6027\u548c\u4eba\u7c7b\u504f\u597d\u7684\u76f8\u5173\u6027\u5747\u4f18\u4e8e\u73b0\u6709\u6307\u6807\u3002", "motivation": "AI\u4ee3\u7801\u751f\u6210\u65e5\u76ca\u666e\u53ca\uff08\u5982GitHub Copilot\u4f30\u8ba1\u751f\u621046%\u7684\u4ee3\u7801\uff09\uff0c\u4f46\u51c6\u786e\u8bc4\u4f30\u751f\u6210\u4ee3\u7801\u662f\u5426\u7b26\u5408\u5f00\u53d1\u8005\u610f\u56fe\u9762\u4e34\u4e25\u5cfb\u6311\u6218\u3002\u4f20\u7edf\u7684\u5355\u5143\u6d4b\u8bd5\u65b9\u6cd5\u6210\u672c\u9ad8\u3001\u53ef\u6269\u5c55\u6027\u5dee\uff1bBLEU\u3001ROUGE\u7b49\u8bed\u6cd5\u76f8\u4f3c\u6027\u6307\u6807\u65e0\u6cd5\u8861\u91cf\u4ee3\u7801\u529f\u80fd\uff1bCodeBERTScore\u7b49\u6307\u6807\u5219\u9700\u8981\u53c2\u8003\u4ee3\u7801\uff0c\u5e76\u975e\u603b\u662f\u53ef\u7528\u3002\u56e0\u6b64\uff0c\u5728\u7f3a\u4e4f\u53c2\u8003\u4ee3\u7801\u7684\u60c5\u51b5\u4e0b\uff0c\u9700\u8981\u4e00\u79cd\u6709\u6548\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4ee5\u586b\u8865\u73b0\u6709\u8bc4\u4f30\u624b\u6bb5\u7684\u4e0d\u8db3\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMATCH\u7684\u65b0\u578b\u65e0\u53c2\u8003\u8bc4\u4f30\u6307\u6807\u3002MATCH\u5229\u7528\u5bf9\u6bd4\u5b66\u4e60\uff08Contrastive Learning\uff09\u6280\u672f\uff0c\u4e3a\u4ee3\u7801\u548c\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u63cf\u8ff0\u751f\u6210\u6709\u610f\u4e49\u7684\u5d4c\u5165\uff08embeddings\uff09\u3002\u901a\u8fc7\u8ba1\u7b97\u8fd9\u4e9b\u5d4c\u5165\u4e4b\u95f4\u7684\u76f8\u4f3c\u5ea6\uff0cMATCH\u80fd\u591f\u91cf\u5316\u751f\u6210\u4ee3\u7801\u5728\u591a\u5927\u7a0b\u5ea6\u4e0a\u5b9e\u73b0\u4e86\u7ed9\u5b9a\u7684\u4efb\u52a1\u63cf\u8ff0\u3002\u8fd9\u79cd\u65b9\u6cd5\u65e8\u5728\u63d0\u4f9b\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u65e0\u9700\u53c2\u8003\u4ee3\u7801\u7684\u4ee3\u7801\u8bc4\u4f30\u65b9\u6848\u3002", "result": "\u901a\u8fc7\u5728\u591a\u79cd\u7f16\u7a0b\u8bed\u8a00\u4e0a\u7684\u5b9e\u9a8c\uff0c\u7814\u7a76\u8868\u660eMATCH\u6307\u6807\u5728\u8bc4\u4f30\u751f\u6210\u4ee3\u7801\u7684\u529f\u80fd\u6b63\u786e\u6027\u548c\u4eba\u7c7b\u504f\u597d\u65b9\u9762\uff0c\u8868\u73b0\u51fa\u4e86\u6bd4\u73b0\u6709\u6307\u6807\uff08\u5305\u62ec\u4e00\u4e9b\u65e0\u53c2\u8003\u6307\u6807\u5982ICE-Score\uff09\u66f4\u5f3a\u7684\u76f8\u5173\u6027\u3002\u8fd9\u8bc1\u660e\u4e86MATCH\u5728\u8861\u91cfAI\u751f\u6210\u4ee3\u7801\u8d28\u91cf\u65b9\u9762\u7684\u6709\u6548\u6027\u548c\u4f18\u8d8a\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684MATCH\u6307\u6807\u4e3aAI\u751f\u6210\u4ee3\u7801\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u9896\u4e14\u6709\u6548\u7684\u65e0\u53c2\u8003\u8bc4\u4f30\u65b9\u6cd5\u3002MATCH\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u751f\u6210\u4ee3\u7801\u548c\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u7684\u5d4c\u5165\uff0c\u80fd\u591f\u66f4\u597d\u5730\u53cd\u6620\u4ee3\u7801\u7684\u529f\u80fd\u6027\u548c\u5f00\u53d1\u8005\u610f\u56fe\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u8bc4\u4f30\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002\u672a\u6765\u53ef\u5728\u6b64\u57fa\u7840\u4e0a\u8fdb\u4e00\u6b65\u63a2\u7d22\u548c\u4f18\u5316\uff0c\u4ee5\u9002\u5e94\u66f4\u5e7f\u6cdb\u7684\u4ee3\u7801\u751f\u6210\u548c\u8bc4\u4f30\u573a\u666f\u3002"}}
